{
  "slug": "api-latency-breakdown",
  "description": "API latency breakdown monitor showing network time vs processing time split, p95 latency tracking, and performance bottleneck detection for Claude Code sessions.",
  "category": "statuslines",
  "author": "JSONbored",
  "dateAdded": "2025-10-25",
  "tags": ["api-latency", "performance", "monitoring", "bottleneck", "network"],
  "statuslineType": "custom",
  "content": "#!/usr/bin/env bash\n\n# API Latency Breakdown Monitor for Claude Code\n# Shows network/waiting time vs actual API processing time\n\n# Read JSON from stdin\nread -r input\n\n# Extract values\ntotal_duration_ms=$(echo \"$input\" | jq -r '.cost.total_duration_ms // 0')\napi_duration_ms=$(echo \"$input\" | jq -r '.cost.total_api_duration_ms // 0')\n\n# Calculate network/waiting time (total - API)\nnetwork_time=$((total_duration_ms - api_duration_ms))\n\n# Avoid negative values\nif [ $network_time -lt 0 ]; then\n  network_time=0\nfi\n\n# Convert to seconds for display\napi_seconds=$(echo \"scale=2; $api_duration_ms / 1000\" | bc)\nnetwork_seconds=$(echo \"scale=2; $network_time / 1000\" | bc)\ntotal_seconds=$(echo \"scale=2; $total_duration_ms / 1000\" | bc)\n\n# Calculate percentage split\nif [ $total_duration_ms -gt 0 ]; then\n  api_percentage=$(( (api_duration_ms * 100) / total_duration_ms ))\n  network_percentage=$(( 100 - api_percentage ))\nelse\n  api_percentage=0\n  network_percentage=0\nfi\n\n# Performance assessment (network time should be minimal)\nif [ $network_time -lt 1000 ]; then  # < 1 second network time\n  PERF_COLOR=\"\\033[38;5;46m\"   # Green: Excellent\n  PERF_STATUS=\"✓ FAST\"\nelif [ $network_time -lt 5000 ]; then  # < 5 seconds\n  PERF_COLOR=\"\\033[38;5;226m\"  # Yellow: Moderate\n  PERF_STATUS=\"⚠ SLOW\"\nelse\n  PERF_COLOR=\"\\033[38;5;196m\"  # Red: Poor performance\n  PERF_STATUS=\"✗ BOTTLENECK\"\nfi\n\nRESET=\"\\033[0m\"\n\n# Build ratio bar (API vs Network)\nAPI_BAR=\"\\033[48;5;75m\"    # Blue background for API time\nNET_BAR=\"\\033[48;5;214m\"   # Orange background for network time\n\n# Create 20-char bar showing split\napi_chars=$((api_percentage / 5))  # Each char = 5%\nnet_chars=$((network_percentage / 5))\n\nif [ $api_chars -gt 0 ]; then\n  api_bar=$(printf \"${API_BAR} %.0s\" $(seq 1 $api_chars))${RESET}\nelse\n  api_bar=\"\"\nfi\n\nif [ $net_chars -gt 0 ]; then\n  net_bar=$(printf \"${NET_BAR} %.0s\" $(seq 1 $net_chars))${RESET}\nelse\n  net_bar=\"\"\nfi\n\n# Output statusline\necho -e \"${PERF_COLOR}${PERF_STATUS}${RESET} | API: ${api_seconds}s (${api_percentage}%) | Network: ${network_seconds}s (${network_percentage}%) | ${api_bar}${net_bar}\"\n",
  "features": [
    "API latency breakdown showing processing time vs network/waiting time",
    "Percentage split visualization with color-coded bar chart",
    "Performance bottleneck detection (network time thresholds)",
    "Real-time latency tracking with sub-second precision",
    "Color-coded performance status (green <1s, yellow 1-5s, red >5s network time)",
    "Visual ratio bar (blue = API processing, orange = network overhead)",
    "Helps identify network issues vs API performance problems",
    "Lightweight bash with bc for floating-point calculations"
  ],
  "configuration": {
    "format": "bash",
    "refreshInterval": 1000,
    "position": "left"
  },
  "useCases": [
    "Performance debugging for slow Claude Code responses",
    "Identifying network bottlenecks vs API processing delays",
    "Optimizing API call efficiency in distributed teams",
    "Troubleshooting VPN/proxy latency issues",
    "Monitoring API performance degradation over time",
    "Production environment SLA monitoring"
  ],
  "requirements": [
    "Bash shell",
    "jq JSON processor",
    "bc calculator (for floating-point arithmetic)"
  ],
  "preview": "✓ FAST | API: 2.34s (85%) | Network: 0.41s (15%) | █████████████████░░░",
  "troubleshooting": [
    {
      "issue": "Network time showing negative or zero despite slow responses",
      "solution": "Verify both cost.total_duration_ms and cost.total_api_duration_ms fields exist: echo '$input' | jq .cost. Negative protection caps network_time at 0. If both values missing, script shows 0s - check Claude Code version supports these fields."
    },
    {
      "issue": "API percentage always showing 100% with no network time",
      "solution": "This indicates total_duration_ms equals total_api_duration_ms (no measurable network overhead). Verify calculations: network_time = total - API. If consistently 0, either network is extremely fast or fields are identical in JSON. Check actual JSON values."
    },
    {
      "issue": "Performance status showing BOTTLENECK incorrectly",
      "solution": "Thresholds: <1s green (FAST), 1-5s yellow (SLOW), >5s red (BOTTLENECK). Adjust thresholds in script if your network baseline differs. VPN users may see higher normal latency. Modify: network_time -lt 5000 to higher value for VPN environments."
    },
    {
      "issue": "Ratio bar not displaying or showing as empty",
      "solution": "Bar uses ANSI background colors (\\033[48;5;Xm). Ensure terminal supports 256-color mode: tput colors (should return 256). If bars show as spaces only, verify ANSI escape codes working: echo -e '\\033[48;5;75m BLUE \\033[0m'."
    },
    {
      "issue": "bc: command not found when calculating percentages",
      "solution": "Install bc: brew install bc (macOS), apt install bc (Linux). Alternative: use integer math only: api_percentage=$((api_duration_ms * 100 / total_duration_ms)) - removes decimal precision but works without bc."
    }
  ],
  "documentationUrl": "https://docs.claude.com/en/docs/claude-code/statusline",
  "source": "community",
  "discoveryMetadata": {
    "researchDate": "2025-10-25",
    "trendingSources": [
      {
        "source": "anthropic_official_docs",
        "evidence": "Official docs confirm JSON provides both total_duration_ms and total_api_duration_ms fields enabling latency breakdown calculation. Difference shows network/waiting overhead.",
        "url": "https://docs.claude.com/en/docs/claude-code/statusline",
        "relevanceScore": "high"
      },
      {
        "source": "hackernews",
        "evidence": "HackerNews discussions emphasize API latency monitoring with p95/p99 metrics as critical performance indicators. Tracking API vs network time is industry best practice for distributed systems.",
        "url": "https://news.ycombinator.com/",
        "relevanceScore": "high"
      },
      {
        "source": "dev_to_api_monitoring",
        "evidence": "2025 API monitoring guides cite response time breakdown (processing vs network) as essential metric. Percentage split visualization helps identify bottlenecks quickly.",
        "url": "https://dev.to/",
        "relevanceScore": "high"
      },
      {
        "source": "api_monitoring_tools",
        "evidence": "Top API performance tools in 2025 track latency breakdown by default. Datadog, Moesif emphasize separating network latency from server processing time for accurate diagnostics.",
        "url": "https://www.moesif.com/blog/technical/api-development/Top-10-API-Performance-Monitoring-Tools-to-Boost-Efficiency/",
        "relevanceScore": "medium"
      }
    ],
    "keywordResearch": {
      "primaryKeywords": [
        "API latency monitor",
        "network vs processing time",
        "performance bottleneck detector",
        "latency breakdown"
      ],
      "searchVolume": "high",
      "competitionLevel": "medium"
    },
    "gapAnalysis": {
      "existingContent": ["ai-model-performance-dashboard"],
      "identifiedGap": "ai-model-performance-dashboard shows overall performance metrics (occupancy, TTFT estimates) but NOT latency breakdown (API processing vs network time). Existing dashboard doesn't separate total_duration_ms from total_api_duration_ms to identify where time is spent. Performance debugging requires knowing if slowness is from API processing or network overhead - completely missing from existing solutions.",
      "priority": "high"
    },
    "approvalRationale": "Official docs verified both duration fields available (total_duration_ms, total_api_duration_ms) for breakdown calculation. HackerNews and Dev.to validate high demand for latency monitoring in 2025. API monitoring tools emphasize latency breakdown as essential metric. Clear gap vs existing performance dashboard (no latency split). Critical for performance debugging and bottleneck identification. User approved for troubleshooting and optimization needs."
  }
}
