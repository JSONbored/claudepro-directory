{
  "slug": "error-rate-monitor",
  "description": "Tracks error patterns and alerts when error rates spike",
  "category": "hooks",
  "author": "JSONbored",
  "dateAdded": "2025-09-19",
  "tags": [
    "errors",
    "monitoring",
    "notification",
    "debugging",
    "alerts"
  ],
  "hookType": "Notification",
  "features": [
    "Real-time error pattern detection in log files",
    "Configurable error rate thresholds and alerting",
    "Multi-log file monitoring (*.log, logs/*, custom paths)",
    "Error severity classification (fatal, error, warning)",
    "Recent error sample display for quick debugging",
    "Time-based error rate calculations",
    "Framework-specific error pattern recognition",
    "Silent operation with threshold-based notifications"
  ],
  "configuration": {
    "hookConfig": {
      "hooks": {
        "notification": {
          "script": "./.claude/hooks/error-rate-monitor.sh"
        }
      }
    },
    "scriptContent": "#!/usr/bin/env bash\n\necho \"ðŸ” Monitoring error rates across log files...\" >&2\n\n# Configurable thresholds (can be overridden by environment variables)\nERROR_THRESHOLD_PER_FILE=${ERROR_THRESHOLD_PER_FILE:-5}\nTOTAL_ERROR_THRESHOLD=${TOTAL_ERROR_THRESHOLD:-10}\nLOG_LINES_TO_CHECK=${LOG_LINES_TO_CHECK:-100}\nMAX_SAMPLE_ERRORS=${MAX_SAMPLE_ERRORS:-3}\n\n# Initialize counters\nTOTAL_ERRORS=0\nFILES_WITH_ERRORS=0\nCRITICAL_FILES=()\nERROR_SAMPLES=()\n\n# Define error patterns with severity levels\nFATAL_PATTERNS=(\"fatal\" \"critical\" \"panic\" \"abort\" \"segfault\")\nERROR_PATTERNS=(\"error\" \"exception\" \"failed\" \"failure\" \"timeout\")\nWARNING_PATTERNS=(\"warning\" \"warn\" \"deprecated\" \"notice\")\n\n# Function to count errors by severity\ncount_errors_by_severity() {\n  local log_file=\"$1\"\n  local fatal_count=0\n  local error_count=0\n  local warning_count=0\n  \n  if [ ! -f \"$log_file\" ]; then\n    return\n  fi\n  \n  # Check last N lines of the log file\n  local recent_logs=$(tail -\"$LOG_LINES_TO_CHECK\" \"$log_file\" 2>/dev/null || echo \"\")\n  \n  if [ -z \"$recent_logs\" ]; then\n    return\n  fi\n  \n  # Count fatal errors\n  for pattern in \"${FATAL_PATTERNS[@]}\"; do\n    fatal_count=$((fatal_count + $(echo \"$recent_logs\" | grep -icE \"\\\\b$pattern\\\\b\" || echo \"0\")))\n  done\n  \n  # Count errors (excluding fatals already counted)\n  for pattern in \"${ERROR_PATTERNS[@]}\"; do\n    error_count=$((error_count + $(echo \"$recent_logs\" | grep -icE \"\\\\b$pattern\\\\b\" || echo \"0\")))\n  done\n  \n  # Count warnings\n  for pattern in \"${WARNING_PATTERNS[@]}\"; do\n    warning_count=$((warning_count + $(echo \"$recent_logs\" | grep -icE \"\\\\b$pattern\\\\b\" || echo \"0\")))\n  done\n  \n  echo \"$fatal_count $error_count $warning_count\"\n}\n\n# Function to extract error samples\nextract_error_samples() {\n  local log_file=\"$1\"\n  local sample_count=\"$2\"\n  \n  if [ ! -f \"$log_file\" ]; then\n    return\n  fi\n  \n  # Get recent error lines with timestamps if available\n  tail -\"$LOG_LINES_TO_CHECK\" \"$log_file\" 2>/dev/null | \\\n    grep -iE '(fatal|critical|error|exception|failed)' | \\\n    head -\"$sample_count\" | \\\n    while IFS= read -r line; do\n      # Truncate very long lines\n      if [ ${#line} -gt 120 ]; then\n        echo \"${line:0:120}...\"\n      else\n        echo \"$line\"\n      fi\n    done\n}\n\n# Function to check log files in a directory\ncheck_log_directory() {\n  local dir=\"$1\"\n  local pattern=\"$2\"\n  \n  if [ ! -d \"$dir\" ]; then\n    return\n  fi\n  \n  find \"$dir\" -name \"$pattern\" -type f 2>/dev/null | while read -r log_file; do\n    echo \"$log_file\"\n  done\n}\n\n# Collect all log files to check\nLOG_FILES=()\n\n# Standard log locations\nfor pattern in \"*.log\" \"*.out\" \"*.err\"; do\n  while IFS= read -r -d '' file; do\n    LOG_FILES+=(\"$file\")\n  done < <(find . -maxdepth 1 -name \"$pattern\" -type f -print0 2>/dev/null)\ndone\n\n# Common log directories\nLOG_DIRS=(\"logs\" \"log\" \"var/log\" \".logs\" \"tmp/logs\")\nfor log_dir in \"${LOG_DIRS[@]}\"; do\n  if [ -d \"$log_dir\" ]; then\n    while IFS= read -r -d '' file; do\n      LOG_FILES+=(\"$file\")\n    done < <(find \"$log_dir\" -name \"*.log\" -o -name \"*.out\" -o -name \"*.err\" -type f -print0 2>/dev/null)\n  fi\ndone\n\n# Framework-specific log locations\nif [ -f \"package.json\" ]; then\n  # Node.js specific logs\n  for pattern in \"npm-debug.log\" \"yarn-error.log\" \"pnpm-debug.log\"; do\n    [ -f \"$pattern\" ] && LOG_FILES+=(\"$pattern\")\n  done\n  \n  # Next.js logs\n  [ -d \".next\" ] && find .next -name \"*.log\" -type f 2>/dev/null | while read -r file; do\n    LOG_FILES+=(\"$file\")\n  done\nfi\n\n# Python specific logs\nif [ -f \"requirements.txt\" ] || [ -f \"pyproject.toml\" ]; then\n  for pattern in \"django.log\" \"flask.log\" \"celery.log\" \"pytest.log\"; do\n    [ -f \"$pattern\" ] && LOG_FILES+=(\"$pattern\")\n  done\nfi\n\n# Docker logs if Docker is available\nif command -v docker &> /dev/null && docker info &> /dev/null 2>&1; then\n  # Check for recent container logs with errors\n  CONTAINERS=$(docker ps --format \"{{.Names}}\" 2>/dev/null | head -5)\n  for container in $CONTAINERS; do\n    if [ -n \"$container\" ]; then\n      ERROR_COUNT=$(docker logs \"$container\" --since=10m 2>&1 | grep -icE '(fatal|critical|error|exception)' || echo \"0\")\n      if [ \"$ERROR_COUNT\" -gt 0 ]; then\n        echo \"ðŸ³ Container '$container' has $ERROR_COUNT recent errors\" >&2\n        TOTAL_ERRORS=$((TOTAL_ERRORS + ERROR_COUNT))\n        \n        # Get error samples from container logs\n        CONTAINER_ERRORS=$(docker logs \"$container\" --since=10m 2>&1 | grep -iE '(fatal|critical|error|exception)' | head -2)\n        if [ -n \"$CONTAINER_ERRORS\" ]; then\n          echo \"ðŸ“ Sample from $container:\" >&2\n          echo \"$CONTAINER_ERRORS\" | head -1 >&2\n        fi\n      fi\n    fi\n  done\nfi\n\n# Remove duplicates from LOG_FILES array\nreadarray -t UNIQUE_LOG_FILES < <(printf '%s\\n' \"${LOG_FILES[@]}\" | sort -u)\n\necho \"ðŸ“Š Checking ${#UNIQUE_LOG_FILES[@]} log files for error patterns...\" >&2\n\n# Check each log file\nfor log_file in \"${UNIQUE_LOG_FILES[@]}\"; do\n  if [ ! -f \"$log_file\" ]; then\n    continue\n  fi\n  \n  # Get error counts by severity\n  read -r fatal_count error_count warning_count <<< \"$(count_errors_by_severity \"$log_file\")\"\n  \n  file_total_errors=$((fatal_count + error_count))\n  TOTAL_ERRORS=$((TOTAL_ERRORS + file_total_errors))\n  \n  if [ \"$file_total_errors\" -gt 0 ]; then\n    FILES_WITH_ERRORS=$((FILES_WITH_ERRORS + 1))\n    \n    log_basename=$(basename \"$log_file\")\n    \n    # Report file-level errors\n    if [ \"$fatal_count\" -gt 0 ]; then\n      echo \"ðŸš¨ CRITICAL: $log_basename has $fatal_count fatal errors\" >&2\n      CRITICAL_FILES+=(\"$log_file\")\n    fi\n    \n    if [ \"$file_total_errors\" -gt \"$ERROR_THRESHOLD_PER_FILE\" ]; then\n      echo \"âš ï¸ ERROR SPIKE: $log_basename has $file_total_errors errors (fatal: $fatal_count, error: $error_count)\" >&2\n      \n      # Extract error samples\n      echo \"ðŸ“ Recent error samples from $log_basename:\" >&2\n      extract_error_samples \"$log_file\" \"$MAX_SAMPLE_ERRORS\" | while IFS= read -r sample; do\n        echo \"  â†’ $sample\" >&2\n      done\n    elif [ \"$file_total_errors\" -gt 0 ]; then\n      echo \"â„¹ï¸ $log_basename: $file_total_errors errors detected\" >&2\n    fi\n    \n    if [ \"$warning_count\" -gt 0 ]; then\n      echo \"âš ï¸ $log_basename: $warning_count warnings\" >&2\n    fi\n  fi\ndone\n\n# Overall error rate analysis\necho \"\" >&2\necho \"ðŸ“‹ Error Rate Summary:\" >&2\necho \"  ðŸ“ Files checked: ${#UNIQUE_LOG_FILES[@]}\" >&2\necho \"  ðŸ“„ Files with errors: $FILES_WITH_ERRORS\" >&2\necho \"  ðŸ”¢ Total errors: $TOTAL_ERRORS\" >&2\necho \"  ðŸš¨ Critical files: ${#CRITICAL_FILES[@]}\" >&2\n\n# Alert on high error rates\nif [ \"$TOTAL_ERRORS\" -gt \"$TOTAL_ERROR_THRESHOLD\" ]; then\n  echo \"\" >&2\n  echo \"ðŸš¨ HIGH ERROR RATE DETECTED!\" >&2\n  echo \"âš ï¸ Total errors ($TOTAL_ERRORS) exceed threshold ($TOTAL_ERROR_THRESHOLD)\" >&2\n  \n  if [ ${#CRITICAL_FILES[@]} -gt 0 ]; then\n    echo \"ðŸ”¥ Critical files requiring immediate attention:\" >&2\n    for critical_file in \"${CRITICAL_FILES[@]}\"; do\n      echo \"  â†’ $(basename \"$critical_file\")\" >&2\n    done\n  fi\n  \nelif [ \"$TOTAL_ERRORS\" -gt 0 ]; then\n  echo \"â„¹ï¸ Errors detected but within acceptable threshold\" >&2\nelse\n  echo \"âœ… No errors detected in monitored log files\" >&2\nfi\n\n# Performance recommendations\nif [ ${#UNIQUE_LOG_FILES[@]} -gt 20 ]; then\n  echo \"\" >&2\n  echo \"ðŸ’¡ Performance tip: Consider log rotation or filtering for faster monitoring\" >&2\nfi\n\necho \"\" >&2\necho \"ðŸ”§ Monitoring Configuration:\" >&2\necho \"  â€¢ Error threshold per file: $ERROR_THRESHOLD_PER_FILE\" >&2\necho \"  â€¢ Total error threshold: $TOTAL_ERROR_THRESHOLD\" >&2\necho \"  â€¢ Lines checked per file: $LOG_LINES_TO_CHECK\" >&2\necho \"\" >&2\necho \"ðŸ’¡ Customize thresholds with environment variables:\" >&2\necho \"  export ERROR_THRESHOLD_PER_FILE=10\" >&2\necho \"  export TOTAL_ERROR_THRESHOLD=25\" >&2\n\nexit 0"
  },
  "useCases": [
    "Real-time error monitoring during development",
    "Automated error rate alerting for CI/CD pipelines",
    "Multi-service application error tracking",
    "Docker container log monitoring",
    "Framework-specific error pattern detection"
  ],
  "source": "community"
}
