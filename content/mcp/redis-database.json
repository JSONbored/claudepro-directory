{
  "title": "Redis Database MCP",
  "description": "High-performance Redis integration for caching, session management, pub/sub messaging, and real-time data operations",
  "category": "development",
  "author": "claudepro",
  "dateAdded": "2025-09-16",
  "tags": ["redis", "cache", "database", "nosql", "messaging", "real-time"],
  "content": "The Redis Database MCP Server provides comprehensive integration with Redis, the in-memory data structure store, enabling high-performance caching, real-time messaging, and advanced data operations.\n\n## Core Capabilities\n\n### Data Structures & Operations\n- **Strings**: Simple key-value operations, atomic counters\n- **Hashes**: Object storage, field-level operations\n- **Lists**: Queues, stacks, timeline data\n- **Sets**: Unique collections, set operations\n- **Sorted Sets**: Leaderboards, rankings, time-series\n- **Streams**: Event sourcing, message queues\n- **Bitmaps**: Efficient boolean operations\n- **HyperLogLog**: Cardinality estimation\n\n### Advanced Features\n- **Pub/Sub Messaging**: Real-time communication channels\n- **Lua Scripting**: Atomic multi-operation scripts\n- **Transactions**: MULTI/EXEC command batching\n- **Pipelining**: Bulk command execution\n- **Cluster Support**: Distributed Redis deployments\n- **Streams**: Advanced message queuing\n\n### Monitoring & Management\n- Real-time performance metrics\n- Memory usage analysis\n- Slow query monitoring\n- Connection pool management\n- Key expiration tracking\n\n## Installation\n\n```bash\nnpm install @claudepro/mcp-redis\n```\n\n## Configuration\n\n```json\n{\n  \"mcpServers\": {\n    \"redis\": {\n      \"command\": \"npx\",\n      \"args\": [\"@claudepro/mcp-redis\"],\n      \"env\": {\n        \"REDIS_URL\": \"redis://localhost:6379\",\n        \"REDIS_PASSWORD\": \"your-password\",\n        \"REDIS_DB\": \"0\",\n        \"REDIS_MAX_RETRIES\": \"3\",\n        \"REDIS_RETRY_DELAY\": \"1000\"\n      }\n    }\n  }\n}\n```\n\n## Connection Configurations\n\n### Local Redis\n```json\n{\n  \"env\": {\n    \"REDIS_URL\": \"redis://localhost:6379\",\n    \"REDIS_DB\": \"0\"\n  }\n}\n```\n\n### Redis Cloud/AWS ElastiCache\n```json\n{\n  \"env\": {\n    \"REDIS_URL\": \"rediss://your-cluster.cache.amazonaws.com:6380\",\n    \"REDIS_PASSWORD\": \"your-auth-token\",\n    \"REDIS_TLS\": \"true\"\n  }\n}\n```\n\n### Redis Cluster\n```json\n{\n  \"env\": {\n    \"REDIS_CLUSTER_NODES\": \"redis-node1:7000,redis-node2:7000,redis-node3:7000\",\n    \"REDIS_CLUSTER_PASSWORD\": \"cluster-password\"\n  }\n}\n```\n\n### Connection Pool Settings\n```json\n{\n  \"env\": {\n    \"REDIS_URL\": \"redis://localhost:6379\",\n    \"REDIS_POOL_MIN\": \"5\",\n    \"REDIS_POOL_MAX\": \"50\",\n    \"REDIS_CONNECT_TIMEOUT\": \"10000\",\n    \"REDIS_COMMAND_TIMEOUT\": \"5000\"\n  }\n}\n```\n\n## Usage Examples\n\n### Basic Key-Value Operations\n```javascript\n// String operations\nconst setResult = await redis.set('user:1000:name', 'John Doe');\nconst getName = await redis.get('user:1000:name');\n\n// Set with expiration (TTL)\nconst setWithTTL = await redis.setex('session:abc123', 3600, JSON.stringify({\n  userId: 1000,\n  loginTime: Date.now(),\n  permissions: ['read', 'write']\n}));\n\n// Atomic operations\nconst increment = await redis.incr('page:views:homepage');\nconst decrement = await redis.decr('inventory:item:123');\n\n// Multiple operations\nconst multiGet = await redis.mget(['user:1000:name', 'user:1000:email', 'user:1000:status']);\nconst multiSet = await redis.mset({\n  'user:1001:name': 'Jane Smith',\n  'user:1001:email': 'jane@example.com',\n  'user:1001:status': 'active'\n});\n```\n\n### Hash Operations (Object Storage)\n```javascript\n// Store user object as hash\nconst userHash = await redis.hset('user:1000', {\n  name: 'John Doe',\n  email: 'john@example.com',\n  age: 30,\n  department: 'Engineering',\n  lastLogin: Date.now()\n});\n\n// Get specific fields\nconst userEmail = await redis.hget('user:1000', 'email');\nconst userInfo = await redis.hmget('user:1000', ['name', 'department', 'lastLogin']);\n\n// Get all fields\nconst fullUser = await redis.hgetall('user:1000');\n\n// Increment numeric field\nconst loginCount = await redis.hincrby('user:1000', 'loginCount', 1);\n\n// Check field existence\nconst hasEmail = await redis.hexists('user:1000', 'email');\n\n// Get all field names\nconst userFields = await redis.hkeys('user:1000');\n```\n\n### List Operations (Queues & Stacks)\n```javascript\n// Task queue implementation\nconst addTask = await redis.lpush('task:queue', JSON.stringify({\n  id: 'task-123',\n  type: 'send_email',\n  payload: {\n    to: 'user@example.com',\n    subject: 'Welcome!',\n    template: 'welcome'\n  },\n  createdAt: Date.now()\n}));\n\n// Process tasks (blocking pop)\nconst processTask = async () => {\n  const task = await redis.brpop('task:queue', 10); // 10 second timeout\n  if (task) {\n    const [queue, taskData] = task;\n    const taskObj = JSON.parse(taskData);\n    console.log('Processing task:', taskObj.id);\n    // Process the task...\n  }\n};\n\n// Activity timeline\nconst addActivity = await redis.lpush('user:1000:activity', JSON.stringify({\n  action: 'login',\n  timestamp: Date.now(),\n  ip: '192.168.1.100',\n  userAgent: 'Mozilla/5.0...'\n}));\n\n// Get recent activities (last 10)\nconst recentActivities = await redis.lrange('user:1000:activity', 0, 9);\n\n// Trim old activities (keep last 100)\nconst trimActivities = await redis.ltrim('user:1000:activity', 0, 99);\n```\n\n### Set Operations (Unique Collections)\n```javascript\n// Tags system\nconst addTags = await redis.sadd('article:123:tags', 'javascript', 'nodejs', 'redis', 'tutorial');\nconst getAllTags = await redis.smembers('article:123:tags');\nconst hasTag = await redis.sismember('article:123:tags', 'redis');\n\n// User interests\nconst userInterests = await redis.sadd('user:1000:interests', 'programming', 'gaming', 'photography');\n\n// Find common interests between users\nconst commonInterests = await redis.sinter('user:1000:interests', 'user:1001:interests');\n\n// Get all interests (union)\nconst allInterests = await redis.sunion('user:1000:interests', 'user:1001:interests');\n\n// Random tag selection\nconst randomTag = await redis.srandmember('article:123:tags');\nconst randomTags = await redis.srandmember('article:123:tags', 3);\n```\n\n### Sorted Sets (Rankings & Leaderboards)\n```javascript\n// Game leaderboard\nconst updateScore = await redis.zadd('game:leaderboard', {\n  'player:john': 15420,\n  'player:jane': 18750,\n  'player:bob': 12340,\n  'player:alice': 19850\n});\n\n// Get top players\nconst topPlayers = await redis.zrevrange('game:leaderboard', 0, 4, 'WITHSCORES');\n\n// Get player rank\nconst johnRank = await redis.zrevrank('game:leaderboard', 'player:john');\nconst johnScore = await redis.zscore('game:leaderboard', 'player:john');\n\n// Get players by score range\nconst highScorers = await redis.zrangebyscore('game:leaderboard', 15000, '+inf', 'WITHSCORES');\n\n// Time-based data (using timestamps as scores)\nconst addEvent = await redis.zadd('user:1000:events', {\n  'login': Date.now() - 3600000,  // 1 hour ago\n  'purchase': Date.now() - 1800000, // 30 minutes ago\n  'logout': Date.now() - 600000    // 10 minutes ago\n});\n\n// Get events in time range\nconst recentEvents = await redis.zrangebyscore(\n  'user:1000:events',\n  Date.now() - 3600000, // Last hour\n  Date.now(),\n  'WITHSCORES'\n);\n```\n\n### Pub/Sub Messaging\n```javascript\n// Publisher\nconst publishMessage = async (channel, message) => {\n  const result = await redis.publish(channel, JSON.stringify({\n    type: 'user_action',\n    userId: 1000,\n    action: 'purchase',\n    productId: 'prod-123',\n    timestamp: Date.now(),\n    metadata: {\n      amount: 99.99,\n      currency: 'USD'\n    }\n  }));\n  \n  console.log(`Message sent to ${result} subscribers`);\n};\n\n// Subscriber\nconst subscriber = redis.duplicate();\n\nsubscriber.on('message', (channel, message) => {\n  const data = JSON.parse(message);\n  console.log(`Received on ${channel}:`, data);\n  \n  // Process the message based on type\n  switch (data.type) {\n    case 'user_action':\n      handleUserAction(data);\n      break;\n    case 'system_alert':\n      handleSystemAlert(data);\n      break;\n  }\n});\n\nsubscriber.on('subscribe', (channel, count) => {\n  console.log(`Subscribed to ${channel}. Total subscriptions: ${count}`);\n});\n\n// Subscribe to channels\nconst subscribe = await subscriber.subscribe('user:events', 'system:alerts', 'notifications');\n\n// Pattern subscription\nconst patternSubscribe = await subscriber.psubscribe('user:*:events', 'system:*');\n```\n\n### Lua Scripting (Atomic Operations)\n```javascript\n// Rate limiting script\nconst rateLimitScript = `\n  local key = KEYS[1]\n  local window = tonumber(ARGV[1])\n  local limit = tonumber(ARGV[2])\n  local current_time = tonumber(ARGV[3])\n  \n  local current = redis.call('GET', key)\n  if current == false then\n    redis.call('SETEX', key, window, 1)\n    return {1, limit - 1}\n  end\n  \n  current = tonumber(current)\n  if current < limit then\n    local new_val = redis.call('INCR', key)\n    local ttl = redis.call('TTL', key)\n    return {new_val, limit - new_val}\n  else\n    local ttl = redis.call('TTL', key)\n    return {current, 0, ttl}\n  end\n`;\n\n// Execute rate limit check\nconst checkRateLimit = async (userId, windowSeconds = 60, maxRequests = 100) => {\n  const result = await redis.eval(\n    rateLimitScript,\n    1,\n    `rate_limit:${userId}`,\n    windowSeconds,\n    maxRequests,\n    Math.floor(Date.now() / 1000)\n  );\n  \n  return {\n    currentRequests: result[0],\n    remainingRequests: result[1],\n    resetTime: result[2] || windowSeconds\n  };\n};\n\n// Distributed lock script\nconst acquireLockScript = `\n  local key = KEYS[1]\n  local value = ARGV[1]\n  local ttl = tonumber(ARGV[2])\n  \n  local current = redis.call('GET', key)\n  if current == false then\n    redis.call('SETEX', key, ttl, value)\n    return 1\n  elseif current == value then\n    redis.call('EXPIRE', key, ttl)\n    return 1\n  else\n    return 0\n  end\n`;\n\nconst acquireLock = async (lockName, identifier, ttlSeconds = 30) => {\n  const result = await redis.eval(\n    acquireLockScript,\n    1,\n    `lock:${lockName}`,\n    identifier,\n    ttlSeconds\n  );\n  \n  return result === 1;\n};\n```\n\n### Redis Streams (Advanced Messaging)\n```javascript\n// Add events to stream\nconst addToStream = await redis.xadd(\n  'events:user_actions',\n  '*', // Auto-generate ID\n  'user_id', '1000',\n  'action', 'purchase',\n  'product_id', 'prod-123',\n  'amount', '99.99',\n  'timestamp', Date.now()\n);\n\n// Read from stream\nconst readStream = await redis.xread(\n  'COUNT', 10,\n  'STREAMS', 'events:user_actions', '0-0' // From beginning\n);\n\n// Consumer groups\nconst createGroup = await redis.xgroup(\n  'CREATE', 'events:user_actions', 'analytics_group', '0', 'MKSTREAM'\n);\n\n// Read as consumer\nconst readAsConsumer = await redis.xreadgroup(\n  'GROUP', 'analytics_group', 'consumer1',\n  'COUNT', 5,\n  'STREAMS', 'events:user_actions', '>'\n);\n\n// Acknowledge processed messages\nconst ackMessages = await redis.xack(\n  'events:user_actions',\n  'analytics_group',\n  '1642784400000-0', '1642784401000-0'\n);\n```\n\n### Caching Patterns\n```javascript\n// Cache-aside pattern\nconst getUserWithCache = async (userId) => {\n  const cacheKey = `user:${userId}`;\n  \n  // Try cache first\n  let user = await redis.get(cacheKey);\n  if (user) {\n    return JSON.parse(user);\n  }\n  \n  // Cache miss - fetch from database\n  user = await database.getUser(userId);\n  if (user) {\n    // Cache for 1 hour\n    await redis.setex(cacheKey, 3600, JSON.stringify(user));\n  }\n  \n  return user;\n};\n\n// Write-through cache\nconst updateUserWithCache = async (userId, userData) => {\n  const cacheKey = `user:${userId}`;\n  \n  // Update database\n  const updatedUser = await database.updateUser(userId, userData);\n  \n  // Update cache\n  await redis.setex(cacheKey, 3600, JSON.stringify(updatedUser));\n  \n  return updatedUser;\n};\n\n// Cache invalidation\nconst invalidateUserCache = async (userId) => {\n  await redis.del(`user:${userId}`);\n  // Also invalidate related caches\n  await redis.del(`user:${userId}:permissions`, `user:${userId}:preferences`);\n};\n```\n\n## Performance Optimization\n\n### Connection Pooling\n```javascript\n// Configure connection pool\nconst redisConfig = {\n  host: 'localhost',\n  port: 6379,\n  maxRetriesPerRequest: 3,\n  retryDelayOnFailover: 100,\n  enableReadyCheck: false,\n  maxLoadingTimeout: 10000,\n  lazyConnect: true,\n  family: 4,\n  keepAlive: true,\n  // Connection pool settings\n  poolSize: 20,\n  autoResubscribe: true,\n  autoResendUnfulfilledCommands: true\n};\n```\n\n### Pipeline Operations\n```javascript\n// Batch multiple commands\nconst pipeline = redis.pipeline();\n\n// Add commands to pipeline\npipeline.set('key1', 'value1');\npipeline.set('key2', 'value2');\npipeline.incr('counter');\npipeline.hset('user:1000', 'lastSeen', Date.now());\npipeline.expire('session:abc', 3600);\n\n// Execute all commands at once\nconst results = await pipeline.exec();\nresults.forEach((result, index) => {\n  const [error, value] = result;\n  if (error) {\n    console.error(`Command ${index} failed:`, error);\n  } else {\n    console.log(`Command ${index} result:`, value);\n  }\n});\n```\n\n### Memory Optimization\n```javascript\n// Memory-efficient operations\nconst memoryInfo = await redis.memory('usage', 'user:1000');\nconst memoryStats = await redis.memory('stats');\n\n// Use appropriate data types\n// For small sets, consider using lists\n// For boolean flags, use bitmaps\n// For counters, use strings with INCR\n\n// Bitmap for user flags\nconst setUserFlag = await redis.setbit('user:flags:1000', 0, 1); // Email verified\nconst getUserFlag = await redis.getbit('user:flags:1000', 0);\n\n// HyperLogLog for unique counts\nconst addUniqueVisitor = await redis.pfadd('unique:visitors:2025-09', 'user:1000', 'user:1001');\nconst getUniqueCount = await redis.pfcount('unique:visitors:2025-09');\n```\n\n## Monitoring & Debugging\n\n### Performance Monitoring\n```javascript\n// Get Redis info\nconst serverInfo = await redis.info('server');\nconst memoryInfo = await redis.info('memory');\nconst statsInfo = await redis.info('stats');\n\n// Monitor slow queries\nconst slowLog = await redis.slowlog('get', 10);\n\n// Connection monitoring\nconst clientList = await redis.client('list');\nconst clientInfo = await redis.client('info');\n\n// Key statistics\nconst dbSize = await redis.dbsize();\nconst randomKey = await redis.randomkey();\n\n// Memory usage of specific keys\nconst keyMemory = await redis.memory('usage', 'user:1000');\n```\n\n## Error Handling & Resilience\n\n```javascript\n// Connection error handling\nredis.on('error', (error) => {\n  console.error('Redis connection error:', error);\n  // Implement fallback logic\n});\n\nredis.on('reconnecting', (delay) => {\n  console.log(`Reconnecting to Redis in ${delay}ms`);\n});\n\nredis.on('connect', () => {\n  console.log('Connected to Redis');\n});\n\n// Graceful degradation\nconst safeRedisOperation = async (operation) => {\n  try {\n    return await operation();\n  } catch (error) {\n    console.error('Redis operation failed:', error);\n    // Return default value or fetch from alternative source\n    return null;\n  }\n};\n```",
  "configuration": {
    "requiresAuth": false,
    "authType": "password",
    "permissions": ["read", "write"]
  },
  "githubUrl": "https://github.com/claudepro/mcp-redis",
  "documentationUrl": "https://docs.claude.ai/mcp/redis"
}