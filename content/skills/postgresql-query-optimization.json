{
  "slug": "postgresql-query-optimization",
  "title": "PostgreSQL Query Optimization",
  "seoTitle": "PostgreSQL Query Optimization Skill",
  "description": "Analyze and optimize PostgreSQL queries for OLTP and OLAP workloads with AI-assisted performance tuning, indexing strategies, and execution plan analysis.",
  "category": "skills",
  "author": "JSONbored",
  "dateAdded": "2025-10-16",
  "tags": ["postgresql", "database", "optimization", "performance", "sql"],
  "content": "# PostgreSQL Query Optimization Skill\n\n## What This Skill Enables\n\nClaude can analyze PostgreSQL query performance, interpret EXPLAIN plans, design optimal indexes, and tune database configurations for specific workloads (OLTP, OLAP, or hybrid). With expertise in PostgreSQL 16+ features including parallel query execution, JIT compilation, and advanced partitioning strategies, Claude helps achieve sub-millisecond query times for high-traffic applications.\n\n## Prerequisites\n\n**Required:**\n- Claude Pro subscription or Claude Code CLI\n- PostgreSQL 14+ installed (16+ recommended)\n- Access to database with slow queries or performance issues\n- Basic SQL knowledge\n\n**What Claude handles automatically:**\n- Analyzing EXPLAIN ANALYZE output\n- Identifying missing or inefficient indexes\n- Suggesting query rewrites for better performance\n- Recommending configuration parameter tuning\n- Detecting N+1 query problems\n- Proposing table partitioning strategies\n- Analyzing vacuum and autovacuum settings\n- Identifying connection pooling needs\n\n## How to Use This Skill\n\n### Analyze Slow Query\n\n**Prompt:** \"My PostgreSQL query is taking 5 seconds. Here's the query: [paste query]. Analyze the execution plan and suggest optimizations.\"\n\nClaude will:\n1. Run EXPLAIN (ANALYZE, BUFFERS, VERBOSE)\n2. Identify bottlenecks (seq scans, nested loops)\n3. Suggest missing indexes with CREATE INDEX statements\n4. Rewrite query if needed (JOIN order, subquery optimization)\n5. Estimate performance improvement\n6. Provide before/after comparison\n\n### Index Strategy Design\n\n**Prompt:** \"Design an optimal indexing strategy for a high-traffic e-commerce database with 10M products. Include queries: product search by name, filter by category and price range, sort by popularity.\"\n\nClaude will:\n1. Analyze query patterns and access patterns\n2. Create B-tree indexes for equality/range queries\n3. Add GIN indexes for full-text search\n4. Design composite indexes for multi-column filters\n5. Include partial indexes for filtered queries\n6. Add BRIN indexes for time-series data\n7. Calculate index maintenance overhead\n\n### Database Configuration Tuning\n\n**Prompt:** \"Tune PostgreSQL configuration for a 32GB RAM server running high-write OLTP workload with 200 concurrent connections.\"\n\nClaude will:\n1. Set shared_buffers (25% of RAM = 8GB)\n2. Configure work_mem per connection\n3. Adjust max_connections and connection pooling\n4. Tune WAL settings for write performance\n5. Configure autovacuum for high-write scenarios\n6. Set effective_cache_size\n7. Enable parallel query workers\n\n### Query Rewriting for Performance\n\n**Prompt:** \"Rewrite this slow query to eliminate the N+1 problem: [paste ORM-generated query with multiple subqueries].\"\n\nClaude will:\n1. Identify N+1 or N+M pattern\n2. Convert subqueries to JOINs\n3. Use CTEs for readability\n4. Apply window functions for ranking\n5. Implement LATERAL joins where appropriate\n6. Add proper indexes for new query\n7. Validate result correctness\n\n## Tips for Best Results\n\n1. **Always Use EXPLAIN ANALYZE**: Share full EXPLAIN (ANALYZE, BUFFERS) output with Claude. The BUFFERS option reveals I/O patterns crucial for optimization.\n\n2. **Provide Table Schemas**: Include CREATE TABLE statements and existing indexes. Claude needs column types and constraints for accurate recommendations.\n\n3. **Share Query Frequency**: Mention if a query runs once per day or 10,000 times per second. Optimization strategies differ dramatically.\n\n4. **Workload Type Matters**: OLTP (many small transactions) and OLAP (complex analytics) require opposite tuning. Specify your workload.\n\n5. **Include Real Data Volume**: \"1000 rows\" vs \"100M rows\" changes everything. Share actual table sizes with pg_size_pretty.\n\n6. **Monitor After Changes**: Ask Claude to generate monitoring queries to verify improvements don't cause regressions elsewhere.\n\n## Common Workflows\n\n### Complete Performance Audit\n```\n\"Perform a comprehensive PostgreSQL performance audit:\n1. Identify top 10 slowest queries from pg_stat_statements\n2. Analyze EXPLAIN plans for each\n3. Detect missing indexes with pg_stat_user_tables\n4. Find bloated tables needing VACUUM FULL\n5. Review configuration parameters\n6. Check for long-running transactions blocking others\n7. Provide prioritized optimization action plan\"\n```\n\n### Time-Series Optimization\n```\n\"Optimize PostgreSQL for time-series data:\n1. 100M rows of sensor data per month\n2. Queries filter by device_id and time range\n3. Need 90-day retention with automated archival\n4. Implement declarative partitioning by month\n5. Add BRIN indexes on timestamp columns\n6. Configure autovacuum for partition management\n7. Create aggregate materialized views\"\n```\n\n### Full-Text Search Tuning\n```\n\"Build high-performance full-text search:\n1. Search across title, description, tags fields\n2. Support phrase queries and ranking\n3. Handle 50M documents\n4. Sub-100ms query response time\n5. Use GIN indexes with tsvector\n6. Implement trigram similarity for typo tolerance\n7. Add weighted search across columns\"\n```\n\n### Replication Lag Analysis\n```\n\"Debug PostgreSQL replication lag:\n1. Replica is 30 seconds behind primary\n2. Analyze pg_stat_replication metrics\n3. Check for long-running queries on replica\n4. Identify write-heavy tables causing lag\n5. Tune max_wal_senders and wal_keep_size\n6. Recommend synchronous vs asynchronous replication\n7. Implement connection pooling strategy\"\n```\n\n## Troubleshooting\n\n**Issue:** Query still slow after adding index\n**Solution:** Index may not be used. Check EXPLAIN plan shows Index Scan (not Seq Scan). Run ANALYZE to update statistics. Consider index-only scans with INCLUDE columns or covering indexes.\n\n**Issue:** Database running out of connections\n**Solution:** Implement connection pooling with PgBouncer or pgpool-II. Reduce max_connections and increase per-connection work_mem. Fix application connection leaks.\n\n**Issue:** Autovacuum not keeping up\n**Solution:** Lower autovacuum_vacuum_scale_factor and autovacuum_vacuum_threshold for high-write tables. Increase autovacuum_max_workers. Consider manual VACUUM during maintenance windows.\n\n**Issue:** Query fast in development, slow in production\n**Solution:** Production has different data distribution. Run ANALYZE on production. Check if production has proper indexes. Compare EXPLAIN plans between environments.\n\n**Issue:** Disk I/O bottleneck\n**Solution:** Increase shared_buffers for caching. Use NVMe SSDs. Consider table partitioning to reduce I/O per query. Implement read replicas for read-heavy workloads.\n\n**Issue:** Connection pool exhausted\n**Solution:** Tune pool size based on `connections = ((core_count * 2) + effective_spindle_count)`. Implement queue_timeout. Add monitoring for pool saturation.\n\n## Learn More\n\n- [PostgreSQL Performance Tuning Guide](https://www.postgresql.org/docs/current/performance-tips.html)\n- [Use The Index, Luke! - SQL Indexing Guide](https://use-the-index-luke.com/)\n- [Depesz EXPLAIN Visualizer](https://explain.depesz.com/)\n- [PGTune Configuration Calculator](https://pgtune.leopard.in.ua/)\n- [pgAdmin Query Tool](https://www.pgadmin.org/)\n- [pg_stat_statements Extension](https://www.postgresql.org/docs/current/pgstatstatements.html)\n",
  "features": [
    "EXPLAIN plan analysis and visualization",
    "Automatic index recommendation",
    "Workload-specific tuning (OLTP/OLAP)",
    "Query rewriting for performance"
  ],
  "useCases": [
    "Optimize slow database queries",
    "Design indexing strategies",
    "Tune PostgreSQL configuration"
  ],
  "requirements": [
    "PostgreSQL 14+ (16+ recommended)",
    "pg_stat_statements extension",
    "EXPLAIN access permissions",
    "psql or database client"
  ],
  "examples": [
    {
      "title": "Analyze Query Performance",
      "language": "sql",
      "code": "-- Run with EXPLAIN ANALYZE to get actual execution times\nEXPLAIN (ANALYZE, BUFFERS, VERBOSE)\nSELECT p.name, c.name as category, p.price\nFROM products p\nJOIN categories c ON p.category_id = c.id\nWHERE p.price BETWEEN 100 AND 500\n  AND c.name = 'Electronics'\nORDER BY p.created_at DESC\nLIMIT 20;\n\n-- Check if indexes are being used\nSELECT schemaname, tablename, indexname, idx_scan, idx_tup_read, idx_tup_fetch\nFROM pg_stat_user_indexes\nWHERE schemaname = 'public'\nORDER BY idx_scan ASC;"
    },
    {
      "title": "Create Optimal Indexes",
      "language": "sql",
      "code": "-- Composite index for filtered queries\nCREATE INDEX idx_products_category_price \nON products(category_id, price) \nWHERE price IS NOT NULL;\n\n-- Partial index for active records only\nCREATE INDEX idx_products_active \nON products(created_at) \nWHERE status = 'active';\n\n-- GIN index for full-text search\nCREATE INDEX idx_products_search \nON products USING GIN(to_tsvector('english', name || ' ' || description));\n\n-- BRIN index for time-series data\nCREATE INDEX idx_events_timestamp \nON events USING BRIN(created_at);\n\n-- Covering index (index-only scan)\nCREATE INDEX idx_products_category_include \nON products(category_id) \nINCLUDE (name, price);"
    },
    {
      "title": "Find Slow Queries",
      "language": "sql",
      "code": "-- Enable pg_stat_statements first\nCREATE EXTENSION IF NOT EXISTS pg_stat_statements;\n\n-- Find slowest queries by total time\nSELECT \n  query,\n  calls,\n  total_exec_time,\n  mean_exec_time,\n  max_exec_time,\n  stddev_exec_time\nFROM pg_stat_statements\nORDER BY total_exec_time DESC\nLIMIT 10;\n\n-- Find queries with high I/O\nSELECT \n  query,\n  calls,\n  shared_blks_hit,\n  shared_blks_read,\n  (shared_blks_hit::float / NULLIF(shared_blks_hit + shared_blks_read, 0)) * 100 AS cache_hit_ratio\nFROM pg_stat_statements\nWHERE shared_blks_read > 0\nORDER BY shared_blks_read DESC\nLIMIT 10;"
    },
    {
      "title": "Configuration Tuning",
      "language": "sql",
      "code": "-- OLTP Workload Configuration (postgresql.conf)\n-- For 32GB RAM, 8 cores, NVMe SSD\n\n-- Memory Settings\nshared_buffers = 8GB                    -- 25% of RAM\neffective_cache_size = 24GB             -- 75% of RAM\nwork_mem = 64MB                         -- Per operation\nmaintenance_work_mem = 2GB              -- For VACUUM, CREATE INDEX\n\n-- Write Performance\nwal_buffers = 16MB\ncheckpoint_completion_target = 0.9\nmax_wal_size = 4GB\nmin_wal_size = 1GB\n\n-- Query Planner\nrandom_page_cost = 1.1                  -- For SSD\neffective_io_concurrency = 200          -- For SSD\n\n-- Connections\nmax_connections = 200\n\n-- Parallelism\nmax_worker_processes = 8\nmax_parallel_workers_per_gather = 4\nmax_parallel_workers = 8\n\n-- Autovacuum (high-write workload)\nautovacuum_max_workers = 4\nautovacuum_naptime = 10s\nautovacuum_vacuum_scale_factor = 0.05\nautovacuum_analyze_scale_factor = 0.02"
    }
  ],
  "installation": {
    "claudeDesktop": {
      "steps": [
        "Install PostgreSQL: brew install postgresql@16",
        "Start server: brew services start postgresql@16",
        "Enable extensions: CREATE EXTENSION pg_stat_statements;",
        "Ask Claude: 'Analyze this slow query and optimize it'"
      ]
    },
    "claudeCode": {
      "steps": [
        "sudo apt install postgresql-16",
        "sudo systemctl start postgresql",
        "psql -U postgres",
        "CREATE EXTENSION pg_stat_statements;",
        "ALTER SYSTEM SET shared_preload_libraries = 'pg_stat_statements';"
      ]
    }
  },
  "troubleshooting": [
    {
      "issue": "Index not being used by query planner",
      "solution": "Run ANALYZE to update statistics, check WHERE clause matches index columns exactly, lower random_page_cost for SSDs, or use pg_hint_plan extension to force index usage."
    },
    {
      "issue": "Out of memory errors",
      "solution": "Reduce work_mem or max_connections. Implement connection pooling with PgBouncer. Check for memory-intensive queries using hash joins or sorts."
    },
    {
      "issue": "Slow VACUUM operations",
      "solution": "Increase maintenance_work_mem, run VACUUM during off-peak hours, consider VACUUM FREEZE for old tables, or use pg_repack for online table reorganization."
    }
  ],
  "documentationUrl": "https://www.postgresql.org/docs/current/performance-tips.html",
  "source": "community"
}
