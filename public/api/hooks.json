{
  "hooks": [
    {
      "slug": "accessibility-checker",
      "description": "Automated accessibility testing and compliance checking for web applications following WCAG guidelines",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "accessibility",
        "a11y",
        "wcag",
        "testing",
        "compliance"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Automated WCAG compliance testing with axe-core",
        "Color contrast analysis and validation",
        "Keyboard navigation testing",
        "Screen reader compatibility checks",
        "Image accessibility validation",
        "Comprehensive accessibility reporting"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/accessibility-checker.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Check if it's an HTML file\nif [[ \"$FILE_PATH\" != *.html ]]; then\n  exit 0\nfi\n\necho \"🔍 Running accessibility checks on $FILE_PATH...\"\n\n# Check for basic accessibility issues\nif command -v axe &> /dev/null; then\n  echo \"Running axe-core accessibility scan...\"\n  axe \"$FILE_PATH\" --format json 2>/dev/null | jq -r '.violations[] | \"⚠️ \" + .id + \": \" + .description'\n  echo \"✅ Accessibility scan completed\" >&2\nelse\n  # Basic checks without axe\n  echo \"Running basic accessibility checks...\"\n  \n  # Check for missing alt attributes\n  if grep -q '<img[^>]*>' \"$FILE_PATH\" && ! grep -q 'alt=' \"$FILE_PATH\"; then\n    echo \"⚠️ Images without alt attributes found\" >&2\n  fi\n  \n  # Check for missing labels\n  if grep -q '<input[^>]*>' \"$FILE_PATH\" && ! grep -q 'aria-label\\|<label' \"$FILE_PATH\"; then\n    echo \"⚠️ Form inputs without labels found\" >&2\n  fi\n  \n  echo \"✅ Basic accessibility checks completed\" >&2\nfi\n\nexit 0"
      },
      "useCases": [
        "Automated accessibility testing in CI/CD pipelines",
        "Pre-deployment WCAG compliance validation",
        "Real-time accessibility feedback during development",
        "Color contrast validation for design systems",
        "Screen reader compatibility testing"
      ],
      "troubleshooting": [
        {
          "issue": "Hook executes on non-HTML files wasting resources",
          "solution": "Verify file extension check works: grep 'html' hook-file. Ensure matcher filters to .html files only. Add extension validation before processing."
        },
        {
          "issue": "Axe-core not found but script expects it installed",
          "solution": "Install globally: npm i -g @axe-core/cli. Or add fallback checks in script. Verify command availability: which axe. Add installation to project setup docs."
        },
        {
          "issue": "PostToolUse hook runs after Write but no output shown",
          "solution": "Check stderr redirection in hook script. Verify echo statements use >&2 for user feedback. Test with: bash hook-file <<< '{\"tool_name\":\"write\"}'."
        },
        {
          "issue": "Hook captures stdin but file_path extraction fails",
          "solution": "Debug jq parsing: echo \"$INPUT\" | jq -r '.tool_input.file_path'. Verify JSON structure matches expected format. Add fallback paths for nested inputs."
        },
        {
          "issue": "Accessibility violations detected but build continues",
          "solution": "Change exit 0 to exit 1 on violations if blocking desired. Add violation count threshold. Use jq to filter critical issues: jq 'select(.impact==\"critical\")'."
        }
      ],
      "documentationUrl": "https://www.w3.org/WAI/WCAG21/quickref/",
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/accessibility-checker"
    },
    {
      "slug": "api-endpoint-documentation-generator",
      "seoTitle": "API Doc Generator",
      "description": "Automatically generates or updates API documentation when endpoint files are modified",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "api",
        "documentation",
        "openapi",
        "swagger",
        "automation"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Automatic OpenAPI/Swagger documentation generation",
        "Real-time documentation updates when API files change",
        "Support for JavaScript and Python API routes",
        "Extracts endpoint information and parameters",
        "Response type documentation extraction",
        "Multi-format output (JSON, Markdown)"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/api-endpoint-documentation-generator.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Check if it's an API-related file\nif [[ \"$FILE_PATH\" == *routes/* ]] || [[ \"$FILE_PATH\" == *controllers/* ]] || [[ \"$FILE_PATH\" == *api/* ]]; then\n  echo \"📚 Generating API documentation for $FILE_PATH...\"\n  \n  # Get file extension\n  EXT=\"${FILE_PATH##*.}\"\n  \n  case \"$EXT\" in\n    js|jsx|ts|tsx)\n      # JavaScript/TypeScript API files\n      if command -v swagger-jsdoc &> /dev/null && [ -f \"swaggerDef.js\" ]; then\n        echo \"Generating Swagger documentation...\"\n        npx swagger-jsdoc -d swaggerDef.js -o ./docs/api.json \"$FILE_PATH\" 2>/dev/null\n        echo \"✅ Swagger documentation updated\" >&2\n      elif command -v npx &> /dev/null; then\n        echo \"Generating JSDoc documentation...\"\n        npx jsdoc \"$FILE_PATH\" -d ./docs/api/ 2>/dev/null\n        echo \"✅ JSDoc documentation updated\" >&2\n      fi\n      ;;\n    py)\n      # Python API files\n      if command -v pydoc &> /dev/null; then\n        echo \"Generating Python API documentation...\"\n        python -m pydoc -w \"$FILE_PATH\" 2>/dev/null\n        echo \"✅ Python documentation updated\" >&2\n      fi\n      ;;\n  esac\nelse\n  echo \"File not in API directory, skipping documentation generation\" >&2\nfi\n\nexit 0"
      },
      "useCases": [
        "Automatic API documentation in development workflows",
        "Keep OpenAPI specs synchronized with code changes",
        "Generate documentation for REST API endpoints",
        "Maintain up-to-date API reference docs",
        "Integration with Swagger UI for live documentation"
      ],
      "troubleshooting": [
        {
          "issue": "Hook triggers but file path pattern match fails",
          "solution": "Debug path detection: echo \"$FILE_PATH\" | grep -E 'routes|controllers|api'. Verify directory structure matches expected patterns. Add custom paths to case statement."
        },
        {
          "issue": "swagger-jsdoc command not found during execution",
          "solution": "Install dependencies: npm i -D swagger-jsdoc. Verify swaggerDef.js exists in project root. Check node_modules/.bin is in PATH. Use npx for local binaries."
        },
        {
          "issue": "Documentation generates but writes to wrong location",
          "solution": "Create docs/api directory: mkdir -p ./docs/api. Verify write permissions on output paths. Check current working directory in hook context: pwd >&2."
        },
        {
          "issue": "PostToolUse fires on all edits not just API files",
          "solution": "Enhance path filtering in script. Use stricter regex: [[ \"$FILE_PATH\" =~ (routes|api)/.*\\.(ts|js)$ ]]. Add early exit for non-matching paths."
        },
        {
          "issue": "Hook processes file but npx commands timeout silently",
          "solution": "Remove 2>/dev/null to see actual errors. Add timeout wrapper: timeout 30s npx command. Check for hanging processes: ps aux | grep jsdoc. Verify npm registry access."
        }
      ],
      "documentationUrl": "https://swagger.io/docs/",
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/api-endpoint-documentation-generator"
    },
    {
      "slug": "auto-code-formatter-hook",
      "description": "Automatically formats code files after Claude writes or edits them using Prettier, Black, or other formatters",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "formatting",
        "prettier",
        "black",
        "code-quality",
        "automation"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Supports multiple formatters (Prettier, Black, gofmt, rustfmt)",
        "Language-specific formatting rules",
        "Runs automatically after file modifications",
        "Preserves file permissions and structure",
        "Silent operation with optional feedback",
        "Configurable timeout and error handling"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/auto-code-formatter-hook.sh",
              "matchers": [
                "write",
                "edit",
                "multiedit"
              ]
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Get file extension\nEXT=\"${FILE_PATH##*.}\"\n\n# Format based on file type\ncase \"$EXT\" in\n  js|jsx|ts|tsx|json|md|mdx|css|scss|html|vue|yaml|yml)\n    # JavaScript/TypeScript/Web files - use Prettier\n    if command -v prettier &> /dev/null; then\n      prettier --write \"$FILE_PATH\" 2>/dev/null\n      echo \"✅ Formatted $FILE_PATH with Prettier\" >&2\n    fi\n    ;;\n  \n  py)\n    # Python files - use Black\n    if command -v black &> /dev/null; then\n      black \"$FILE_PATH\" 2>/dev/null\n      echo \"✅ Formatted $FILE_PATH with Black\" >&2\n    elif command -v ruff &> /dev/null; then\n      ruff format \"$FILE_PATH\" 2>/dev/null\n      echo \"✅ Formatted $FILE_PATH with Ruff\" >&2\n    fi\n    ;;\n  \n  go)\n    # Go files - use gofmt\n    if command -v gofmt &> /dev/null; then\n      gofmt -w \"$FILE_PATH\" 2>/dev/null\n      echo \"✅ Formatted $FILE_PATH with gofmt\" >&2\n    fi\n    ;;\n  \n  rs)\n    # Rust files - use rustfmt\n    if command -v rustfmt &> /dev/null; then\n      rustfmt \"$FILE_PATH\" 2>/dev/null\n      echo \"✅ Formatted $FILE_PATH with rustfmt\" >&2\n    fi\n    ;;\nesac\n\nexit 0"
      },
      "useCases": [
        "Maintain consistent code style across team projects",
        "Automatically fix formatting issues after AI code generation",
        "Enforce project coding standards without manual intervention",
        "Support multiple programming languages in the same project",
        "Reduce code review friction by handling formatting automatically"
      ],
      "troubleshooting": [
        {
          "issue": "Formatter runs but changes get overwritten immediately",
          "solution": "Check for competing hooks or watchers. Verify PostToolUse timing - runs after file write completes. Add debouncing if multiple formatters conflict. Review hook execution order."
        },
        {
          "issue": "Prettier config ignored and default settings applied",
          "solution": "Verify .prettierrc exists in project root or ancestor directories. Check config search path: prettier --find-config-path file.js. Set explicit config: prettier --config path."
        },
        {
          "issue": "Hook matches multiedit but only formats first file",
          "solution": "Check if FILE_PATH is array in multiedit context. Parse all paths: jq -r '.tool_input.edits[].file_path'. Loop through each file for formatting."
        },
        {
          "issue": "Formatter executable found but exits with permission denied",
          "solution": "Verify formatter binary permissions: ls -la $(which prettier). Install locally: npm i -D prettier. Use npx to ensure correct binary: npx prettier --write file."
        },
        {
          "issue": "Silent failures with no feedback on format errors",
          "solution": "Remove 2>/dev/null to expose stderr. Capture exit codes: prettier --write file || echo \"Failed: $?\" >&2. Add --loglevel debug for verbose output."
        }
      ],
      "documentationUrl": "https://prettier.io/docs/en/",
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/auto-code-formatter-hook"
    },
    {
      "slug": "auto-save-backup",
      "description": "Automatically creates timestamped backups of files before modification to prevent data loss",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "backup",
        "safety",
        "file-management",
        "data-protection"
      ],
      "hookType": "PreToolUse",
      "features": [
        "Automatic timestamped backups before file modification",
        "Organized backup storage in .backups directory",
        "Filename format: filename_YYYYMMDD_HHMMSS.ext",
        "Support for all file editing operations",
        "Version history maintenance",
        "Silent failure handling to prevent workflow interruption"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "preToolUse": {
              "script": "./.claude/hooks/auto-save-backup.sh",
              "matchers": [
                "edit",
                "write",
                "multiedit"
              ]
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Check if file exists before backing up\nif [ -f \"$FILE_PATH\" ]; then\n  echo \"💾 Creating backup for $FILE_PATH...\" >&2\n  \n  # Create backups directory\n  mkdir -p .backups\n  \n  # Generate timestamped backup filename\n  BASENAME=$(basename \"$FILE_PATH\")\n  TIMESTAMP=$(date +%Y%m%d_%H%M%S)\n  BACKUP_NAME=\"${BASENAME%.*}_${TIMESTAMP}.${BASENAME##*.}\"\n  \n  # Create backup\n  cp \"$FILE_PATH\" \".backups/$BACKUP_NAME\" 2>/dev/null || true\n  \n  if [ $? -eq 0 ]; then\n    echo \"✅ Backup created: .backups/$BACKUP_NAME\" >&2\n  else\n    echo \"⚠️ Backup failed for $FILE_PATH\" >&2\n  fi\nelse\n  echo \"📝 Creating new file $FILE_PATH (no backup needed)\" >&2\nfi\n\nexit 0"
      },
      "useCases": [
        "Automatic version control for critical configuration files",
        "Safety net during development and debugging sessions",
        "Recovery from accidental file modifications",
        "Maintaining edit history without git commits",
        "Protection during bulk file operations"
      ],
      "troubleshooting": [
        {
          "issue": "PreToolUse hook runs but backup directory not created",
          "solution": "Verify mkdir permissions in project root. Check disk space: df -h. Ensure script runs with correct CWD: pwd >&2 in hook. Create .backups manually if needed."
        },
        {
          "issue": "Backup created but original file modification fails after",
          "solution": "PreToolUse only creates backup, doesn't block edits. Check subsequent tool execution logs. Verify hook exits with 0 (non-blocking). Review tool output for actual edit errors."
        },
        {
          "issue": "Timestamp collisions when editing same file rapidly",
          "solution": "Add milliseconds to timestamp: date +%Y%m%d_%H%M%S_%N. Or use hash suffix: ${TIMESTAMP}_$(md5sum file | cut -c1-8). Implement collision detection and retry logic."
        },
        {
          "issue": "Hook backs up new files that don't exist yet on Write",
          "solution": "Verify [ -f \"$FILE_PATH\" ] check works correctly. Check TOOL_NAME to distinguish edit vs write: if [[ \"$TOOL_NAME\" == \"edit\" ]]. Skip backup for new file creation."
        },
        {
          "issue": "Backup directory grows unbounded filling disk space",
          "solution": "Add retention policy: find .backups -mtime +30 -delete. Implement backup rotation script. Use git for versioning instead. Add size limit checks before creating backups."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/auto-save-backup"
    },
    {
      "slug": "aws-cloudformation-validator",
      "description": "Validates AWS CloudFormation templates for syntax errors and best practices",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "aws",
        "cloudformation",
        "infrastructure",
        "validation",
        "cloud"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Advanced CloudFormation template validation with cfn-lint",
        "Syntax error detection and reporting",
        "AWS best practices compliance checking",
        "Type mismatch validation",
        "Fallback to AWS CLI validation when cfn-lint unavailable",
        "Support for JSON and YAML template formats"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/aws-cloudformation-validator.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Check if it's a CloudFormation template\nif [[ \"$FILE_PATH\" == *.cf.json ]] || [[ \"$FILE_PATH\" == *.cf.yaml ]] || [[ \"$FILE_PATH\" == *cloudformation*.yaml ]] || [[ \"$FILE_PATH\" == *cloudformation*.json ]]; then\n  echo \"☁️ Validating CloudFormation template $FILE_PATH...\" >&2\n  \n  # Try cfn-lint first (preferred)\n  if command -v cfn-lint &> /dev/null; then\n    echo \"Running cfn-lint validation...\" >&2\n    if cfn-lint \"$FILE_PATH\" 2>&1; then\n      echo \"✅ CloudFormation template validation passed\" >&2\n    else\n      echo \"❌ CloudFormation template validation failed\" >&2\n    fi\n  elif command -v aws &> /dev/null; then\n    echo \"⚠️ cfn-lint not installed, using AWS CLI validation...\" >&2\n    if aws cloudformation validate-template --template-body \"file://$FILE_PATH\" 2>/dev/null; then\n      echo \"✅ Basic CloudFormation validation passed\" >&2\n    else\n      echo \"❌ CloudFormation template validation failed\" >&2\n    fi\n  else\n    echo \"⚠️ Neither cfn-lint nor AWS CLI available for validation\" >&2\n  fi\nelse\n  echo \"File $FILE_PATH is not a CloudFormation template, skipping validation\" >&2\nfi\n\nexit 0"
      },
      "useCases": [
        "Pre-deployment CloudFormation template validation",
        "Infrastructure as Code quality assurance",
        "CI/CD pipeline integration for AWS deployments",
        "Development workflow validation for cloud resources",
        "Compliance checking against AWS best practices"
      ],
      "troubleshooting": [
        {
          "issue": "Hook recognizes CloudFormation file but cfn-lint fails",
          "solution": "Install cfn-lint: pip install cfn-lint. Verify Python environment active: which python. Check template syntax with: cfn-lint --version. Review cfn-lint logs without 2>&1."
        },
        {
          "issue": "AWS CLI validation requires credentials unexpectedly",
          "solution": "Use cfn-lint for offline validation instead. Or configure AWS credentials: aws configure. Use IAM role with minimal permissions. Skip AWS CLI fallback if credentials unavailable."
        },
        {
          "issue": "Template passes validation but hook shows failure message",
          "solution": "Check exit code handling in script. Capture command output: OUTPUT=$(cfn-lint file) && echo success. Review conditional logic for success detection. Debug with: set -x in script."
        },
        {
          "issue": "Hook processes YAML files that aren't CloudFormation",
          "solution": "Strengthen template detection regex. Check file content for AWSTemplateFormatVersion key: grep -q AWSTemplateFormatVersion file. Add explicit template marker in filename convention."
        },
        {
          "issue": "PostToolUse timing causes validation on incomplete writes",
          "solution": "Verify file write completed before validation. Add small sleep: sleep 0.5 before validation. Check file size: [ -s \"$FILE_PATH\" ]. Use file lock detection if available."
        }
      ],
      "documentationUrl": "https://aws.amazon.com/cloudformation/",
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/aws-cloudformation-validator"
    },
    {
      "slug": "cloud-backup-on-session-stop",
      "description": "Automatically backs up changed files to cloud storage when session ends",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "backup",
        "cloud",
        "stop-hook",
        "aws",
        "safety"
      ],
      "hookType": "Stop",
      "features": [
        "Automatic cloud backup when Claude session ends",
        "Support for multiple cloud providers (AWS S3, Google Cloud, Dropbox)",
        "Intelligent file selection using git diff",
        "Timestamped backup archives",
        "Fallback to rclone for universal cloud support",
        "Environment variable configuration for security"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "stop": {
              "script": "./.claude/hooks/cloud-backup-on-session-stop.sh"
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\necho \"☁️ Starting cloud backup process...\" >&2\n\n# Generate timestamped backup directory name\nBACKUP_DIR=\"claude-backup-$(date +%Y%m%d_%H%M%S)\"\n\n# Get list of modified files\nMODIFIED_FILES=$(git diff --name-only 2>/dev/null)\n\nif [ -z \"$MODIFIED_FILES\" ]; then\n  echo \"📂 No modified files to backup\" >&2\n  exit 0\nfi\n\necho \"📦 Found modified files to backup\" >&2\n\n# Try AWS S3 first\nif command -v aws >/dev/null 2>&1 && [[ -n \"$AWS_BACKUP_BUCKET\" ]]; then\n  echo \"📦 Backing up to AWS S3...\" >&2\n  if echo \"$MODIFIED_FILES\" | tar -czf - -T - | aws s3 cp - \"s3://$AWS_BACKUP_BUCKET/$BACKUP_DIR.tar.gz\"; then\n    echo \"✅ Successfully backed up to S3: $AWS_BACKUP_BUCKET/$BACKUP_DIR.tar.gz\" >&2\n    exit 0\n  else\n    echo \"❌ AWS S3 backup failed\" >&2\n  fi\nfi\n\n# Try Google Cloud Storage\nif command -v gcloud >/dev/null 2>&1 && [[ -n \"$GCS_BACKUP_BUCKET\" ]]; then\n  echo \"📦 Backing up to Google Cloud Storage...\" >&2\n  if echo \"$MODIFIED_FILES\" | tar -czf - -T - | gsutil cp - \"gs://$GCS_BACKUP_BUCKET/$BACKUP_DIR.tar.gz\"; then\n    echo \"✅ Successfully backed up to GCS: $GCS_BACKUP_BUCKET/$BACKUP_DIR.tar.gz\" >&2\n    exit 0\n  else\n    echo \"❌ Google Cloud backup failed\" >&2\n  fi\nfi\n\n# Try rclone as universal fallback\nif command -v rclone >/dev/null 2>&1; then\n  echo \"📦 Backing up using rclone...\" >&2\n  TEMP_BACKUP=\"/tmp/$BACKUP_DIR.tar.gz\"\n  if echo \"$MODIFIED_FILES\" | tar -czf \"$TEMP_BACKUP\" -T - && rclone copy \"$TEMP_BACKUP\" remote:backups/; then\n    echo \"✅ Successfully backed up using rclone\" >&2\n    rm -f \"$TEMP_BACKUP\"\n    exit 0\n  else\n    echo \"❌ rclone backup failed\" >&2\n    rm -f \"$TEMP_BACKUP\"\n  fi\nfi\n\necho \"⚠️ No cloud storage provider configured or available\" >&2\necho \"💡 Configure AWS_BACKUP_BUCKET, GCS_BACKUP_BUCKET, or rclone to enable cloud backup\" >&2\nexit 1"
      },
      "useCases": [
        "Automatic session-end backup for critical projects",
        "Data loss prevention in cloud-first workflows",
        "Multi-cloud backup strategy implementation",
        "CI/CD integration for development artifacts",
        "Remote work safety net for unsaved changes"
      ],
      "troubleshooting": [
        {
          "issue": "Stop hook not triggering when Claude session ends",
          "solution": "Verify hook script is executable with chmod +x and registered in .claude/config.json. Check hook script path matches config. Ensure session ends cleanly without force quit."
        },
        {
          "issue": "AWS S3 backup fails with permission denied error",
          "solution": "Configure AWS_BACKUP_BUCKET environment variable in .env file. Verify AWS credentials with aws s3 ls. Check IAM permissions allow s3:PutObject action on target bucket."
        },
        {
          "issue": "Git diff returns no modified files despite changes",
          "solution": "Ensure files are tracked by git. Run git status to verify changes exist. Stage files with git add if needed. Check hook runs after file operations complete, not during."
        },
        {
          "issue": "Backup archive creation hangs on large file sets",
          "solution": "Use .gitignore to exclude node_modules and build artifacts from git tracking. Consider implementing file size filtering in hook script. Add timeout parameter to tar command."
        },
        {
          "issue": "Multiple cloud providers configured but rclone used",
          "solution": "Hook tries AWS S3 first, then Google Cloud, then rclone. Check AWS_BACKUP_BUCKET and GCS_BACKUP_BUCKET variables are set. Verify aws or gcloud CLI tools are in PATH and authenticated."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/cloud-backup-on-session-stop"
    },
    {
      "slug": "code-complexity-alert-monitor",
      "description": "Alerts when code complexity exceeds thresholds in real-time",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "complexity",
        "code-quality",
        "notification",
        "monitoring",
        "maintainability"
      ],
      "hookType": "Notification",
      "features": [
        "Real-time complexity monitoring for JavaScript, TypeScript, and Python",
        "Configurable line count thresholds (default: 500 lines)",
        "Function count analysis and alerting",
        "Nesting level detection for code structure",
        "Instant feedback on code maintainability issues",
        "Multi-language support with pattern matching"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "notification": {
              "script": "./.claude/hooks/code-complexity-alert-monitor.sh"
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Check if it's a supported file type\nif [[ \"$FILE_PATH\" == *.js ]] || [[ \"$FILE_PATH\" == *.jsx ]] || [[ \"$FILE_PATH\" == *.ts ]] || [[ \"$FILE_PATH\" == *.tsx ]] || [[ \"$FILE_PATH\" == *.py ]]; then\n  echo \"🔍 Analyzing code complexity for $FILE_PATH...\" >&2\n  \n  # Check file exists\n  if [ ! -f \"$FILE_PATH\" ]; then\n    echo \"📁 File does not exist yet, skipping complexity analysis\" >&2\n    exit 0\n  fi\n  \n  # Line count analysis\n  LINES=$(wc -l < \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n  if [ \"$LINES\" -gt 500 ]; then\n    echo \"⚠️ COMPLEXITY: File exceeds 500 lines ($LINES lines) - consider splitting into smaller modules\" >&2\n  elif [ \"$LINES\" -gt 300 ]; then\n    echo \"📊 INFO: File is getting large ($LINES lines) - monitor for complexity\" >&2\n  fi\n  \n  # Function/method count analysis\n  FUNCTION_COUNT=$(grep -E '(function|def |const.*=>|class |async |export function)' \"$FILE_PATH\" 2>/dev/null | wc -l || echo \"0\")\n  if [ \"$FUNCTION_COUNT\" -gt 20 ]; then\n    echo \"⚠️ COMPLEXITY: Too many functions/methods ($FUNCTION_COUNT) - consider modularization\" >&2\n  elif [ \"$FUNCTION_COUNT\" -gt 15 ]; then\n    echo \"📊 INFO: High function count ($FUNCTION_COUNT) - good candidate for refactoring\" >&2\n  fi\n  \n  # Nesting level analysis (rough estimate)\n  OPEN_BRACES=$(grep -o '{' \"$FILE_PATH\" 2>/dev/null | wc -l || echo \"0\")\n  CLOSE_BRACES=$(grep -o '}' \"$FILE_PATH\" 2>/dev/null | wc -l || echo \"0\")\n  \n  if [ \"$OPEN_BRACES\" -gt 50 ]; then\n    echo \"⚠️ COMPLEXITY: High nesting detected ($OPEN_BRACES braces) - consider flattening logic\" >&2\n  fi\n  \n  # Python-specific checks\n  if [[ \"$FILE_PATH\" == *.py ]]; then\n    INDENT_DEPTH=$(grep -E '^[ ]{12,}' \"$FILE_PATH\" 2>/dev/null | wc -l || echo \"0\")\n    if [ \"$INDENT_DEPTH\" -gt 5 ]; then\n      echo \"⚠️ COMPLEXITY: Deep indentation detected in Python code - consider function extraction\" >&2\n    fi\n  fi\n  \n  echo \"✅ Complexity analysis completed for $FILE_PATH\" >&2\nelse\n  echo \"File $FILE_PATH is not a supported type for complexity analysis\" >&2\nfi\n\nexit 0"
      },
      "useCases": [
        "Real-time code quality monitoring during development",
        "Automated complexity alerts in CI/CD pipelines",
        "Code review assistance and maintainability checks",
        "Technical debt prevention and early detection",
        "Team coding standards enforcement"
      ],
      "troubleshooting": [
        {
          "issue": "Notification hook not running on file write operations",
          "solution": "Verify hook is registered under hooks.notification in .claude/config.json. Check script has executable permissions. Ensure jq is installed for JSON parsing from stdin input."
        },
        {
          "issue": "Complexity alerts not showing for TypeScript files",
          "solution": "Check file extension matches supported types: .js, .jsx, .ts, .tsx, .py. Verify FILE_PATH extraction from tool_input using jq processes correctly. Test with echo command to debug input parsing."
        },
        {
          "issue": "False positives for brace count in JSX files",
          "solution": "Hook counts all braces including JSX elements. Adjust thresholds in script for JSX-heavy files. Consider implementing AST-based complexity analysis instead of regex pattern matching."
        },
        {
          "issue": "File does not exist error during notification processing",
          "solution": "Hook runs after tool execution but file may not be written yet. Add delay with sleep 1 before analysis. Check tool_name matches write or edit operations. Verify path resolution is absolute."
        },
        {
          "issue": "Python indentation warnings incorrect for valid code",
          "solution": "Hook detects 12+ space indentation as deep nesting. Adjust threshold for projects using different indent styles. Use grep -E pattern to match your preferred indentation depth level."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/code-complexity-alert-monitor"
    },
    {
      "slug": "css-unused-selector-detector",
      "description": "Detects unused CSS selectors when stylesheets are modified to keep CSS lean",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "css",
        "optimization",
        "cleanup",
        "performance",
        "purge"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Automatic unused CSS selector detection with PurgeCSS",
        "Support for CSS, SCSS, and modern CSS frameworks",
        "Content analysis across HTML, JS, JSX, TS, and TSX files",
        "Before/after comparison with line count reduction",
        "Optimized CSS output generation",
        "Integration with modern build workflows"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/css-unused-selector-detector.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Check if it's a CSS/SCSS file\nif [[ \"$FILE_PATH\" == *.css ]] || [[ \"$FILE_PATH\" == *.scss ]] || [[ \"$FILE_PATH\" == *.sass ]]; then\n  echo \"🔍 Analyzing CSS file for unused selectors: $FILE_PATH\" >&2\n  \n  # Check if file exists\n  if [ ! -f \"$FILE_PATH\" ]; then\n    echo \"📁 CSS file does not exist yet, skipping analysis\" >&2\n    exit 0\n  fi\n  \n  # Get original file size\n  ORIGINAL_LINES=$(wc -l < \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n  ORIGINAL_SIZE=$(wc -c < \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n  \n  echo \"📊 Original CSS: $ORIGINAL_LINES lines, $ORIGINAL_SIZE bytes\" >&2\n  \n  # Try PurgeCSS if available\n  if command -v npx &> /dev/null && npx purgecss --version &> /dev/null; then\n    echo \"🧹 Running PurgeCSS analysis...\" >&2\n    \n    # Create analysis directory\n    mkdir -p css-analysis\n    \n    # Run PurgeCSS with multiple content patterns\n    if npx purgecss --css \"$FILE_PATH\" \\\n      --content './src/**/*.{html,js,jsx,ts,tsx,vue,svelte}' \\\n      --content './**/*.{html,js,jsx,ts,tsx,vue,svelte}' \\\n      --output ./css-analysis/ 2>/dev/null; then\n      \n      # Analyze results\n      PURGED_FILE=\"./css-analysis/$(basename \"$FILE_PATH\")\"\n      if [ -f \"$PURGED_FILE\" ]; then\n        PURGED_LINES=$(wc -l < \"$PURGED_FILE\" 2>/dev/null || echo \"0\")\n        PURGED_SIZE=$(wc -c < \"$PURGED_FILE\" 2>/dev/null || echo \"0\")\n        \n        SAVED_LINES=$((ORIGINAL_LINES - PURGED_LINES))\n        SAVED_SIZE=$((ORIGINAL_SIZE - PURGED_SIZE))\n        REDUCTION_PERCENT=$((SAVED_SIZE * 100 / ORIGINAL_SIZE))\n        \n        echo \"📉 Optimized CSS: $PURGED_LINES lines, $PURGED_SIZE bytes\" >&2\n        echo \"✅ Potential savings: $SAVED_LINES lines, $SAVED_SIZE bytes ($REDUCTION_PERCENT% reduction)\" >&2\n        echo \"📁 Check css-analysis/$(basename \"$FILE_PATH\") for optimized version\" >&2\n      else\n        echo \"⚠️ PurgeCSS analysis completed but no output generated\" >&2\n      fi\n    else\n      echo \"❌ PurgeCSS analysis failed - check content paths\" >&2\n    fi\n  else\n    echo \"💡 Install PurgeCSS (npm install -g purgecss) for CSS optimization analysis\" >&2\n    \n    # Basic analysis without PurgeCSS\n    SELECTOR_COUNT=$(grep -o '[.#][a-zA-Z][-a-zA-Z0-9_]*' \"$FILE_PATH\" 2>/dev/null | sort -u | wc -l || echo \"0\")\n    echo \"📊 Found $SELECTOR_COUNT unique CSS selectors in file\" >&2\n  fi\n  \n  echo \"✅ CSS analysis completed for $FILE_PATH\" >&2\nelse\n  echo \"File $FILE_PATH is not a CSS/SCSS file, skipping analysis\" >&2\nfi\n\nexit 0"
      },
      "useCases": [
        "Automatic CSS optimization during stylesheet development",
        "Dead code elimination in large CSS codebases",
        "Performance optimization for web applications",
        "CSS bundle size reduction in production builds",
        "Maintenance of clean, lean stylesheets"
      ],
      "troubleshooting": [
        {
          "issue": "PurgeCSS not detecting any unused selectors in CSS",
          "solution": "Verify content paths match your project structure. Update --content patterns to include all HTML/JSX/TSX files. Check PurgeCSS config safelist if critical selectors are protected."
        },
        {
          "issue": "PostToolUse hook only runs for write, not edit operations",
          "solution": "Add both matchers to hook config: matchers: ['write', 'edit']. Verify tool_name extraction from stdin matches expected values. Test with echo to debug tool input parsing."
        },
        {
          "issue": "css-analysis directory not created or files missing",
          "solution": "Check write permissions in project root. Ensure mkdir -p succeeds without errors. Verify PurgeCSS output path is writable. Check disk space if directory creation fails silently."
        },
        {
          "issue": "PurgeCSS removes critical CSS framework classes",
          "solution": "Add safelist patterns to PurgeCSS config for framework classes. Use safelist: [/^btn-/, /^nav-/] syntax. Consider extracting framework CSS to separate file excluded from purging."
        },
        {
          "issue": "No output generated message despite PurgeCSS success",
          "solution": "Check PURGED_FILE path construction matches PurgeCSS output. Verify basename command extracts correct filename. Ensure output directory exists before PurgeCSS runs with mkdir -p."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/css-unused-selector-detector"
    },
    {
      "slug": "database-connection-cleanup",
      "description": "Closes all database connections and cleans up resources when session ends",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "database",
        "cleanup",
        "stop-hook",
        "connections",
        "resources"
      ],
      "hookType": "Stop",
      "features": [
        "Automatic database connection cleanup on session end",
        "Multi-database support (PostgreSQL, MySQL, MongoDB, Redis)",
        "Idle connection termination for PostgreSQL",
        "Connection monitoring and reporting",
        "Safe cleanup with error handling",
        "Resource leak prevention"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "stop": {
              "script": "./.claude/hooks/database-connection-cleanup.sh"
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\necho \"🗄️ Starting database connection cleanup...\" >&2\n\n# PostgreSQL cleanup\nif pgrep postgres >/dev/null 2>&1; then\n  echo \"🐘 PostgreSQL: Checking connections...\" >&2\n  \n  # Check if psql is available and we can connect\n  if command -v psql &> /dev/null; then\n    # Count active connections\n    ACTIVE_CONNECTIONS=$(psql -t -c \"SELECT count(*) FROM pg_stat_activity WHERE state = 'active' AND pid <> pg_backend_pid();\" 2>/dev/null | xargs || echo \"0\")\n    IDLE_CONNECTIONS=$(psql -t -c \"SELECT count(*) FROM pg_stat_activity WHERE state = 'idle' AND pid <> pg_backend_pid();\" 2>/dev/null | xargs || echo \"0\")\n    \n    echo \"📊 PostgreSQL: $ACTIVE_CONNECTIONS active, $IDLE_CONNECTIONS idle connections\" >&2\n    \n    # Terminate long-running idle connections (older than 5 minutes)\n    if [ \"$IDLE_CONNECTIONS\" -gt 0 ]; then\n      TERMINATED=$(psql -t -c \"SELECT count(*) FROM (SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE state = 'idle' AND state_change < now() - interval '5 minutes' AND pid <> pg_backend_pid()) t;\" 2>/dev/null | xargs || echo \"0\")\n      if [ \"$TERMINATED\" -gt 0 ]; then\n        echo \"✅ PostgreSQL: Terminated $TERMINATED idle connections\" >&2\n      fi\n    fi\n  else\n    echo \"⚠️ PostgreSQL running but psql not available\" >&2\n  fi\nfi\n\n# MySQL cleanup\nif pgrep mysql >/dev/null 2>&1 || pgrep mysqld >/dev/null 2>&1; then\n  echo \"🐬 MySQL: Checking connections...\" >&2\n  \n  if command -v mysql &> /dev/null; then\n    PROCESSLIST=$(mysql -e \"SHOW PROCESSLIST;\" 2>/dev/null | grep -c \"Sleep\" || echo \"0\")\n    TOTAL_CONNECTIONS=$(mysql -e \"SHOW PROCESSLIST;\" 2>/dev/null | wc -l || echo \"0\")\n    echo \"📊 MySQL: $TOTAL_CONNECTIONS total connections, $PROCESSLIST sleeping\" >&2\n    \n    # Kill long-running sleeping connections (optional, requires PROCESS privilege)\n    # mysql -e \"KILL CONNECTION_ID;\" 2>/dev/null || true\n  else\n    echo \"⚠️ MySQL running but mysql client not available\" >&2\n  fi\nfi\n\n# MongoDB cleanup\nif pgrep mongod >/dev/null 2>&1; then\n  echo \"🍃 MongoDB: Checking connections...\" >&2\n  \n  if command -v mongosh &> /dev/null; then\n    CONNECTIONS=$(mongosh --quiet --eval \"db.currentOp().inprog.length\" 2>/dev/null || echo \"0\")\n    echo \"📊 MongoDB: $CONNECTIONS active operations\" >&2\n  elif command -v mongo &> /dev/null; then\n    CONNECTIONS=$(mongo --quiet --eval \"db.currentOp().inprog.length\" 2>/dev/null || echo \"0\")\n    echo \"📊 MongoDB: $CONNECTIONS active operations\" >&2\n  else\n    echo \"⚠️ MongoDB running but mongo client not available\" >&2\n  fi\nfi\n\n# Redis cleanup\nif pgrep redis-server >/dev/null 2>&1; then\n  echo \"📮 Redis: Checking connections...\" >&2\n  \n  if command -v redis-cli &> /dev/null; then\n    CLIENT_COUNT=$(redis-cli CLIENT LIST 2>/dev/null | wc -l || echo \"0\")\n    echo \"📊 Redis: $CLIENT_COUNT connected clients\" >&2\n    \n    # Optionally close idle clients\n    # redis-cli CLIENT KILL TYPE normal SKIPME yes 2>/dev/null || true\n  else\n    echo \"⚠️ Redis running but redis-cli not available\" >&2\n  fi\nfi\n\n# Check for database connection strings in environment\nif [ -f \".env\" ]; then\n  DB_VARS=$(grep -E \"(DATABASE_URL|MONGODB_URI|REDIS_URL|POSTGRES|MYSQL)\" .env 2>/dev/null | wc -l || echo \"0\")\n  if [ \"$DB_VARS\" -gt 0 ]; then\n    echo \"📋 Found $DB_VARS database configuration variables in .env\" >&2\n  fi\nfi\n\necho \"✅ Database connection cleanup completed\" >&2\nexit 0"
      },
      "useCases": [
        "Automatic resource cleanup in development environments",
        "Prevention of database connection leaks",
        "Clean session termination for database applications",
        "Resource monitoring and management",
        "Multi-database environment cleanup"
      ],
      "troubleshooting": [
        {
          "issue": "PostgreSQL connections not terminated despite hook execution",
          "solution": "Verify psql client is in PATH and can connect without password. Check pg_hba.conf allows local connections. Ensure user has permission to query pg_stat_activity and call pg_terminate_backend."
        },
        {
          "issue": "Stop hook runs but database processes still detected",
          "solution": "Hook reports connections but doesn't stop database servers. Use pgrep to verify process detection works. Check connection cleanup SQL executes successfully. Monitor stderr for command errors."
        },
        {
          "issue": "Idle connection count shows zero despite active sessions",
          "solution": "Check state filter in pg_stat_activity query matches your PostgreSQL version. Verify 5-minute threshold is appropriate for your workflow. Use psql directly to debug query results."
        },
        {
          "issue": "MySQL processlist command fails with access denied",
          "solution": "Grant PROCESS privilege to MySQL user. Run GRANT PROCESS ON *.* TO 'user'@'localhost'. Verify mysql client connects with correct credentials from .env or environment variables."
        },
        {
          "issue": "MongoDB connection check fails with authentication error",
          "solution": "Use mongosh for MongoDB 5+ or mongo for older versions. Configure connection string with credentials. Check authentication database matches user creation. Verify network access if using remote MongoDB."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/database-connection-cleanup"
    },
    {
      "slug": "database-migration-runner",
      "description": "Automated database migration management with rollback capabilities, validation, and multi-environment support",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-16",
      "tags": [
        "database",
        "migration",
        "automation",
        "deployment",
        "sql"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Automated database migration detection and execution",
        "Support for multiple database systems (PostgreSQL, MySQL, SQLite)",
        "Safe rollback capabilities with validation",
        "Migration file integrity checking with checksums",
        "Environment-specific migration configurations",
        "CI/CD pipeline integration"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/database-migration-runner.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Check if it's a migration-related file\nif [[ \"$FILE_PATH\" == *migration* ]] || [[ \"$FILE_PATH\" == *schema* ]] || [[ \"$FILE_PATH\" == *.sql ]]; then\n  echo \"🗃️ Database migration file detected: $FILE_PATH\" >&2\n  \n  # Check for common migration frameworks\n  if [ -f \"package.json\" ] && (grep -q \"knex\" package.json || grep -q \"sequelize\" package.json || grep -q \"typeorm\" package.json); then\n    echo \"📦 Node.js migration framework detected\" >&2\n    \n    # Knex migrations\n    if command -v npx &> /dev/null && npx knex --version &> /dev/null 2>&1; then\n      echo \"🔧 Running Knex migration status check...\" >&2\n      MIGRATION_STATUS=$(npx knex migrate:status 2>/dev/null || echo \"No pending migrations\")\n      echo \"📊 Migration Status: $MIGRATION_STATUS\" >&2\n      \n      # Check for pending migrations\n      if echo \"$MIGRATION_STATUS\" | grep -q \"pending\"; then\n        echo \"⚠️ Pending migrations detected. Run 'npx knex migrate:latest' to apply them\" >&2\n      else\n        echo \"✅ All migrations are up to date\" >&2\n      fi\n      \n    # Sequelize migrations\n    elif command -v npx &> /dev/null && npx sequelize-cli --version &> /dev/null 2>&1; then\n      echo \"🔧 Sequelize CLI detected\" >&2\n      echo \"💡 Run 'npx sequelize-cli db:migrate:status' to check migration status\" >&2\n      \n    # TypeORM migrations\n    elif command -v npx &> /dev/null && npx typeorm --version &> /dev/null 2>&1; then\n      echo \"🔧 TypeORM detected\" >&2\n      echo \"💡 Run 'npx typeorm migration:show' to check migration status\" >&2\n    fi\n    \n  # Django migrations\n  elif [ -f \"manage.py\" ]; then\n    echo \"🐍 Django project detected\" >&2\n    if command -v python &> /dev/null; then\n      echo \"🔧 Checking Django migration status...\" >&2\n      python manage.py showmigrations --plan 2>/dev/null | tail -5 | head -3 || echo \"💡 Run 'python manage.py showmigrations' to check status\" >&2\n    fi\n    \n  # Rails migrations\n  elif [ -f \"Gemfile\" ] && grep -q \"rails\" Gemfile; then\n    echo \"💎 Rails project detected\" >&2\n    if command -v bundle &> /dev/null; then\n      echo \"🔧 Checking Rails migration status...\" >&2\n      bundle exec rails db:migrate:status 2>/dev/null | tail -5 || echo \"💡 Run 'rails db:migrate:status' to check status\" >&2\n    fi\n    \n  # Raw SQL files\n  elif [[ \"$FILE_PATH\" == *.sql ]]; then\n    echo \"📜 Raw SQL migration file detected\" >&2\n    \n    # Check file size and complexity\n    if [ -f \"$FILE_PATH\" ]; then\n      LINE_COUNT=$(wc -l < \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n      echo \"📊 SQL file contains $LINE_COUNT lines\" >&2\n      \n      # Check for potentially destructive operations\n      if grep -i \"DROP\\|DELETE\\|TRUNCATE\" \"$FILE_PATH\" >/dev/null 2>&1; then\n        echo \"⚠️ WARNING: Potentially destructive SQL operations detected (DROP/DELETE/TRUNCATE)\" >&2\n        echo \"💡 Consider creating a backup before executing this migration\" >&2\n      fi\n      \n      # Check for common patterns\n      if grep -i \"CREATE TABLE\\|ALTER TABLE\\|CREATE INDEX\" \"$FILE_PATH\" >/dev/null 2>&1; then\n        echo \"🏗️ Schema modification statements detected\" >&2\n      fi\n      \n      if grep -i \"INSERT\\|UPDATE\" \"$FILE_PATH\" >/dev/null 2>&1; then\n        echo \"📝 Data modification statements detected\" >&2\n      fi\n    fi\n  fi\n  \n  # General migration best practices reminder\n  echo \"📋 Migration Best Practices:\" >&2\n  echo \"   • Always backup database before running migrations\" >&2\n  echo \"   • Test migrations on development/staging first\" >&2\n  echo \"   • Ensure migrations are reversible when possible\" >&2\n  echo \"   • Use transactions for atomic operations\" >&2\n  \nelse\n  echo \"File $FILE_PATH is not a migration file, skipping analysis\" >&2\nfi\n\nexit 0"
      },
      "useCases": [
        "Automated database schema evolution in development workflows",
        "CI/CD pipeline integration for deployment migrations",
        "Multi-environment database synchronization",
        "Migration validation and rollback safety",
        "Database versioning and change tracking"
      ],
      "troubleshooting": [
        {
          "issue": "Hook detects migration file but framework check fails",
          "solution": "Verify package.json contains knex, sequelize, or typeorm dependency. Run npm install to ensure frameworks are installed. Check npx command availability and node_modules/.bin in PATH."
        },
        {
          "issue": "Knex migration status shows no pending despite new files",
          "solution": "Run npx knex migrate:list to verify migration discovery. Check migration file naming follows timestamp pattern. Ensure knexfile.js configuration points to correct migrations directory."
        },
        {
          "issue": "PostToolUse hook triggers on non-migration SQL files",
          "solution": "Refine file path pattern matching to exclude seed/query files. Add migration directory check: [[ $FILE_PATH == *migrations/* ]]. Update matchers to prevent false positives."
        },
        {
          "issue": "Destructive operation warning for safe rollback scripts",
          "solution": "Hook warns on DROP/DELETE/TRUNCATE in any context. Add migration safety comments to suppress warnings. Consider splitting destructive down migrations into separate reviewed files."
        },
        {
          "issue": "Django migration detection fails in virtual environment",
          "solution": "Activate virtualenv before hook runs: source venv/bin/activate in shell config. Use absolute python path from which python. Ensure manage.py is executable and in project root."
        }
      ],
      "documentationUrl": "https://knexjs.org/guide/migrations.html",
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/database-migration-runner"
    },
    {
      "slug": "database-query-performance-logger",
      "description": "Monitors and logs database query performance metrics with slow query detection, N+1 analysis, and optimization suggestions",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-10-19",
      "tags": [
        "database",
        "performance",
        "monitoring",
        "optimization",
        "logging"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Automatic slow query detection and alerting",
        "N+1 query pattern identification",
        "Query execution time tracking and statistics",
        "Database connection pool monitoring",
        "Query plan analysis and optimization hints",
        "Support for PostgreSQL, MySQL, SQLite query logs"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/database-query-performance-logger.sh",
              "matchers": [
                "bash",
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\nCOMMAND=$(echo \"$INPUT\" | jq -r '.tool_input.command // \"\"')\n\n# Configuration\nSLOW_QUERY_THRESHOLD_MS=${SLOW_QUERY_THRESHOLD_MS:-1000}\nLOG_FILE=\".claude/logs/query-performance.log\"\n\n# Create log directory if it doesn't exist\nmkdir -p \"$(dirname \"$LOG_FILE\")\"\n\n# Function to check for query files\ncheck_query_file() {\n  local file=$1\n  \n  if [ -z \"$file\" ]; then\n    return 1\n  fi\n  \n  # Check if file contains SQL or database queries\n  if [[ \"$file\" == *.sql ]] || \\\n     [[ \"$file\" == *query* ]] || \\\n     [[ \"$file\" == *model* ]] || \\\n     [[ \"$file\" == *repository* ]] || \\\n     [[ \"$file\" == *dao* ]]; then\n    return 0\n  fi\n  \n  return 1\n}\n\n# Function to analyze query patterns\nanalyze_query_patterns() {\n  local file=$1\n  \n  echo \"🔍 Analyzing query patterns in: $file\" >&2\n  \n  if [ ! -f \"$file\" ]; then\n    return\n  fi\n  \n  # Check for N+1 query patterns (loops with queries)\n  if grep -n \"for\\|while\\|forEach\" \"$file\" | head -5 | grep -q .; then\n    if grep -i \"SELECT\\|query\\|find\" \"$file\" >/dev/null 2>&1; then\n      echo \"⚠️ Potential N+1 query pattern detected\" >&2\n      echo \"💡 Consider using JOIN or eager loading instead of queries in loops\" >&2\n    fi\n  fi\n  \n  # Check for SELECT * patterns\n  if grep -i \"SELECT \\*\" \"$file\" >/dev/null 2>&1; then\n    echo \"⚠️ SELECT * detected - consider specifying columns explicitly\" >&2\n    echo \"💡 Reduces data transfer and improves performance\" >&2\n  fi\n  \n  # Check for missing LIMIT clauses\n  if grep -i \"SELECT\" \"$file\" | grep -iv \"LIMIT\\|TOP\" >/dev/null 2>&1; then\n    echo \"💡 Consider adding LIMIT clauses to prevent unbounded result sets\" >&2\n  fi\n  \n  # Check for unindexed WHERE clauses\n  if grep -i \"WHERE\" \"$file\" >/dev/null 2>&1; then\n    echo \"📊 WHERE clauses detected - ensure columns are indexed\" >&2\n  fi\n  \n  # Log analysis timestamp\n  echo \"[$(date -u +\"%Y-%m-%dT%H:%M:%SZ\")] Analyzed: $file\" >> \"$LOG_FILE\"\n}\n\n# Function to check for slow query logs\ncheck_slow_query_logs() {\n  echo \"📈 Checking for slow query logs...\" >&2\n  \n  # PostgreSQL slow query log\n  if [ -f \"postgresql.conf\" ] || [ -f \"pg_log/postgresql.log\" ]; then\n    echo \"🐘 PostgreSQL detected\" >&2\n    echo \"💡 Enable slow query logging: log_min_duration_statement = $SLOW_QUERY_THRESHOLD_MS\" >&2\n  fi\n  \n  # MySQL slow query log\n  if [ -f \"my.cnf\" ] || [ -f \"/etc/mysql/my.cnf\" ]; then\n    echo \"🐬 MySQL detected\" >&2\n    echo \"💡 Enable slow query log: slow_query_log = 1\" >&2\n  fi\n  \n  # Check for ORM query logging\n  if [ -f \"package.json\" ]; then\n    if grep -q \"sequelize\\|typeorm\\|prisma\" package.json 2>/dev/null; then\n      echo \"📦 ORM detected - query logging available\" >&2\n      echo \"💡 Enable logging in ORM configuration for query performance insights\" >&2\n    fi\n  fi\n}\n\n# Main execution\nif check_query_file \"$FILE_PATH\"; then\n  echo \"🗃️ Database query file detected: $FILE_PATH\" >&2\n  analyze_query_patterns \"$FILE_PATH\"\n  check_slow_query_logs\n  \n  # Performance tips\n  echo \"\" >&2\n  echo \"🎯 Query Performance Best Practices:\" >&2\n  echo \"   • Use indexes on frequently queried columns\" >&2\n  echo \"   • Avoid N+1 queries with eager loading\" >&2\n  echo \"   • Use EXPLAIN/ANALYZE to understand query plans\" >&2\n  echo \"   • Monitor slow queries > ${SLOW_QUERY_THRESHOLD_MS}ms\" >&2\n  echo \"   • Use connection pooling for better resource management\" >&2\n  \nelif [[ \"$COMMAND\" == *\"psql\"* ]] || [[ \"$COMMAND\" == *\"mysql\"* ]] || [[ \"$COMMAND\" == *\"sqlite\"* ]]; then\n  echo \"🗃️ Database command detected\" >&2\n  echo \"⏱️ Query execution started at: $(date)\" >&2\n  echo \"[$(date -u +\"%Y-%m-%dT%H:%M:%SZ\")] Database command: $COMMAND\" >> \"$LOG_FILE\"\nfi\n\nexit 0"
      },
      "useCases": [
        "Real-time database performance monitoring during development",
        "Slow query identification and optimization",
        "N+1 query pattern detection and prevention",
        "Database migration performance validation",
        "ORM query optimization and debugging"
      ],
      "troubleshooting": [
        {
          "issue": "Hook triggers on every file but query analysis shows nothing",
          "solution": "Verify file path matching patterns in check_query_file. Add specific matchers for your ORM/query files. Check grep patterns match your SQL syntax (PostgreSQL vs MySQL syntax differences)."
        },
        {
          "issue": "N+1 detection gives false positives on batch operations",
          "solution": "Hook flags loops with queries regardless of batching. Add @performance-safe comments to suppress warnings. Refine regex to detect batch/eager loading keywords like includes() or with()."
        },
        {
          "issue": "Slow query threshold environment variable not respected",
          "solution": "Export SLOW_QUERY_THRESHOLD_MS before hook runs. Check bash environment inheritance from shell config. Set in .clauderc: export SLOW_QUERY_THRESHOLD_MS=500 for global override."
        },
        {
          "issue": "Query log file grows too large in active development",
          "solution": "Implement log rotation: mv query-performance.log query-performance.$(date +%Y%m%d).log periodically. Use logrotate or cleanup hook. Add log size check with truncation at 10MB threshold."
        },
        {
          "issue": "ORM query logging suggestions appear but feature is enabled",
          "solution": "Hook checks package.json presence, not active config. Suppress by adding ORM_LOGGING_ENABLED=true env var. Update hook to detect active logging from config files (ormconfig.json, database.yml)."
        }
      ],
      "documentationUrl": "https://www.postgresql.org/docs/current/runtime-config-logging.html",
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/database-query-performance-logger"
    },
    {
      "slug": "dead-code-eliminator",
      "description": "Automatically detects and removes unused code, imports, and dependencies with safe deletion verification and rollback support",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-10-19",
      "tags": [
        "code-quality",
        "cleanup",
        "optimization",
        "refactoring",
        "automation"
      ],
      "hookType": "SessionEnd",
      "features": [
        "Unused import detection and removal across multiple languages",
        "Dead code path identification using static analysis",
        "Unreferenced function and variable detection",
        "Orphaned test file cleanup with verification",
        "Safe deletion with backup and rollback capabilities",
        "Bundle size impact analysis after cleanup"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "sessionEnd": {
              "script": "./.claude/hooks/dead-code-eliminator.sh"
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\necho \"🧹 Dead Code Eliminator - Session Cleanup\" >&2\n\n# Configuration\nBACKUP_DIR=\".claude/backups/dead-code-$(date +%Y%m%d-%H%M%S)\"\nREPORT_FILE=\".claude/reports/dead-code-report.txt\"\nDRY_RUN=${DRY_RUN:-true}\n\nmkdir -p \"$(dirname \"$REPORT_FILE\")\"\nmkdir -p \"$BACKUP_DIR\"\n\necho \"📊 Analyzing codebase for dead code...\" >&2\necho \"Dead Code Analysis - $(date)\" > \"$REPORT_FILE\"\necho \"===========================================\" >> \"$REPORT_FILE\"\n\n# Function to find unused imports (JavaScript/TypeScript)\nfind_unused_imports_js() {\n  echo \"🔍 Checking for unused imports in JS/TS files...\" >&2\n  \n  if command -v npx &> /dev/null; then\n    # Check if eslint-plugin-unused-imports is available\n    if [ -f \"package.json\" ] && grep -q \"eslint\" package.json; then\n      echo \"📦 Running ESLint unused imports check...\" >&2\n      npx eslint --ext .js,.jsx,.ts,.tsx --quiet --format compact . 2>/dev/null | \\\n        grep \"unused\" | head -20 >> \"$REPORT_FILE\" || true\n    fi\n    \n    # Use ts-prune for TypeScript projects\n    if [ -f \"tsconfig.json\" ] && command -v npx &> /dev/null; then\n      echo \"📦 Running ts-prune for unused exports...\" >&2\n      npx ts-prune 2>/dev/null | head -30 >> \"$REPORT_FILE\" || \\\n        echo \"💡 Install ts-prune: npm i -D ts-prune\" >&2\n    fi\n  fi\n}\n\n# Function to find unused Python imports\nfind_unused_imports_python() {\n  echo \"🔍 Checking for unused imports in Python files...\" >&2\n  \n  if command -v autoflake &> /dev/null; then\n    echo \"📦 Running autoflake for unused imports...\" >&2\n    autoflake --check --recursive --remove-all-unused-imports . 2>/dev/null | \\\n      head -20 >> \"$REPORT_FILE\" || true\n  elif command -v pylint &> /dev/null; then\n    echo \"📦 Running pylint for unused imports...\" >&2\n    find . -name \"*.py\" -type f | head -10 | while read -r file; do\n      pylint --disable=all --enable=unused-import \"$file\" 2>/dev/null\n    done >> \"$REPORT_FILE\" || true\n  else\n    echo \"💡 Install autoflake or pylint for Python dead code detection\" >&2\n  fi\n}\n\n# Function to find unreferenced files\nfind_unreferenced_files() {\n  echo \"🔍 Finding potentially unreferenced files...\" >&2\n  \n  # Find files that might be orphaned (not imported anywhere)\n  if command -v rg &> /dev/null; then\n    echo \"\" >> \"$REPORT_FILE\"\n    echo \"Potentially Unreferenced Files:\" >> \"$REPORT_FILE\"\n    echo \"--------------------------------\" >> \"$REPORT_FILE\"\n    \n    # Find .js/.ts files in src\n    find src -type f \\( -name \"*.js\" -o -name \"*.ts\" -o -name \"*.tsx\" -o -name \"*.jsx\" \\) 2>/dev/null | \\\n      head -50 | while read -r file; do\n        basename=\"$(basename \"$file\" | sed 's/\\.[^.]*$//')\"\n        # Check if file is imported anywhere\n        if ! rg -q \"from.*['\\\"].*$basename\" . 2>/dev/null && \\\n           ! rg -q \"import.*['\\\"].*$basename\" . 2>/dev/null; then\n          echo \"  - $file (no imports found)\" >> \"$REPORT_FILE\"\n        fi\n      done\n  fi\n}\n\n# Function to find unused dependencies\nfind_unused_dependencies() {\n  echo \"🔍 Checking for unused npm dependencies...\" >&2\n  \n  if [ -f \"package.json\" ]; then\n    if command -v npx &> /dev/null; then\n      echo \"\" >> \"$REPORT_FILE\"\n      echo \"Unused Dependencies Check:\" >> \"$REPORT_FILE\"\n      echo \"-------------------------\" >> \"$REPORT_FILE\"\n      \n      # Use depcheck if available\n      if npx depcheck --version &> /dev/null; then\n        npx depcheck --json 2>/dev/null | \\\n          jq -r '.dependencies[]' 2>/dev/null | \\\n          head -10 >> \"$REPORT_FILE\" || \\\n          echo \"💡 Install depcheck: npm i -D depcheck\" >&2\n      fi\n    fi\n  fi\n}\n\n# Function to analyze dead code with coverage data\nanalyze_with_coverage() {\n  echo \"📊 Analyzing test coverage for dead code hints...\" >&2\n  \n  if [ -f \"coverage/coverage-summary.json\" ]; then\n    echo \"\" >> \"$REPORT_FILE\"\n    echo \"Zero-Coverage Files (Potential Dead Code):\" >> \"$REPORT_FILE\"\n    echo \"------------------------------------------\" >> \"$REPORT_FILE\"\n    \n    jq -r 'to_entries[] | select(.value.lines.pct == 0) | .key' \\\n      coverage/coverage-summary.json 2>/dev/null | \\\n      head -10 >> \"$REPORT_FILE\" || true\n  fi\n}\n\n# Run all analysis functions\nfind_unused_imports_js\nfind_unused_imports_python\nfind_unreferenced_files\nfind_unused_dependencies\nanalyze_with_coverage\n\n# Report summary\necho \"\" >> \"$REPORT_FILE\"\necho \"Analysis Complete - $(date)\" >> \"$REPORT_FILE\"\n\n# Display report\nif [ -s \"$REPORT_FILE\" ]; then\n  echo \"\" >&2\n  echo \"📋 Dead Code Analysis Report:\" >&2\n  cat \"$REPORT_FILE\" >&2\n  echo \"\" >&2\n  echo \"💾 Full report saved to: $REPORT_FILE\" >&2\n  \n  if [ \"$DRY_RUN\" = \"true\" ]; then\n    echo \"\" >&2\n    echo \"🔒 DRY RUN mode enabled - no files deleted\" >&2\n    echo \"💡 Set DRY_RUN=false to enable automatic cleanup\" >&2\n  else\n    echo \"⚠️ Automatic cleanup enabled - review report carefully\" >&2\n  fi\nelse\n  echo \"✅ No dead code detected\" >&2\nfi\n\necho \"\" >&2\necho \"🎯 Dead Code Elimination Best Practices:\" >&2\necho \"   • Run static analysis tools regularly\" >&2\necho \"   • Use tree-shaking for production builds\" >&2\necho \"   • Review unused exports before removal\" >&2\necho \"   • Maintain high test coverage to identify dead code\" >&2\necho \"   • Use automated tools: ts-prune, depcheck, autoflake\" >&2\n\nexit 0"
      },
      "useCases": [
        "Automated codebase cleanup on session completion",
        "Bundle size optimization through dead code removal",
        "Refactoring support with safe unused code detection",
        "CI/CD integration for continuous code quality",
        "Technical debt reduction and maintenance"
      ],
      "troubleshooting": [
        {
          "issue": "SessionEnd hook runs but no dead code report generated",
          "solution": "Check .claude/reports directory permissions and disk space. Verify jq command available for JSON parsing. Run manually to see stderr output: bash .claude/hooks/dead-code-eliminator.sh."
        },
        {
          "issue": "False positives for dynamic imports and runtime dependencies",
          "solution": "Hook uses static analysis only. Exclude dynamic require() patterns from reports. Add ignore patterns to .dead-code-ignore file. Use /* dead-code-safe */ comments for runtime-loaded modules."
        },
        {
          "issue": "ts-prune reports too many false positives on exports",
          "solution": "Configure ts-prune with .ts-prunerc ignore patterns. Export unused items intentionally for public API. Use ts-prune --ignore to exclude specific paths or patterns from analysis."
        },
        {
          "issue": "DRY_RUN=false mode deletes files without confirmation",
          "solution": "Backup created in .claude/backups before deletion. Review report first in dry run mode. Implement confirmation prompt in script. Use git to recover deleted files if needed."
        },
        {
          "issue": "Coverage-based detection misses files outside test scope",
          "solution": "Zero coverage indicates potential dead code but not definitive. Cross-reference with import analysis. Check if files are runtime-loaded or dynamically required. Verify files aren't entry points or config files."
        }
      ],
      "documentationUrl": "https://github.com/nadeesha/ts-prune",
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/dead-code-eliminator"
    },
    {
      "slug": "dependency-security-audit-on-stop",
      "seoTitle": "Dependency Security Audit",
      "description": "Performs a comprehensive security audit of all dependencies when session ends",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "security",
        "dependencies",
        "audit",
        "stop-hook",
        "vulnerabilities"
      ],
      "hookType": "Stop",
      "features": [
        "Comprehensive security audit for multiple package managers",
        "Support for NPM, Yarn, Python, and Ruby dependency scanning",
        "Vulnerability detection with severity levels",
        "Outdated package identification",
        "Detailed audit report generation",
        "Integration with popular security tools (npm audit, safety, bundle audit)"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "stop": {
              "script": "./.claude/hooks/dependency-security-audit-on-stop.sh"
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\necho \"🔒 DEPENDENCY SECURITY AUDIT\" >&2\necho \"===========================\" >&2\n\n# Generate timestamp for report\nTIMESTAMP=$(date +%Y%m%d_%H%M%S)\nREPORT_FILE=\"security-audit-$TIMESTAMP.log\"\n\n# Initialize report\necho \"Dependency Security Audit Report - $TIMESTAMP\" > \"$REPORT_FILE\"\necho \"=============================================\" >> \"$REPORT_FILE\"\necho \"\" >> \"$REPORT_FILE\"\n\n# Node.js projects (NPM)\nif [ -f \"package-lock.json\" ]; then\n  echo \"📦 NPM Project Detected - Running audit...\" >&2\n  echo \"NPM AUDIT RESULTS\" >> \"$REPORT_FILE\"\n  echo \"-----------------\" >> \"$REPORT_FILE\"\n  \n  if command -v npm &> /dev/null; then\n    # Run npm audit with detailed output\n    NPM_AUDIT_OUTPUT=$(npm audit --audit-level=moderate 2>&1)\n    \n    if echo \"$NPM_AUDIT_OUTPUT\" | grep -q \"found 0 vulnerabilities\"; then\n      echo \"✅ No vulnerabilities found in NPM dependencies\" >&2\n      echo \"✅ No vulnerabilities found\" >> \"$REPORT_FILE\"\n    else\n      VULN_COUNT=$(echo \"$NPM_AUDIT_OUTPUT\" | grep -o '[0-9]\\+ vulnerabilities' | head -1 || echo \"unknown vulnerabilities\")\n      echo \"⚠️ NPM audit found: $VULN_COUNT\" >&2\n      echo \"$NPM_AUDIT_OUTPUT\" >> \"$REPORT_FILE\"\n    fi\n    \n    echo \"\" >> \"$REPORT_FILE\"\n    echo \"OUTDATED PACKAGES\" >> \"$REPORT_FILE\"\n    echo \"-----------------\" >> \"$REPORT_FILE\"\n    \n    # Check for outdated packages\n    OUTDATED_OUTPUT=$(npm outdated 2>/dev/null || echo \"All packages up to date\")\n    echo \"$OUTDATED_OUTPUT\" >> \"$REPORT_FILE\"\n    \n    if [ \"$OUTDATED_OUTPUT\" = \"All packages up to date\" ]; then\n      echo \"✅ All NPM packages are up to date\" >&2\n    else\n      OUTDATED_COUNT=$(echo \"$OUTDATED_OUTPUT\" | wc -l)\n      echo \"📊 Found $OUTDATED_COUNT outdated NPM packages\" >&2\n    fi\n  else\n    echo \"⚠️ npm command not available\" >&2\n  fi\n  \n# Yarn projects\nelif [ -f \"yarn.lock\" ]; then\n  echo \"🧶 Yarn Project Detected - Running audit...\" >&2\n  echo \"YARN AUDIT RESULTS\" >> \"$REPORT_FILE\"\n  echo \"------------------\" >> \"$REPORT_FILE\"\n  \n  if command -v yarn &> /dev/null; then\n    YARN_AUDIT_OUTPUT=$(yarn audit --level moderate 2>&1 || echo \"Yarn audit completed\")\n    echo \"$YARN_AUDIT_OUTPUT\" >> \"$REPORT_FILE\"\n    \n    if echo \"$YARN_AUDIT_OUTPUT\" | grep -q \"0 vulnerabilities\"; then\n      echo \"✅ No vulnerabilities found in Yarn dependencies\" >&2\n    else\n      echo \"⚠️ Yarn audit found potential issues\" >&2\n    fi\n  else\n    echo \"⚠️ yarn command not available\" >&2\n  fi\n  \n# Python projects\nelif [ -f \"requirements.txt\" ] || [ -f \"Pipfile\" ] || [ -f \"pyproject.toml\" ]; then\n  echo \"🐍 Python Project Detected - Running security check...\" >&2\n  echo \"PYTHON SECURITY CHECK\" >> \"$REPORT_FILE\"\n  echo \"--------------------\" >> \"$REPORT_FILE\"\n  \n  # Try safety first (recommended for Python security scanning)\n  if command -v safety &> /dev/null; then\n    echo \"🔍 Running Safety security scanner...\" >&2\n    SAFETY_OUTPUT=$(safety check --json 2>/dev/null || safety check 2>/dev/null || echo \"Safety check completed\")\n    echo \"$SAFETY_OUTPUT\" >> \"$REPORT_FILE\"\n    \n    if echo \"$SAFETY_OUTPUT\" | grep -q \"No known security vulnerabilities\"; then\n      echo \"✅ No known security vulnerabilities in Python dependencies\" >&2\n    else\n      echo \"⚠️ Safety scan found potential security issues\" >&2\n    fi\n  else\n    echo \"💡 Install 'safety' for Python security scanning: pip install safety\" >&2\n    echo \"safety not installed - using pip list --outdated\" >> \"$REPORT_FILE\"\n  fi\n  \n  echo \"\" >> \"$REPORT_FILE\"\n  echo \"OUTDATED PYTHON PACKAGES\" >> \"$REPORT_FILE\"\n  echo \"------------------------\" >> \"$REPORT_FILE\"\n  \n  if command -v pip &> /dev/null; then\n    PIP_OUTDATED=$(pip list --outdated 2>/dev/null || echo \"Unable to check outdated packages\")\n    echo \"$PIP_OUTDATED\" >> \"$REPORT_FILE\"\n    \n    OUTDATED_COUNT=$(echo \"$PIP_OUTDATED\" | wc -l)\n    echo \"📊 Found $OUTDATED_COUNT potentially outdated Python packages\" >&2\n  fi\n  \n# Ruby projects\nelif [ -f \"Gemfile.lock\" ]; then\n  echo \"💎 Ruby Project Detected - Running bundle audit...\" >&2\n  echo \"RUBY BUNDLE AUDIT\" >> \"$REPORT_FILE\"\n  echo \"-----------------\" >> \"$REPORT_FILE\"\n  \n  if command -v bundle &> /dev/null; then\n    # Check if bundler-audit is available\n    if bundle exec bundler-audit --version &> /dev/null; then\n      BUNDLE_AUDIT_OUTPUT=$(bundle exec bundler-audit check 2>&1 || echo \"Bundle audit completed\")\n      echo \"$BUNDLE_AUDIT_OUTPUT\" >> \"$REPORT_FILE\"\n      \n      if echo \"$BUNDLE_AUDIT_OUTPUT\" | grep -q \"No vulnerabilities found\"; then\n        echo \"✅ No vulnerabilities found in Ruby gems\" >&2\n      else\n        echo \"⚠️ Bundle audit found potential issues\" >&2\n      fi\n    else\n      echo \"💡 Install bundler-audit: gem install bundler-audit\" >&2\n      echo \"bundler-audit not installed\" >> \"$REPORT_FILE\"\n    fi\n  else\n    echo \"⚠️ bundle command not available\" >&2\n  fi\n  \nelse\n  echo \"📁 No recognized dependency files found\" >&2\n  echo \"No package manager files detected (package.json, requirements.txt, Gemfile, etc.)\" >> \"$REPORT_FILE\"\nfi\n\necho \"\" >> \"$REPORT_FILE\"\necho \"Report generated at: $(date)\" >> \"$REPORT_FILE\"\necho \"===========================\" >&2\necho \"📄 Full security audit report saved to: $REPORT_FILE\" >&2\necho \"💡 Review the report for detailed vulnerability information\" >&2\n\nexit 0"
      },
      "useCases": [
        "End-of-session security assessment for development projects",
        "Automated vulnerability detection in CI/CD pipelines",
        "Regular dependency health monitoring",
        "Security compliance reporting",
        "Multi-language project security auditing"
      ],
      "troubleshooting": [
        {
          "issue": "Security audit report files accumulate in project root directory",
          "solution": "Configure REPORT_FILE path to use dedicated logs directory, or add security-audit-*.log pattern to .gitignore to prevent repository clutter from timestamp-based audit files."
        },
        {
          "issue": "Stop hook executes before dependencies finish installing or updating",
          "solution": "Ensure package manager operations complete before session ends. Hook runs after Claude stops, so install commands in active session won't conflict with audit timing."
        },
        {
          "issue": "npm audit hangs indefinitely when network connectivity issues occur",
          "solution": "Set npm config registry timeout with 'npm config set timeout 30000' or add timeout wrapper around audit commands to prevent hook from blocking session termination."
        },
        {
          "issue": "Safety scanner for Python fails with 'database not found' error message",
          "solution": "Update safety vulnerability database using 'safety check --update-db' command. Install latest version with 'pip install --upgrade safety' to ensure compatibility with current database schema."
        },
        {
          "issue": "Audit severity level flags not recognized by older package manager versions",
          "solution": "Update npm to version 6.1.0+ for --audit-level flag support. For older versions, remove --audit-level parameter and parse full audit output using grep for severity filtering."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/dependency-security-audit-on-stop"
    },
    {
      "slug": "dependency-security-scanner",
      "description": "Real-time vulnerability scanning for dependencies with automated CVE detection, severity assessment, and patch recommendations",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-10-19",
      "tags": [
        "security",
        "dependencies",
        "vulnerability",
        "cve",
        "automation"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Automated vulnerability scanning on dependency file changes",
        "CVE database integration for real-time threat detection",
        "Severity-based alerting (critical, high, medium, low)",
        "Automatic patch version recommendations",
        "Support for npm, yarn, pip, cargo, go modules",
        "License compliance checking and risk assessment"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/dependency-security-scanner.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Configuration\nSECURITY_REPORT=\".claude/reports/security-scan-$(date +%Y%m%d).txt\"\nSEVERITY_THRESHOLD=${SEVERITY_THRESHOLD:-medium}\n\nmkdir -p \"$(dirname \"$SECURITY_REPORT\")\"\n\n# Function to check if file is a dependency manifest\nis_dependency_file() {\n  local file=$1\n  \n  case \"$(basename \"$file\")\" in\n    package.json|package-lock.json|yarn.lock|pnpm-lock.yaml)\n      echo \"npm\"\n      return 0\n      ;;\n    requirements.txt|Pipfile|Pipfile.lock|poetry.lock)\n      echo \"pip\"\n      return 0\n      ;;\n    Cargo.toml|Cargo.lock)\n      echo \"cargo\"\n      return 0\n      ;;\n    go.mod|go.sum)\n      echo \"go\"\n      return 0\n      ;;\n    Gemfile|Gemfile.lock)\n      echo \"bundler\"\n      return 0\n      ;;\n    composer.json|composer.lock)\n      echo \"composer\"\n      return 0\n      ;;\n    *)\n      return 1\n      ;;\n  esac\n}\n\n# Function to run npm audit\nscan_npm_dependencies() {\n  echo \"📦 Scanning npm dependencies for vulnerabilities...\" >&2\n  \n  if ! command -v npm &> /dev/null; then\n    echo \"⚠️ npm not found - install Node.js for security scanning\" >&2\n    return\n  fi\n  \n  echo \"\" >> \"$SECURITY_REPORT\"\n  echo \"NPM Audit Report - $(date)\" >> \"$SECURITY_REPORT\"\n  echo \"================================\" >> \"$SECURITY_REPORT\"\n  \n  # Run npm audit\n  AUDIT_OUTPUT=$(npm audit --json 2>/dev/null)\n  \n  if [ -n \"$AUDIT_OUTPUT\" ]; then\n    # Parse vulnerabilities\n    CRITICAL=$(echo \"$AUDIT_OUTPUT\" | jq -r '.metadata.vulnerabilities.critical // 0')\n    HIGH=$(echo \"$AUDIT_OUTPUT\" | jq -r '.metadata.vulnerabilities.high // 0')\n    MODERATE=$(echo \"$AUDIT_OUTPUT\" | jq -r '.metadata.vulnerabilities.moderate // 0')\n    LOW=$(echo \"$AUDIT_OUTPUT\" | jq -r '.metadata.vulnerabilities.low // 0')\n    \n    echo \"Critical: $CRITICAL | High: $HIGH | Moderate: $MODERATE | Low: $LOW\" >> \"$SECURITY_REPORT\"\n    \n    # Alert on critical/high vulnerabilities\n    if [ \"$CRITICAL\" -gt 0 ] || [ \"$HIGH\" -gt 0 ]; then\n      echo \"\" >&2\n      echo \"🚨 SECURITY ALERT: Critical or High severity vulnerabilities detected!\" >&2\n      echo \"   Critical: $CRITICAL vulnerabilities\" >&2\n      echo \"   High: $HIGH vulnerabilities\" >&2\n      echo \"\" >&2\n      echo \"🔧 Run 'npm audit fix' to automatically fix vulnerabilities\" >&2\n      echo \"🔧 Run 'npm audit fix --force' for breaking changes\" >&2\n    fi\n    \n    # Get fixable vulnerabilities\n    FIXABLE=$(echo \"$AUDIT_OUTPUT\" | jq -r '.metadata.vulnerabilities.info // 0')\n    if [ \"$FIXABLE\" -gt 0 ]; then\n      echo \"💡 $FIXABLE vulnerabilities can be fixed automatically\" >&2\n    fi\n  else\n    echo \"✅ No vulnerabilities detected\" >> \"$SECURITY_REPORT\"\n  fi\n}\n\n# Function to scan Python dependencies\nscan_pip_dependencies() {\n  echo \"🐍 Scanning Python dependencies for vulnerabilities...\" >&2\n  \n  if command -v safety &> /dev/null; then\n    echo \"\" >> \"$SECURITY_REPORT\"\n    echo \"Python Safety Report - $(date)\" >> \"$SECURITY_REPORT\"\n    echo \"=================================\" >> \"$SECURITY_REPORT\"\n    \n    safety check --json 2>/dev/null | \\\n      jq -r '.[] | \"\\(.package): \\(.vulnerability)\"' 2>/dev/null >> \"$SECURITY_REPORT\" || \\\n      echo \"✅ No vulnerabilities detected\" >> \"$SECURITY_REPORT\"\n  elif command -v pip-audit &> /dev/null; then\n    echo \"Running pip-audit...\" >&2\n    pip-audit --format json 2>/dev/null >> \"$SECURITY_REPORT\" || \\\n      echo \"💡 Install pip-audit: pip install pip-audit\" >&2\n  else\n    echo \"💡 Install safety or pip-audit for Python security scanning\" >&2\n  fi\n}\n\n# Function to scan Rust dependencies\nscan_cargo_dependencies() {\n  echo \"🦀 Scanning Rust dependencies for vulnerabilities...\" >&2\n  \n  if command -v cargo &> /dev/null; then\n    if cargo audit --version &> /dev/null; then\n      echo \"\" >> \"$SECURITY_REPORT\"\n      echo \"Cargo Audit Report - $(date)\" >> \"$SECURITY_REPORT\"\n      echo \"==============================\" >> \"$SECURITY_REPORT\"\n      \n      cargo audit --json 2>/dev/null >> \"$SECURITY_REPORT\" || \\\n        echo \"✅ No vulnerabilities detected\" >> \"$SECURITY_REPORT\"\n    else\n      echo \"💡 Install cargo-audit: cargo install cargo-audit\" >&2\n    fi\n  fi\n}\n\n# Function to scan Go dependencies\nscan_go_dependencies() {\n  echo \"🐹 Scanning Go dependencies for vulnerabilities...\" >&2\n  \n  if command -v govulncheck &> /dev/null; then\n    echo \"\" >> \"$SECURITY_REPORT\"\n    echo \"Go Vulnerability Check - $(date)\" >> \"$SECURITY_REPORT\"\n    echo \"==================================\" >> \"$SECURITY_REPORT\"\n    \n    govulncheck ./... 2>/dev/null >> \"$SECURITY_REPORT\" || \\\n      echo \"✅ No vulnerabilities detected\" >> \"$SECURITY_REPORT\"\n  else\n    echo \"💡 Install govulncheck: go install golang.org/x/vuln/cmd/govulncheck@latest\" >&2\n  fi\n}\n\n# Main execution\nDEP_TYPE=$(is_dependency_file \"$FILE_PATH\")\n\nif [ -n \"$DEP_TYPE\" ]; then\n  echo \"🔐 Security scan triggered: $FILE_PATH\" >&2\n  echo \"📋 Dependency type: $DEP_TYPE\" >&2\n  \n  # Run appropriate scanner\n  case \"$DEP_TYPE\" in\n    npm)\n      scan_npm_dependencies\n      ;;\n    pip)\n      scan_pip_dependencies\n      ;;\n    cargo)\n      scan_cargo_dependencies\n      ;;\n    go)\n      scan_go_dependencies\n      ;;\n    *)\n      echo \"💡 Security scanning available for: npm, pip, cargo, go\" >&2\n      ;;\n  esac\n  \n  # General security tips\n  echo \"\" >&2\n  echo \"🛡️ Dependency Security Best Practices:\" >&2\n  echo \"   • Keep dependencies updated regularly\" >&2\n  echo \"   • Review security advisories before updates\" >&2\n  echo \"   • Use lock files to ensure reproducible builds\" >&2\n  echo \"   • Minimize dependency count to reduce attack surface\" >&2\n  echo \"   • Enable automated security alerts in your repo\" >&2\n  \n  if [ -s \"$SECURITY_REPORT\" ]; then\n    echo \"\" >&2\n    echo \"📄 Security report: $SECURITY_REPORT\" >&2\n  fi\nfi\n\nexit 0"
      },
      "useCases": [
        "Continuous security monitoring during dependency updates",
        "CI/CD pipeline integration for automated vulnerability detection",
        "Compliance scanning for security audits",
        "Real-time CVE alerting on new vulnerabilities",
        "Supply chain security validation"
      ],
      "troubleshooting": [
        {
          "issue": "PostToolUse hook triggers but npm audit shows empty results",
          "solution": "Ensure package-lock.json exists (run npm install first). Check npm version supports audit (npm 6+). Verify network connectivity for CVE database access. Try npm audit --registry=https://registry.npmjs.org."
        },
        {
          "issue": "Critical vulnerabilities reported but npm audit fix fails",
          "solution": "Breaking changes require --force flag but review impact first. Check if vulnerability is in transitive dependency requiring upstream fix. Pin vulnerable package version with resolutions in package.json. Consider alternative packages."
        },
        {
          "issue": "Python safety check reports vulnerabilities in dev packages",
          "solution": "Separate dev and prod requirements: safety check -r requirements.txt. Use --ignore to suppress false positives. Check if vulnerability affects your usage context. Update to patched versions in requirements.txt."
        },
        {
          "issue": "Security scan creates duplicate reports on each save",
          "solution": "Hook runs on every write/edit matcher trigger. Implement debouncing with timestamp check. Use daily report files to prevent spam. Add file hash check to skip scans if content unchanged."
        },
        {
          "issue": "Cargo audit fails with index update errors in CI",
          "solution": "Pre-download advisory database: cargo audit fetch in CI setup. Use offline mode if network restricted. Cache advisory-db directory between runs. Check firewall rules for https://github.com/rustsec access."
        }
      ],
      "documentationUrl": "https://docs.npmjs.com/cli/v8/commands/npm-audit",
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/dependency-security-scanner"
    },
    {
      "slug": "dependency-update-checker",
      "description": "Automatically checks for outdated dependencies and suggests updates with security analysis",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-16",
      "tags": [
        "dependencies",
        "security",
        "automation",
        "npm",
        "package-management"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Automated dependency analysis for multiple package managers",
        "Security vulnerability detection and reporting",
        "Categorized update recommendations (critical, major, minor)",
        "Breaking change warnings for major version updates",
        "Multi-language support (Node.js, Python, Ruby, Go)",
        "Detailed update strategy guidance"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/dependency-update-checker.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Check if it's a dependency file\nif [[ \"$FILE_PATH\" == *package.json ]] || [[ \"$FILE_PATH\" == *requirements.txt ]] || [[ \"$FILE_PATH\" == *Gemfile ]] || [[ \"$FILE_PATH\" == *go.mod ]] || [[ \"$FILE_PATH\" == *Cargo.toml ]]; then\n  echo \"📦 Dependency file detected: $FILE_PATH\" >&2\n  \n  # Node.js projects\n  if [[ \"$FILE_PATH\" == *package.json ]]; then\n    echo \"🟢 Node.js project detected - checking dependencies...\" >&2\n    \n    if command -v npm &> /dev/null; then\n      echo \"🔍 Running npm outdated check...\" >&2\n      OUTDATED_OUTPUT=$(npm outdated --depth=0 2>/dev/null || echo \"No outdated packages\")\n      \n      if [ \"$OUTDATED_OUTPUT\" = \"No outdated packages\" ]; then\n        echo \"✅ All npm packages are up to date\" >&2\n      else\n        echo \"📊 Found outdated npm packages:\" >&2\n        echo \"$OUTDATED_OUTPUT\" | head -10 >&2\n        \n        OUTDATED_COUNT=$(echo \"$OUTDATED_OUTPUT\" | wc -l)\n        echo \"📈 Total outdated packages: $OUTDATED_COUNT\" >&2\n      fi\n      \n      # Check for security vulnerabilities\n      echo \"🔒 Checking for security vulnerabilities...\" >&2\n      AUDIT_OUTPUT=$(npm audit --audit-level=moderate 2>&1)\n      \n      if echo \"$AUDIT_OUTPUT\" | grep -q \"found 0 vulnerabilities\"; then\n        echo \"✅ No security vulnerabilities found\" >&2\n      else\n        VULN_COUNT=$(echo \"$AUDIT_OUTPUT\" | grep -o '[0-9]\\+ vulnerabilities' | head -1 || echo \"unknown vulnerabilities\")\n        echo \"⚠️ Security audit found: $VULN_COUNT\" >&2\n        echo \"💡 Run 'npm audit fix' to automatically fix vulnerabilities\" >&2\n      fi\n      \n      # Check for npm-check-updates availability\n      if command -v npx &> /dev/null && npx ncu --version &> /dev/null 2>&1; then\n        echo \"🔧 Running npm-check-updates for detailed analysis...\" >&2\n        NCU_OUTPUT=$(npx ncu 2>/dev/null | head -5)\n        echo \"$NCU_OUTPUT\" >&2\n      else\n        echo \"💡 Install npm-check-updates for better dependency analysis: npm install -g npm-check-updates\" >&2\n      fi\n    else\n      echo \"⚠️ npm command not available\" >&2\n    fi\n    \n  # Python projects\n  elif [[ \"$FILE_PATH\" == *requirements.txt ]] || [[ \"$FILE_PATH\" == *pyproject.toml ]]; then\n    echo \"🐍 Python project detected - checking dependencies...\" >&2\n    \n    if command -v pip &> /dev/null; then\n      echo \"🔍 Checking for outdated Python packages...\" >&2\n      PIP_OUTDATED=$(pip list --outdated 2>/dev/null || echo \"Unable to check outdated packages\")\n      \n      if [ \"$PIP_OUTDATED\" = \"Unable to check outdated packages\" ]; then\n        echo \"⚠️ Unable to check pip packages\" >&2\n      else\n        OUTDATED_COUNT=$(echo \"$PIP_OUTDATED\" | wc -l)\n        if [ \"$OUTDATED_COUNT\" -gt 1 ]; then\n          echo \"📊 Found $OUTDATED_COUNT outdated Python packages\" >&2\n          echo \"$PIP_OUTDATED\" | head -5 >&2\n        else\n          echo \"✅ All Python packages are up to date\" >&2\n        fi\n      fi\n      \n      # Check for security issues with safety\n      if command -v safety &> /dev/null; then\n        echo \"🔒 Running Safety security check...\" >&2\n        SAFETY_OUTPUT=$(safety check --json 2>/dev/null || safety check 2>/dev/null || echo \"Safety check completed\")\n        \n        if echo \"$SAFETY_OUTPUT\" | grep -q \"No known security vulnerabilities\"; then\n          echo \"✅ No known security vulnerabilities in Python dependencies\" >&2\n        else\n          echo \"⚠️ Safety scan found potential security issues\" >&2\n        fi\n      else\n        echo \"💡 Install Safety for Python security scanning: pip install safety\" >&2\n      fi\n    else\n      echo \"⚠️ pip command not available\" >&2\n    fi\n    \n  # Ruby projects\n  elif [[ \"$FILE_PATH\" == *Gemfile ]]; then\n    echo \"💎 Ruby project detected - checking dependencies...\" >&2\n    \n    if command -v bundle &> /dev/null; then\n      echo \"🔍 Checking for outdated Ruby gems...\" >&2\n      BUNDLE_OUTDATED=$(bundle outdated 2>/dev/null | head -10 || echo \"Unable to check outdated gems\")\n      echo \"$BUNDLE_OUTDATED\" >&2\n      \n      # Check for security issues\n      if bundle exec bundler-audit --version &> /dev/null; then\n        echo \"🔒 Running bundler-audit security check...\" >&2\n        BUNDLE_AUDIT=$(bundle exec bundler-audit check 2>&1 || echo \"Bundle audit completed\")\n        \n        if echo \"$BUNDLE_AUDIT\" | grep -q \"No vulnerabilities found\"; then\n          echo \"✅ No vulnerabilities found in Ruby gems\" >&2\n        else\n          echo \"⚠️ Bundle audit found potential issues\" >&2\n        fi\n      else\n        echo \"💡 Install bundler-audit: gem install bundler-audit\" >&2\n      fi\n    else\n      echo \"⚠️ bundle command not available\" >&2\n    fi\n    \n  # Go projects\n  elif [[ \"$FILE_PATH\" == *go.mod ]]; then\n    echo \"🐹 Go project detected - checking dependencies...\" >&2\n    \n    if command -v go &> /dev/null; then\n      echo \"🔍 Checking Go module dependencies...\" >&2\n      \n      # List modules\n      GO_LIST=$(go list -m -u all 2>/dev/null | head -10 || echo \"Unable to list Go modules\")\n      echo \"$GO_LIST\" >&2\n      \n      # Check for available updates\n      OUTDATED_MODULES=$(echo \"$GO_LIST\" | grep -c '\\[' 2>/dev/null || echo \"0\")\n      if [ \"$OUTDATED_MODULES\" -gt 0 ]; then\n        echo \"📊 Found $OUTDATED_MODULES Go modules with available updates\" >&2\n        echo \"💡 Run 'go get -u ./...' to update dependencies\" >&2\n      else\n        echo \"✅ All Go modules are up to date\" >&2\n      fi\n    else\n      echo \"⚠️ go command not available\" >&2\n    fi\n    \n  # Rust projects\n  elif [[ \"$FILE_PATH\" == *Cargo.toml ]]; then\n    echo \"🦀 Rust project detected - checking dependencies...\" >&2\n    \n    if command -v cargo &> /dev/null; then\n      # Check for outdated crates\n      if cargo outdated --version &> /dev/null; then\n        echo \"🔍 Checking for outdated Rust crates...\" >&2\n        CARGO_OUTDATED=$(cargo outdated 2>/dev/null | head -10 || echo \"Unable to check outdated crates\")\n        echo \"$CARGO_OUTDATED\" >&2\n      else\n        echo \"💡 Install cargo-outdated: cargo install cargo-outdated\" >&2\n      fi\n      \n      # Security audit\n      if cargo audit --version &> /dev/null; then\n        echo \"🔒 Running Rust security audit...\" >&2\n        CARGO_AUDIT=$(cargo audit 2>&1 || echo \"Audit completed\")\n        \n        if echo \"$CARGO_AUDIT\" | grep -q \"Success No vulnerable packages found\"; then\n          echo \"✅ No vulnerable crates found\" >&2\n        else\n          echo \"⚠️ Cargo audit found potential issues\" >&2\n        fi\n      else\n        echo \"💡 Install cargo-audit: cargo install cargo-audit\" >&2\n      fi\n    else\n      echo \"⚠️ cargo command not available\" >&2\n    fi\n  fi\n  \n  # General recommendations\n  echo \"\" >&2\n  echo \"📋 Dependency Update Best Practices:\" >&2\n  echo \"   • Review changelogs before major version updates\" >&2\n  echo \"   • Test thoroughly after dependency updates\" >&2\n  echo \"   • Update security-critical packages immediately\" >&2\n  echo \"   • Use lockfiles for reproducible builds\" >&2\n  \nelse\n  echo \"File $FILE_PATH is not a recognized dependency file, skipping analysis\" >&2\nfi\n\nexit 0"
      },
      "useCases": [
        "Automated dependency health monitoring during development",
        "Security vulnerability detection in package updates",
        "CI/CD pipeline integration for dependency validation",
        "Multi-language project dependency management",
        "Safe update strategy recommendations"
      ],
      "troubleshooting": [
        {
          "issue": "Hook triggers on every file write but only dependency files should activate it",
          "solution": "Verify matchers array includes only 'write' and 'edit' tools. Add file path validation in script header to exit early when FILE_PATH doesn't match dependency file patterns."
        },
        {
          "issue": "npm outdated command returns empty output despite outdated packages existing",
          "solution": "Run 'npm update --dry-run' instead of 'npm outdated' to see available updates. Check npm cache with 'npm cache verify' and clear if corrupted using 'npm cache clean --force'."
        },
        {
          "issue": "Hook execution floods stderr with security warnings during rapid file edits",
          "solution": "Add debouncing by storing last check timestamp in temp file. Skip audit if less than 5 minutes elapsed since previous check to reduce noise during active development sessions."
        },
        {
          "issue": "jq command not found error prevents hook from parsing tool input JSON",
          "solution": "Install jq JSON processor using package manager: 'brew install jq' on macOS, 'apt-get install jq' on Ubuntu. Verify installation with 'jq --version' before testing hook again."
        },
        {
          "issue": "Python safety check fails in virtual environments with permission errors",
          "solution": "Activate correct virtual environment before running hook or detect venv using VIRTUAL_ENV variable. Install safety in project venv rather than globally: 'pip install safety' within activated environment."
        }
      ],
      "documentationUrl": "https://docs.npmjs.com/cli/v8/commands/npm-audit",
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/dependency-update-checker"
    },
    {
      "slug": "discord-activity-notifier",
      "description": "Sends development activity updates to Discord channel for team collaboration",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "discord",
        "notification",
        "collaboration",
        "webhooks",
        "team"
      ],
      "hookType": "Notification",
      "features": [
        "Real-time Discord notifications for Claude Code activities",
        "Rich embed messages with file information and timestamps",
        "Dynamic color coding based on action types (success, error, info)",
        "Team collaboration and activity visibility",
        "Configurable webhook integration",
        "Silent operation with fallback error handling"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "notification": {
              "script": "./.claude/hooks/discord-activity-notifier.sh"
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\n# Check if Discord webhook URL is configured\nif [ -z \"$DISCORD_WEBHOOK_URL\" ]; then\n  echo \"💡 Set DISCORD_WEBHOOK_URL environment variable to enable Discord notifications\" >&2\n  exit 0\nfi\n\necho \"📤 Sending Discord notification for tool: $TOOL_NAME\" >&2\n\n# Determine color based on tool name or file type\nCOLOR=\"3447003\"  # Default blue\n\n# Success indicators\nif [[ \"$TOOL_NAME\" == *\"Success\"* ]] || [[ \"$TOOL_NAME\" == *\"Complete\"* ]]; then\n  COLOR=\"3066993\"  # Green\n# Error indicators\nelif [[ \"$TOOL_NAME\" == *\"Error\"* ]] || [[ \"$TOOL_NAME\" == *\"Fail\"* ]]; then\n  COLOR=\"15158332\"  # Red\n# Warning indicators\nelif [[ \"$TOOL_NAME\" == *\"Warning\"* ]] || [[ \"$TOOL_NAME\" == *\"Alert\"* ]]; then\n  COLOR=\"16776960\"  # Yellow\n# Edit/Write operations\nelif [[ \"$TOOL_NAME\" == \"Edit\" ]] || [[ \"$TOOL_NAME\" == \"Write\" ]] || [[ \"$TOOL_NAME\" == \"MultiEdit\" ]]; then\n  COLOR=\"5793266\"  # Purple\nfi\n\n# Get file information\nif [ -n \"$FILE_PATH\" ]; then\n  FILENAME=$(basename \"$FILE_PATH\" 2>/dev/null || echo \"Unknown file\")\n  FILE_EXT=\"${FILENAME##*.}\"\n  \n  # Add file type icon based on extension\n  case \"$FILE_EXT\" in\n    js|jsx|ts|tsx) FILE_ICON=\"⚛️\" ;;\n    py) FILE_ICON=\"🐍\" ;;\n    rb) FILE_ICON=\"💎\" ;;\n    go) FILE_ICON=\"🐹\" ;;\n    rs) FILE_ICON=\"🦀\" ;;\n    java) FILE_ICON=\"☕\" ;;\n    cpp|c|cc) FILE_ICON=\"⚙️\" ;;\n    html) FILE_ICON=\"🌐\" ;;\n    css|scss) FILE_ICON=\"🎨\" ;;\n    json) FILE_ICON=\"📋\" ;;\n    md) FILE_ICON=\"📝\" ;;\n    *) FILE_ICON=\"📄\" ;;\n  esac\n  \n  FILE_DISPLAY=\"$FILE_ICON $FILENAME\"\nelse\n  FILE_DISPLAY=\"📂 General activity\"\nfi\n\n# Get current timestamp\nTIMESTAMP=$(date +\"%H:%M:%S\")\nDATE_TIME=$(date +\"%Y-%m-%d %H:%M:%S\")\n\n# Get Git information if available\nGIT_BRANCH=\"\"\nGIT_COMMIT=\"\"\nif command -v git &> /dev/null && git rev-parse --git-dir > /dev/null 2>&1; then\n  GIT_BRANCH=$(git branch --show-current 2>/dev/null || echo \"\")\n  GIT_COMMIT=$(git rev-parse --short HEAD 2>/dev/null || echo \"\")\nfi\n\n# Build the Discord embed JSON\nEMBED_DESCRIPTION=\"**Tool:** \\`$TOOL_NAME\\`\"\nif [ -n \"$GIT_BRANCH\" ]; then\n  EMBED_DESCRIPTION=\"$EMBED_DESCRIPTION\\n**Branch:** \\`$GIT_BRANCH\\`\"\nfi\n\n# Create fields array\nFIELDS='['\nFIELDS=\"$FIELDS{\\\"name\\\": \\\"File\\\", \\\"value\\\": \\\"$FILE_DISPLAY\\\", \\\"inline\\\": true}\"\nFIELDS=\"$FIELDS,{\\\"name\\\": \\\"Time\\\", \\\"value\\\": \\\"$TIMESTAMP\\\", \\\"inline\\\": true}\"\n\nif [ -n \"$GIT_COMMIT\" ]; then\n  FIELDS=\"$FIELDS,{\\\"name\\\": \\\"Commit\\\", \\\"value\\\": \\\"\\`$GIT_COMMIT\\`\\\", \\\"inline\\\": true}\"\nfi\n\nFIELDS=\"$FIELDS]\"\n\n# Create the complete webhook payload\nPAYLOAD=$(cat <<EOF\n{\n  \"embeds\": [{\n    \"title\": \"🤖 Claude Code Activity\",\n    \"description\": \"$EMBED_DESCRIPTION\",\n    \"color\": $COLOR,\n    \"fields\": $FIELDS,\n    \"footer\": {\n      \"text\": \"Claude Code • $DATE_TIME\",\n      \"icon_url\": \"https://claude.ai/favicon.ico\"\n    },\n    \"timestamp\": \"$(date -u +%Y-%m-%dT%H:%M:%S.000Z)\"\n  }]\n}\nEOF\n)\n\n# Send the webhook\nif command -v curl &> /dev/null; then\n  RESPONSE=$(curl -s -w \"%{http_code}\" -H \"Content-Type: application/json\" -X POST -d \"$PAYLOAD\" \"$DISCORD_WEBHOOK_URL\" 2>/dev/null)\n  HTTP_CODE=\"${RESPONSE: -3}\"\n  \n  if [ \"$HTTP_CODE\" = \"204\" ]; then\n    echo \"✅ Discord notification sent successfully\" >&2\n  else\n    echo \"⚠️ Discord notification failed with HTTP code: $HTTP_CODE\" >&2\n  fi\nelse\n  echo \"⚠️ curl not available - cannot send Discord notification\" >&2\nfi\n\nexit 0"
      },
      "useCases": [
        "Real-time team collaboration and activity sharing",
        "Development workflow transparency and communication",
        "Remote team coordination and progress tracking",
        "Automated project activity logging",
        "Integration with team chat workflows"
      ],
      "troubleshooting": [
        {
          "issue": "DISCORD_WEBHOOK_URL environment variable not available in hook execution context",
          "solution": "Export webhook URL in shell profile (.bashrc/.zshrc) or add to Claude Code config. Test with 'echo $DISCORD_WEBHOOK_URL' in hook script to verify environment variable persists."
        },
        {
          "issue": "Discord webhook returns HTTP 400 with 'invalid JSON body' error message",
          "solution": "Validate PAYLOAD JSON structure before sending with 'echo $PAYLOAD | jq' command. Ensure special characters in file names are properly escaped within JSON string values."
        },
        {
          "issue": "Notifications flood Discord channel during rapid-fire Edit or MultiEdit operations",
          "solution": "Add rate limiting by checking notification count per minute using temporary file counter. Skip notification if threshold exceeded, or batch multiple operations into single embed with field array."
        },
        {
          "issue": "Git branch detection fails when hook runs in detached HEAD state",
          "solution": "Add fallback to display commit SHA instead of branch name when 'git branch --show-current' returns empty. Use 'git describe --tags --always' for readable detached HEAD representation."
        },
        {
          "issue": "Timestamp format incompatible with Discord embed RFC3339 requirement causes validation errors",
          "solution": "Ensure 'date -u +%Y-%m-%dT%H:%M:%S.000Z' command generates UTC ISO 8601 format. Use gdate on macOS if BSD date lacks proper UTC formatting support: 'brew install coreutils'."
        }
      ],
      "documentationUrl": "https://discord.com/developers/docs/resources/webhook",
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/discord-activity-notifier"
    },
    {
      "slug": "docker-container-auto-rebuild",
      "description": "Automatically rebuilds Docker containers when Dockerfile or docker-compose.yml files are modified",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "docker",
        "containers",
        "devops",
        "automation"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Automatic Docker image rebuilding on Dockerfile changes",
        "Docker Compose service rebuilding for compose file updates",
        "Intelligent file detection for Docker-related configurations",
        "Support for multiple Docker file patterns and variations",
        "Build status reporting and error handling",
        "Development environment synchronization"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/docker-container-auto-rebuild.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Check if it's a Docker-related file\nif [[ \"$FILE_PATH\" == *Dockerfile* ]] || [[ \"$FILE_PATH\" == *docker-compose* ]] || [[ \"$FILE_PATH\" == *.dockerfile ]] || [[ \"$FILE_PATH\" == *dockerignore* ]]; then\n  echo \"🐳 Docker file detected: $FILE_PATH\" >&2\n  \n  # Check if Docker is available\n  if ! command -v docker &> /dev/null; then\n    echo \"⚠️ Docker not found - install Docker to enable auto-rebuild\" >&2\n    exit 0\n  fi\n  \n  # Check if Docker daemon is running\n  if ! docker info &> /dev/null; then\n    echo \"⚠️ Docker daemon not running - start Docker to enable auto-rebuild\" >&2\n    exit 0\n  fi\n  \n  # Handle different Docker file types\n  if [[ \"$FILE_PATH\" == *Dockerfile* ]] || [[ \"$FILE_PATH\" == *.dockerfile ]]; then\n    echo \"🔨 Dockerfile modified - rebuilding Docker image...\" >&2\n    \n    # Determine image name (use directory name by default)\n    IMAGE_NAME=$(basename \"$(pwd)\"):latest\n    \n    # Check if there's a specific Dockerfile path\n    DOCKERFILE_DIR=$(dirname \"$FILE_PATH\")\n    \n    echo \"📦 Building image: $IMAGE_NAME\" >&2\n    echo \"📁 Build context: $DOCKERFILE_DIR\" >&2\n    \n    # Build the Docker image\n    if docker build -t \"$IMAGE_NAME\" \"$DOCKERFILE_DIR\" 2>&1; then\n      echo \"✅ Docker image '$IMAGE_NAME' rebuilt successfully\" >&2\n      \n      # Show image details\n      IMAGE_ID=$(docker images -q \"$IMAGE_NAME\" | head -1)\n      if [ -n \"$IMAGE_ID\" ]; then\n        IMAGE_SIZE=$(docker images \"$IMAGE_NAME\" --format \"table {{.Size}}\" | tail -1)\n        echo \"📊 Image ID: $IMAGE_ID, Size: $IMAGE_SIZE\" >&2\n      fi\n    else\n      echo \"❌ Docker image build failed\" >&2\n      exit 1\n    fi\n    \n  elif [[ \"$FILE_PATH\" == *docker-compose* ]]; then\n    echo \"🔨 Docker Compose file modified - rebuilding services...\" >&2\n    \n    COMPOSE_FILE=$(basename \"$FILE_PATH\")\n    COMPOSE_DIR=$(dirname \"$FILE_PATH\")\n    \n    echo \"📁 Compose file: $COMPOSE_FILE\" >&2\n    echo \"📁 Working directory: $COMPOSE_DIR\" >&2\n    \n    # Change to the directory containing the compose file\n    cd \"$COMPOSE_DIR\" || exit 1\n    \n    # Check if docker-compose or docker compose is available\n    if command -v docker-compose &> /dev/null; then\n      COMPOSE_CMD=\"docker-compose\"\n    elif docker compose version &> /dev/null; then\n      COMPOSE_CMD=\"docker compose\"\n    else\n      echo \"⚠️ Neither docker-compose nor 'docker compose' found\" >&2\n      exit 0\n    fi\n    \n    # Build the services\n    echo \"🔧 Using: $COMPOSE_CMD\" >&2\n    if $COMPOSE_CMD -f \"$COMPOSE_FILE\" build 2>&1; then\n      echo \"✅ Docker Compose services rebuilt successfully\" >&2\n      \n      # Show service status\n      echo \"📊 Service status:\" >&2\n      $COMPOSE_CMD -f \"$COMPOSE_FILE\" ps --format \"table {{.Service}}\\t{{.Status}}\" 2>/dev/null || true\n    else\n      echo \"❌ Docker Compose build failed\" >&2\n      exit 1\n    fi\n    \n  elif [[ \"$FILE_PATH\" == *dockerignore* ]]; then\n    echo \"📝 .dockerignore file modified\" >&2\n    echo \"💡 This will affect the next Docker build by excluding specified files\" >&2\n    \n    # Show dockerignore contents for reference\n    if [ -f \"$FILE_PATH\" ]; then\n      echo \"📋 Current .dockerignore rules:\" >&2\n      head -10 \"$FILE_PATH\" >&2\n    fi\n  fi\n  \n  # General Docker tips\n  echo \"\" >&2\n  echo \"💡 Docker Development Tips:\" >&2\n  echo \"   • Use .dockerignore to exclude unnecessary files\" >&2\n  echo \"   • Consider multi-stage builds for smaller images\" >&2\n  echo \"   • Use docker system prune to clean up unused resources\" >&2\n  \nelse\n  echo \"File $FILE_PATH is not a Docker-related file, skipping rebuild\" >&2\nfi\n\nexit 0"
      },
      "useCases": [
        "Automated Docker development workflow synchronization",
        "Real-time container rebuilding during development",
        "DevOps pipeline integration for container updates",
        "Multi-service application development with Docker Compose",
        "Continuous integration for containerized applications"
      ],
      "troubleshooting": [
        {
          "issue": "Docker build fails with 'daemon not running' despite Docker Desktop being active",
          "solution": "Verify Docker socket accessibility with 'docker info' command. Restart Docker daemon or add user to docker group on Linux: 'sudo usermod -aG docker $USER' then log out and back in."
        },
        {
          "issue": "Hook triggers rebuild but uses wrong Dockerfile when multiple exist in project",
          "solution": "Specify Dockerfile path explicitly using 'docker build -f $FILE_PATH' instead of relying on directory context. Detect Dockerfile name pattern and use as -f argument for targeted builds."
        },
        {
          "issue": "Docker Compose rebuild hangs indefinitely when services have dependency conflicts",
          "solution": "Add --no-cache flag to force clean rebuild: 'docker-compose build --no-cache'. Stop running containers first with 'docker-compose down' before rebuild to prevent port and resource conflicts."
        },
        {
          "issue": "Build context too large error when .dockerignore changes not respected in hook",
          "solution": "Ensure .dockerignore is in same directory as Dockerfile being built. Docker reads .dockerignore from build context root, not from Dockerfile directory if using -f flag with different path."
        },
        {
          "issue": "Hook exits successfully but image not updated with latest changes after rebuild",
          "solution": "Verify Docker build cache invalidation by checking layer hashes in build output. Add COPY instruction for modified files or use 'docker build --pull --no-cache' to force complete rebuild without cache."
        }
      ],
      "documentationUrl": "https://docs.docker.com/compose/",
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/docker-container-auto-rebuild"
    },
    {
      "slug": "docker-image-security-scanner",
      "description": "Comprehensive Docker image vulnerability scanning with layer analysis, base image recommendations, and security best practices enforcement",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-10-19",
      "tags": [
        "docker",
        "security",
        "containers",
        "vulnerability",
        "devops"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Automated vulnerability scanning on Dockerfile changes",
        "Docker image layer-by-layer security analysis",
        "Base image vulnerability detection and recommendations",
        "Malware and rootkit scanning in container images",
        "Security best practices validation (non-root user, minimal layers)",
        "Integration with Trivy, Grype, and Docker Scout"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/docker-image-security-scanner.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Configuration\nSECURITY_REPORT=\".claude/reports/docker-security-$(date +%Y%m%d).txt\"\nSEVERITY_THRESHOLD=${DOCKER_SCAN_SEVERITY:-HIGH}\nSCAN_ENABLED=${DOCKER_SECURITY_SCAN:-true}\n\nmkdir -p \"$(dirname \"$SECURITY_REPORT\")\"\n\n# Function to check if file is a Dockerfile\nis_dockerfile() {\n  local file=$1\n  [[ \"$file\" == *Dockerfile* ]] || [[ \"$file\" == *.dockerfile ]]\n}\n\n# Function to analyze Dockerfile for security issues\nanalyze_dockerfile_security() {\n  local dockerfile=$1\n  \n  echo \"🔍 Analyzing Dockerfile security practices: $dockerfile\" >&2\n  echo \"\" >> \"$SECURITY_REPORT\"\n  echo \"Dockerfile Security Analysis - $(date)\" >> \"$SECURITY_REPORT\"\n  echo \"========================================\" >> \"$SECURITY_REPORT\"\n  echo \"File: $dockerfile\" >> \"$SECURITY_REPORT\"\n  echo \"\" >> \"$SECURITY_REPORT\"\n  \n  local issues_found=0\n  \n  # Check for non-root user\n  if ! grep -i \"^USER\" \"$dockerfile\" >/dev/null 2>&1; then\n    echo \"⚠️ WARNING: No USER directive found (running as root)\" >&2\n    echo \"[SECURITY] Missing USER directive - container runs as root\" >> \"$SECURITY_REPORT\"\n    issues_found=$((issues_found + 1))\n  fi\n  \n  # Check for version pinning\n  if grep -i \"^FROM.*:latest\" \"$dockerfile\" >/dev/null 2>&1; then\n    echo \"⚠️ WARNING: Using :latest tag (not reproducible)\" >&2\n    echo \"[SECURITY] Base image uses :latest tag instead of pinned version\" >> \"$SECURITY_REPORT\"\n    issues_found=$((issues_found + 1))\n  fi\n  \n  # Check for COPY with broad wildcards\n  if grep -i \"COPY . \" \"$dockerfile\" >/dev/null 2>&1; then\n    echo \"💡 INFO: COPY . detected - ensure .dockerignore excludes secrets\" >&2\n    echo \"[INFO] Broad COPY directive - verify .dockerignore configuration\" >> \"$SECURITY_REPORT\"\n  fi\n  \n  # Check for hardcoded secrets\n  if grep -iE \"PASSWORD|SECRET|TOKEN|KEY.*=\" \"$dockerfile\" >/dev/null 2>&1; then\n    echo \"🚨 CRITICAL: Potential hardcoded secrets detected!\" >&2\n    echo \"[CRITICAL] Hardcoded credentials found - use build args or secrets\" >> \"$SECURITY_REPORT\"\n    issues_found=$((issues_found + 1))\n  fi\n  \n  # Check for HEALTHCHECK\n  if ! grep -i \"^HEALTHCHECK\" \"$dockerfile\" >/dev/null 2>&1; then\n    echo \"💡 INFO: No HEALTHCHECK directive (recommended for production)\" >&2\n    echo \"[INFO] Missing HEALTHCHECK - consider adding for production readiness\" >> \"$SECURITY_REPORT\"\n  fi\n  \n  # Check for minimal base images\n  if grep -iE \"FROM.*ubuntu|FROM.*debian\" \"$dockerfile\" >/dev/null 2>&1; then\n    echo \"💡 INFO: Consider using alpine or distroless for smaller attack surface\" >&2\n    echo \"[INFO] Full OS base image - consider alpine or distroless alternatives\" >> \"$SECURITY_REPORT\"\n  fi\n  \n  echo \"\" >> \"$SECURITY_REPORT\"\n  echo \"Issues found: $issues_found\" >> \"$SECURITY_REPORT\"\n  \n  return $issues_found\n}\n\n# Function to scan image with Trivy\nscan_with_trivy() {\n  local image=$1\n  \n  if ! command -v trivy &> /dev/null; then\n    echo \"💡 Install Trivy for comprehensive vulnerability scanning\" >&2\n    echo \"   brew install trivy (macOS)\" >&2\n    echo \"   apt install trivy (Debian/Ubuntu)\" >&2\n    return\n  fi\n  \n  echo \"🔒 Scanning image with Trivy: $image\" >&2\n  \n  echo \"\" >> \"$SECURITY_REPORT\"\n  echo \"Trivy Vulnerability Scan\" >> \"$SECURITY_REPORT\"\n  echo \"========================\" >> \"$SECURITY_REPORT\"\n  \n  # Run Trivy scan\n  trivy image --severity \"$SEVERITY_THRESHOLD\",CRITICAL \\\n    --format json \"$image\" 2>/dev/null | \\\n    jq -r '.Results[]? | .Vulnerabilities[]? | \"\\(.VulnerabilityID): \\(.Severity) - \\(.Title)\"' 2>/dev/null | \\\n    head -20 >> \"$SECURITY_REPORT\" || \\\n    echo \"✅ No vulnerabilities found at $SEVERITY_THRESHOLD or higher severity\" >> \"$SECURITY_REPORT\"\n  \n  # Get summary\n  local vuln_count=$(trivy image --severity CRITICAL,HIGH --format json \"$image\" 2>/dev/null | \\\n    jq '[.Results[]?.Vulnerabilities[]?] | length' 2>/dev/null || echo \"0\")\n  \n  if [ \"$vuln_count\" -gt 0 ]; then\n    echo \"\" >&2\n    echo \"🚨 Found $vuln_count HIGH/CRITICAL vulnerabilities in $image\" >&2\n    echo \"💡 Review full report: $SECURITY_REPORT\" >&2\n  else\n    echo \"✅ No critical vulnerabilities detected\" >&2\n  fi\n}\n\n# Function to scan with Docker Scout\nscan_with_docker_scout() {\n  local image=$1\n  \n  if ! docker scout version &> /dev/null 2>&1; then\n    echo \"💡 Docker Scout available in Docker Desktop 4.17+\" >&2\n    return\n  fi\n  \n  echo \"🔍 Scanning with Docker Scout: $image\" >&2\n  \n  echo \"\" >> \"$SECURITY_REPORT\"\n  echo \"Docker Scout Analysis\" >> \"$SECURITY_REPORT\"\n  echo \"=====================\" >> \"$SECURITY_REPORT\"\n  \n  docker scout cves \"$image\" --format json 2>/dev/null | \\\n    jq -r '.vulnerabilities[] | \"\\(.id): \\(.severity) - \\(.packageName)\"' 2>/dev/null | \\\n    head -15 >> \"$SECURITY_REPORT\" || \\\n    echo \"✅ Scout scan complete\" >> \"$SECURITY_REPORT\"\n}\n\n# Main execution\nif is_dockerfile \"$FILE_PATH\"; then\n  echo \"🐳 Dockerfile detected: $FILE_PATH\" >&2\n  \n  if [ \"$SCAN_ENABLED\" != \"true\" ]; then\n    echo \"ℹ️ Security scanning disabled (DOCKER_SECURITY_SCAN=false)\" >&2\n    exit 0\n  fi\n  \n  # Analyze Dockerfile best practices\n  analyze_dockerfile_security \"$FILE_PATH\"\n  \n  # Try to determine image name\n  IMAGE_NAME=$(grep -i \"^FROM\" \"$FILE_PATH\" | tail -1 | awk '{print $2}')\n  \n  if [ -n \"$IMAGE_NAME\" ]; then\n    echo \"📦 Base image: $IMAGE_NAME\" >&2\n    \n    # Check if Docker is available and daemon is running\n    if command -v docker &> /dev/null && docker info &> /dev/null 2>&1; then\n      # Pull image if not present\n      if ! docker image inspect \"$IMAGE_NAME\" &> /dev/null; then\n        echo \"📥 Pulling base image for scanning...\" >&2\n        docker pull \"$IMAGE_NAME\" >&2 2>/dev/null || \\\n          echo \"⚠️ Could not pull image for scanning\" >&2\n      fi\n      \n      # Run security scans\n      scan_with_trivy \"$IMAGE_NAME\"\n      scan_with_docker_scout \"$IMAGE_NAME\"\n    else\n      echo \"⚠️ Docker daemon not running - cannot scan images\" >&2\n    fi\n  fi\n  \n  # Display security best practices\n  echo \"\" >&2\n  echo \"🛡️ Docker Security Best Practices:\" >&2\n  echo \"   • Use specific version tags, not :latest\" >&2\n  echo \"   • Run containers as non-root user (USER directive)\" >&2\n  echo \"   • Use multi-stage builds to minimize image size\" >&2\n  echo \"   • Scan images regularly with Trivy or Docker Scout\" >&2\n  echo \"   • Keep base images updated and prefer minimal bases\" >&2\n  echo \"   • Never include secrets in images (use build secrets)\" >&2\n  \n  if [ -s \"$SECURITY_REPORT\" ]; then\n    echo \"\" >&2\n    echo \"📄 Full security report: $SECURITY_REPORT\" >&2\n  fi\nfi\n\nexit 0"
      },
      "useCases": [
        "Automated container security validation in development",
        "CI/CD pipeline integration for image vulnerability scanning",
        "Compliance enforcement for containerized applications",
        "Supply chain security for base image verification",
        "Production readiness checks before deployment"
      ],
      "troubleshooting": [
        {
          "issue": "Trivy scan fails with database update errors",
          "solution": "Update Trivy vulnerability DB: trivy image --download-db-only. Check network connectivity to ghcr.io registry. Use offline mode with cached DB: trivy --skip-update. Clear cache: rm -rf ~/.cache/trivy."
        },
        {
          "issue": "Hook detects Dockerfile but Docker daemon not accessible",
          "solution": "Start Docker Desktop or dockerd service. Check DOCKER_HOST environment variable. Verify user permissions: sudo usermod -aG docker $USER. Test with docker info before running hook."
        },
        {
          "issue": "False positive warnings for multi-stage builds with root",
          "solution": "Hook checks final stage only if multiple USER directives. Add USER in final stage even if earlier stages use root. Use comments to document why root needed in build stages."
        },
        {
          "issue": "Base image pull fails behind corporate proxy or firewall",
          "solution": "Configure Docker proxy in daemon.json. Use internal registry mirror. Pre-pull images: docker pull before hook runs. Skip image scanning: DOCKER_SECURITY_SCAN=false."
        },
        {
          "issue": "Docker Scout shows different results than Trivy",
          "solution": "Different vulnerability databases and update frequencies. Scout uses Docker's curated database. Trivy uses multiple sources. Cross-reference both for comprehensive coverage. Check scan timestamps."
        }
      ],
      "documentationUrl": "https://aquasecurity.github.io/trivy/",
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/docker-image-security-scanner"
    },
    {
      "slug": "documentation-auto-generator-on-stop",
      "seoTitle": "Doc Auto Generator",
      "description": "Automatically generates or updates project documentation when session ends",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "documentation",
        "stop-hook",
        "automation",
        "markdown",
        "jsdoc"
      ],
      "hookType": "Stop",
      "features": [
        "Automatic API documentation generation for multiple languages",
        "Changelog updates with session summaries",
        "Support for JSDoc, TypeDoc, Sphinx, and other doc generators",
        "Project structure analysis and documentation",
        "README file updates and maintenance",
        "Multi-format output (HTML, Markdown, PDF)"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "stop": {
              "script": "./.claude/hooks/documentation-auto-generator-on-stop.sh"
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\necho \"📚 Starting documentation generation...\" >&2\n\n# Create docs directory if it doesn't exist\nmkdir -p ./docs\n\n# Generate timestamp for session\nSESSION_DATE=$(date +\"%Y-%m-%d\")\nSESSION_TIME=$(date +\"%H:%M:%S\")\nTIMESTAMP=\"$SESSION_DATE $SESSION_TIME\"\n\n# Count modified files if in git repo\nMODIFIED_COUNT=0\nif command -v git &> /dev/null && git rev-parse --git-dir > /dev/null 2>&1; then\n  MODIFIED_COUNT=$(git diff --name-only 2>/dev/null | wc -l | xargs)\nfi\n\necho \"📊 Session summary: $MODIFIED_COUNT files modified\" >&2\n\n# JavaScript/TypeScript projects\nif [ -f \"package.json\" ]; then\n  echo \"🟡 JavaScript/TypeScript project detected\" >&2\n  \n  # Try TypeDoc first for TypeScript projects\n  if ls *.ts src/**/*.ts 2>/dev/null | head -1 > /dev/null; then\n    if command -v npx &> /dev/null && npx typedoc --version &> /dev/null 2>&1; then\n      echo \"📝 Generating TypeDoc documentation...\" >&2\n      npx typedoc --out ./docs/api src 2>/dev/null && echo \"✅ TypeDoc documentation generated\" >&2\n    else\n      echo \"💡 Install TypeDoc for better TypeScript docs: npm install -g typedoc\" >&2\n    fi\n  fi\n  \n  # Try JSDoc for JavaScript projects\n  if [ -f \"jsdoc.json\" ] || [ -f \"jsdoc.conf.json\" ]; then\n    if command -v npx &> /dev/null && npx jsdoc --version &> /dev/null 2>&1; then\n      echo \"📝 Generating JSDoc documentation...\" >&2\n      npx jsdoc -c jsdoc.json 2>/dev/null || npx jsdoc -c jsdoc.conf.json 2>/dev/null\n      [ $? -eq 0 ] && echo \"✅ JSDoc documentation generated\" >&2\n    fi\n  fi\n  \n  # Try documentation.js as fallback\n  if command -v npx &> /dev/null; then\n    if npx documentation --version &> /dev/null 2>&1; then\n      echo \"📝 Generating documentation.js docs...\" >&2\n      npx documentation build './src/**/*.js' -f md -o ./docs/api.md 2>/dev/null\n      [ $? -eq 0 ] && echo \"✅ Documentation.js docs generated\" >&2\n    fi\n  fi\nfi\n\n# Python projects\nif [ -f \"setup.py\" ] || [ -f \"pyproject.toml\" ] || [ -f \"requirements.txt\" ]; then\n  echo \"🐍 Python project detected\" >&2\n  \n  # Try pdoc for simple API docs\n  if command -v pdoc &> /dev/null; then\n    echo \"📝 Generating pdoc documentation...\" >&2\n    pdoc --html --output-dir ./docs . 2>/dev/null && echo \"✅ pdoc documentation generated\" >&2\n  elif command -v python &> /dev/null; then\n    if python -c \"import pdoc\" 2>/dev/null; then\n      echo \"📝 Generating pdoc documentation...\" >&2\n      python -m pdoc --html --output-dir ./docs . 2>/dev/null && echo \"✅ pdoc documentation generated\" >&2\n    fi\n  fi\n  \n  # Try Sphinx for comprehensive docs\n  if [ -f \"docs/conf.py\" ]; then\n    if command -v sphinx-build &> /dev/null; then\n      echo \"📝 Building Sphinx documentation...\" >&2\n      sphinx-build -b html docs ./docs/_build 2>/dev/null && echo \"✅ Sphinx documentation built\" >&2\n    fi\n  elif command -v sphinx-quickstart &> /dev/null; then\n    echo \"📝 Setting up Sphinx documentation...\" >&2\n    PROJECT_NAME=$(basename \"$(pwd)\")\n    sphinx-quickstart -q -p \"$PROJECT_NAME\" -a \"Claude\" --ext-autodoc --makefile docs 2>/dev/null\n    [ $? -eq 0 ] && echo \"✅ Sphinx project initialized in docs/\" >&2\n  fi\nfi\n\n# Go projects\nif [ -f \"go.mod\" ]; then\n  echo \"🐹 Go project detected\" >&2\n  \n  if command -v go &> /dev/null; then\n    echo \"📝 Generating Go documentation...\" >&2\n    go doc -all > ./docs/api.txt 2>/dev/null && echo \"✅ Go documentation generated\" >&2\n    \n    # Try godoc if available\n    if command -v godoc &> /dev/null; then\n      echo \"💡 Run 'godoc -http=:6060' to serve documentation locally\" >&2\n    fi\n  fi\nfi\n\n# Rust projects\nif [ -f \"Cargo.toml\" ]; then\n  echo \"🦀 Rust project detected\" >&2\n  \n  if command -v cargo &> /dev/null; then\n    echo \"📝 Generating Rust documentation...\" >&2\n    cargo doc --no-deps --target-dir ./docs/rust 2>/dev/null && echo \"✅ Rust documentation generated\" >&2\n  fi\nfi\n\n# Update CHANGELOG.md\necho \"📝 Updating changelog...\" >&2\nCHANGELOG_ENTRY=\"## Session $SESSION_DATE at $SESSION_TIME\\n\\n- Files modified: $MODIFIED_COUNT\\n- Documentation updated automatically\\n- Session completed\\n\\n\"\n\nif [ -f \"CHANGELOG.md\" ]; then\n  # Prepend to existing changelog\n  echo -e \"$CHANGELOG_ENTRY$(cat CHANGELOG.md)\" > CHANGELOG.md.tmp && mv CHANGELOG.md.tmp CHANGELOG.md\nelse\n  # Create new changelog\n  echo -e \"# Changelog\\n\\n$CHANGELOG_ENTRY\" > CHANGELOG.md\nfi\n\necho \"✅ Changelog updated\" >&2\n\n# Generate or update README.md if it doesn't exist\nif [ ! -f \"README.md\" ]; then\n  echo \"📝 Creating basic README.md...\" >&2\n  PROJECT_NAME=$(basename \"$(pwd)\")\n  cat > README.md << EOF\n# $PROJECT_NAME\n\nProject documentation generated automatically.\n\n## Documentation\n\nAPI documentation can be found in the \\`docs/\\` directory.\n\n## Last Updated\n\n$TIMESTAMP\nEOF\n  echo \"✅ README.md created\" >&2\nfi\n\n# Create documentation index\necho \"📋 Creating documentation index...\" >&2\ncat > ./docs/index.md << EOF\n# Project Documentation\n\nGenerated on: $TIMESTAMP\n\n## Available Documentation\n\nEOF\n\n# List available documentation files\nfind ./docs -name \"*.md\" -o -name \"*.html\" -o -name \"index.html\" 2>/dev/null | while read -r file; do\n  echo \"- [$(basename \"$file\")]($(basename \"$file\"))\" >> ./docs/index.md\ndone\n\necho \"\" >&2\necho \"📚 Documentation generation completed!\" >&2\necho \"📁 Check the ./docs/ directory for generated documentation\" >&2\necho \"📋 Documentation index available at ./docs/index.md\" >&2\n\nexit 0"
      },
      "useCases": [
        "Automated API documentation maintenance",
        "End-of-session project documentation updates",
        "Multi-language documentation generation",
        "Changelog automation and project tracking",
        "Development workflow documentation integration"
      ],
      "troubleshooting": [
        {
          "issue": "TypeDoc generation fails with 'unable to resolve entry point' configuration error",
          "solution": "Create tsconfig.json with explicit include paths or add 'entryPoints' to typedoc.json config. Use 'npx typedoc --entryPoints src/index.ts' to specify entry point directly in command."
        },
        {
          "issue": "CHANGELOG.md grows unbounded as every session appends duplicate timestamp entries",
          "solution": "Implement changelog rotation by keeping only last 50 entries or use date-based sections. Archive old entries to CHANGELOG.archive.md when main file exceeds size threshold like 10KB."
        },
        {
          "issue": "Documentation generation completes but docs directory remains empty after stop hook",
          "solution": "Check documentation tool exit codes and stderr output for generation failures. Ensure write permissions on docs directory and verify sufficient disk space for generated HTML and asset files."
        },
        {
          "issue": "Sphinx autodoc fails to import modules during documentation build process",
          "solution": "Add project root to PYTHONPATH in hook script: 'export PYTHONPATH=\"${PYTHONPATH}:$(pwd)\"'. Install project dependencies in documentation build environment before running sphinx-build command."
        },
        {
          "issue": "Hook execution timeout when building large documentation sets on session stop",
          "solution": "Move heavy documentation builds to separate CI job instead of stop hook. Use lightweight generators like pdoc for stop hook, reserving Sphinx or comprehensive builds for scheduled documentation updates."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/documentation-auto-generator-on-stop"
    },
    {
      "slug": "documentation-coverage-checker",
      "description": "Automated documentation coverage analysis with missing docstring detection, API documentation validation, and completeness scoring",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-10-19",
      "tags": [
        "documentation",
        "code-quality",
        "analysis",
        "automation",
        "best-practices"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Automatic detection of undocumented functions and classes",
        "JSDoc, TSDoc, and Python docstring validation",
        "API endpoint documentation completeness checking",
        "Documentation coverage metrics and reporting",
        "README and changelog freshness validation",
        "Support for multiple languages and documentation formats"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/documentation-coverage-checker.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Configuration\nREPORT_FILE=\".claude/reports/docs-coverage-$(date +%Y%m%d).txt\"\nMIN_COVERAGE=${DOC_COVERAGE_THRESHOLD:-70}\n\nmkdir -p \"$(dirname \"$REPORT_FILE\")\"\n\n# Function to check if file needs documentation review\nneeds_doc_check() {\n  local file=$1\n  \n  case \"$file\" in\n    *.js|*.jsx|*.ts|*.tsx|*.py|*.go|*.rs|*.java|*.rb)\n      return 0\n      ;;\n    *)\n      return 1\n      ;;\n  esac\n}\n\n# Function to check JavaScript/TypeScript documentation\ncheck_js_ts_docs() {\n  local file=$1\n  \n  echo \"📝 Checking JS/TS documentation: $file\" >&2\n  \n  # Count functions\n  local total_functions=$(grep -cE \"^\\s*(export\\s+)?(async\\s+)?function\\s+\\w+|^\\s*const\\s+\\w+\\s*=\\s*(async\\s+)?\\(|^\\s*\\w+\\s*\\(.*\\)\\s*\\{\" \"$file\" 2>/dev/null || echo \"0\")\n  \n  # Count documented functions (with JSDoc /** */)\n  local documented=$(grep -B1 -cE \"^\\s*\\/\\*\\*\" \"$file\" 2>/dev/null || echo \"0\")\n  \n  if [ \"$total_functions\" -gt 0 ]; then\n    local coverage=$((documented * 100 / total_functions))\n    \n    echo \"\" >> \"$REPORT_FILE\"\n    echo \"JavaScript/TypeScript Documentation - $file\" >> \"$REPORT_FILE\"\n    echo \"Total functions: $total_functions\" >> \"$REPORT_FILE\"\n    echo \"Documented: $documented\" >> \"$REPORT_FILE\"\n    echo \"Coverage: ${coverage}%\" >> \"$REPORT_FILE\"\n    \n    if [ \"$coverage\" -lt \"$MIN_COVERAGE\" ]; then\n      echo \"⚠️ Documentation coverage ${coverage}% below threshold ${MIN_COVERAGE}%\" >&2\n      echo \"💡 Add JSDoc comments to exported functions\" >&2\n    else\n      echo \"✅ Documentation coverage: ${coverage}%\" >&2\n    fi\n  fi\n  \n  # Check for exported items without docs\n  if grep -E \"^export (class|function|const|interface|type)\" \"$file\" >/dev/null 2>&1; then\n    echo \"📦 Exported items detected - ensure public API is documented\" >&2\n  fi\n}\n\n# Function to check Python documentation\ncheck_python_docs() {\n  local file=$1\n  \n  echo \"🐍 Checking Python documentation: $file\" >&2\n  \n  # Use interrogate if available\n  if command -v interrogate &> /dev/null; then\n    echo \"\" >> \"$REPORT_FILE\"\n    echo \"Python Docstring Coverage - $file\" >> \"$REPORT_FILE\"\n    \n    local coverage_output=$(interrogate -v \"$file\" 2>/dev/null)\n    echo \"$coverage_output\" >> \"$REPORT_FILE\"\n    \n    # Extract coverage percentage\n    local coverage=$(echo \"$coverage_output\" | grep -oE '[0-9]+\\.[0-9]+%' | head -1 | tr -d '%')\n    \n    if [ -n \"$coverage\" ]; then\n      if (( $(echo \"$coverage < $MIN_COVERAGE\" | bc -l) )); then\n        echo \"⚠️ Docstring coverage ${coverage}% below threshold ${MIN_COVERAGE}%\" >&2\n      else\n        echo \"✅ Docstring coverage: ${coverage}%\" >&2\n      fi\n    fi\n  else\n    # Manual check for docstrings\n    local total_defs=$(grep -cE \"^\\s*def\\s+\\w+|^\\s*class\\s+\\w+\" \"$file\" 2>/dev/null || echo \"0\")\n    local documented=$(grep -A1 -cE \"^\\s*def\\s+\\w+|^\\s*class\\s+\\w+\" \"$file\" | grep -c '\"\"\"' || echo \"0\")\n    \n    if [ \"$total_defs\" -gt 0 ]; then\n      local coverage=$((documented * 100 / total_defs))\n      echo \"⚠️ Estimated docstring coverage: ${coverage}%\" >&2\n      echo \"💡 Install interrogate for accurate analysis: pip install interrogate\" >&2\n    fi\n  fi\n}\n\n# Function to check Go documentation\ncheck_go_docs() {\n  local file=$1\n  \n  echo \"🐹 Checking Go documentation: $file\" >&2\n  \n  if command -v go &> /dev/null; then\n    # Use go doc if available\n    if go doc -all 2>/dev/null | grep -q \"$file\"; then\n      echo \"✅ Go documentation present\" >&2\n    else\n      echo \"💡 Add godoc comments to exported functions/types\" >&2\n    fi\n  fi\n  \n  # Check for exported items without comments\n  local undocumented=$(grep -E \"^func [A-Z]|^type [A-Z]\" \"$file\" | \\\n    while read -r line; do\n      grep -B1 \"$line\" \"$file\" | head -1 | grep -q \"^//\" || echo \"$line\"\n    done | wc -l)\n  \n  if [ \"$undocumented\" -gt 0 ]; then\n    echo \"⚠️ Found $undocumented undocumented exported items\" >&2\n  fi\n}\n\n# Function to check README freshness\ncheck_readme_freshness() {\n  if [ -f \"README.md\" ]; then\n    local readme_age=$(($(date +%s) - $(stat -f%m \"README.md\" 2>/dev/null || stat -c%Y \"README.md\" 2>/dev/null || echo \"0\")))\n    local days_old=$((readme_age / 86400))\n    \n    if [ \"$days_old\" -gt 90 ]; then\n      echo \"📋 README.md is $days_old days old - consider updating\" >&2\n    fi\n  else\n    echo \"⚠️ No README.md found - create project documentation\" >&2\n  fi\n}\n\n# Function to check API documentation\ncheck_api_docs() {\n  local file=$1\n  \n  # Check for API route definitions\n  if grep -iE \"@(get|post|put|delete|patch)|router\\.(get|post|put|delete|patch)|app\\.(get|post|put|delete|patch)\" \"$file\" >/dev/null 2>&1; then\n    echo \"🌐 API endpoint detected in: $file\" >&2\n    \n    # Check for OpenAPI/Swagger comments\n    if ! grep -E \"@swagger|@openapi|@api\" \"$file\" >/dev/null 2>&1; then\n      echo \"💡 Consider adding OpenAPI/Swagger documentation for API endpoints\" >&2\n    fi\n    \n    # Check for request/response documentation\n    if ! grep -E \"@param|@returns|@request|@response\" \"$file\" >/dev/null 2>&1; then\n      echo \"💡 Document request parameters and response types\" >&2\n    fi\n  fi\n}\n\n# Main execution\nif needs_doc_check \"$FILE_PATH\"; then\n  echo \"📚 Documentation check triggered: $FILE_PATH\" >&2\n  \n  # Language-specific checks\n  case \"$FILE_PATH\" in\n    *.js|*.jsx|*.ts|*.tsx)\n      check_js_ts_docs \"$FILE_PATH\"\n      check_api_docs \"$FILE_PATH\"\n      ;;\n    *.py)\n      check_python_docs \"$FILE_PATH\"\n      check_api_docs \"$FILE_PATH\"\n      ;;\n    *.go)\n      check_go_docs \"$FILE_PATH\"\n      ;;\n  esac\n  \n  # General documentation checks\n  check_readme_freshness\n  \n  # Documentation best practices\n  echo \"\" >&2\n  echo \"📖 Documentation Best Practices:\" >&2\n  echo \"   • Document all public APIs and exported functions\" >&2\n  echo \"   • Include parameter types and return values\" >&2\n  echo \"   • Add usage examples for complex functions\" >&2\n  echo \"   • Keep README.md up-to-date with recent changes\" >&2\n  echo \"   • Use consistent documentation format (JSDoc/TSDoc/etc)\" >&2\n  \n  if [ -s \"$REPORT_FILE\" ]; then\n    echo \"\" >&2\n    echo \"📄 Documentation report: $REPORT_FILE\" >&2\n  fi\nelif [[ \"$FILE_PATH\" == *README* ]] || [[ \"$FILE_PATH\" == *CHANGELOG* ]]; then\n  echo \"📝 Documentation file updated: $(basename \"$FILE_PATH\")\" >&2\n  echo \"✅ Keep documentation current with code changes\" >&2\nfi\n\nexit 0"
      },
      "useCases": [
        "Automated documentation quality enforcement in development",
        "API documentation completeness validation",
        "Code review preparation with documentation checks",
        "Open source project documentation standards",
        "Technical debt tracking for missing documentation"
      ],
      "troubleshooting": [
        {
          "issue": "Hook reports low coverage but functions have inline comments",
          "solution": "Hook detects structured docstrings (JSDoc/TSDoc) not inline comments. Convert // comments to /** */ JSDoc format. Use @param and @returns tags for proper documentation detection."
        },
        {
          "issue": "Python interrogate not found but installed in virtualenv",
          "solution": "Activate virtualenv before hook runs: source venv/bin/activate in shell config. Use absolute path to interrogate binary. Add virtualenv bin directory to PATH in hook script."
        },
        {
          "issue": "False positives on private/internal functions flagged as undocumented",
          "solution": "Hook checks all functions regardless of visibility. Use naming conventions (_private in Python). Configure threshold lower for internal files. Add @internal JSDoc tag to suppress warnings."
        },
        {
          "issue": "Coverage threshold environment variable not applied",
          "solution": "Export DOC_COVERAGE_THRESHOLD before hook execution. Check bash environment in hook context. Set in .clauderc or shell profile. Verify with echo $DOC_COVERAGE_THRESHOLD in hook script."
        },
        {
          "issue": "API endpoint detection triggers on test files with mock routes",
          "solution": "Hook matches route patterns without context awareness. Exclude test directories from matchers: ! [[ $FILE_PATH == *test* ]]. Add separate threshold for test documentation."
        }
      ],
      "documentationUrl": "https://jsdoc.app/",
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/documentation-coverage-checker"
    },
    {
      "slug": "documentation-generator",
      "description": "Automatically generates and updates project documentation from code comments, README files, and API definitions",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-16",
      "tags": [
        "documentation",
        "automation",
        "api",
        "markdown",
        "jsdoc"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Real-time documentation generation from code comments",
        "Multi-language support (JavaScript, TypeScript, Python, Go, Rust)",
        "API documentation extraction from JSDoc, docstrings, and comments",
        "README.md analysis and improvement suggestions",
        "Documentation quality and completeness checking",
        "Integration with popular documentation tools"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/documentation-generator.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Check if it's a documentation-relevant file\nif [[ \"$FILE_PATH\" == *.js ]] || [[ \"$FILE_PATH\" == *.jsx ]] || [[ \"$FILE_PATH\" == *.ts ]] || [[ \"$FILE_PATH\" == *.tsx ]] || [[ \"$FILE_PATH\" == *.py ]] || [[ \"$FILE_PATH\" == *.go ]] || [[ \"$FILE_PATH\" == *.rs ]] || [[ \"$FILE_PATH\" == *README* ]] || [[ \"$FILE_PATH\" == *.md ]]; then\n  echo \"📚 Documentation-relevant file detected: $FILE_PATH\" >&2\n  \n  # Create docs directory if it doesn't exist\n  mkdir -p ./docs\n  \n  # JavaScript/TypeScript documentation\n  if [[ \"$FILE_PATH\" == *.js ]] || [[ \"$FILE_PATH\" == *.jsx ]] || [[ \"$FILE_PATH\" == *.ts ]] || [[ \"$FILE_PATH\" == *.tsx ]]; then\n    echo \"🟡 JavaScript/TypeScript file - checking for documentation...\" >&2\n    \n    # Check for JSDoc comments\n    if [ -f \"$FILE_PATH\" ]; then\n      JSDOC_COMMENTS=$(grep -c '/\\*\\*' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n      FUNCTIONS=$(grep -c '^\\s*\\(function\\|const\\s.*=>\\|class\\)' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n      \n      echo \"📊 Found $JSDOC_COMMENTS JSDoc comments and $FUNCTIONS functions/classes\" >&2\n      \n      if [ \"$JSDOC_COMMENTS\" -gt 0 ]; then\n        # Try generating JSDoc documentation\n        if command -v npx &> /dev/null; then\n          if npx jsdoc --version &> /dev/null 2>&1; then\n            echo \"📝 Generating JSDoc documentation...\" >&2\n            npx jsdoc \"$FILE_PATH\" -d ./docs/jsdoc 2>/dev/null && echo \"✅ JSDoc documentation generated\" >&2\n          fi\n          \n          # Try jsdoc2md for markdown output\n          if npx jsdoc2md --version &> /dev/null 2>&1; then\n            echo \"📝 Generating Markdown documentation...\" >&2\n            npx jsdoc2md \"$FILE_PATH\" > \"./docs/$(basename \"$FILE_PATH\" .js).md\" 2>/dev/null && echo \"✅ Markdown documentation generated\" >&2\n          fi\n        fi\n      else\n        echo \"💡 Consider adding JSDoc comments to improve documentation coverage\" >&2\n      fi\n      \n      # TypeScript-specific documentation\n      if [[ \"$FILE_PATH\" == *.ts ]] || [[ \"$FILE_PATH\" == *.tsx ]]; then\n        if command -v npx &> /dev/null && npx typedoc --version &> /dev/null 2>&1; then\n          echo \"📝 Generating TypeDoc documentation...\" >&2\n          npx typedoc \"$FILE_PATH\" --out ./docs/typedoc 2>/dev/null && echo \"✅ TypeDoc documentation generated\" >&2\n        else\n          echo \"💡 Install TypeDoc for comprehensive TypeScript documentation: npm install -g typedoc\" >&2\n        fi\n      fi\n    fi\n    \n  # Python documentation\n  elif [[ \"$FILE_PATH\" == *.py ]]; then\n    echo \"🐍 Python file - checking for documentation...\" >&2\n    \n    if [ -f \"$FILE_PATH\" ]; then\n      DOCSTRINGS=$(grep -c '\"\"\"\\|'\\''\\''\\'''' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n      FUNCTIONS=$(grep -c '^def\\s\\|^class\\s' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n      \n      echo \"📊 Found $DOCSTRINGS docstrings and $FUNCTIONS functions/classes\" >&2\n      \n      # Try generating Python documentation\n      if command -v pdoc &> /dev/null; then\n        echo \"📝 Generating pdoc documentation...\" >&2\n        pdoc \"$FILE_PATH\" --html --output-dir ./docs/python 2>/dev/null && echo \"✅ Python documentation generated\" >&2\n      elif command -v python &> /dev/null; then\n        if python -c \"import pydoc\" 2>/dev/null; then\n          echo \"📝 Generating pydoc documentation...\" >&2\n          python -m pydoc -w \"$FILE_PATH\" 2>/dev/null && echo \"✅ Python documentation generated\" >&2\n        fi\n      fi\n      \n      if [ \"$DOCSTRINGS\" -eq 0 ] && [ \"$FUNCTIONS\" -gt 0 ]; then\n        echo \"💡 Consider adding docstrings to Python functions and classes\" >&2\n      fi\n    fi\n    \n  # Go documentation\n  elif [[ \"$FILE_PATH\" == *.go ]]; then\n    echo \"🐹 Go file - checking for documentation...\" >&2\n    \n    if [ -f \"$FILE_PATH\" ] && command -v go &> /dev/null; then\n      COMMENTS=$(grep -c '^//\\s' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n      echo \"📊 Found $COMMENTS documentation comments\" >&2\n      \n      echo \"📝 Generating Go documentation...\" >&2\n      go doc \"$FILE_PATH\" > \"./docs/$(basename \"$FILE_PATH\" .go).txt\" 2>/dev/null && echo \"✅ Go documentation generated\" >&2\n    fi\n    \n  # Rust documentation\n  elif [[ \"$FILE_PATH\" == *.rs ]]; then\n    echo \"🦀 Rust file - checking for documentation...\" >&2\n    \n    if [ -f \"$FILE_PATH\" ] && command -v cargo &> /dev/null; then\n      DOC_COMMENTS=$(grep -c '^///\\|^//!' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n      echo \"📊 Found $DOC_COMMENTS documentation comments\" >&2\n      \n      if [ \"$DOC_COMMENTS\" -gt 0 ]; then\n        echo \"📝 Generating Rust documentation...\" >&2\n        cargo doc --no-deps --target-dir ./docs/rust 2>/dev/null && echo \"✅ Rust documentation generated\" >&2\n      else\n        echo \"💡 Consider adding /// documentation comments to Rust code\" >&2\n      fi\n    fi\n    \n  # README and markdown documentation\n  elif [[ \"$FILE_PATH\" == *README* ]] || [[ \"$FILE_PATH\" == *.md ]]; then\n    echo \"📝 Markdown file - analyzing documentation structure...\" >&2\n    \n    if [ -f \"$FILE_PATH\" ]; then\n      HEADERS=$(grep -c '^#' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n      CODE_BLOCKS=$(grep -c '^```' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n      LINKS=$(grep -c '\\[.*\\](.*)' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n      \n      echo \"📊 Document structure: $HEADERS headers, $CODE_BLOCKS code blocks, $LINKS links\" >&2\n      \n      # Check for common README sections\n      if [[ \"$FILE_PATH\" == *README* ]]; then\n        echo \"📋 Checking README completeness...\" >&2\n        \n        REQUIRED_SECTIONS=(\"Installation\" \"Usage\" \"API\" \"Contributing\" \"License\")\n        MISSING_SECTIONS=()\n        \n        for section in \"${REQUIRED_SECTIONS[@]}\"; do\n          if ! grep -qi \"^#.*$section\" \"$FILE_PATH\"; then\n            MISSING_SECTIONS+=(\"$section\")\n          fi\n        done\n        \n        if [ ${#MISSING_SECTIONS[@]} -eq 0 ]; then\n          echo \"✅ README contains all recommended sections\" >&2\n        else\n          echo \"💡 Consider adding these sections: ${MISSING_SECTIONS[*]}\" >&2\n        fi\n        \n        # Check for project metadata\n        if [ -f \"package.json\" ]; then\n          PROJECT_NAME=$(jq -r '.name // \"unknown\"' package.json 2>/dev/null)\n          PROJECT_DESC=$(jq -r '.description // \"\"' package.json 2>/dev/null)\n          \n          if ! grep -q \"$PROJECT_NAME\" \"$FILE_PATH\"; then\n            echo \"💡 Consider mentioning project name '$PROJECT_NAME' in README\" >&2\n          fi\n        fi\n      fi\n      \n      # Check for broken links (basic check)\n      if [ \"$LINKS\" -gt 0 ]; then\n        echo \"🔗 Found $LINKS links - consider running a link checker\" >&2\n      fi\n    fi\n  fi\n  \n  # General documentation quality tips\n  echo \"\" >&2\n  echo \"📋 Documentation Best Practices:\" >&2\n  echo \"   • Add clear function/method descriptions\" >&2\n  echo \"   • Include parameter types and return values\" >&2\n  echo \"   • Provide usage examples in documentation\" >&2\n  echo \"   • Keep README updated with latest changes\" >&2\n  \nelse\n  echo \"File $FILE_PATH is not relevant for documentation generation, skipping\" >&2\nfi\n\nexit 0"
      },
      "useCases": [
        "Real-time documentation updates during development",
        "API documentation maintenance and generation",
        "Code quality improvement through documentation analysis",
        "Multi-language project documentation consistency",
        "README and project documentation enhancement"
      ],
      "troubleshooting": [
        {
          "issue": "Hook runs on every file edit causing slow workflows",
          "solution": "Refine matchers to specific extensions: ['write:*.js', 'write:*.ts', 'edit:*.md', 'edit:README*']. Use postToolUse with targeted matchers instead of wildcard to reduce unnecessary executions."
        },
        {
          "issue": "JSDoc generation fails with 'npx jsdoc not found' error",
          "solution": "Check jsdoc availability before running: npx jsdoc --version &> /dev/null before generation. Add npm install -g jsdoc to project setup or include in package.json devDependencies."
        },
        {
          "issue": "Documentation tools timeout on large codebases",
          "solution": "Add timeout limits to each tool execution: timeout 60s npx jsdoc. Process individual files instead of entire directories. Consider incremental documentation generation for changed files only."
        },
        {
          "issue": "TypeDoc fails with module resolution errors in TypeScript",
          "solution": "Ensure tsconfig.json exists with proper module settings. Run TypeDoc from project root: npx typedoc --tsconfig ./tsconfig.json. Check for conflicting TypeScript versions between project and TypeDoc."
        },
        {
          "issue": "Python pdoc generation creates no output for modules",
          "solution": "Verify module has __init__.py if package. Use absolute imports and check PYTHONPATH. Run pdoc with explicit module paths: pdoc --html --output-dir ./docs mymodule rather than file paths."
        }
      ],
      "documentationUrl": "https://jsdoc.app/",
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/documentation-generator"
    },
    {
      "slug": "environment-cleanup-handler",
      "description": "Cleans up temporary files, caches, and resources when Claude session ends",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "cleanup",
        "stop-hook",
        "maintenance",
        "resources",
        "optimization"
      ],
      "hookType": "Stop",
      "features": [
        "Automatic temporary file cleanup (*.tmp, *.log, .DS_Store, Thumbs.db)",
        "NPM cache verification and cleanup",
        "Python bytecode and __pycache__ directory removal",
        "Development build artifacts cleanup",
        "Disk space usage reporting and optimization",
        "Multi-platform support (macOS, Linux, Windows)",
        "Safe cleanup with error handling and logging",
        "Cache invalidation for faster future builds"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "stop": {
              "script": "./.claude/hooks/environment-cleanup-handler.sh"
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\necho \"🧹 Starting environment cleanup...\" >&2\n\n# Initialize cleanup counters\nFILES_REMOVED=0\nSPACE_FREED=0\nERRORS=0\n\n# Function to safely remove files and count them\nsafe_remove() {\n  local pattern=\"$1\"\n  local description=\"$2\"\n  \n  echo \"📁 Cleaning $description...\" >&2\n  \n  if [ \"$pattern\" = \"__pycache__\" ]; then\n    # Special handling for __pycache__ directories\n    FOUND=$(find . -type d -name \"__pycache__\" 2>/dev/null | wc -l | xargs)\n    if [ \"$FOUND\" -gt 0 ]; then\n      find . -type d -name \"__pycache__\" -exec rm -rf {} + 2>/dev/null && echo \"  ✅ Removed $FOUND __pycache__ directories\" >&2\n      FILES_REMOVED=$((FILES_REMOVED + FOUND))\n    else\n      echo \"  ℹ️ No __pycache__ directories found\" >&2\n    fi\n  else\n    # Handle file patterns\n    FOUND=$(find . -name \"$pattern\" 2>/dev/null | wc -l | xargs)\n    if [ \"$FOUND\" -gt 0 ]; then\n      find . -name \"$pattern\" -delete 2>/dev/null && echo \"  ✅ Removed $FOUND $description files\" >&2\n      FILES_REMOVED=$((FILES_REMOVED + FOUND))\n    else\n      echo \"  ℹ️ No $description files found\" >&2\n    fi\n  fi\n}\n\n# Clean temporary files\nsafe_remove \"*.tmp\" \"temporary\"\nsafe_remove \"*.log\" \"log\"\nsafe_remove \"*.bak\" \"backup\"\nsafe_remove \"*~\" \"editor backup\"\n\n# Clean system-specific files\ncase \"$(uname)\" in\n  Darwin)\n    safe_remove \".DS_Store\" \"macOS metadata\"\n    safe_remove \"._*\" \"macOS resource fork\"\n    ;;\n  CYGWIN*|MINGW*|MSYS*)\n    safe_remove \"Thumbs.db\" \"Windows thumbnail cache\"\n    safe_remove \"Desktop.ini\" \"Windows desktop config\"\n    ;;\n  Linux)\n    safe_remove \".directory\" \"KDE directory config\"\n    ;;\nesac\n\n# Clean Python cache files\necho \"🐍 Cleaning Python artifacts...\" >&2\nsafe_remove \"*.pyc\" \"Python bytecode\"\nsafe_remove \"*.pyo\" \"Python optimized bytecode\"\nsafe_remove \"__pycache__\" \"Python cache directories\"\n\n# Clean Node.js related files\nif [ -f \"package.json\" ]; then\n  echo \"🟢 Node.js project detected - cleaning caches...\" >&2\n  \n  # Clean npm cache\n  if command -v npm &> /dev/null; then\n    echo \"  🗑️ Verifying npm cache...\" >&2\n    if npm cache verify 2>/dev/null; then\n      echo \"  ✅ npm cache verified and cleaned\" >&2\n    else\n      echo \"  ⚠️ npm cache verification failed\" >&2\n      ERRORS=$((ERRORS + 1))\n    fi\n  fi\n  \n  # Clean node_modules/.cache if it exists\n  if [ -d \"node_modules/.cache\" ]; then\n    CACHE_SIZE=$(du -sh node_modules/.cache 2>/dev/null | cut -f1 || echo \"unknown\")\n    rm -rf node_modules/.cache 2>/dev/null && echo \"  ✅ Removed node_modules/.cache ($CACHE_SIZE)\" >&2\n  fi\nfi\n\n# Clean build artifacts\necho \"🔧 Cleaning build artifacts...\" >&2\nsafe_remove \"*.o\" \"object files\"\nsafe_remove \"*.obj\" \"Windows object files\"\nsafe_remove \"*.so\" \"shared object files\"\nsafe_remove \"*.dll\" \"Windows library files\"\nsafe_remove \"*.dylib\" \"macOS dynamic libraries\"\n\n# Clean IDE and editor files\necho \"💻 Cleaning IDE artifacts...\" >&2\nsafe_remove \".vscode/settings.json.bak\" \"VS Code backup settings\"\nif [ -d \".vscode\" ]; then\n  find .vscode -name \"*.log\" -delete 2>/dev/null || true\nfi\n\n# Clean test artifacts\necho \"🧪 Cleaning test artifacts...\" >&2\nsafe_remove \"coverage.xml\" \"coverage report\"\nsafe_remove \".coverage\" \"Python coverage data\"\nif [ -d \"coverage\" ]; then\n  rm -rf coverage 2>/dev/null && echo \"  ✅ Removed coverage directory\" >&2\nfi\nif [ -d \".nyc_output\" ]; then\n  rm -rf .nyc_output 2>/dev/null && echo \"  ✅ Removed .nyc_output directory\" >&2\nfi\n\n# Clean Docker artifacts if Docker is available\nif command -v docker &> /dev/null && docker info &> /dev/null 2>&1; then\n  echo \"🐳 Docker detected - cleaning unused resources...\" >&2\n  \n  # Clean dangling images\n  DANGLING_IMAGES=$(docker images -f \"dangling=true\" -q 2>/dev/null | wc -l | xargs)\n  if [ \"$DANGLING_IMAGES\" -gt 0 ]; then\n    docker image prune -f &> /dev/null && echo \"  ✅ Removed $DANGLING_IMAGES dangling Docker images\" >&2\n  else\n    echo \"  ℹ️ No dangling Docker images found\" >&2\n  fi\nfi\n\n# Calculate disk space if possible\necho \"💾 Calculating disk space usage...\" >&2\nif command -v du &> /dev/null; then\n  # Check cache directories\n  for cache_dir in ~/.npm ~/.cache ~/.cargo/registry; do\n    if [ -d \"$cache_dir\" ]; then\n      CACHE_SIZE=$(du -sh \"$cache_dir\" 2>/dev/null | cut -f1 || echo \"unknown\")\n      echo \"  📊 $cache_dir: $CACHE_SIZE\" >&2\n    fi\n  done\nfi\n\n# Report cleanup summary\necho \"\" >&2\necho \"📋 Cleanup Summary:\" >&2\necho \"  🗑️ Files/directories removed: $FILES_REMOVED\" >&2\necho \"  ⚠️ Errors encountered: $ERRORS\" >&2\n\nif [ \"$ERRORS\" -eq 0 ]; then\n  echo \"✅ Environment cleanup completed successfully\" >&2\nelse\n  echo \"⚠️ Environment cleanup completed with $ERRORS errors\" >&2\nfi\n\necho \"\" >&2\necho \"💡 Cleanup Tips:\" >&2\necho \"   • Run 'docker system prune' for more aggressive Docker cleanup\" >&2\necho \"   • Use 'npm cache clean --force' for complete npm cache reset\" >&2\necho \"   • Consider 'pip cache purge' for Python package cache cleanup\" >&2\n\nexit 0"
      },
      "useCases": [
        "Automated development environment maintenance",
        "Post-session cleanup for CI/CD pipelines",
        "Disk space optimization and management",
        "Multi-language project artifact cleanup",
        "Docker container development environment cleanup"
      ],
      "troubleshooting": [
        {
          "issue": "Stop hook doesn't execute when Claude terminates unexpectedly",
          "solution": "Stop hooks only run on graceful shutdown. For crash scenarios, use OS-level cleanup via trap signals or systemd service cleanup. Add trap 'cleanup_function' EXIT SIGTERM SIGINT to shell sessions for broader coverage."
        },
        {
          "issue": "Docker cleanup fails with permission denied on daemon socket",
          "solution": "Script checks 'docker info' but may lack permissions. Ensure user in docker group: sudo usermod -aG docker $USER or skip docker cleanup gracefully: docker image prune -f 2>/dev/null || echo 'Skipping docker cleanup'."
        },
        {
          "issue": "NPM cache verify hangs indefinitely blocking hook completion",
          "solution": "Network issues can stall npm operations. Add timeout: timeout 10s npm cache verify or use npm cache verify --offline to avoid network calls. Set NPM_CONFIG_CACHE to control cache directory location."
        },
        {
          "issue": "Find commands fail with 'too many arguments' on large directories",
          "solution": "Large directory trees exceed ARG_MAX limits. Replace find ... -delete with: find . -name '*.tmp' -print0 | xargs -0 rm -f to handle arguments in batches safely using null delimiter for paths with spaces."
        },
        {
          "issue": "Du command for cache size calculation hangs on network mounts",
          "solution": "Script checks ~/.npm and other user dirs which may be on slow filesystems. Add timeout: timeout 5s du -sh \"$cache_dir\" or skip network paths: df \"$cache_dir\" | grep -q nfs && continue to avoid stalling."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/environment-cleanup-handler"
    },
    {
      "slug": "environment-variable-validator",
      "seoTitle": "Environment Validator",
      "description": "Validates environment variables, checks for required vars, and ensures proper configuration across environments",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-16",
      "tags": [
        "environment",
        "configuration",
        "validation",
        "deployment",
        "security"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Automatic validation when .env files are modified",
        "Required environment variable checking",
        "Security validation for insecure defaults and weak secrets",
        "Format validation for URLs, emails, ports, and booleans",
        "Cross-environment consistency checking",
        "Production vs development environment validation",
        "Configuration schema validation",
        "Comprehensive error reporting and security warnings"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/environment-variable-validator.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Check if it's an environment-related file\nif [[ \"$FILE_PATH\" == *.env* ]] || [[ \"$FILE_PATH\" == *environment* ]] || [[ \"$FILE_PATH\" == *config* ]] || [[ \"$FILE_PATH\" == docker-compose.yml ]] || [[ \"$FILE_PATH\" == docker-compose.yaml ]]; then\n  echo \"🔧 Environment file detected: $FILE_PATH\" >&2\n  \n  # Initialize validation counters\n  ERRORS=0\n  WARNINGS=0\n  VALIDATIONS=0\n  \n  # Function to report validation results\n  report_issue() {\n    local level=\"$1\"\n    local message=\"$2\"\n    \n    if [ \"$level\" = \"ERROR\" ]; then\n      echo \"❌ $message\" >&2\n      ERRORS=$((ERRORS + 1))\n    elif [ \"$level\" = \"WARNING\" ]; then\n      echo \"⚠️ $message\" >&2\n      WARNINGS=$((WARNINGS + 1))\n    elif [ \"$level\" = \"INFO\" ]; then\n      echo \"ℹ️ $message\" >&2\n    fi\n    VALIDATIONS=$((VALIDATIONS + 1))\n  }\n  \n  # Validate environment file if it exists\n  if [ -f \"$FILE_PATH\" ]; then\n    echo \"🔍 Validating environment configuration...\" >&2\n    \n    # Check for common required variables\n    COMMON_REQUIRED_VARS=(\"NODE_ENV\" \"PORT\")\n    \n    if [[ \"$FILE_PATH\" == *.env* ]]; then\n      echo \"📋 Checking for environment variables in $FILE_PATH\" >&2\n      \n      # Extract variables from the file\n      ENV_VARS=$(grep -oE '^[A-Z_][A-Z0-9_]*=' \"$FILE_PATH\" 2>/dev/null | sed 's/=//' || echo \"\")\n      \n      if [ -n \"$ENV_VARS\" ]; then\n        ENV_COUNT=$(echo \"$ENV_VARS\" | wc -l | xargs)\n        echo \"📊 Found $ENV_COUNT environment variables\" >&2\n      fi\n      \n      # Security validation - check for insecure defaults\n      echo \"🔒 Performing security validation...\" >&2\n      \n      INSECURE_PATTERNS=(\n        \"password=admin\"\n        \"password=123\"\n        \"secret=123\"\n        \"api_key=test\"\n        \"token=demo\"\n        \"password=password\"\n        \"secret=secret\"\n        \"key=key\"\n      )\n      \n      for pattern in \"${INSECURE_PATTERNS[@]}\"; do\n        if grep -qi \"$pattern\" \"$FILE_PATH\" 2>/dev/null; then\n          report_issue \"ERROR\" \"Insecure default detected: $pattern\"\n        fi\n      done\n      \n      # Check for secrets that are too short\n      while IFS= read -r line; do\n        if [[ \"$line\" =~ ^([A-Z_]+)=(.+)$ ]]; then\n          var_name=\"${BASH_REMATCH[1]}\"\n          var_value=\"${BASH_REMATCH[2]}\"\n          \n          # Remove quotes from value\n          var_value=$(echo \"$var_value\" | sed 's/^[\"'\\'']*//;s/[\"'\\'']*$//')\n          \n          # Check secret length for security-related variables\n          if [[ \"$var_name\" =~ (SECRET|KEY|TOKEN|PASSWORD) ]]; then\n            if [ ${#var_value} -lt 16 ]; then\n              report_issue \"WARNING\" \"$var_name is too short (${#var_value} chars), should be at least 16 characters\"\n            elif [ ${#var_value} -lt 32 ] && [[ \"$var_name\" =~ (JWT_SECRET|ENCRYPTION_KEY) ]]; then\n              report_issue \"WARNING\" \"$var_name should be at least 32 characters for security\"\n            fi\n          fi\n          \n          # Format validation\n          case \"$var_name\" in\n            *PORT*)\n              if ! [[ \"$var_value\" =~ ^[0-9]+$ ]] || [ \"$var_value\" -le 0 ] || [ \"$var_value\" -gt 65535 ]; then\n                report_issue \"ERROR\" \"$var_name must be a valid port number (1-65535)\"\n              fi\n              ;;\n            *URL*|*URI*)\n              if ! [[ \"$var_value\" =~ ^https?:// ]] && ! [[ \"$var_value\" =~ ^[a-zA-Z][a-zA-Z0-9+.-]*:// ]]; then\n                report_issue \"WARNING\" \"$var_name should be a valid URL with protocol\"\n              fi\n              ;;\n            *EMAIL*)\n              if ! [[ \"$var_value\" =~ ^[^@]+@[^@]+\\.[^@]+$ ]]; then\n                report_issue \"ERROR\" \"$var_name must be a valid email address\"\n              fi\n              ;;\n            *BOOL*|*ENABLE*|*DEBUG*)\n              if ! [[ \"$var_value\" =~ ^(true|false|1|0|yes|no)$ ]]; then\n                report_issue \"WARNING\" \"$var_name should be a boolean value (true/false, 1/0, yes/no)\"\n              fi\n              ;;\n          esac\n        fi\n      done < \"$FILE_PATH\"\n      \n      # Environment-specific validation\n      if grep -q \"NODE_ENV=production\" \"$FILE_PATH\" 2>/dev/null; then\n        echo \"🏭 Production environment detected - performing production checks\" >&2\n        \n        # Check for development settings in production\n        if grep -qi \"debug=true\" \"$FILE_PATH\" 2>/dev/null; then\n          report_issue \"ERROR\" \"DEBUG should not be enabled in production\"\n        fi\n        \n        # Check for required production variables\n        PROD_REQUIRED=(\"JWT_SECRET\" \"DATABASE_URL\")\n        for var in \"${PROD_REQUIRED[@]}\"; do\n          if ! grep -q \"^$var=\" \"$FILE_PATH\" 2>/dev/null; then\n            report_issue \"WARNING\" \"$var is recommended for production environments\"\n          fi\n        done\n        \n      elif grep -q \"NODE_ENV=development\" \"$FILE_PATH\" 2>/dev/null; then\n        echo \"🔧 Development environment detected\" >&2\n        \n        # Development-specific checks\n        if ! grep -q \"DEBUG\" \"$FILE_PATH\" 2>/dev/null; then\n          report_issue \"INFO\" \"Consider adding DEBUG variable for development\"\n        fi\n      fi\n    fi\n    \n    # Cross-environment consistency check\n    echo \"🔄 Checking cross-environment consistency...\" >&2\n    ENV_FILES=(\".env\" \".env.local\" \".env.development\" \".env.staging\" \".env.production\")\n    \n    EXISTING_ENV_FILES=()\n    for env_file in \"${ENV_FILES[@]}\"; do\n      if [ -f \"$env_file\" ] && [ \"$env_file\" != \"$FILE_PATH\" ]; then\n        EXISTING_ENV_FILES+=(\"$env_file\")\n      fi\n    done\n    \n    if [ ${#EXISTING_ENV_FILES[@]} -gt 0 ]; then\n      echo \"📂 Found ${#EXISTING_ENV_FILES[@]} other environment files for comparison\" >&2\n      \n      # Extract variable names from current file\n      if [[ \"$FILE_PATH\" == *.env* ]]; then\n        CURRENT_VARS=$(grep -oE '^[A-Z_][A-Z0-9_]*=' \"$FILE_PATH\" 2>/dev/null | sed 's/=//' | sort || echo \"\")\n        \n        for other_file in \"${EXISTING_ENV_FILES[@]}\"; do\n          OTHER_VARS=$(grep -oE '^[A-Z_][A-Z0-9_]*=' \"$other_file\" 2>/dev/null | sed 's/=//' | sort || echo \"\")\n          \n          # Find variables in current file but not in other file\n          MISSING_IN_OTHER=$(comm -23 <(echo \"$CURRENT_VARS\") <(echo \"$OTHER_VARS\") 2>/dev/null || echo \"\")\n          \n          if [ -n \"$MISSING_IN_OTHER\" ] && [ \"$MISSING_IN_OTHER\" != \"\" ]; then\n            MISSING_COUNT=$(echo \"$MISSING_IN_OTHER\" | wc -l | xargs)\n            if [ \"$MISSING_COUNT\" -gt 0 ]; then\n              report_issue \"INFO\" \"$MISSING_COUNT variables in $FILE_PATH not found in $other_file\"\n            fi\n          fi\n        done\n      fi\n    fi\n    \n    # Check for .env files in version control\n    if [ -f \".gitignore\" ]; then\n      if ! grep -q \"\\.env\" \".gitignore\" 2>/dev/null; then\n        report_issue \"WARNING\" \"Consider adding .env files to .gitignore to prevent committing secrets\"\n      fi\n    fi\n    \n  else\n    echo \"⚠️ Environment file $FILE_PATH not found for validation\" >&2\n  fi\n  \n  # Docker compose specific validation\n  if [[ \"$FILE_PATH\" == docker-compose.y*ml ]]; then\n    echo \"🐳 Docker Compose file detected - checking environment configuration\" >&2\n    \n    if [ -f \"$FILE_PATH\" ]; then\n      # Check for hardcoded secrets in docker-compose\n      if grep -q \"password:\" \"$FILE_PATH\" 2>/dev/null; then\n        report_issue \"WARNING\" \"Consider using environment variables instead of hardcoded passwords\"\n      fi\n      \n      # Check for env_file usage\n      if grep -q \"env_file:\" \"$FILE_PATH\" 2>/dev/null; then\n        echo \"✅ Good practice: using env_file for environment variables\" >&2\n      else\n        report_issue \"INFO\" \"Consider using env_file for better environment variable management\"\n      fi\n    fi\n  fi\n  \n  # Summary report\n  echo \"\" >&2\n  echo \"📋 Validation Summary:\" >&2\n  echo \"  🔍 Validations performed: $VALIDATIONS\" >&2\n  echo \"  ❌ Errors found: $ERRORS\" >&2\n  echo \"  ⚠️ Warnings: $WARNINGS\" >&2\n  \n  if [ \"$ERRORS\" -eq 0 ] && [ \"$WARNINGS\" -eq 0 ]; then\n    echo \"✅ Environment validation passed\" >&2\n  elif [ \"$ERRORS\" -eq 0 ]; then\n    echo \"✅ Environment validation passed with warnings\" >&2\n  else\n    echo \"⚠️ Environment validation completed with errors\" >&2\n  fi\n  \n  echo \"\" >&2\n  echo \"💡 Environment Security Tips:\" >&2\n  echo \"   • Use strong, unique secrets (32+ characters)\" >&2\n  echo \"   • Never commit .env files to version control\" >&2\n  echo \"   • Use different configurations for each environment\" >&2\n  echo \"   • Validate environment variables in CI/CD pipelines\" >&2\n  \nelse\n  echo \"File $FILE_PATH is not an environment configuration file, skipping validation\" >&2\nfi\n\nexit 0"
      },
      "useCases": [
        "Automated environment variable validation during development",
        "Security auditing of configuration files",
        "Cross-environment consistency checking",
        "Production deployment safety validation",
        "CI/CD pipeline configuration validation"
      ],
      "troubleshooting": [
        {
          "issue": "Hook triggers on every file write, slowing development",
          "solution": "Narrow matchers to specific .env files only: matchers: ['write:.env*', 'edit:.env*'] in hookConfig to reduce unnecessary validations and improve performance."
        },
        {
          "issue": "False positives for weak secrets in development environments",
          "solution": "Add NODE_ENV check in script to skip strict secret length validation for development. Use conditional logic: if NODE_ENV != production, bypass warnings."
        },
        {
          "issue": "Hook fails to detect environment files in nested directories",
          "solution": "Update file path matching regex to include subdirectories: [[ \"$FILE_PATH\" == */.env* ]] and find .env files recursively for comprehensive validation."
        },
        {
          "issue": "Cross-environment comparison reports too many false differences",
          "solution": "Filter comparison to only critical variables (DB, API keys, secrets). Exclude dev-only vars like DEBUG or LOCAL_DEV_PORT from consistency checks to reduce noise."
        },
        {
          "issue": "Script exits with errors preventing file saves entirely",
          "solution": "Change validation errors to warnings with exit 0 instead of exit 1. Log issues to stderr for review but allow operations to complete without blocking development."
        }
      ],
      "documentationUrl": "https://12factor.net/config",
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/environment-variable-validator"
    },
    {
      "slug": "error-rate-monitor",
      "description": "Tracks error patterns and alerts when error rates spike",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "errors",
        "monitoring",
        "notification",
        "debugging",
        "alerts"
      ],
      "hookType": "Notification",
      "features": [
        "Real-time error pattern detection in log files",
        "Configurable error rate thresholds and alerting",
        "Multi-log file monitoring (*.log, logs/*, custom paths)",
        "Error severity classification (fatal, error, warning)",
        "Recent error sample display for quick debugging",
        "Time-based error rate calculations",
        "Framework-specific error pattern recognition",
        "Silent operation with threshold-based notifications"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "notification": {
              "script": "./.claude/hooks/error-rate-monitor.sh"
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\necho \"🔍 Monitoring error rates across log files...\" >&2\n\n# Configurable thresholds (can be overridden by environment variables)\nERROR_THRESHOLD_PER_FILE=${ERROR_THRESHOLD_PER_FILE:-5}\nTOTAL_ERROR_THRESHOLD=${TOTAL_ERROR_THRESHOLD:-10}\nLOG_LINES_TO_CHECK=${LOG_LINES_TO_CHECK:-100}\nMAX_SAMPLE_ERRORS=${MAX_SAMPLE_ERRORS:-3}\n\n# Initialize counters\nTOTAL_ERRORS=0\nFILES_WITH_ERRORS=0\nCRITICAL_FILES=()\nERROR_SAMPLES=()\n\n# Define error patterns with severity levels\nFATAL_PATTERNS=(\"fatal\" \"critical\" \"panic\" \"abort\" \"segfault\")\nERROR_PATTERNS=(\"error\" \"exception\" \"failed\" \"failure\" \"timeout\")\nWARNING_PATTERNS=(\"warning\" \"warn\" \"deprecated\" \"notice\")\n\n# Function to count errors by severity\ncount_errors_by_severity() {\n  local log_file=\"$1\"\n  local fatal_count=0\n  local error_count=0\n  local warning_count=0\n  \n  if [ ! -f \"$log_file\" ]; then\n    return\n  fi\n  \n  # Check last N lines of the log file\n  local recent_logs=$(tail -\"$LOG_LINES_TO_CHECK\" \"$log_file\" 2>/dev/null || echo \"\")\n  \n  if [ -z \"$recent_logs\" ]; then\n    return\n  fi\n  \n  # Count fatal errors\n  for pattern in \"${FATAL_PATTERNS[@]}\"; do\n    fatal_count=$((fatal_count + $(echo \"$recent_logs\" | grep -icE \"\\\\b$pattern\\\\b\" || echo \"0\")))\n  done\n  \n  # Count errors (excluding fatals already counted)\n  for pattern in \"${ERROR_PATTERNS[@]}\"; do\n    error_count=$((error_count + $(echo \"$recent_logs\" | grep -icE \"\\\\b$pattern\\\\b\" || echo \"0\")))\n  done\n  \n  # Count warnings\n  for pattern in \"${WARNING_PATTERNS[@]}\"; do\n    warning_count=$((warning_count + $(echo \"$recent_logs\" | grep -icE \"\\\\b$pattern\\\\b\" || echo \"0\")))\n  done\n  \n  echo \"$fatal_count $error_count $warning_count\"\n}\n\n# Function to extract error samples\nextract_error_samples() {\n  local log_file=\"$1\"\n  local sample_count=\"$2\"\n  \n  if [ ! -f \"$log_file\" ]; then\n    return\n  fi\n  \n  # Get recent error lines with timestamps if available\n  tail -\"$LOG_LINES_TO_CHECK\" \"$log_file\" 2>/dev/null | \\\n    grep -iE '(fatal|critical|error|exception|failed)' | \\\n    head -\"$sample_count\" | \\\n    while IFS= read -r line; do\n      # Truncate very long lines\n      if [ ${#line} -gt 120 ]; then\n        echo \"${line:0:120}...\"\n      else\n        echo \"$line\"\n      fi\n    done\n}\n\n# Function to check log files in a directory\ncheck_log_directory() {\n  local dir=\"$1\"\n  local pattern=\"$2\"\n  \n  if [ ! -d \"$dir\" ]; then\n    return\n  fi\n  \n  find \"$dir\" -name \"$pattern\" -type f 2>/dev/null | while read -r log_file; do\n    echo \"$log_file\"\n  done\n}\n\n# Collect all log files to check\nLOG_FILES=()\n\n# Standard log locations\nfor pattern in \"*.log\" \"*.out\" \"*.err\"; do\n  while IFS= read -r -d '' file; do\n    LOG_FILES+=(\"$file\")\n  done < <(find . -maxdepth 1 -name \"$pattern\" -type f -print0 2>/dev/null)\ndone\n\n# Common log directories\nLOG_DIRS=(\"logs\" \"log\" \"var/log\" \".logs\" \"tmp/logs\")\nfor log_dir in \"${LOG_DIRS[@]}\"; do\n  if [ -d \"$log_dir\" ]; then\n    while IFS= read -r -d '' file; do\n      LOG_FILES+=(\"$file\")\n    done < <(find \"$log_dir\" -name \"*.log\" -o -name \"*.out\" -o -name \"*.err\" -type f -print0 2>/dev/null)\n  fi\ndone\n\n# Framework-specific log locations\nif [ -f \"package.json\" ]; then\n  # Node.js specific logs\n  for pattern in \"npm-debug.log\" \"yarn-error.log\" \"pnpm-debug.log\"; do\n    [ -f \"$pattern\" ] && LOG_FILES+=(\"$pattern\")\n  done\n  \n  # Next.js logs\n  [ -d \".next\" ] && find .next -name \"*.log\" -type f 2>/dev/null | while read -r file; do\n    LOG_FILES+=(\"$file\")\n  done\nfi\n\n# Python specific logs\nif [ -f \"requirements.txt\" ] || [ -f \"pyproject.toml\" ]; then\n  for pattern in \"django.log\" \"flask.log\" \"celery.log\" \"pytest.log\"; do\n    [ -f \"$pattern\" ] && LOG_FILES+=(\"$pattern\")\n  done\nfi\n\n# Docker logs if Docker is available\nif command -v docker &> /dev/null && docker info &> /dev/null 2>&1; then\n  # Check for recent container logs with errors\n  CONTAINERS=$(docker ps --format \"{{.Names}}\" 2>/dev/null | head -5)\n  for container in $CONTAINERS; do\n    if [ -n \"$container\" ]; then\n      ERROR_COUNT=$(docker logs \"$container\" --since=10m 2>&1 | grep -icE '(fatal|critical|error|exception)' || echo \"0\")\n      if [ \"$ERROR_COUNT\" -gt 0 ]; then\n        echo \"🐳 Container '$container' has $ERROR_COUNT recent errors\" >&2\n        TOTAL_ERRORS=$((TOTAL_ERRORS + ERROR_COUNT))\n        \n        # Get error samples from container logs\n        CONTAINER_ERRORS=$(docker logs \"$container\" --since=10m 2>&1 | grep -iE '(fatal|critical|error|exception)' | head -2)\n        if [ -n \"$CONTAINER_ERRORS\" ]; then\n          echo \"📝 Sample from $container:\" >&2\n          echo \"$CONTAINER_ERRORS\" | head -1 >&2\n        fi\n      fi\n    fi\n  done\nfi\n\n# Remove duplicates from LOG_FILES array\nreadarray -t UNIQUE_LOG_FILES < <(printf '%s\\n' \"${LOG_FILES[@]}\" | sort -u)\n\necho \"📊 Checking ${#UNIQUE_LOG_FILES[@]} log files for error patterns...\" >&2\n\n# Check each log file\nfor log_file in \"${UNIQUE_LOG_FILES[@]}\"; do\n  if [ ! -f \"$log_file\" ]; then\n    continue\n  fi\n  \n  # Get error counts by severity\n  read -r fatal_count error_count warning_count <<< \"$(count_errors_by_severity \"$log_file\")\"\n  \n  file_total_errors=$((fatal_count + error_count))\n  TOTAL_ERRORS=$((TOTAL_ERRORS + file_total_errors))\n  \n  if [ \"$file_total_errors\" -gt 0 ]; then\n    FILES_WITH_ERRORS=$((FILES_WITH_ERRORS + 1))\n    \n    log_basename=$(basename \"$log_file\")\n    \n    # Report file-level errors\n    if [ \"$fatal_count\" -gt 0 ]; then\n      echo \"🚨 CRITICAL: $log_basename has $fatal_count fatal errors\" >&2\n      CRITICAL_FILES+=(\"$log_file\")\n    fi\n    \n    if [ \"$file_total_errors\" -gt \"$ERROR_THRESHOLD_PER_FILE\" ]; then\n      echo \"⚠️ ERROR SPIKE: $log_basename has $file_total_errors errors (fatal: $fatal_count, error: $error_count)\" >&2\n      \n      # Extract error samples\n      echo \"📝 Recent error samples from $log_basename:\" >&2\n      extract_error_samples \"$log_file\" \"$MAX_SAMPLE_ERRORS\" | while IFS= read -r sample; do\n        echo \"  → $sample\" >&2\n      done\n    elif [ \"$file_total_errors\" -gt 0 ]; then\n      echo \"ℹ️ $log_basename: $file_total_errors errors detected\" >&2\n    fi\n    \n    if [ \"$warning_count\" -gt 0 ]; then\n      echo \"⚠️ $log_basename: $warning_count warnings\" >&2\n    fi\n  fi\ndone\n\n# Overall error rate analysis\necho \"\" >&2\necho \"📋 Error Rate Summary:\" >&2\necho \"  📁 Files checked: ${#UNIQUE_LOG_FILES[@]}\" >&2\necho \"  📄 Files with errors: $FILES_WITH_ERRORS\" >&2\necho \"  🔢 Total errors: $TOTAL_ERRORS\" >&2\necho \"  🚨 Critical files: ${#CRITICAL_FILES[@]}\" >&2\n\n# Alert on high error rates\nif [ \"$TOTAL_ERRORS\" -gt \"$TOTAL_ERROR_THRESHOLD\" ]; then\n  echo \"\" >&2\n  echo \"🚨 HIGH ERROR RATE DETECTED!\" >&2\n  echo \"⚠️ Total errors ($TOTAL_ERRORS) exceed threshold ($TOTAL_ERROR_THRESHOLD)\" >&2\n  \n  if [ ${#CRITICAL_FILES[@]} -gt 0 ]; then\n    echo \"🔥 Critical files requiring immediate attention:\" >&2\n    for critical_file in \"${CRITICAL_FILES[@]}\"; do\n      echo \"  → $(basename \"$critical_file\")\" >&2\n    done\n  fi\n  \nelif [ \"$TOTAL_ERRORS\" -gt 0 ]; then\n  echo \"ℹ️ Errors detected but within acceptable threshold\" >&2\nelse\n  echo \"✅ No errors detected in monitored log files\" >&2\nfi\n\n# Performance recommendations\nif [ ${#UNIQUE_LOG_FILES[@]} -gt 20 ]; then\n  echo \"\" >&2\n  echo \"💡 Performance tip: Consider log rotation or filtering for faster monitoring\" >&2\nfi\n\necho \"\" >&2\necho \"🔧 Monitoring Configuration:\" >&2\necho \"  • Error threshold per file: $ERROR_THRESHOLD_PER_FILE\" >&2\necho \"  • Total error threshold: $TOTAL_ERROR_THRESHOLD\" >&2\necho \"  • Lines checked per file: $LOG_LINES_TO_CHECK\" >&2\necho \"\" >&2\necho \"💡 Customize thresholds with environment variables:\" >&2\necho \"  export ERROR_THRESHOLD_PER_FILE=10\" >&2\necho \"  export TOTAL_ERROR_THRESHOLD=25\" >&2\n\nexit 0"
      },
      "useCases": [
        "Real-time error monitoring during development",
        "Automated error rate alerting for CI/CD pipelines",
        "Multi-service application error tracking",
        "Docker container log monitoring",
        "Framework-specific error pattern detection"
      ],
      "troubleshooting": [
        {
          "issue": "Hook runs continuously causing terminal spam",
          "solution": "Add sleep interval or debounce logic to notification hook: sleep 60 between checks. Reduce LOG_LINES_TO_CHECK to 50 for faster processing with less output."
        },
        {
          "issue": "Docker container log checks fail with permission denied",
          "solution": "Ensure user is in docker group: sudo usermod -aG docker $USER and restart session. Alternatively, skip Docker checks: remove docker logs section from script."
        },
        {
          "issue": "Log file pattern matching misses framework-specific logs",
          "solution": "Add custom log paths to LOG_DIRS array: LOG_DIRS+=('build/logs' '.next/logs'). Extend file patterns: find with -name '*.out' -o -name 'app*.log' for comprehensive coverage."
        },
        {
          "issue": "Error rate threshold alerts for normal warning messages",
          "solution": "Separate ERROR_PATTERNS from WARNING_PATTERNS in severity classification. Only count fatal+error toward threshold, exclude warnings: TOTAL_ERRORS=$((fatal_count + error_count))."
        },
        {
          "issue": "Hook performance degrades with many large log files",
          "solution": "Limit file search depth: find . -maxdepth 2 instead of recursive. Increase LOG_LINES_TO_CHECK interval but reduce file count: head -5 on find results for performance."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/error-rate-monitor"
    },
    {
      "slug": "file-size-warning-monitor",
      "description": "Alerts when files exceed size thresholds that could impact performance",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "file-size",
        "performance",
        "notification",
        "monitoring",
        "optimization"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Real-time file size monitoring during write/edit operations",
        "Configurable size thresholds for different file types",
        "File type-specific recommendations (images, JSON, code, etc.)",
        "Performance impact warnings for large files",
        "Git repository size impact analysis",
        "Compression suggestions for media files",
        "Size comparison with previous versions",
        "Multi-platform file size detection (macOS, Linux, Windows)"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/file-size-warning-monitor.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Check if file exists and is a regular file\nif [ ! -f \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\necho \"📏 Checking file size for: $(basename \"$FILE_PATH\")\" >&2\n\n# Get file size in bytes (cross-platform)\nget_file_size() {\n  local file=\"$1\"\n  \n  # Try different stat formats for cross-platform compatibility\n  if stat -f%z \"$file\" 2>/dev/null; then\n    # macOS/BSD\n    return 0\n  elif stat -c%s \"$file\" 2>/dev/null; then\n    # Linux/GNU\n    return 0\n  elif [ -f \"$file\" ]; then\n    # Fallback: use wc for text files (less accurate for binary)\n    wc -c < \"$file\" 2>/dev/null || echo \"0\"\n  else\n    echo \"0\"\n  fi\n}\n\n# Convert bytes to human-readable format\nformat_size() {\n  local bytes=\"$1\"\n  \n  if [ \"$bytes\" -lt 1024 ]; then\n    echo \"${bytes}B\"\n  elif [ \"$bytes\" -lt 1048576 ]; then\n    echo \"$((bytes / 1024))KB\"\n  elif [ \"$bytes\" -lt 1073741824 ]; then\n    echo \"$((bytes / 1048576))MB\"\n  else\n    echo \"$((bytes / 1073741824))GB\"\n  fi\n}\n\n# Get file extension\nget_file_extension() {\n  local file=\"$1\"\n  echo \"${file##*.}\" | tr '[:upper:]' '[:lower:]'\n}\n\n# Define file type categories and their thresholds\nget_size_threshold() {\n  local extension=\"$1\"\n  \n  case \"$extension\" in\n    # Source code files - should be relatively small\n    js|jsx|ts|tsx|py|rb|go|rs|java|cpp|c|h|hpp|php|cs)\n      echo \"500000\"  # 500KB\n      ;;\n    # Data/config files\n    json|xml|yaml|yml|toml|ini|conf)\n      echo \"1048576\"  # 1MB\n      ;;\n    # Documentation\n    md|txt|rst|org)\n      echo \"1048576\"  # 1MB\n      ;;\n    # Images\n    jpg|jpeg|png|gif|bmp|webp|svg)\n      echo \"2097152\"  # 2MB\n      ;;\n    # Videos\n    mp4|avi|mov|wmv|flv|webm|mkv)\n      echo \"52428800\"  # 50MB\n      ;;\n    # Audio\n    mp3|wav|flac|aac|ogg)\n      echo \"10485760\"  # 10MB\n      ;;\n    # Archives\n    zip|tar|gz|bz2|xz|7z|rar)\n      echo \"20971520\"  # 20MB\n      ;;\n    # Binary executables\n    exe|bin|app|dmg|deb|rpm)\n      echo \"104857600\"  # 100MB\n      ;;\n    # Default for unknown file types\n    *)\n      echo \"5242880\"  # 5MB\n      ;;\n  esac\n}\n\n# Get optimization suggestions for file type\nget_optimization_suggestions() {\n  local extension=\"$1\"\n  local size_mb=\"$2\"\n  \n  case \"$extension\" in\n    js|jsx|ts|tsx)\n      echo \"Consider code splitting, tree shaking, or minification\"\n      ;;\n    json)\n      echo \"Consider JSON streaming, compression, or breaking into smaller files\"\n      ;;\n    jpg|jpeg)\n      echo \"Consider JPEG optimization, WebP format, or progressive JPEG\"\n      ;;\n    png)\n      echo \"Consider PNG optimization, WebP format, or SVG for simple graphics\"\n      ;;\n    gif)\n      echo \"Consider converting to WebP or MP4 for better compression\"\n      ;;\n    svg)\n      echo \"Consider SVG optimization tools to remove unnecessary elements\"\n      ;;\n    mp4|mov)\n      echo \"Consider video compression, lower resolution, or streaming\"\n      ;;\n    pdf)\n      echo \"Consider PDF compression or splitting into smaller documents\"\n      ;;\n    zip|tar|gz)\n      echo \"Archive seems large - verify contents are necessary\"\n      ;;\n    md|txt)\n      echo \"Consider breaking into smaller documents or using external storage\"\n      ;;\n    *)\n      echo \"Consider file compression or alternative storage solutions\"\n      ;;\n  esac\n}\n\n# Get file size\nSIZE_BYTES=$(get_file_size \"$FILE_PATH\")\nSIZE_HUMAN=$(format_size \"$SIZE_BYTES\")\nSIZE_MB=$((SIZE_BYTES / 1048576))\nSIZE_KB=$((SIZE_BYTES / 1024))\n\n# Get file info\nFILE_EXTENSION=$(get_file_extension \"$FILE_PATH\")\nFILE_NAME=$(basename \"$FILE_PATH\")\nTHRESHOLD_BYTES=$(get_size_threshold \"$FILE_EXTENSION\")\nTHRESHOLD_HUMAN=$(format_size \"$THRESHOLD_BYTES\")\n\necho \"📊 File: $FILE_NAME ($SIZE_HUMAN)\" >&2\n\n# Check if file exceeds threshold\nif [ \"$SIZE_BYTES\" -gt \"$THRESHOLD_BYTES\" ]; then\n  echo \"⚠️ SIZE WARNING: File exceeds recommended threshold for .$FILE_EXTENSION files\" >&2\n  echo \"   Current: $SIZE_HUMAN | Recommended: < $THRESHOLD_HUMAN\" >&2\n  \n  # Provide optimization suggestions\n  SUGGESTION=$(get_optimization_suggestions \"$FILE_EXTENSION\" \"$SIZE_MB\")\n  echo \"💡 Suggestion: $SUGGESTION\" >&2\n  \n  # Specific warnings for very large files\n  if [ \"$SIZE_MB\" -gt 50 ]; then\n    echo \"🚨 VERY LARGE FILE: This file may cause performance issues\" >&2\n    echo \"   Consider using Git LFS for files over 50MB\" >&2\n  elif [ \"$SIZE_MB\" -gt 10 ]; then\n    echo \"⚠️ LARGE FILE: May impact repository performance\" >&2\n  fi\n  \nelse\n  echo \"✅ File size within acceptable range ($THRESHOLD_HUMAN threshold)\" >&2\nfi\n\n# Special checks for specific file types\ncase \"$FILE_EXTENSION\" in\n  js|jsx|ts|tsx)\n    if [ \"$SIZE_KB\" -gt 100 ]; then\n      echo \"📦 JavaScript bundle size check: Consider code splitting for better performance\" >&2\n    fi\n    ;;\n  json)\n    if [ \"$SIZE_KB\" -gt 500 ]; then\n      echo \"📄 Large JSON detected: Consider pagination or streaming for API responses\" >&2\n    fi\n    ;;\n  jpg|jpeg|png|gif|webp)\n    if [ \"$SIZE_KB\" -gt 500 ]; then\n      echo \"🖼️ Image optimization: Large images impact web performance\" >&2\n      if command -v identify &> /dev/null; then\n        DIMENSIONS=$(identify -format '%wx%h' \"$FILE_PATH\" 2>/dev/null || echo \"unknown\")\n        echo \"   Dimensions: $DIMENSIONS\" >&2\n      fi\n    fi\n    ;;\n  css|scss|sass)\n    if [ \"$SIZE_KB\" -gt 200 ]; then\n      echo \"🎨 CSS size check: Consider removing unused styles or splitting stylesheets\" >&2\n    fi\n    ;;\nesac\n\n# Check if file is in git repository\nif command -v git &> /dev/null && git rev-parse --git-dir > /dev/null 2>&1; then\n  # Check if file is tracked by git\n  if git ls-files --error-unmatch \"$FILE_PATH\" &> /dev/null; then\n    echo \"🔄 Git repository impact:\" >&2\n    \n    # Check if file has grown significantly\n    if git log --oneline -n 1 -- \"$FILE_PATH\" &> /dev/null; then\n      # File has history, check previous size\n      PREV_SIZE=$(git show HEAD:\"$FILE_PATH\" 2>/dev/null | wc -c | xargs || echo \"0\")\n      if [ \"$PREV_SIZE\" -gt 0 ]; then\n        PREV_SIZE_HUMAN=$(format_size \"$PREV_SIZE\")\n        SIZE_DIFF=$((SIZE_BYTES - PREV_SIZE))\n        \n        if [ \"$SIZE_DIFF\" -gt 0 ]; then\n          DIFF_HUMAN=$(format_size \"$SIZE_DIFF\")\n          PERCENT_INCREASE=$((SIZE_DIFF * 100 / PREV_SIZE))\n          echo \"   Size change: +$DIFF_HUMAN (+$PERCENT_INCREASE%) from previous version\" >&2\n          \n          if [ \"$PERCENT_INCREASE\" -gt 100 ]; then\n            echo \"   📈 Significant size increase detected\" >&2\n          fi\n        fi\n      fi\n    fi\n    \n    # Suggest Git LFS for large files\n    if [ \"$SIZE_MB\" -gt 10 ]; then\n      echo \"   💡 Consider using Git LFS for this large file\" >&2\n      if [ -f \".gitattributes\" ]; then\n        if ! grep -q \"*.$FILE_EXTENSION.*lfs\" \".gitattributes\" 2>/dev/null; then\n          echo \"   Add to .gitattributes: *.$FILE_EXTENSION filter=lfs diff=lfs merge=lfs -text\" >&2\n        fi\n      else\n        echo \"   Create .gitattributes with: *.$FILE_EXTENSION filter=lfs diff=lfs merge=lfs -text\" >&2\n      fi\n    fi\n  fi\nfi\n\n# Overall performance impact assessment\necho \"\" >&2\necho \"📋 Performance Impact Assessment:\" >&2\n\nif [ \"$SIZE_MB\" -gt 50 ]; then\n  echo \"  🔴 High Impact: File may cause significant performance issues\" >&2\nelif [ \"$SIZE_MB\" -gt 10 ]; then\n  echo \"  🟡 Medium Impact: File may cause minor performance issues\" >&2\nelif [ \"$SIZE_KB\" -gt 500 ]; then\n  echo \"  🟢 Low Impact: File size is acceptable but monitor growth\" >&2\nelse\n  echo \"  ✅ Minimal Impact: File size is optimal\" >&2\nfi\n\necho \"\" >&2\necho \"💡 File Size Best Practices:\" >&2\necho \"   • Keep source code files under 500KB\" >&2\necho \"   • Optimize images before committing\" >&2\necho \"   • Use Git LFS for files over 10MB\" >&2\necho \"   • Consider file compression for large data files\" >&2\n\nexit 0"
      },
      "useCases": [
        "Real-time file size monitoring during development",
        "Performance optimization through size awareness",
        "Git repository size management",
        "Asset optimization for web applications",
        "CI/CD pipeline size validation"
      ],
      "troubleshooting": [
        {
          "issue": "Hook triggers warnings for legitimate large binary files",
          "solution": "Create size threshold overrides in .claude/hook-config.json: THRESHOLD_OVERRIDES={'*.wasm': 10485760}. Add file extension exclusions for known large asset types."
        },
        {
          "issue": "File size calculation fails on Windows with stat errors",
          "solution": "Use PowerShell fallback for Windows: (Get-Item $FILE_PATH).Length. Add platform detection: if [[ $OSTYPE == 'msys' ]], use alternative stat format or wc -c."
        },
        {
          "issue": "Git size comparison shows incorrect previous version size",
          "solution": "Check if file is staged vs committed: use git show :\"$FILE_PATH\" for staged, git show HEAD:\"$FILE_PATH\" for committed. Handle new files with [ -z $PREV_SIZE ] check."
        },
        {
          "issue": "Hook slows down every file write operation significantly",
          "solution": "Add file size pre-check before running full analysis: skip hook if size < 100KB. Use matcher filters: matchers: ['write'] only, exclude 'edit' for incremental changes."
        },
        {
          "issue": "Image dimension detection with identify command fails",
          "solution": "Check if ImageMagick installed: command -v identify || skip dimension check. Use alternative: file command for basic image info without requiring external dependencies."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/file-size-warning-monitor"
    },
    {
      "slug": "final-bundle-size-reporter",
      "description": "Analyzes and reports final bundle sizes when the development session ends",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "bundle-size",
        "performance",
        "stop-hook",
        "optimization",
        "reporting"
      ],
      "hookType": "Stop",
      "features": [
        "Comprehensive bundle size analysis for multiple build tools",
        "Asset size breakdown by file type (JS, CSS, images, fonts)",
        "Performance impact assessment with size thresholds",
        "Build output detection for various frameworks",
        "Timestamped bundle reports with historical tracking",
        "Bundle optimization recommendations",
        "Gzip and Brotli compression analysis",
        "Tree-shaking effectiveness measurement"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "stop": {
              "script": "./.claude/hooks/final-bundle-size-reporter.sh"
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\necho \"📦 FINAL BUNDLE SIZE REPORT\" >&2\necho \"===========================================\" >&2\n\n# Initialize variables\nTIMESTAMP=$(date +\"%Y-%m-%d %H:%M:%S\")\nREPORT_FILE=\"bundle-report-$(date +%Y%m%d_%H%M%S).txt\"\nBUILD_DETECTED=false\nTOTAL_SIZE=0\nJS_SIZE=0\nCSS_SIZE=0\nIMAGE_SIZE=0\nOTHER_SIZE=0\n\n# Function to convert bytes to human readable\nformat_bytes() {\n  local bytes=$1\n  if [ $bytes -ge 1073741824 ]; then\n    echo \"$(echo \"scale=2; $bytes/1073741824\" | bc 2>/dev/null || echo $((bytes/1073741824)))GB\"\n  elif [ $bytes -ge 1048576 ]; then\n    echo \"$(echo \"scale=2; $bytes/1048576\" | bc 2>/dev/null || echo $((bytes/1048576)))MB\"\n  elif [ $bytes -ge 1024 ]; then\n    echo \"$(echo \"scale=2; $bytes/1024\" | bc 2>/dev/null || echo $((bytes/1024)))KB\"\n  else\n    echo \"${bytes}B\"\n  fi\n}\n\n# Function to analyze directory\nanalyze_directory() {\n  local dir=\"$1\"\n  local label=\"$2\"\n  \n  if [ ! -d \"$dir\" ]; then\n    return\n  fi\n  \n  echo \"📁 Analyzing $label: $dir\" >&2\n  BUILD_DETECTED=true\n  \n  # Calculate total directory size\n  DIR_SIZE=$(du -sb \"$dir\" 2>/dev/null | cut -f1 || echo \"0\")\n  TOTAL_SIZE=$((TOTAL_SIZE + DIR_SIZE))\n  \n  echo \"   Total size: $(format_bytes $DIR_SIZE)\" >&2\n  \n  # Analyze by file types\n  echo \"   📊 File type breakdown:\" >&2\n  \n  # JavaScript files\n  if find \"$dir\" -name \"*.js\" -o -name \"*.mjs\" -o -name \"*.ts\" 2>/dev/null | head -1 > /dev/null; then\n    JS_FILES_SIZE=$(find \"$dir\" \\( -name \"*.js\" -o -name \"*.mjs\" -o -name \"*.ts\" \\) -exec du -cb {} + 2>/dev/null | tail -1 | cut -f1 || echo \"0\")\n    JS_SIZE=$((JS_SIZE + JS_FILES_SIZE))\n    echo \"      JavaScript: $(format_bytes $JS_FILES_SIZE)\" >&2\n  fi\n  \n  # CSS files\n  if find \"$dir\" -name \"*.css\" 2>/dev/null | head -1 > /dev/null; then\n    CSS_FILES_SIZE=$(find \"$dir\" -name \"*.css\" -exec du -cb {} + 2>/dev/null | tail -1 | cut -f1 || echo \"0\")\n    CSS_SIZE=$((CSS_SIZE + CSS_FILES_SIZE))\n    echo \"      CSS: $(format_bytes $CSS_FILES_SIZE)\" >&2\n  fi\n  \n  # Images\n  if find \"$dir\" \\( -name \"*.png\" -o -name \"*.jpg\" -o -name \"*.jpeg\" -o -name \"*.gif\" -o -name \"*.svg\" -o -name \"*.webp\" \\) 2>/dev/null | head -1 > /dev/null; then\n    IMG_FILES_SIZE=$(find \"$dir\" \\( -name \"*.png\" -o -name \"*.jpg\" -o -name \"*.jpeg\" -o -name \"*.gif\" -o -name \"*.svg\" -o -name \"*.webp\" \\) -exec du -cb {} + 2>/dev/null | tail -1 | cut -f1 || echo \"0\")\n    IMAGE_SIZE=$((IMAGE_SIZE + IMG_FILES_SIZE))\n    echo \"      Images: $(format_bytes $IMG_FILES_SIZE)\" >&2\n  fi\n  \n  # Show largest files in this directory\n  echo \"   🔍 Largest files:\" >&2\n  find \"$dir\" -type f -exec du -b {} + 2>/dev/null | sort -rn | head -5 | while read size file; do\n    echo \"      $(format_bytes $size) - $(basename \"$file\")\" >&2\n  done\n  \n  # Gzip analysis for text files\n  GZIPPABLE_SIZE=$(find \"$dir\" \\( -name \"*.js\" -o -name \"*.css\" -o -name \"*.html\" -o -name \"*.json\" \\) -exec du -cb {} + 2>/dev/null | tail -1 | cut -f1 || echo \"0\")\n  if [ \"$GZIPPABLE_SIZE\" -gt 0 ] && command -v gzip &> /dev/null; then\n    # Estimate gzip compression\n    TEMP_DIR=$(mktemp -d)\n    find \"$dir\" \\( -name \"*.js\" -o -name \"*.css\" -o -name \"*.html\" -o -name \"*.json\" \\) -exec cp {} \"$TEMP_DIR/\" \\; 2>/dev/null\n    \n    if [ \"$(ls -A \"$TEMP_DIR\" 2>/dev/null)\" ]; then\n      cd \"$TEMP_DIR\" && gzip *.* 2>/dev/null && GZIPPED_SIZE=$(du -cb *.gz 2>/dev/null | tail -1 | cut -f1 || echo \"0\") && cd - > /dev/null\n      \n      if [ \"$GZIPPED_SIZE\" -gt 0 ]; then\n        COMPRESSION_RATIO=$(echo \"scale=1; ($GZIPPABLE_SIZE - $GZIPPED_SIZE) * 100 / $GZIPPABLE_SIZE\" | bc 2>/dev/null || echo \"N/A\")\n        echo \"   📦 Gzip compression potential: $(format_bytes $GZIPPED_SIZE) (-${COMPRESSION_RATIO}%)\" >&2\n      fi\n    fi\n    \n    rm -rf \"$TEMP_DIR\" 2>/dev/null\n  fi\n  \n  echo \"\" >&2\n}\n\n# Start report\necho \"Starting bundle analysis at $TIMESTAMP\" >&2\necho \"\" >&2\n\n# Check if this is a Node.js project\nif [ -f \"package.json\" ]; then\n  echo \"🟢 Node.js project detected\" >&2\n  \n  PROJECT_NAME=$(grep '\"name\"' package.json | head -1 | cut -d'\"' -f4 2>/dev/null || echo \"Unknown\")\n  echo \"📋 Project: $PROJECT_NAME\" >&2\n  \n  # Try to build the project\n  echo \"🔨 Attempting to build project...\" >&2\n  \n  # Check for common build scripts\n  BUILD_SCRIPT=\"\"\n  if grep -q '\"build\"' package.json; then\n    BUILD_SCRIPT=\"npm run build\"\n  elif grep -q '\"build:prod\"' package.json; then\n    BUILD_SCRIPT=\"npm run build:prod\"\n  elif grep -q '\"dist\"' package.json; then\n    BUILD_SCRIPT=\"npm run dist\"\n  fi\n  \n  if [ -n \"$BUILD_SCRIPT\" ]; then\n    echo \"   Running: $BUILD_SCRIPT\" >&2\n    if $BUILD_SCRIPT > /tmp/build_output.log 2>&1; then\n      echo \"   ✅ Build completed successfully\" >&2\n    else\n      echo \"   ⚠️ Build failed or incomplete - analyzing existing output\" >&2\n      echo \"   📝 Build log: /tmp/build_output.log\" >&2\n    fi\n  else\n    echo \"   ℹ️ No build script found - analyzing existing files\" >&2\n  fi\n  \n  echo \"\" >&2\nfi\n\n# Common build output directories\nBUILD_DIRS=(\"dist\" \"build\" \"out\" \".next\" \"public\" \"www\" \"target/release\")\n\n# Analyze each potential build directory\nfor dir in \"${BUILD_DIRS[@]}\"; do\n  if [ -d \"$dir\" ]; then\n    case \"$dir\" in\n      \"dist\")\n        analyze_directory \"$dir\" \"Distribution Build\"\n        ;;\n      \"build\")\n        analyze_directory \"$dir\" \"Production Build\"\n        ;;\n      \"out\")\n        analyze_directory \"$dir\" \"Output Build\"\n        ;;\n      \".next\")\n        analyze_directory \"$dir\" \"Next.js Build\"\n        ;;\n      \"public\")\n        # Only analyze if it looks like a build output\n        if [ -f \"$dir/index.html\" ] || [ -f \"$dir/main.js\" ]; then\n          analyze_directory \"$dir\" \"Public Assets\"\n        fi\n        ;;\n      \"www\")\n        analyze_directory \"$dir\" \"Web Assets\"\n        ;;\n      \"target/release\")\n        analyze_directory \"$dir\" \"Rust Release Build\"\n        ;;\n    esac\n  fi\ndone\n\n# Framework-specific analysis\nif [ -f \"webpack.config.js\" ] || [ -f \"webpack.config.ts\" ]; then\n  echo \"⚙️ Webpack configuration detected\" >&2\n  \n  # Look for webpack-bundle-analyzer output\n  if [ -f \"bundle-analyzer-report.html\" ]; then\n    echo \"   📊 Bundle analyzer report available: bundle-analyzer-report.html\" >&2\n  fi\nfi\n\nif [ -f \"vite.config.js\" ] || [ -f \"vite.config.ts\" ]; then\n  echo \"⚡ Vite configuration detected\" >&2\nfi\n\nif [ -f \"next.config.js\" ] || [ -f \"next.config.ts\" ]; then\n  echo \"▲ Next.js configuration detected\" >&2\nfi\n\nif [ -f \"rollup.config.js\" ]; then\n  echo \"📦 Rollup configuration detected\" >&2\nfi\n\n# Generate summary\necho \"\" >&2\necho \"📋 BUNDLE SIZE SUMMARY\" >&2\necho \"=====================================\" >&2\n\nif [ \"$BUILD_DETECTED\" = true ]; then\n  echo \"📊 Total bundle size: $(format_bytes $TOTAL_SIZE)\" >&2\n  echo \"\" >&2\n  echo \"📈 Breakdown by type:\" >&2\n  [ \"$JS_SIZE\" -gt 0 ] && echo \"   JavaScript: $(format_bytes $JS_SIZE)\" >&2\n  [ \"$CSS_SIZE\" -gt 0 ] && echo \"   CSS: $(format_bytes $CSS_SIZE)\" >&2\n  [ \"$IMAGE_SIZE\" -gt 0 ] && echo \"   Images: $(format_bytes $IMAGE_SIZE)\" >&2\n  \n  echo \"\" >&2\n  echo \"🎯 Performance Assessment:\" >&2\n  \n  # Performance thresholds\n  if [ \"$TOTAL_SIZE\" -gt 5242880 ]; then  # 5MB\n    echo \"   🔴 Large bundle size - may impact load times significantly\" >&2\n  elif [ \"$TOTAL_SIZE\" -gt 1048576 ]; then  # 1MB\n    echo \"   🟡 Moderate bundle size - consider optimization\" >&2\n  else\n    echo \"   🟢 Good bundle size - within performance budget\" >&2\n  fi\n  \n  if [ \"$JS_SIZE\" -gt 1048576 ]; then  # 1MB JS\n    echo \"   ⚠️ JavaScript bundle is large - consider code splitting\" >&2\n  fi\n  \n  echo \"\" >&2\n  echo \"💡 Optimization Recommendations:\" >&2\n  echo \"   • Enable gzip/brotli compression on your server\" >&2\n  echo \"   • Consider code splitting for large JavaScript bundles\" >&2\n  echo \"   • Optimize images with modern formats (WebP, AVIF)\" >&2\n  echo \"   • Remove unused CSS and JavaScript code\" >&2\n  echo \"   • Use dynamic imports for non-critical code\" >&2\n  \nelse\n  echo \"ℹ️ No build output detected in common directories\" >&2\n  echo \"   Searched: ${BUILD_DIRS[*]}\" >&2\n  echo \"   Consider running a build command first\" >&2\nfi\n\necho \"\" >&2\necho \"📄 Report timestamp: $TIMESTAMP\" >&2\necho \"💾 Full report saved to: $REPORT_FILE\" >&2\n\n# Save detailed report to file\n{\n  echo \"BUNDLE SIZE REPORT\"\n  echo \"Generated: $TIMESTAMP\"\n  echo \"Project: $(basename \"$(pwd)\")\"\n  echo \"\"\n  \n  if [ \"$BUILD_DETECTED\" = true ]; then\n    echo \"SUMMARY\"\n    echo \"=======\"\n    echo \"Total Size: $(format_bytes $TOTAL_SIZE)\"\n    echo \"JavaScript: $(format_bytes $JS_SIZE)\"\n    echo \"CSS: $(format_bytes $CSS_SIZE)\"\n    echo \"Images: $(format_bytes $IMAGE_SIZE)\"\n    echo \"\"\n    \n    echo \"DETAILED ANALYSIS\"\n    echo \"=================\"\n    for dir in \"${BUILD_DIRS[@]}\"; do\n      if [ -d \"$dir\" ]; then\n        echo \"$dir directory:\"\n        find \"$dir\" -type f -exec du -b {} + 2>/dev/null | sort -rn | head -10 | while read size file; do\n          echo \"  $(format_bytes $size) - $file\"\n        done\n        echo \"\"\n      fi\n    done\n  else\n    echo \"No build output detected\"\n  fi\n} > \"$REPORT_FILE\"\n\necho \"=====================================\" >&2\n\nexit 0"
      },
      "useCases": [
        "End-of-session bundle size analysis and tracking",
        "Performance budget monitoring for web applications",
        "Build optimization impact measurement",
        "CI/CD pipeline bundle size validation",
        "Framework-agnostic build output analysis"
      ],
      "troubleshooting": [
        {
          "issue": "No build output detected even after running build",
          "solution": "Hook searches standard directories (dist, build, out, .next). Check your build output location in package.json or framework config and add custom directory to BUILD_DIRS array in hook script."
        },
        {
          "issue": "Build command runs but fails silently in hook",
          "solution": "Check /tmp/build_output.log for error details. Ensure build script in package.json doesn't require interactive prompts. Add --no-interactive or CI=true environment variable to build command."
        },
        {
          "issue": "Bundle size calculation includes development files",
          "solution": "Hook analyzes build output directories only. Ensure your build process excludes source maps, test files, and dev dependencies. Check if framework outputs dev builds to different directory."
        },
        {
          "issue": "Gzip compression analysis shows N/A or fails",
          "solution": "Install bc command for compression ratio calculation (brew install bc on macOS). Ensure gzip is available in PATH. Large bundles may timeout in compression analysis, skip for files over 100MB."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/final-bundle-size-reporter"
    },
    {
      "slug": "git-auto-commit-on-stop",
      "description": "Automatically commits all changes with a summary when Claude Code session ends",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "git",
        "version-control",
        "stop-hook",
        "automation",
        "commit"
      ],
      "hookType": "Stop",
      "features": [
        "Automatic git commit creation when session ends",
        "Detailed commit statistics (files changed, insertions, deletions)",
        "Smart commit message generation with timestamps",
        "Pre-commit validation and safety checks",
        "Branch and repository state verification",
        "Customizable commit message templates",
        "Untracked file handling and gitignore respect",
        "Error handling with informative feedback"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "stop": {
              "script": "./.claude/hooks/git-auto-commit-on-stop.sh"
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\necho \"💾 Checking for changes to auto-commit...\" >&2\n\n# Check if we're in a git repository\nif ! git rev-parse --git-dir > /dev/null 2>&1; then\n  echo \"⚠️ Not in a git repository - skipping auto-commit\" >&2\n  exit 0\nfi\n\n# Check if git is configured\nif ! git config user.email > /dev/null 2>&1 || ! git config user.name > /dev/null 2>&1; then\n  echo \"⚠️ Git user not configured - skipping auto-commit\" >&2\n  echo \"💡 Run: git config --global user.email 'your@email.com'\" >&2\n  echo \"💡 Run: git config --global user.name 'Your Name'\" >&2\n  exit 0\nfi\n\n# Get current timestamp\nTIMESTAMP=$(date +\"%Y-%m-%d %H:%M:%S\")\nISO_TIMESTAMP=$(date -u +\"%Y-%m-%dT%H:%M:%SZ\" 2>/dev/null || date +\"%Y-%m-%d %H:%M:%S UTC\")\n\n# Get current branch\nCURRENT_BRANCH=$(git branch --show-current 2>/dev/null || echo \"unknown\")\n\n# Check for uncommitted changes\nif [ -z \"$(git status --porcelain 2>/dev/null)\" ]; then\n  echo \"✨ No changes to commit - repository is clean\" >&2\n  exit 0\nfi\n\necho \"📊 Analyzing changes for auto-commit...\" >&2\n\n# Get status information\nUNTRACKED_FILES=$(git status --porcelain 2>/dev/null | grep '^??' | wc -l | xargs)\nMODIFIED_FILES=$(git status --porcelain 2>/dev/null | grep '^.M' | wc -l | xargs)\nADDED_FILES=$(git status --porcelain 2>/dev/null | grep '^A' | wc -l | xargs)\nDELETED_FILES=$(git status --porcelain 2>/dev/null | grep '^.D' | wc -l | xargs)\nRENAMED_FILES=$(git status --porcelain 2>/dev/null | grep '^R' | wc -l | xargs)\n\necho \"📋 Change summary:\" >&2\necho \"   Branch: $CURRENT_BRANCH\" >&2\necho \"   Untracked: $UNTRACKED_FILES files\" >&2\necho \"   Modified: $MODIFIED_FILES files\" >&2\necho \"   Added: $ADDED_FILES files\" >&2\necho \"   Deleted: $DELETED_FILES files\" >&2\necho \"   Renamed: $RENAMED_FILES files\" >&2\n\n# Check for sensitive files before committing\necho \"🔒 Checking for sensitive files...\" >&2\nSENSITIVE_PATTERNS=(\n  \"\\.env\"\n  \"\\.env\\.*\"\n  \"*secret*\"\n  \"*password*\"\n  \"*key*\"\n  \"id_rsa\"\n  \"id_ed25519\"\n  \"*.pem\"\n  \"*.p12\"\n  \"*.pfx\"\n)\n\nSENSITIVE_FOUND=false\nfor pattern in \"${SENSITIVE_PATTERNS[@]}\"; do\n  if git status --porcelain 2>/dev/null | grep -q \"$pattern\"; then\n    SENSITIVE_FOUND=true\n    echo \"⚠️ Potentially sensitive file detected: $pattern\" >&2\n  fi\ndone\n\n# Check if .gitignore exists and is respected\nif [ ! -f \".gitignore\" ]; then\n  echo \"💡 Consider creating a .gitignore file to exclude unwanted files\" >&2\nfi\n\n# Option to skip auto-commit if environment variable is set\nif [ \"$SKIP_AUTO_COMMIT\" = \"true\" ]; then\n  echo \"⏭️ Auto-commit skipped (SKIP_AUTO_COMMIT=true)\" >&2\n  exit 0\nfi\n\n# Warn about sensitive files but don't block (user choice)\nif [ \"$SENSITIVE_FOUND\" = true ]; then\n  echo \"⚠️ Sensitive files detected - proceeding with caution\" >&2\n  echo \"💡 Set SKIP_AUTO_COMMIT=true to disable auto-commits\" >&2\nfi\n\n# Add all changes (respecting .gitignore)\necho \"📥 Staging changes for commit...\" >&2\ngit add -A\n\n# Double-check that we have staged changes\nif [ -z \"$(git diff --cached --name-only)\" ]; then\n  echo \"ℹ️ No changes staged after git add - nothing to commit\" >&2\n  exit 0\nfi\n\n# Calculate detailed statistics\necho \"📊 Calculating commit statistics...\" >&2\n\nFILES_CHANGED=$(git diff --cached --numstat | wc -l | xargs)\nINSERTIONS=0\nDELETIONS=0\n\n# Calculate insertions and deletions more reliably\nif command -v awk &> /dev/null; then\n  STATS=$(git diff --cached --numstat | awk '{insertions+=$1; deletions+=$2} END {print insertions \" \" deletions}')\n  read -r INSERTIONS DELETIONS <<< \"$STATS\"\nelse\n  # Fallback method\n  INSERTIONS=$(git diff --cached --stat | grep -oE '[0-9]+ insertion' | grep -oE '[0-9]+' | paste -sd+ | bc 2>/dev/null || echo '0')\n  DELETIONS=$(git diff --cached --stat | grep -oE '[0-9]+ deletion' | grep -oE '[0-9]+' | paste -sd+ | bc 2>/dev/null || echo '0')\nfi\n\n# Generate commit message\nCOMMIT_MSG=\"🤖 Claude Code auto-commit: Session ended\"\n\n# Add detailed commit body\nCOMMIT_BODY=$(cat <<EOF\n\nSession Summary:\n- Branch: $CURRENT_BRANCH\n- Files changed: $FILES_CHANGED\n- Insertions: +$INSERTIONS\n- Deletions: -$DELETIONS\n- Timestamp: $TIMESTAMP\n\nChanges by type:\n- Modified files: $MODIFIED_FILES\n- New files: $UNTRACKED_FILES\n- Deleted files: $DELETED_FILES\n- Renamed files: $RENAMED_FILES\n\n🤖 Generated with Claude Code\nEOF\n)\n\n# Show what will be committed\necho \"📝 Files to be committed:\" >&2\ngit diff --cached --name-status | head -10 | while read status file; do\n  case $status in\n    A) echo \"   ✅ Added: $file\" >&2 ;;\n    M) echo \"   ✏️  Modified: $file\" >&2 ;;\n    D) echo \"   ❌ Deleted: $file\" >&2 ;;\n    R*) echo \"   🔄 Renamed: $file\" >&2 ;;\n    *) echo \"   📄 $status: $file\" >&2 ;;\n  esac\ndone\n\nif [ \"$FILES_CHANGED\" -gt 10 ]; then\n  echo \"   ... and $((FILES_CHANGED - 10)) more files\" >&2\nfi\n\necho \"\" >&2\necho \"💾 Creating auto-commit...\" >&2\n\n# Create the commit\nif echo \"$COMMIT_BODY\" | git commit -F -; then\n  echo \"✅ Auto-commit successful!\" >&2\n  \n  # Show commit info\n  COMMIT_HASH=$(git rev-parse --short HEAD)\n  echo \"📝 Commit: $COMMIT_HASH\" >&2\n  echo \"🌿 Branch: $CURRENT_BRANCH\" >&2\n  \n  # Check if we should push (optional)\n  if [ \"$AUTO_PUSH\" = \"true\" ]; then\n    echo \"📤 Auto-pushing to remote...\" >&2\n    if git push 2>/dev/null; then\n      echo \"✅ Pushed to remote successfully\" >&2\n    else\n      echo \"⚠️ Push failed - commit created locally\" >&2\n      echo \"💡 Run 'git push' manually when ready\" >&2\n    fi\n  else\n    echo \"💡 Set AUTO_PUSH=true to automatically push commits\" >&2\n  fi\n  \nelse\n  echo \"❌ Auto-commit failed\" >&2\n  echo \"💡 You may need to resolve conflicts or check git status\" >&2\n  exit 1\nfi\n\necho \"\" >&2\necho \"📋 Auto-Commit Summary:\" >&2\necho \"   ✅ $FILES_CHANGED files committed\" >&2\necho \"   📈 +$INSERTIONS insertions, -$DELETIONS deletions\" >&2\necho \"   ⏰ $TIMESTAMP\" >&2\necho \"\" >&2\necho \"💡 Git Auto-Commit Tips:\" >&2\necho \"   • Set SKIP_AUTO_COMMIT=true to disable\" >&2\necho \"   • Set AUTO_PUSH=true to auto-push commits\" >&2\necho \"   • Review commits with 'git log --oneline'\" >&2\necho \"   • Use .gitignore to exclude sensitive files\" >&2\n\nexit 0"
      },
      "useCases": [
        "Automatic version control for development sessions",
        "Backup and history preservation of work progress",
        "Collaborative development with session tracking",
        "CI/CD integration with automated commits",
        "Project milestone and progress documentation"
      ],
      "troubleshooting": [
        {
          "issue": "Hook creates commits even when no meaningful changes made",
          "solution": "git status --porcelain check shows temp files. Update .gitignore excluding: '.DS_Store', '.swp', 'node_modules/'. Or add file count threshold: 'if [ \"$MODIFIED_FILES\" -lt 2 ]; then exit 0; fi'."
        },
        {
          "issue": "Sensitive files (.env) committed despite pattern detection warnings",
          "solution": "Pattern match non-blocking by design. Add hard block: 'if [ \"$SENSITIVE_FOUND\" = true ]; then exit 1; fi' before git add. Or use git-secrets: 'git secrets --scan' pre-commit."
        },
        {
          "issue": "Auto-commit fails with empty commit message or malformed body",
          "solution": "COMMIT_BODY uses cat with EOF delimiter requiring proper quoting. Replace with: 'git commit -m \"Auto-commit: $TIMESTAMP\" -m \"Files: $FILES_CHANGED\" -m \"Branch: $CURRENT_BRANCH\"' avoiding heredoc issues."
        },
        {
          "issue": "SKIP_AUTO_COMMIT environment variable ignored when set",
          "solution": "Variable not exported to subprocess. Use: 'export SKIP_AUTO_COMMIT=true' before Claude session. Or add to shell profile: 'echo \"export SKIP_AUTO_COMMIT=true\" >> ~/.bashrc'. Verify: 'env | grep SKIP'."
        },
        {
          "issue": "Statistics show zero insertions/deletions despite file changes",
          "solution": "git diff --stat fails on binary files or first commit. Add: '--ignore-all-space --ignore-blank-lines' flags. Or use: 'git diff --numstat | awk \"{add+=$1; del+=$2} END {print add, del}\"' for accurate counts."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/git-auto-commit-on-stop"
    },
    {
      "slug": "git-branch-protection",
      "description": "Prevents direct edits to protected branches like main or master, enforcing PR-based workflows",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "git",
        "branch-protection",
        "workflow",
        "safety"
      ],
      "hookType": "PreToolUse",
      "features": [
        "Protection of critical branches (main, master, production, release)",
        "Configurable protected branch patterns",
        "Clear error messages with actionable guidance",
        "Feature branch creation suggestions",
        "Integration with CI/CD workflow enforcement",
        "Override capability for emergency changes",
        "Branch naming convention validation",
        "Repository safety and collaboration enforcement"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "preToolUse": {
              "script": "./.claude/hooks/git-branch-protection.sh",
              "matchers": [
                "edit",
                "write",
                "multiEdit"
              ]
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\n# Check if we're in a git repository\nif ! git rev-parse --git-dir > /dev/null 2>&1; then\n  # Not in a git repo, allow the operation\n  exit 0\nfi\n\n# Get current branch\nCURRENT_BRANCH=$(git rev-parse --abbrev-ref HEAD 2>/dev/null)\n\nif [ -z \"$CURRENT_BRANCH\" ]; then\n  # Can't determine branch, allow operation with warning\n  echo \"⚠️ Warning: Unable to determine current Git branch\" >&2\n  exit 0\nfi\n\necho \"🔍 Checking branch protection for: $CURRENT_BRANCH\" >&2\n\n# Define protected branches (can be customized via environment variables)\nPROTECTED_BRANCHES=()\n\n# Default protected branches\nDEFAULT_PROTECTED=(\"main\" \"master\" \"production\" \"prod\" \"release\" \"staging\" \"develop\")\n\n# Add custom protected branches from environment variable\nif [ -n \"$PROTECTED_BRANCHES_LIST\" ]; then\n  IFS=',' read -ra CUSTOM_PROTECTED <<< \"$PROTECTED_BRANCHES_LIST\"\n  PROTECTED_BRANCHES+=(\"${CUSTOM_PROTECTED[@]}\")\nelse\n  PROTECTED_BRANCHES+=(\"${DEFAULT_PROTECTED[@]}\")\nfi\n\n# Check if current branch is protected\nIS_PROTECTED=false\nfor protected_branch in \"${PROTECTED_BRANCHES[@]}\"; do\n  if [[ \"$CURRENT_BRANCH\" == \"$protected_branch\" ]]; then\n    IS_PROTECTED=true\n    break\n  fi\ndone\n\n# Check for pattern-based protection (e.g., release/* branches)\nPROTECTED_PATTERNS=(\"release/*\" \"hotfix/*\" \"support/*\")\nif [ -n \"$PROTECTED_PATTERNS_LIST\" ]; then\n  IFS=',' read -ra CUSTOM_PATTERNS <<< \"$PROTECTED_PATTERNS_LIST\"\n  PROTECTED_PATTERNS+=(\"${CUSTOM_PATTERNS[@]}\")\nfi\n\nfor pattern in \"${PROTECTED_PATTERNS[@]}\"; do\n  if [[ \"$CURRENT_BRANCH\" == $pattern ]]; then\n    IS_PROTECTED=true\n    break\n  fi\ndone\n\n# Allow override in emergency situations\nif [ \"$FORCE_ALLOW_PROTECTED_EDIT\" = \"true\" ]; then\n  echo \"⚠️ EMERGENCY OVERRIDE: Allowing edit on protected branch $CURRENT_BRANCH\" >&2\n  echo \"💡 Remove FORCE_ALLOW_PROTECTED_EDIT=true when done\" >&2\n  exit 0\nfi\n\n# If branch is protected, prevent the operation\nif [ \"$IS_PROTECTED\" = true ]; then\n  echo \"\" >&2\n  echo \"🚫 BRANCH PROTECTION VIOLATION\" >&2\n  echo \"=====================================\" >&2\n  echo \"❌ Direct edits to '$CURRENT_BRANCH' branch are not allowed\" >&2\n  echo \"\" >&2\n  echo \"🔒 Protected branches: ${PROTECTED_BRANCHES[*]}\" >&2\n  echo \"🔒 Protected patterns: ${PROTECTED_PATTERNS[*]}\" >&2\n  echo \"\" >&2\n  echo \"✅ Recommended workflow:\" >&2\n  echo \"   1. Create a feature branch:\" >&2\n  echo \"      git checkout -b feature/your-feature-name\" >&2\n  echo \"\" >&2\n  echo \"   2. Make your changes on the feature branch\" >&2\n  echo \"\" >&2\n  echo \"   3. Push and create a Pull Request:\" >&2\n  echo \"      git push -u origin feature/your-feature-name\" >&2\n  echo \"\" >&2\n  \n  # Suggest specific branch names based on the file being edited\n  if [ -n \"$FILE_PATH\" ]; then\n    BASE_NAME=$(basename \"$FILE_PATH\" | cut -d. -f1)\n    SUGGESTED_BRANCH=\"feature/update-${BASE_NAME}\"\n    echo \"💡 Suggested branch name: $SUGGESTED_BRANCH\" >&2\n    echo \"   Quick command: git checkout -b $SUGGESTED_BRANCH\" >&2\n    echo \"\" >&2\n  fi\n  \n  # Show current branch status\n  echo \"📊 Current repository status:\" >&2\n  echo \"   Current branch: $CURRENT_BRANCH\" >&2\n  \n  # Show available branches\n  AVAILABLE_BRANCHES=$(git branch | grep -v \"\\*\" | head -5 | xargs)\n  if [ -n \"$AVAILABLE_BRANCHES\" ]; then\n    echo \"   Available branches: $AVAILABLE_BRANCHES\" >&2\n  fi\n  \n  # Check if there are uncommitted changes\n  if [ -n \"$(git status --porcelain 2>/dev/null)\" ]; then\n    echo \"   ⚠️ You have uncommitted changes\" >&2\n    echo \"   💡 Consider: git stash (to save changes temporarily)\" >&2\n  fi\n  \n  echo \"\" >&2\n  echo \"🆘 Emergency override (use with caution):\" >&2\n  echo \"   FORCE_ALLOW_PROTECTED_EDIT=true [your command]\" >&2\n  echo \"\" >&2\n  echo \"📚 Branch protection helps maintain:\" >&2\n  echo \"   • Code quality through peer review\" >&2\n  echo \"   • Stable main/master branches\" >&2\n  echo \"   • Proper CI/CD pipeline execution\" >&2\n  echo \"   • Team collaboration standards\" >&2\n  echo \"\" >&2\n  \n  # Exit with error to prevent the tool from running\n  exit 1\nfi\n\n# Branch is not protected, show informational message\necho \"✅ Branch '$CURRENT_BRANCH' is not protected - operation allowed\" >&2\n\n# Show branch protection tips for unprotected branches\nif [[ \"$CURRENT_BRANCH\" == feature/* ]] || [[ \"$CURRENT_BRANCH\" == bugfix/* ]] || [[ \"$CURRENT_BRANCH\" == hotfix/* ]]; then\n  echo \"💡 Working on feature branch - remember to create a PR when ready\" >&2\nfi\n\n# Check if branch is ahead/behind remote\nif git rev-parse --verify \"origin/$CURRENT_BRANCH\" > /dev/null 2>&1; then\n  AHEAD=$(git rev-list --count \"origin/$CURRENT_BRANCH\"..HEAD 2>/dev/null || echo \"0\")\n  BEHIND=$(git rev-list --count HEAD..\"origin/$CURRENT_BRANCH\" 2>/dev/null || echo \"0\")\n  \n  if [ \"$AHEAD\" -gt 0 ]; then\n    echo \"📤 Branch is $AHEAD commits ahead of origin\" >&2\n  fi\n  \n  if [ \"$BEHIND\" -gt 0 ]; then\n    echo \"📥 Branch is $BEHIND commits behind origin - consider pulling\" >&2\n  fi\nfi\n\n# All checks passed, allow the operation\nexit 0"
      },
      "useCases": [
        "Enforcing pull request workflows in team environments",
        "Preventing accidental direct commits to main branches",
        "CI/CD pipeline protection and quality gates",
        "Code review process enforcement",
        "Repository governance and compliance"
      ],
      "troubleshooting": [
        {
          "issue": "Hook blocks edits even when FORCE_ALLOW_PROTECTED_EDIT set to true",
          "solution": "Environment variable not exported to hook subprocess. Use: 'export FORCE_ALLOW_PROTECTED_EDIT=true' before command. Or add to .bashrc/.zshrc for session-wide availability."
        },
        {
          "issue": "Protected branch pattern matching fails for release/* branches",
          "solution": "Bash pattern requires proper glob: use 'case \"$CURRENT_BRANCH\" in release/*) IS_PROTECTED=true;;' instead of [[ match. Or use regex: '[[ \"$CURRENT_BRANCH\" =~ ^release/ ]]'."
        },
        {
          "issue": "Custom protected branches from PROTECTED_BRANCHES_LIST ignored",
          "solution": "CSV parsing expects exact format. Ensure no spaces: 'main,staging,prod' not 'main, staging, prod'. Or handle: 'IFS=',' read -ra CUSTOM | tr -d ' '' stripping whitespace."
        },
        {
          "issue": "Branch detection fails in detached HEAD state showing empty branch",
          "solution": "git rev-parse --abbrev-ref returns 'HEAD' when detached. Add check: 'if [ \"$CURRENT_BRANCH\" = \"HEAD\" ]; then echo \"Detached HEAD allowed\"; exit 0; fi' before protection logic."
        },
        {
          "issue": "Suggested branch names contain special characters breaking git commands",
          "solution": "Filename with spaces/slashes creates invalid branch names. Sanitize: 'SUGGESTED=$(echo \"$BASE_NAME\" | tr ' /' '-' | tr -cd 'a-zA-Z0-9-')' removing unsafe characters before suggestion."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/git-branch-protection"
    },
    {
      "slug": "git-pre-commit-validator",
      "description": "Comprehensive pre-commit hook that validates code quality, runs tests, and enforces standards",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-16",
      "tags": [
        "git",
        "validation",
        "code-quality",
        "testing",
        "automation"
      ],
      "hookType": "PreToolUse",
      "features": [
        "Code quality validation with linting and formatting",
        "Security scanning for secrets and vulnerabilities",
        "Automated test execution before commits",
        "File validation and size limits",
        "Commit message format enforcement",
        "Support for multiple programming languages",
        "Integration with popular pre-commit frameworks"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "preToolUse": {
              "script": "./.claude/hooks/git-pre-commit-validator.sh",
              "matchers": [
                "git"
              ]
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nCOMMAND=$(echo \"$INPUT\" | jq -r '.tool_input.command // \"\"')\n\n# Only run on git commit commands\nif [[ \"$COMMAND\" != *\"git commit\"* ]]; then\n  exit 0\nfi\n\necho \"🔍 Running pre-commit validations...\"\n\n# Check for staged files\nSTAGED_FILES=$(git diff --cached --name-only 2>/dev/null || echo \"\")\nif [ -z \"$STAGED_FILES\" ]; then\n  echo \"No staged files to validate\"\n  exit 0\nfi\n\necho \"Validating staged files: $STAGED_FILES\"\n\n# Check for forbidden files\necho \"Checking for forbidden files...\"\nif echo \"$STAGED_FILES\" | grep -E \"\\.(env|DS_Store)$|node_modules/\"; then\n  echo \"❌ Forbidden files detected in staging area\" >&2\n  echo \"Remove .env, .DS_Store, or node_modules files before committing\" >&2\n  exit 2\nfi\n\n# Check file sizes\necho \"Checking file sizes...\"\nfor file in $STAGED_FILES; do\n  if [ -f \"$file\" ]; then\n    size=$(wc -c < \"$file\")\n    if [ \"$size\" -gt 10485760 ]; then  # 10MB limit\n      echo \"⚠️ Large file detected: $file ($(($size / 1024 / 1024))MB)\" >&2\n    fi\n  fi\ndone\n\n# Run linting if available\nif command -v npm &> /dev/null && [ -f \"package.json\" ]; then\n  echo \"Running ESLint...\"\n  npm run lint 2>/dev/null || echo \"⚠️ Linting issues found\" >&2\nfi\n\n# Run formatting if available\nif command -v prettier &> /dev/null; then\n  echo \"Running Prettier...\"\n  prettier --check $STAGED_FILES 2>/dev/null || echo \"⚠️ Formatting issues found\" >&2\nfi\n\n# Run tests if available\nif command -v npm &> /dev/null && [ -f \"package.json\" ]; then\n  echo \"Running tests...\"\n  npm test 2>/dev/null || echo \"⚠️ Tests failed\" >&2\nfi\n\necho \"✅ Pre-commit validation completed\" >&2\nexit 0"
      },
      "useCases": [
        "Enforce code quality standards before commits",
        "Automated testing in git workflows",
        "Prevent commits with security vulnerabilities",
        "Maintain consistent code formatting across team",
        "Validate commit message conventions"
      ],
      "troubleshooting": [
        {
          "issue": "Hook blocks all git commits even when validation passes",
          "solution": "Ensure script exits with exit 0 on success. Check that matchers pattern ['git'] doesn't intercept non-commit git commands like status or diff which should bypass validation."
        },
        {
          "issue": "npm run lint fails with 'script not found' error",
          "solution": "Add existence check before running: [ -f package.json ] && grep -q '\"lint\"' package.json before npm run lint. Provide fallback or skip linting gracefully if unavailable."
        },
        {
          "issue": "Prettier check prevents commits due to formatting differences",
          "solution": "Auto-fix formatting instead of blocking: prettier --write $STAGED_FILES && git add $STAGED_FILES. Alternatively, set --warn-only flag to log issues without exit code."
        },
        {
          "issue": "Test suite runs entire test set causing slow commit times",
          "solution": "Run only tests related to changed files: npm test -- --findRelatedTests $STAGED_FILES. Add timeout: npm test -- --maxWorkers=2 --bail for faster feedback."
        },
        {
          "issue": "Hook rejects large files but files are already in history",
          "solution": "Check if file is new vs modified: git diff --cached --diff-filter=A to detect additions only. Skip size check for existing tracked files to avoid retroactive enforcement."
        }
      ],
      "documentationUrl": "https://pre-commit.com/",
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/git-pre-commit-validator"
    },
    {
      "slug": "github-actions-workflow-validator",
      "seoTitle": "GitHub Actions Validator",
      "description": "Validates GitHub Actions workflow files for syntax errors and best practices",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "github-actions",
        "ci-cd",
        "workflows",
        "validation",
        "yaml"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Comprehensive GitHub Actions workflow YAML validation",
        "Actionlint integration for advanced workflow checking",
        "Deprecated action version detection and warnings",
        "Security best practices validation (permissions, secrets)",
        "YAML syntax verification with fallback methods",
        "Action pinning and version control recommendations",
        "Workflow performance and optimization suggestions",
        "CI/CD pipeline security and compliance checking"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/github-actions-workflow-validator.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Check if this is a GitHub Actions workflow file\nif [[ \"$FILE_PATH\" == *.github/workflows/*.yml ]] || [[ \"$FILE_PATH\" == *.github/workflows/*.yaml ]]; then\n  echo \"🔄 Validating GitHub Actions workflow: $(basename \"$FILE_PATH\")\" >&2\n  \n  # Initialize validation counters\n  WARNINGS=0\n  ERRORS=0\n  SUGGESTIONS=0\n  \n  # Function to report issues\n  report_issue() {\n    local level=\"$1\"\n    local message=\"$2\"\n    \n    case \"$level\" in\n      \"ERROR\")\n        echo \"❌ ERROR: $message\" >&2\n        ERRORS=$((ERRORS + 1))\n        ;;\n      \"WARNING\")\n        echo \"⚠️ WARNING: $message\" >&2\n        WARNINGS=$((WARNINGS + 1))\n        ;;\n      \"SUGGESTION\")\n        echo \"💡 SUGGESTION: $message\" >&2\n        SUGGESTIONS=$((SUGGESTIONS + 1))\n        ;;\n      \"INFO\")\n        echo \"ℹ️ INFO: $message\" >&2\n        ;;\n    esac\n  }\n  \n  # Check if file exists and is readable\n  if [ ! -f \"$FILE_PATH\" ]; then\n    report_issue \"ERROR\" \"Workflow file not found: $FILE_PATH\"\n    exit 1\n  fi\n  \n  # 1. YAML Syntax Validation\n  echo \"📋 Checking YAML syntax...\" >&2\n  \n  # Try actionlint first (most comprehensive)\n  if command -v actionlint &> /dev/null; then\n    echo \"   Using actionlint for comprehensive validation...\" >&2\n    \n    ACTIONLINT_OUTPUT=$(actionlint \"$FILE_PATH\" 2>&1)\n    ACTIONLINT_EXIT_CODE=$?\n    \n    if [ $ACTIONLINT_EXIT_CODE -eq 0 ]; then\n      echo \"   ✅ actionlint validation passed\" >&2\n    else\n      report_issue \"ERROR\" \"actionlint validation failed\"\n      echo \"$ACTIONLINT_OUTPUT\" >&2\n    fi\n  else\n    # Fallback to yamllint\n    if command -v yamllint &> /dev/null; then\n      echo \"   Using yamllint for YAML validation...\" >&2\n      if yamllint \"$FILE_PATH\" 2>/dev/null; then\n        echo \"   ✅ YAML syntax valid (yamllint)\" >&2\n      else\n        report_issue \"WARNING\" \"yamllint found issues in YAML syntax\"\n      fi\n    # Fallback to Python YAML parser\n    elif command -v python3 &> /dev/null; then\n      echo \"   Using Python YAML parser for validation...\" >&2\n      if python3 -c \"import yaml; yaml.safe_load(open('$FILE_PATH'))\" 2>/dev/null; then\n        echo \"   ✅ YAML syntax valid (Python)\" >&2\n      else\n        report_issue \"ERROR\" \"Invalid YAML syntax detected\"\n      fi\n    else\n      report_issue \"WARNING\" \"No YAML validator available (actionlint, yamllint, or python3)\"\n    fi\n  fi\n  \n  # 2. Action Version Validation\n  echo \"🔍 Checking action versions...\" >&2\n  \n  # Check for outdated action versions\n  OUTDATED_ACTIONS=(\n    \"actions/checkout@v[12]\"\n    \"actions/setup-node@v[12]\"\n    \"actions/setup-python@v[12]\"\n    \"actions/cache@v[12]\"\n    \"actions/upload-artifact@v[12]\"\n    \"actions/download-artifact@v[12]\"\n  )\n  \n  for pattern in \"${OUTDATED_ACTIONS[@]}\"; do\n    if grep -q \"$pattern\" \"$FILE_PATH\" 2>/dev/null; then\n      ACTION_NAME=$(echo \"$pattern\" | cut -d'@' -f1)\n      report_issue \"WARNING\" \"Using outdated $ACTION_NAME version - consider upgrading to latest\"\n    fi\n  done\n  \n  # Check for unpinned action versions (security risk)\n  if grep -E 'uses:.*@(main|master|develop)' \"$FILE_PATH\" >&2 2>/dev/null; then\n    report_issue \"WARNING\" \"Actions using branch references instead of pinned versions detected\"\n    echo \"   💡 Use specific version tags or commit SHAs for security\" >&2\n  fi\n  \n  # 3. Security Best Practices\n  echo \"🔒 Checking security best practices...\" >&2\n  \n  # Check for explicit permissions\n  if ! grep -q \"permissions:\" \"$FILE_PATH\" 2>/dev/null; then\n    report_issue \"SUGGESTION\" \"Consider adding explicit 'permissions:' for better security\"\n    echo \"   Example: permissions: { contents: read, actions: read }\" >&2\n  fi\n  \n  # Check for pull_request_target usage (potential security risk)\n  if grep -q \"pull_request_target:\" \"$FILE_PATH\" 2>/dev/null; then\n    report_issue \"WARNING\" \"pull_request_target can be a security risk - ensure proper handling\"\n  fi\n  \n  # Check for secrets in plain text (basic check)\n  if grep -iE '(password|secret|token|key).*:.*[a-zA-Z0-9]+' \"$FILE_PATH\" | grep -v '\\${{' >&2 2>/dev/null; then\n    report_issue \"ERROR\" \"Potential hardcoded secrets detected - use GitHub secrets instead\"\n  fi\n  \n  # 4. Performance and Best Practices\n  echo \"⚡ Checking performance best practices...\" >&2\n  \n  # Check for caching\n  if ! grep -q \"cache\" \"$FILE_PATH\" 2>/dev/null && (grep -q \"npm install\" \"$FILE_PATH\" || grep -q \"pip install\" \"$FILE_PATH\" || grep -q \"bundle install\" \"$FILE_PATH\") 2>/dev/null; then\n    report_issue \"SUGGESTION\" \"Consider adding caching for dependencies to improve workflow speed\"\n  fi\n  \n  # Check for matrix strategy usage\n  if ! grep -q \"strategy:\" \"$FILE_PATH\" 2>/dev/null && grep -q \"runs-on:\" \"$FILE_PATH\" 2>/dev/null; then\n    report_issue \"SUGGESTION\" \"Consider using matrix strategy for testing multiple versions/platforms\"\n  fi\n  \n  # Check for conditional job execution\n  if ! grep -q \"if:\" \"$FILE_PATH\" 2>/dev/null; then\n    report_issue \"SUGGESTION\" \"Consider using conditional execution to optimize workflow runs\"\n  fi\n  \n  # 5. Workflow Structure Validation\n  echo \"📋 Checking workflow structure...\" >&2\n  \n  # Check for required fields\n  if ! grep -q \"name:\" \"$FILE_PATH\" 2>/dev/null; then\n    report_issue \"WARNING\" \"Workflow should have a descriptive 'name' field\"\n  fi\n  \n  if ! grep -q \"on:\" \"$FILE_PATH\" 2>/dev/null; then\n    report_issue \"ERROR\" \"Workflow must have 'on:' trigger definition\"\n  fi\n  \n  if ! grep -q \"jobs:\" \"$FILE_PATH\" 2>/dev/null; then\n    report_issue \"ERROR\" \"Workflow must have 'jobs:' section\"\n  fi\n  \n  # Check for environment variables\n  if grep -q \"env:\" \"$FILE_PATH\" 2>/dev/null; then\n    echo \"   ✅ Environment variables defined\" >&2\n  fi\n  \n  # 6. Action-Specific Checks\n  echo \"🎯 Checking action-specific patterns...\" >&2\n  \n  # Check for Node.js setup\n  if grep -q \"actions/setup-node\" \"$FILE_PATH\" 2>/dev/null; then\n    if ! grep -q \"node-version\" \"$FILE_PATH\" 2>/dev/null; then\n      report_issue \"WARNING\" \"setup-node should specify node-version\"\n    fi\n    \n    if ! grep -q \"cache:\" \"$FILE_PATH\" 2>/dev/null; then\n      report_issue \"SUGGESTION\" \"Consider enabling cache for setup-node (e.g., cache: npm)\"\n    fi\n  fi\n  \n  # Check for Python setup\n  if grep -q \"actions/setup-python\" \"$FILE_PATH\" 2>/dev/null; then\n    if ! grep -q \"python-version\" \"$FILE_PATH\" 2>/dev/null; then\n      report_issue \"WARNING\" \"setup-python should specify python-version\"\n    fi\n  fi\n  \n  # Check for checkout action\n  if grep -q \"actions/checkout\" \"$FILE_PATH\" 2>/dev/null; then\n    # Check if fetch-depth is appropriate for the use case\n    if grep -q \"fetch-depth: 0\" \"$FILE_PATH\" 2>/dev/null; then\n      report_issue \"INFO\" \"Using full history checkout - ensure this is necessary\"\n    fi\n  fi\n  \n  # 7. Generate Summary Report\n  echo \"\" >&2\n  echo \"📊 GitHub Actions Validation Summary:\" >&2\n  echo \"=====================================\" >&2\n  echo \"   📄 Workflow: $(basename \"$FILE_PATH\")\" >&2\n  echo \"   ❌ Errors: $ERRORS\" >&2\n  echo \"   ⚠️ Warnings: $WARNINGS\" >&2\n  echo \"   💡 Suggestions: $SUGGESTIONS\" >&2\n  \n  if [ \"$ERRORS\" -eq 0 ] && [ \"$WARNINGS\" -eq 0 ]; then\n    echo \"   ✅ Validation Status: PASSED\" >&2\n  elif [ \"$ERRORS\" -eq 0 ]; then\n    echo \"   ✅ Validation Status: PASSED (with warnings)\" >&2\n  else\n    echo \"   ❌ Validation Status: FAILED\" >&2\n  fi\n  \n  echo \"\" >&2\n  echo \"💡 GitHub Actions Best Practices:\" >&2\n  echo \"   • Pin actions to specific versions or commit SHAs\" >&2\n  echo \"   • Use explicit permissions for security\" >&2\n  echo \"   • Cache dependencies to improve performance\" >&2\n  echo \"   • Use matrix strategies for cross-platform testing\" >&2\n  echo \"   • Add conditional execution to optimize runs\" >&2\n  echo \"   • Keep secrets out of workflow files\" >&2\n  \n  # Exit with error if there are critical issues\n  if [ \"$ERRORS\" -gt 0 ]; then\n    echo \"⚠️ Workflow has critical errors that should be fixed\" >&2\n    exit 1\n  fi\n  \nelse\n  # Not a GitHub Actions workflow file\n  exit 0\nfi\n\nexit 0"
      },
      "useCases": [
        "CI/CD pipeline validation and quality assurance",
        "Security compliance for GitHub Actions workflows",
        "Automated workflow best practices enforcement",
        "Development workflow optimization and performance",
        "Team collaboration and workflow standardization"
      ],
      "troubleshooting": [
        {
          "issue": "actionlint not found but validation still runs",
          "solution": "Hook falls back to yamllint or Python YAML parser automatically. Install actionlint with brew install actionlint on macOS or download from GitHub releases for comprehensive validation."
        },
        {
          "issue": "False positives for deprecated actions warning",
          "solution": "Update the OUTDATED_ACTIONS array in the hook script to exclude specific action patterns. Use version pinning with commit SHAs instead of version tags to avoid warnings."
        },
        {
          "issue": "Hook fails on pull_request_target workflows",
          "solution": "This is a security warning, not failure. Review pull_request_target usage carefully and ensure proper checkout action configuration with explicit ref parameter for untrusted code."
        },
        {
          "issue": "YAML validation passes but workflow fails in GitHub",
          "solution": "Install actionlint for GitHub-specific validation beyond YAML syntax. Check for GitHub Actions context variables, expression syntax, and action version compatibility issues."
        },
        {
          "issue": "Performance suggestions appear for optimized workflows",
          "solution": "Suggestions are recommendations, not errors. Customize the hook script to skip specific checks by commenting out sections or adjust thresholds in the performance validation logic."
        }
      ],
      "documentationUrl": "https://docs.github.com/en/actions",
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/github-actions-workflow-validator"
    },
    {
      "slug": "go-module-tidy",
      "description": "Automatically runs go mod tidy when Go files or go.mod are modified to keep dependencies clean",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "go",
        "golang",
        "modules",
        "dependencies",
        "cleanup"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Automatic go mod tidy execution for Go file and go.mod changes",
        "Go vet integration for static analysis and error detection",
        "Module dependency validation and inconsistency detection",
        "Unused dependency cleanup and missing import resolution",
        "Go workspace and multi-module project support",
        "Dependency vulnerability scanning with go list",
        "Module cache optimization and cleanup suggestions",
        "Build constraint and Go version compatibility checking"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/go-module-tidy.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Check if this is a Go-related file\nif [[ \"$FILE_PATH\" == *.go ]] || [[ \"$FILE_PATH\" == *go.mod ]] || [[ \"$FILE_PATH\" == *go.sum ]] || [[ \"$FILE_PATH\" == *go.work* ]]; then\n  echo \"🔧 Go Module Maintenance for: $(basename \"$FILE_PATH\")\" >&2\n  \n  # Find the Go module root\n  MODULE_DIR=\"$(dirname \"$FILE_PATH\")\"\n  \n  # Walk up the directory tree to find go.mod\n  while [ \"$MODULE_DIR\" != \"/\" ] && [ ! -f \"$MODULE_DIR/go.mod\" ]; do\n    MODULE_DIR=\"$(dirname \"$MODULE_DIR\")\"\n  done\n  \n  if [ ! -f \"$MODULE_DIR/go.mod\" ]; then\n    echo \"⚠️ No go.mod found - not a Go module\" >&2\n    exit 0\n  fi\n  \n  echo \"📁 Go module root: $MODULE_DIR\" >&2\n  cd \"$MODULE_DIR\"\n  \n  # Check if Go is installed\n  if ! command -v go &> /dev/null; then\n    echo \"❌ Go is not installed or not in PATH\" >&2\n    exit 1\n  fi\n  \n  GO_VERSION=$(go version | cut -d' ' -f3 2>/dev/null || echo \"unknown\")\n  echo \"🐹 Go version: $GO_VERSION\" >&2\n  \n  # Initialize maintenance counters\n  ERRORS=0\n  WARNINGS=0\n  FIXED=0\n  \n  # Function to report issues\n  report_issue() {\n    local level=\"$1\"\n    local message=\"$2\"\n    \n    case \"$level\" in\n      \"ERROR\")\n        echo \"❌ ERROR: $message\" >&2\n        ERRORS=$((ERRORS + 1))\n        ;;\n      \"WARNING\")\n        echo \"⚠️ WARNING: $message\" >&2\n        WARNINGS=$((WARNINGS + 1))\n        ;;\n      \"FIXED\")\n        echo \"✅ FIXED: $message\" >&2\n        FIXED=$((FIXED + 1))\n        ;;\n      \"INFO\")\n        echo \"ℹ️ INFO: $message\" >&2\n        ;;\n    esac\n  }\n  \n  # 1. Pre-tidy Module Analysis\n  echo \"📊 Analyzing module state...\" >&2\n  \n  # Check go.mod syntax\n  if ! go mod edit -json > /dev/null 2>&1; then\n    report_issue \"ERROR\" \"go.mod has syntax errors\"\n    exit 1\n  else\n    echo \"   ✅ go.mod syntax is valid\" >&2\n  fi\n  \n  # Get current dependencies before tidy\n  DEPS_BEFORE=$(go list -m all 2>/dev/null | wc -l | xargs || echo \"0\")\n  echo \"   📦 Dependencies before tidy: $DEPS_BEFORE\" >&2\n  \n  # Check for any build errors\n  if go list ./... > /dev/null 2>&1; then\n    echo \"   ✅ Module builds successfully\" >&2\n  else\n    report_issue \"WARNING\" \"Module has build issues that may affect dependency resolution\"\n  fi\n  \n  # 2. Run go mod tidy\n  echo \"🧹 Running go mod tidy...\" >&2\n  \n  if go mod tidy; then\n    report_issue \"FIXED\" \"go mod tidy completed successfully\"\n    \n    # Check dependencies after tidy\n    DEPS_AFTER=$(go list -m all 2>/dev/null | wc -l | xargs || echo \"0\")\n    DEPS_CHANGE=$((DEPS_AFTER - DEPS_BEFORE))\n    \n    if [ \"$DEPS_CHANGE\" -gt 0 ]; then\n      echo \"   📈 Added $DEPS_CHANGE dependencies\" >&2\n    elif [ \"$DEPS_CHANGE\" -lt 0 ]; then\n      echo \"   📉 Removed $((DEPS_CHANGE * -1)) dependencies\" >&2\n    else\n      echo \"   📦 No dependency changes\" >&2\n    fi\n    \n  else\n    report_issue \"ERROR\" \"go mod tidy failed\"\n  fi\n  \n  # 3. Verify go.sum integrity\n  echo \"🔐 Verifying module checksums...\" >&2\n  \n  if go mod verify; then\n    echo \"   ✅ All module checksums verified\" >&2\n  else\n    report_issue \"ERROR\" \"Module checksum verification failed\"\n  fi\n  \n  # 4. Check for vulnerabilities (if govulncheck is available)\n  if command -v govulncheck &> /dev/null; then\n    echo \"🛡️ Scanning for vulnerabilities...\" >&2\n    \n    if govulncheck ./... 2>/dev/null; then\n      echo \"   ✅ No known vulnerabilities found\" >&2\n    else\n      report_issue \"WARNING\" \"Potential vulnerabilities detected - run 'govulncheck ./...' for details\"\n    fi\n  else\n    echo \"   💡 Install govulncheck for vulnerability scanning: go install golang.org/x/vuln/cmd/govulncheck@latest\" >&2\n  fi\n  \n  # 5. Run go vet for Go source files\n  if [[ \"$FILE_PATH\" == *.go ]]; then\n    echo \"🔍 Running go vet...\" >&2\n    \n    if go vet ./...; then\n      echo \"   ✅ go vet passed - no issues found\" >&2\n    else\n      report_issue \"WARNING\" \"go vet found potential issues\"\n    fi\n    \n    # Check for common Go issues\n    echo \"🔍 Additional Go code analysis...\" >&2\n    \n    # Check for gofmt issues\n    UNFORMATTED=$(find . -name '*.go' -not -path './vendor/*' -exec gofmt -l {} \\; 2>/dev/null)\n    if [ -n \"$UNFORMATTED\" ]; then\n      report_issue \"WARNING\" \"Some files are not gofmt formatted\"\n      echo \"$UNFORMATTED\" | head -5 | while read file; do\n        echo \"     $file\" >&2\n      done\n    else\n      echo \"   ✅ All Go files are properly formatted\" >&2\n    fi\n    \n    # Check imports with goimports if available\n    if command -v goimports &> /dev/null; then\n      IMPORT_ISSUES=$(find . -name '*.go' -not -path './vendor/*' -exec goimports -l {} \\; 2>/dev/null)\n      if [ -n \"$IMPORT_ISSUES\" ]; then\n        report_issue \"WARNING\" \"Some files have import formatting issues\"\n      else\n        echo \"   ✅ All imports are properly formatted\" >&2\n      fi\n    fi\n  fi\n  \n  # 6. Module cleanup suggestions\n  echo \"🧹 Module optimization check...\" >&2\n  \n  # Check for indirect dependencies that could be direct\n  INDIRECT_COUNT=$(go list -m all | grep -c '// indirect' || echo \"0\")\n  if [ \"$INDIRECT_COUNT\" -gt 0 ]; then\n    echo \"   📊 Indirect dependencies: $INDIRECT_COUNT\" >&2\n    echo \"   💡 Review if any indirect deps should be direct\" >&2\n  fi\n  \n  # Check for replace directives\n  REPLACE_COUNT=$(grep -c '^replace ' go.mod 2>/dev/null || echo \"0\")\n  if [ \"$REPLACE_COUNT\" -gt 0 ]; then\n    echo \"   🔄 Replace directives: $REPLACE_COUNT\" >&2\n    echo \"   💡 Review replace directives for production readiness\" >&2\n  fi\n  \n  # 7. Workspace support\n  if [ -f \"go.work\" ]; then\n    echo \"🏢 Go workspace detected\" >&2\n    \n    if go work sync; then\n      echo \"   ✅ Workspace synced successfully\" >&2\n    else\n      report_issue \"WARNING\" \"Workspace sync issues detected\"\n    fi\n  fi\n  \n  # 8. Module cache suggestions\n  if [ \"$DEPS_AFTER\" -gt 50 ]; then\n    echo \"💡 Large dependency count - consider 'go clean -modcache' if disk space is low\" >&2\n  fi\n  \n  # 9. Generate Summary Report\n  echo \"\" >&2\n  echo \"📋 Go Module Maintenance Summary:\" >&2\n  echo \"================================\" >&2\n  echo \"   📄 Module: $(basename \"$(pwd)\")\" >&2\n  echo \"   🐹 Go: $GO_VERSION\" >&2\n  echo \"   📦 Dependencies: $DEPS_AFTER\" >&2\n  echo \"   ✅ Fixed: $FIXED\" >&2\n  echo \"   ⚠️ Warnings: $WARNINGS\" >&2\n  echo \"   ❌ Errors: $ERRORS\" >&2\n  \n  if [ \"$ERRORS\" -eq 0 ] && [ \"$WARNINGS\" -eq 0 ]; then\n    echo \"   🎉 Status: EXCELLENT - Module is clean and optimized\" >&2\n  elif [ \"$ERRORS\" -eq 0 ]; then\n    echo \"   ✅ Status: GOOD - Minor warnings to review\" >&2\n  else\n    echo \"   ❌ Status: NEEDS ATTENTION - Errors require fixing\" >&2\n  fi\n  \n  echo \"\" >&2\n  echo \"💡 Go Module Best Practices:\" >&2\n  echo \"   • Run 'go mod tidy' regularly to keep dependencies clean\" >&2\n  echo \"   • Use 'go mod why <module>' to understand dependency reasons\" >&2\n  echo \"   • Update dependencies with 'go get -u ./...' carefully\" >&2\n  echo \"   • Consider using 'go mod graph' for dependency visualization\" >&2\n  echo \"   • Pin important dependencies to specific versions\" >&2\n  \n  # Exit with error if there are critical issues\n  if [ \"$ERRORS\" -gt 0 ]; then\n    echo \"⚠️ Go module maintenance completed with errors\" >&2\n    exit 1\n  fi\n  \nelse\n  # Not a Go file, exit silently\n  exit 0\nfi\n\nexit 0"
      },
      "useCases": [
        "Automated Go dependency management in development workflows",
        "Go module cleanup and optimization in CI/CD pipelines",
        "Multi-module workspace maintenance and synchronization",
        "Go codebase quality assurance with integrated static analysis",
        "Dependency security and vulnerability management"
      ],
      "troubleshooting": [
        {
          "issue": "Hook fails to find go.mod in nested module subdirectories",
          "solution": "Script walks up directories but may hit root before finding go.mod. Ensure MODULE_DIR search starts from FILE_PATH directory: cd $(dirname \"$FILE_PATH\") before the while loop to guarantee proper traversal."
        },
        {
          "issue": "Go mod tidy hangs when network unavailable for dependency downloads",
          "solution": "Add timeout to go commands: timeout 30s go mod tidy to prevent infinite hangs. Set GOPROXY=off to use only local cache, or configure module cache directory with GOMODCACHE for offline operation."
        },
        {
          "issue": "Workspace sync errors when go.work references missing modules",
          "solution": "Script runs 'go work sync' without validation. Add existence checks: go work edit -json | jq -r '.Use[].DiskPath' | while read dir; do [ -d \"$dir\" ] || echo \"Missing: $dir\"; done before syncing."
        },
        {
          "issue": "PostToolUse timing causes stale go.sum checksums on rapid changes",
          "solution": "Hook runs after each write but go.sum updates may lag. Add explicit go.sum validation: go mod verify before tidy: if verification fails, run go mod tidy -v to refresh checksums and rebuild module graph."
        },
        {
          "issue": "Context lost when cd changes directory breaking relative path access",
          "solution": "Script changes to MODULE_DIR but hook execution happens per-file. Store original: ORIG_DIR=$(pwd) and restore after: cd \"$ORIG_DIR\" or use absolute paths: FILE_ABS=$(realpath \"$FILE_PATH\") throughout script."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/go-module-tidy"
    },
    {
      "slug": "graphql-schema-validator",
      "description": "Validates GraphQL schema files and checks for breaking changes when modified",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "graphql",
        "api",
        "schema",
        "validation",
        "breaking-changes"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Comprehensive GraphQL schema syntax validation",
        "Breaking change detection with detailed impact analysis",
        "Schema evolution tracking and version comparison",
        "Multi-tool validation support (graphql-inspector, graphql-schema-linter)",
        "Custom directive and scalar type validation",
        "Schema complexity analysis and performance warnings",
        "Federation schema compatibility checking",
        "Auto-backup and rollback capabilities for schema changes"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/graphql-schema-validator.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Check if this is a GraphQL schema file\nif [[ \"$FILE_PATH\" == *.graphql ]] || [[ \"$FILE_PATH\" == *.gql ]] || [[ \"$FILE_PATH\" == *schema* ]]; then\n  echo \"🔍 GraphQL Schema Validation for: $(basename \"$FILE_PATH\")\" >&2\n  \n  # Initialize validation counters\n  ERRORS=0\n  WARNINGS=0\n  VALIDATIONS=0\n  BREAKING_CHANGES=0\n  \n  # Function to report validation results\n  report_validation() {\n    local level=\"$1\"\n    local message=\"$2\"\n    \n    case \"$level\" in\n      \"ERROR\")\n        echo \"❌ ERROR: $message\" >&2\n        ERRORS=$((ERRORS + 1))\n        ;;\n      \"WARNING\")\n        echo \"⚠️ WARNING: $message\" >&2\n        WARNINGS=$((WARNINGS + 1))\n        ;;\n      \"BREAKING\")\n        echo \"💥 BREAKING CHANGE: $message\" >&2\n        BREAKING_CHANGES=$((BREAKING_CHANGES + 1))\n        ;;\n      \"PASS\")\n        echo \"✅ PASS: $message\" >&2\n        VALIDATIONS=$((VALIDATIONS + 1))\n        ;;\n      \"INFO\")\n        echo \"ℹ️ INFO: $message\" >&2\n        ;;\n    esac\n  }\n  \n  # Check if file exists and is readable\n  if [ ! -f \"$FILE_PATH\" ]; then\n    report_validation \"ERROR\" \"Schema file not found: $FILE_PATH\"\n    exit 1\n  fi\n  \n  if [ ! -r \"$FILE_PATH\" ]; then\n    report_validation \"ERROR\" \"Schema file is not readable: $FILE_PATH\"\n    exit 1\n  fi\n  \n  # Basic file info\n  FILE_SIZE=$(wc -c < \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n  echo \"📊 Schema file: $(basename \"$FILE_PATH\") ($(( FILE_SIZE / 1024 ))KB)\" >&2\n  \n  # 1. Basic GraphQL Syntax Validation\n  echo \"📋 Checking GraphQL syntax...\" >&2\n  \n  # Check for basic GraphQL structure\n  if ! grep -q -E '(type|interface|enum|scalar|input|directive)' \"$FILE_PATH\" 2>/dev/null; then\n    report_validation \"ERROR\" \"File doesn't appear to contain valid GraphQL schema definitions\"\n  else\n    report_validation \"PASS\" \"Basic GraphQL structure detected\"\n  fi\n  \n  # Check for common syntax errors\n  if grep -q ',$' \"$FILE_PATH\" 2>/dev/null; then\n    report_validation \"WARNING\" \"Trailing commas detected - may cause parsing issues\"\n  fi\n  \n  # Check for proper type definitions\n  TYPE_COUNT=$(grep -c '^type ' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n  INTERFACE_COUNT=$(grep -c '^interface ' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n  ENUM_COUNT=$(grep -c '^enum ' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n  INPUT_COUNT=$(grep -c '^input ' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n  \n  echo \"   📊 Schema composition:\" >&2\n  echo \"      Types: $TYPE_COUNT\" >&2\n  echo \"      Interfaces: $INTERFACE_COUNT\" >&2\n  echo \"      Enums: $ENUM_COUNT\" >&2\n  echo \"      Inputs: $INPUT_COUNT\" >&2\n  \n  # 2. Advanced Validation with graphql-inspector (if available)\n  echo \"🔍 Running advanced validation...\" >&2\n  \n  if command -v npx &> /dev/null; then\n    echo \"   Using graphql-inspector for comprehensive validation...\" >&2\n    \n    # Try to validate with graphql-inspector\n    if npx graphql-inspector validate \"$FILE_PATH\" 2>/dev/null; then\n      report_validation \"PASS\" \"graphql-inspector validation successful\"\n    else\n      # Check if graphql-inspector is available\n      if ! npx graphql-inspector --version &> /dev/null; then\n        echo \"   📦 Installing graphql-inspector...\" >&2\n        if npm install -g @graphql-inspector/cli 2>/dev/null; then\n          echo \"   ✅ graphql-inspector installed\" >&2\n          \n          if npx graphql-inspector validate \"$FILE_PATH\" 2>/dev/null; then\n            report_validation \"PASS\" \"graphql-inspector validation successful (after install)\"\n          else\n            report_validation \"ERROR\" \"graphql-inspector validation failed\"\n          fi\n        else\n          report_validation \"WARNING\" \"Unable to install graphql-inspector - validation limited\"\n        fi\n      else\n        report_validation \"ERROR\" \"graphql-inspector validation failed\"\n      fi\n    fi\n  else\n    report_validation \"WARNING\" \"Node.js/npm not available - using basic validation only\"\n  fi\n  \n  # 3. Breaking Change Detection\n  echo \"💥 Checking for breaking changes...\" >&2\n  \n  BACKUP_FILE=\"${FILE_PATH}.backup\"\n  SCHEMA_BACKUP_DIR=\".graphql_backups\"\n  \n  # Create backup directory if it doesn't exist\n  [ ! -d \"$SCHEMA_BACKUP_DIR\" ] && mkdir -p \"$SCHEMA_BACKUP_DIR\"\n  \n  # Generate timestamped backup filename\n  TIMESTAMP=$(date +\"%Y%m%d_%H%M%S\")\n  TIMESTAMPED_BACKUP=\"$SCHEMA_BACKUP_DIR/$(basename \"$FILE_PATH\").${TIMESTAMP}.backup\"\n  \n  if [ -f \"$BACKUP_FILE\" ]; then\n    echo \"   📋 Comparing with previous version...\" >&2\n    \n    # Try graphql-inspector diff if available\n    if command -v npx &> /dev/null && npx graphql-inspector --version &> /dev/null; then\n      DIFF_OUTPUT=$(npx graphql-inspector diff \"$BACKUP_FILE\" \"$FILE_PATH\" 2>&1)\n      DIFF_EXIT_CODE=$?\n      \n      if [ $DIFF_EXIT_CODE -eq 0 ]; then\n        report_validation \"PASS\" \"No breaking changes detected\"\n      else\n        # Parse diff output for breaking changes\n        if echo \"$DIFF_OUTPUT\" | grep -q \"BREAKING\"; then\n          report_validation \"BREAKING\" \"Breaking changes detected in schema\"\n          echo \"$DIFF_OUTPUT\" | grep \"BREAKING\" | head -5 >&2\n        else\n          report_validation \"WARNING\" \"Schema changes detected (non-breaking)\"\n        fi\n      fi\n    else\n      # Basic diff comparison\n      if ! diff -q \"$BACKUP_FILE\" \"$FILE_PATH\" > /dev/null 2>&1; then\n        report_validation \"WARNING\" \"Schema has changed (basic diff check)\"\n        \n        # Look for potentially breaking changes\n        if diff \"$BACKUP_FILE\" \"$FILE_PATH\" | grep -q '^<.*type\\|^<.*field\\|^<.*enum'; then\n          report_validation \"BREAKING\" \"Potential breaking changes detected (type/field/enum removals)\"\n        fi\n      else\n        report_validation \"PASS\" \"No changes detected\"\n      fi\n    fi\n    \n    # Create timestamped backup of previous version\n    cp \"$BACKUP_FILE\" \"$TIMESTAMPED_BACKUP\"\n    echo \"   📁 Previous version backed up to: $TIMESTAMPED_BACKUP\" >&2\n  else\n    echo \"   ℹ️ No previous version found - first time validation\" >&2\n  fi\n  \n  # 4. Schema Quality Analysis\n  echo \"📊 Analyzing schema quality...\" >&2\n  \n  # Check for Query, Mutation, Subscription types\n  if grep -q '^type Query' \"$FILE_PATH\" 2>/dev/null; then\n    report_validation \"PASS\" \"Query type found\"\n  else\n    report_validation \"WARNING\" \"No Query type defined - schema may be incomplete\"\n  fi\n  \n  if grep -q '^type Mutation' \"$FILE_PATH\" 2>/dev/null; then\n    echo \"   ✅ Mutation type found\" >&2\n  else\n    echo \"   ℹ️ No Mutation type (read-only API)\" >&2\n  fi\n  \n  if grep -q '^type Subscription' \"$FILE_PATH\" 2>/dev/null; then\n    echo \"   ✅ Subscription type found\" >&2\n  else\n    echo \"   ℹ️ No Subscription type (no real-time features)\" >&2\n  fi\n  \n  # Check for proper field documentation\n  DOCUMENTED_FIELDS=$(grep -c '\"\"\"' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n  TOTAL_FIELDS=$(grep -c ':' \"$FILE_PATH\" 2>/dev/null || echo \"1\")\n  \n  if [ \"$DOCUMENTED_FIELDS\" -gt 0 ]; then\n    DOCUMENTATION_RATIO=$((DOCUMENTED_FIELDS * 100 / TOTAL_FIELDS))\n    if [ \"$DOCUMENTATION_RATIO\" -gt 50 ]; then\n      report_validation \"PASS\" \"Good documentation coverage (${DOCUMENTATION_RATIO}%)\"\n    else\n      report_validation \"WARNING\" \"Low documentation coverage (${DOCUMENTATION_RATIO}%)\"\n    fi\n  else\n    report_validation \"WARNING\" \"No field documentation found - consider adding descriptions\"\n  fi\n  \n  # 5. Federation Schema Checks (if applicable)\n  if grep -q '@key\\|@external\\|@provides\\|@requires' \"$FILE_PATH\" 2>/dev/null; then\n    echo \"🌐 Federation directives detected - checking federation compatibility...\" >&2\n    \n    if grep -q '@key' \"$FILE_PATH\" && grep -q 'extend type' \"$FILE_PATH\" 2>/dev/null; then\n      report_validation \"PASS\" \"Federation schema structure looks valid\"\n    else\n      report_validation \"WARNING\" \"Federation directives found but schema structure may be incomplete\"\n    fi\n  fi\n  \n  # 6. Schema Complexity Analysis\n  echo \"📈 Analyzing schema complexity...\" >&2\n  \n  NESTING_DEPTH=$(grep -o '  ' \"$FILE_PATH\" | wc -l 2>/dev/null || echo \"0\")\n  if [ \"$NESTING_DEPTH\" -gt 1000 ]; then\n    report_validation \"WARNING\" \"High schema complexity detected - consider simplification\"\n  else\n    echo \"   ✅ Schema complexity within acceptable range\" >&2\n  fi\n  \n  # Check for circular references (basic check)\n  if grep -E 'type.*:.*\\[.*\\]' \"$FILE_PATH\" | grep -q -E '(User.*User|Post.*Post|Comment.*Comment)' 2>/dev/null; then\n    report_validation \"WARNING\" \"Potential circular references detected - review carefully\"\n  fi\n  \n  # 7. Security and Best Practices\n  echo \"🔒 Security and best practices check...\" >&2\n  \n  # Check for potentially dangerous query patterns\n  if grep -q 'allUsers\\|allPosts\\|everything' \"$FILE_PATH\" 2>/dev/null; then\n    report_validation \"WARNING\" \"Potentially dangerous 'all' queries detected - ensure proper pagination\"\n  fi\n  \n  # Check for proper input validation types\n  if [ \"$INPUT_COUNT\" -gt 0 ]; then\n    echo \"   ✅ Input types defined for mutations\" >&2\n  elif grep -q '^type Mutation' \"$FILE_PATH\" 2>/dev/null; then\n    report_validation \"WARNING\" \"Mutations found but no input types - consider using input types\"\n  fi\n  \n  # Update backup for next comparison\n  cp \"$FILE_PATH\" \"$BACKUP_FILE\"\n  echo \"   💾 Current version backed up for future comparisons\" >&2\n  \n  # 8. Generate Validation Summary\n  echo \"\" >&2\n  echo \"📋 GraphQL Schema Validation Summary:\" >&2\n  echo \"===================================\" >&2\n  echo \"   📄 Schema: $(basename \"$FILE_PATH\")\" >&2\n  echo \"   📏 Size: $(( FILE_SIZE / 1024 ))KB\" >&2\n  echo \"   📊 Types: $TYPE_COUNT, Interfaces: $INTERFACE_COUNT, Enums: $ENUM_COUNT\" >&2\n  echo \"   ✅ Validations Passed: $VALIDATIONS\" >&2\n  echo \"   ⚠️ Warnings: $WARNINGS\" >&2\n  echo \"   ❌ Errors: $ERRORS\" >&2\n  echo \"   💥 Breaking Changes: $BREAKING_CHANGES\" >&2\n  \n  if [ \"$ERRORS\" -eq 0 ] && [ \"$BREAKING_CHANGES\" -eq 0 ]; then\n    if [ \"$WARNINGS\" -eq 0 ]; then\n      echo \"   🎉 Status: EXCELLENT - Schema is valid and well-formed\" >&2\n    else\n      echo \"   ✅ Status: GOOD - Schema is valid with minor recommendations\" >&2\n    fi\n  elif [ \"$ERRORS\" -eq 0 ]; then\n    echo \"   ⚠️ Status: BREAKING CHANGES - Review impact before deployment\" >&2\n  else\n    echo \"   ❌ Status: ERRORS - Schema has critical issues that must be fixed\" >&2\n  fi\n  \n  echo \"\" >&2\n  echo \"💡 GraphQL Schema Best Practices:\" >&2\n  echo \"   • Use descriptive type and field names\" >&2\n  echo \"   • Add documentation with triple quotes \\\"\\\"\\\"\" >&2\n  echo \"   • Use input types for mutations\" >&2\n  echo \"   • Implement proper pagination for collections\" >&2\n  echo \"   • Version your schema changes carefully\" >&2\n  echo \"   • Use enums for predefined values\" >&2\n  \n  # Clean up old backups (keep last 10)\n  if [ -d \"$SCHEMA_BACKUP_DIR\" ]; then\n    ls -t \"$SCHEMA_BACKUP_DIR\"/*.backup 2>/dev/null | tail -n +11 | xargs rm -f 2>/dev/null || true\n  fi\n  \n  # Exit with error if there are critical issues\n  if [ \"$ERRORS\" -gt 0 ]; then\n    echo \"⚠️ Schema validation completed with errors\" >&2\n    exit 1\n  fi\n  \nelse\n  # Not a GraphQL file, exit silently\n  exit 0\nfi\n\nexit 0"
      },
      "useCases": [
        "API development with GraphQL schema validation and evolution tracking",
        "Breaking change detection before deploying GraphQL API updates",
        "GraphQL federation schema validation and compatibility checking",
        "Automated schema quality assurance in CI/CD pipelines",
        "Team collaboration with schema versioning and backup management"
      ],
      "troubleshooting": [
        {
          "issue": "Hook triggers on non-GraphQL files despite .graphql extension check",
          "solution": "Tighten matchers to specific paths: 'matchers': ['write:.*\\\\.(graphql|gql)$', 'edit:.*schema.*']. Prevents false positives on files with 'schema' in non-GraphQL contexts."
        },
        {
          "issue": "graphql-inspector installation fails during hook execution",
          "solution": "Pre-install globally: 'npm install -g @graphql-inspector/cli'. Hook's mid-execution installs timeout. Add installation check at project setup instead of runtime."
        },
        {
          "issue": "Breaking change detection misses field type modifications",
          "solution": "Requires valid schemas. If backup corrupted, create fresh: 'cp schema.graphql schema.graphql.backup'. Verify parsing with 'npx graphql-inspector validate' before comparison."
        },
        {
          "issue": "Backup files accumulate despite cleanup logic (10 file limit)",
          "solution": "Cleanup misses timestamped backups in .graphql_backups/. Add: 'find .graphql_backups -name \"*.backup\" -type f | sort -r | tail -n +11 | xargs rm -f' to retention."
        },
        {
          "issue": "Diff output shows false positives for unchanged schemas",
          "solution": "graphql-inspector is whitespace-sensitive. Run 'prettier --write **/*.graphql' before comparisons. Add normalization: format both schemas with GraphQL formatter before diff."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/graphql-schema-validator"
    },
    {
      "slug": "i18n-translation-validator",
      "description": "Validates translation files for missing keys and ensures consistency across different language files",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "i18n",
        "internationalization",
        "translation",
        "localization",
        "validation"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Comprehensive translation key validation across multiple locales",
        "Missing and orphaned translation key detection",
        "JSON structure and syntax validation for translation files",
        "Pluralization rule compliance checking",
        "Translation completeness percentage reporting",
        "Multi-format support (JSON, YAML, gettext PO files)",
        "Variable placeholder validation and consistency checking",
        "Character encoding and special character verification"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/i18n-translation-validator.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Check if this is a translation/localization file\nif [[ \"$FILE_PATH\" == *locales/*.json ]] || [[ \"$FILE_PATH\" == *i18n/*.json ]] || [[ \"$FILE_PATH\" == *lang/*.json ]] || [[ \"$FILE_PATH\" == *translations/*.json ]] || [[ \"$FILE_PATH\" == *.po ]] || [[ \"$FILE_PATH\" == *messages/*.properties ]]; then\n  echo \"🌍 i18n Translation Validation for: $(basename \"$FILE_PATH\")\" >&2\n  \n  # Initialize validation counters\n  ERRORS=0\n  WARNINGS=0\n  MISSING_KEYS=0\n  ORPHANED_KEYS=0\n  TOTAL_KEYS=0\n  \n  # Function to report validation results\n  report_validation() {\n    local level=\"$1\"\n    local message=\"$2\"\n    \n    case \"$level\" in\n      \"ERROR\")\n        echo \"❌ ERROR: $message\" >&2\n        ERRORS=$((ERRORS + 1))\n        ;;\n      \"WARNING\")\n        echo \"⚠️ WARNING: $message\" >&2\n        WARNINGS=$((WARNINGS + 1))\n        ;;\n      \"MISSING\")\n        echo \"🔍 MISSING: $message\" >&2\n        MISSING_KEYS=$((MISSING_KEYS + 1))\n        ;;\n      \"ORPHANED\")\n        echo \"🏷️ ORPHANED: $message\" >&2\n        ORPHANED_KEYS=$((ORPHANED_KEYS + 1))\n        ;;\n      \"PASS\")\n        echo \"✅ PASS: $message\" >&2\n        ;;\n      \"INFO\")\n        echo \"ℹ️ INFO: $message\" >&2\n        ;;\n    esac\n  }\n  \n  # Check if file exists and is readable\n  if [ ! -f \"$FILE_PATH\" ]; then\n    report_validation \"ERROR\" \"Translation file not found: $FILE_PATH\"\n    exit 1\n  fi\n  \n  if [ ! -r \"$FILE_PATH\" ]; then\n    report_validation \"ERROR\" \"Translation file is not readable: $FILE_PATH\"\n    exit 1\n  fi\n  \n  # Determine file format\n  FILE_EXT=\"${FILE_PATH##*.}\"\n  LOCALE_DIR=\"$(dirname \"$FILE_PATH\")\"\n  FILE_NAME=\"$(basename \"$FILE_PATH\")\"\n  LOCALE_CODE=\"${FILE_NAME%.*}\"\n  \n  echo \"📊 Translation file: $FILE_NAME (format: $FILE_EXT, locale: $LOCALE_CODE)\" >&2\n  \n  # 1. File Format Validation\n  echo \"📋 Validating file format...\" >&2\n  \n  case \"$FILE_EXT\" in\n    \"json\")\n      if jq empty \"$FILE_PATH\" 2>/dev/null; then\n        report_validation \"PASS\" \"Valid JSON syntax\"\n        TOTAL_KEYS=$(jq -r 'keys | length' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n      else\n        report_validation \"ERROR\" \"Invalid JSON syntax - file cannot be parsed\"\n        exit 1\n      fi\n      ;;\n    \"po\")\n      if command -v msgfmt &> /dev/null; then\n        if msgfmt --check \"$FILE_PATH\" -o /dev/null 2>/dev/null; then\n          report_validation \"PASS\" \"Valid PO file format\"\n        else\n          report_validation \"ERROR\" \"Invalid PO file format\"\n        fi\n      else\n        report_validation \"WARNING\" \"msgfmt not available - limited PO validation\"\n      fi\n      ;;\n    \"properties\")\n      # Basic properties file validation\n      if grep -q '=' \"$FILE_PATH\" 2>/dev/null; then\n        report_validation \"PASS\" \"Properties file format detected\"\n      else\n        report_validation \"WARNING\" \"No key=value pairs found in properties file\"\n      fi\n      ;;\n    *)\n      report_validation \"WARNING\" \"Unknown translation file format: $FILE_EXT\"\n      ;;\n  esac\n  \n  # 2. Find Base Translation File (for comparison)\n  echo \"🔍 Locating base translation file...\" >&2\n  \n  BASE_FILE=\"\"\n  BASE_CANDIDATES=(\"en.json\" \"en-US.json\" \"en_US.json\" \"base.json\" \"default.json\")\n  \n  for candidate in \"${BASE_CANDIDATES[@]}\"; do\n    if [ -f \"$LOCALE_DIR/$candidate\" ] && [ \"$LOCALE_DIR/$candidate\" != \"$FILE_PATH\" ]; then\n      BASE_FILE=\"$LOCALE_DIR/$candidate\"\n      echo \"   📁 Base file found: $candidate\" >&2\n      break\n    fi\n  done\n  \n  if [ -z \"$BASE_FILE\" ]; then\n    # Look for any .json file in the directory as base\n    FIRST_JSON=$(find \"$LOCALE_DIR\" -name '*.json' -not -path \"$FILE_PATH\" | head -1)\n    if [ -n \"$FIRST_JSON\" ]; then\n      BASE_FILE=\"$FIRST_JSON\"\n      echo \"   📁 Using first available JSON as base: $(basename \"$BASE_FILE\")\" >&2\n    else\n      echo \"   ⚠️ No base translation file found - running standalone validation\" >&2\n    fi\n  fi\n  \n  # 3. Key Structure Validation (JSON files)\n  if [ \"$FILE_EXT\" = \"json\" ]; then\n    echo \"🔑 Analyzing translation keys...\" >&2\n    \n    # Check for nested vs flat structure\n    NESTED_COUNT=$(jq '[.. | objects | keys] | flatten | length' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n    if [ \"$NESTED_COUNT\" -gt \"$TOTAL_KEYS\" ]; then\n      echo \"   📊 Nested key structure detected ($NESTED_COUNT total keys)\" >&2\n    else\n      echo \"   📊 Flat key structure ($TOTAL_KEYS keys)\" >&2\n    fi\n    \n    # Check for empty values\n    EMPTY_VALUES=$(jq '[.. | select(type == \"string\" and length == 0)] | length' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n    if [ \"$EMPTY_VALUES\" -gt 0 ]; then\n      report_validation \"WARNING\" \"$EMPTY_VALUES empty translation values found\"\n    fi\n    \n    # Check for untranslated strings (same as key)\n    UNTRANSLATED=0\n    if command -v jq &> /dev/null; then\n      UNTRANSLATED=$(jq -r 'to_entries[] | select(.key == .value) | .key' \"$FILE_PATH\" 2>/dev/null | wc -l | xargs || echo \"0\")\n      if [ \"$UNTRANSLATED\" -gt 0 ]; then\n        report_validation \"WARNING\" \"$UNTRANSLATED potentially untranslated strings (key equals value)\"\n      fi\n    fi\n  fi\n  \n  # 4. Compare with Base File (if available)\n  if [ -n \"$BASE_FILE\" ] && [ -f \"$BASE_FILE\" ]; then\n    echo \"🔄 Comparing with base translation file...\" >&2\n    \n    if [ \"$FILE_EXT\" = \"json\" ]; then\n      # Extract all keys from both files\n      BASE_KEYS_FILE=\"/tmp/base_keys_$$\"\n      CURRENT_KEYS_FILE=\"/tmp/current_keys_$$\"\n      \n      # Get all nested keys (dot notation)\n      jq -r 'paths(scalars) as $p | $p | join(\".\")' \"$BASE_FILE\" 2>/dev/null | sort > \"$BASE_KEYS_FILE\"\n      jq -r 'paths(scalars) as $p | $p | join(\".\")' \"$FILE_PATH\" 2>/dev/null | sort > \"$CURRENT_KEYS_FILE\"\n      \n      # Find missing keys (in base but not in current)\n      MISSING_KEYS_LIST=\"/tmp/missing_keys_$$\"\n      comm -23 \"$BASE_KEYS_FILE\" \"$CURRENT_KEYS_FILE\" > \"$MISSING_KEYS_LIST\"\n      MISSING_COUNT=$(wc -l < \"$MISSING_KEYS_LIST\" | xargs)\n      \n      if [ \"$MISSING_COUNT\" -gt 0 ]; then\n        report_validation \"MISSING\" \"$MISSING_COUNT translation keys missing from base\"\n        echo \"   Missing keys:\" >&2\n        head -10 \"$MISSING_KEYS_LIST\" | while read key; do\n          echo \"     - $key\" >&2\n        done\n        [ \"$MISSING_COUNT\" -gt 10 ] && echo \"     ... and $((MISSING_COUNT - 10)) more\" >&2\n      else\n        report_validation \"PASS\" \"All base translation keys are present\"\n      fi\n      \n      # Find orphaned keys (in current but not in base)\n      ORPHANED_KEYS_LIST=\"/tmp/orphaned_keys_$$\"\n      comm -13 \"$BASE_KEYS_FILE\" \"$CURRENT_KEYS_FILE\" > \"$ORPHANED_KEYS_LIST\"\n      ORPHANED_COUNT=$(wc -l < \"$ORPHANED_KEYS_LIST\" | xargs)\n      \n      if [ \"$ORPHANED_COUNT\" -gt 0 ]; then\n        report_validation \"ORPHANED\" \"$ORPHANED_COUNT keys not found in base (potential orphans)\"\n        echo \"   Orphaned keys:\" >&2\n        head -5 \"$ORPHANED_KEYS_LIST\" | while read key; do\n          echo \"     - $key\" >&2\n        done\n        [ \"$ORPHANED_COUNT\" -gt 5 ] && echo \"     ... and $((ORPHANED_COUNT - 5)) more\" >&2\n      else\n        report_validation \"PASS\" \"No orphaned keys detected\"\n      fi\n      \n      # Calculate completeness percentage\n      BASE_KEY_COUNT=$(wc -l < \"$BASE_KEYS_FILE\" | xargs)\n      if [ \"$BASE_KEY_COUNT\" -gt 0 ]; then\n        TRANSLATED_COUNT=$((BASE_KEY_COUNT - MISSING_COUNT))\n        COMPLETENESS=$((TRANSLATED_COUNT * 100 / BASE_KEY_COUNT))\n        echo \"   📊 Translation completeness: $COMPLETENESS% ($TRANSLATED_COUNT/$BASE_KEY_COUNT)\" >&2\n        \n        if [ \"$COMPLETENESS\" -eq 100 ]; then\n          report_validation \"PASS\" \"Translation is 100% complete\"\n        elif [ \"$COMPLETENESS\" -ge 90 ]; then\n          report_validation \"WARNING\" \"Translation is $COMPLETENESS% complete (good but not perfect)\"\n        elif [ \"$COMPLETENESS\" -ge 70 ]; then\n          report_validation \"WARNING\" \"Translation is $COMPLETENESS% complete (needs attention)\"\n        else\n          report_validation \"ERROR\" \"Translation is only $COMPLETENESS% complete (significant gaps)\"\n        fi\n      fi\n      \n      # Cleanup temp files\n      rm -f \"$BASE_KEYS_FILE\" \"$CURRENT_KEYS_FILE\" \"$MISSING_KEYS_LIST\" \"$ORPHANED_KEYS_LIST\"\n    fi\n  fi\n  \n  # 5. Variable Placeholder Validation\n  echo \"🔤 Checking variable placeholders...\" >&2\n  \n  if [ \"$FILE_EXT\" = \"json\" ]; then\n    # Check for common placeholder patterns\n    PLACEHOLDER_PATTERNS=(\n      '{{[^}]+}}'     # Handlebars: {{variable}}\n      '{[^}]+}'       # Simple: {variable}\n      '%[a-zA-Z_]+%'  # Percent: %variable%\n      '\\$\\{[^}]+\\}'   # Dollar: ${variable}\n      '%[sd]'         # Printf style: %s, %d\n    )\n    \n    PLACEHOLDER_COUNT=0\n    for pattern in \"${PLACEHOLDER_PATTERNS[@]}\"; do\n      COUNT=$(grep -oE \"$pattern\" \"$FILE_PATH\" 2>/dev/null | wc -l | xargs || echo \"0\")\n      PLACEHOLDER_COUNT=$((PLACEHOLDER_COUNT + COUNT))\n    done\n    \n    if [ \"$PLACEHOLDER_COUNT\" -gt 0 ]; then\n      echo \"   📝 $PLACEHOLDER_COUNT variable placeholders found\" >&2\n      \n      # Check for unmatched placeholders if base file exists\n      if [ -n \"$BASE_FILE\" ]; then\n        # This is a simplified check - in practice, you'd want more sophisticated matching\n        echo \"   🔍 Cross-referencing placeholders with base file...\" >&2\n      fi\n    else\n      echo \"   ℹ️ No variable placeholders detected\" >&2\n    fi\n  fi\n  \n  # 6. Locale-Specific Validation\n  echo \"🌐 Locale-specific validation...\" >&2\n  \n  case \"$LOCALE_CODE\" in\n    \"ar\"*|\"he\"*|\"fa\"*)\n      echo \"   🔄 RTL language detected - ensure proper text direction handling\" >&2\n      ;;\n    \"zh\"*|\"ja\"*|\"ko\"*)\n      echo \"   🈴 CJK language detected - ensure proper character encoding\" >&2\n      ;;\n    \"en\"*)\n      echo \"   🇺🇸 English locale - checking for common issues\" >&2\n      ;;\n    *)\n      echo \"   🌍 Locale: $LOCALE_CODE\" >&2\n      ;;\n  esac\n  \n  # Check for potential encoding issues (non-ASCII characters)\n  if [ \"$FILE_EXT\" = \"json\" ]; then\n    NON_ASCII_COUNT=$(grep -P '[^\\x00-\\x7F]' \"$FILE_PATH\" 2>/dev/null | wc -l | xargs || echo \"0\")\n    if [ \"$NON_ASCII_COUNT\" -gt 0 ]; then\n      echo \"   🔤 $NON_ASCII_COUNT lines contain non-ASCII characters (normal for international content)\" >&2\n    fi\n  fi\n  \n  # 7. Multi-file Consistency Check\n  echo \"📁 Checking consistency across locale files...\" >&2\n  \n  LOCALE_FILES=()\n  while IFS= read -r -d '' file; do\n    LOCALE_FILES+=(\"$file\")\n  done < <(find \"$LOCALE_DIR\" -name \"*.$FILE_EXT\" -print0 2>/dev/null)\n  \n  LOCALE_COUNT=${#LOCALE_FILES[@]}\n  if [ \"$LOCALE_COUNT\" -gt 1 ]; then\n    echo \"   📊 Found $LOCALE_COUNT locale files in directory\" >&2\n    \n    # Check if all files have similar key counts (within 20% difference)\n    if [ \"$FILE_EXT\" = \"json\" ] && [ \"$TOTAL_KEYS\" -gt 0 ]; then\n      INCONSISTENT_FILES=0\n      for locale_file in \"${LOCALE_FILES[@]}\"; do\n        if [ \"$locale_file\" != \"$FILE_PATH\" ]; then\n          OTHER_KEY_COUNT=$(jq -r 'keys | length' \"$locale_file\" 2>/dev/null || echo \"0\")\n          DIFF_PERCENT=$((abs(TOTAL_KEYS - OTHER_KEY_COUNT) * 100 / TOTAL_KEYS))\n          \n          if [ \"$DIFF_PERCENT\" -gt 20 ]; then\n            INCONSISTENT_FILES=$((INCONSISTENT_FILES + 1))\n          fi\n        fi\n      done\n      \n      if [ \"$INCONSISTENT_FILES\" -gt 0 ]; then\n        report_validation \"WARNING\" \"$INCONSISTENT_FILES locale files have significantly different key counts\"\n      else\n        report_validation \"PASS\" \"All locale files have consistent key counts\"\n      fi\n    fi\n  else\n    echo \"   ℹ️ Single locale file found\" >&2\n  fi\n  \n  # 8. Generate Validation Summary\n  echo \"\" >&2\n  echo \"📋 i18n Translation Validation Summary:\" >&2\n  echo \"=====================================\" >&2\n  echo \"   📄 File: $FILE_NAME\" >&2\n  echo \"   🌍 Locale: $LOCALE_CODE\" >&2\n  echo \"   📊 Format: $FILE_EXT\" >&2\n  [ \"$TOTAL_KEYS\" -gt 0 ] && echo \"   🔑 Total Keys: $TOTAL_KEYS\" >&2\n  echo \"   ❌ Errors: $ERRORS\" >&2\n  echo \"   ⚠️ Warnings: $WARNINGS\" >&2\n  echo \"   🔍 Missing Keys: $MISSING_KEYS\" >&2\n  echo \"   🏷️ Orphaned Keys: $ORPHANED_KEYS\" >&2\n  \n  if [ \"$ERRORS\" -eq 0 ] && [ \"$MISSING_KEYS\" -eq 0 ]; then\n    if [ \"$WARNINGS\" -eq 0 ] && [ \"$ORPHANED_KEYS\" -eq 0 ]; then\n      echo \"   🎉 Status: EXCELLENT - Translation file is complete and consistent\" >&2\n    else\n      echo \"   ✅ Status: GOOD - Translation is functional with minor issues\" >&2\n    fi\n  elif [ \"$ERRORS\" -eq 0 ]; then\n    echo \"   ⚠️ Status: INCOMPLETE - Missing translations need attention\" >&2\n  else\n    echo \"   ❌ Status: ERRORS - Critical issues must be fixed\" >&2\n  fi\n  \n  echo \"\" >&2\n  echo \"💡 i18n Translation Best Practices:\" >&2\n  echo \"   • Keep translation keys consistent across all locales\" >&2\n  echo \"   • Use meaningful, hierarchical key names\" >&2\n  echo \"   • Validate placeholder variables across languages\" >&2\n  echo \"   • Consider cultural context in translations\" >&2\n  echo \"   • Test with longer/shorter text in different languages\" >&2\n  echo \"   • Use proper character encoding (UTF-8)\" >&2\n  \n  # Exit with error if there are critical issues\n  if [ \"$ERRORS\" -gt 0 ]; then\n    echo \"⚠️ Translation validation completed with errors\" >&2\n    exit 1\n  fi\n  \nelse\n  # Not a translation file, exit silently\n  exit 0\nfi\n\nexit 0"
      },
      "useCases": [
        "Multi-language application development with automated translation validation",
        "Translation quality assurance and completeness checking in CI/CD",
        "Internationalization workflow management and key consistency enforcement",
        "Localization project coordination with missing translation detection",
        "Cross-platform app development with unified translation standards"
      ],
      "troubleshooting": [
        {
          "issue": "Hook validates non-i18n JSON files in directories with similar names",
          "solution": "Strengthen path detection: [[ \"$FILE_PATH\" =~ /(locales|i18n|lang|translations)/ ]] || exit 0. Check for translation-specific keys like locale/language markers before running full validation."
        },
        {
          "issue": "Missing keys detection fails when base file uses nested structure",
          "solution": "Use jq to flatten nested keys: jq -r 'paths(scalars) as $p | $p | join(\".\")' to get dot notation paths. Compare flattened key lists instead of top-level keys only for accurate missing key detection."
        },
        {
          "issue": "Validation shows false positives for orphaned keys in locale-specific translations",
          "solution": "Some translations legitimately have locale-specific keys (e.g., currency formats, date patterns). Add whitelist patterns or check key prefixes like 'locale.' to skip cultural adaptation keys from orphan detection."
        },
        {
          "issue": "Completeness percentage incorrectly calculated for multi-level nested JSON",
          "solution": "Script uses top-level key count but should count leaf nodes: jq '[paths(scalars)] | length'. Ensure both base and current files are counted at same nesting level for accurate percentage."
        },
        {
          "issue": "Hook crashes with 'command not found: abs' on DIFF_PERCENT calculation",
          "solution": "Bash doesn't have abs() function. Replace with: DIFF_PERCENT=$(( (TOTAL_KEYS - OTHER_KEY_COUNT) < 0 ? (OTHER_KEY_COUNT - TOTAL_KEYS) : (TOTAL_KEYS - OTHER_KEY_COUNT) )) or use bc: echo \"scale=0; sqrt(($A-$B)^2)\" | bc."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/i18n-translation-validator"
    },
    {
      "slug": "jest-snapshot-auto-updater",
      "description": "Automatically updates Jest snapshots when component files are modified significantly",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "jest",
        "testing",
        "snapshots",
        "react",
        "automation"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Intelligent Jest snapshot detection and updating for modified components",
        "Multi-framework support (React, Vue, Angular, vanilla JS)",
        "Snapshot change analysis and impact assessment",
        "Test suite validation before snapshot updates",
        "Orphaned snapshot cleanup and maintenance",
        "Interactive confirmation for significant snapshot changes",
        "Test coverage analysis and reporting",
        "Parallel test execution optimization for large codebases"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/jest-snapshot-auto-updater.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Check if this is a component file that might have Jest snapshots\nif [[ \"$FILE_PATH\" == *.jsx ]] || [[ \"$FILE_PATH\" == *.tsx ]] || [[ \"$FILE_PATH\" == *.js ]] || [[ \"$FILE_PATH\" == *.ts ]] || [[ \"$FILE_PATH\" == *.vue ]] || [[ \"$FILE_PATH\" == *.component.ts ]]; then\n  echo \"📸 Jest Snapshot Management for: $(basename \"$FILE_PATH\")\" >&2\n  \n  # Initialize counters\n  SNAPSHOTS_UPDATED=0\n  TESTS_RUN=0\n  TESTS_PASSED=0\n  TESTS_FAILED=0\n  SNAPSHOT_FILES_FOUND=0\n  \n  # Function to report snapshot operations\n  report_snapshot() {\n    local level=\"$1\"\n    local message=\"$2\"\n    \n    case \"$level\" in\n      \"SUCCESS\")\n        echo \"✅ SUCCESS: $message\" >&2\n        ;;\n      \"WARNING\")\n        echo \"⚠️ WARNING: $message\" >&2\n        ;;\n      \"ERROR\")\n        echo \"❌ ERROR: $message\" >&2\n        ;;\n      \"INFO\")\n        echo \"ℹ️ INFO: $message\" >&2\n        ;;\n      \"SNAPSHOT\")\n        echo \"📸 SNAPSHOT: $message\" >&2\n        SNAPSHOTS_UPDATED=$((SNAPSHOTS_UPDATED + 1))\n        ;;\n    esac\n  }\n  \n  # Extract component information\n  FILE_NAME=\"$(basename \"$FILE_PATH\")\"\n  COMPONENT_NAME=\"${FILE_NAME%.*}\"\n  FILE_DIR=\"$(dirname \"$FILE_PATH\")\"\n  \n  # Check if this is likely a component or test file\n  if [[ \"$FILE_NAME\" == *.test.* ]] || [[ \"$FILE_NAME\" == *.spec.* ]]; then\n    echo \"   🧪 Test file detected - checking for snapshot updates\" >&2\n  else\n    echo \"   🔧 Component file detected - looking for related tests\" >&2\n  fi\n  \n  # Check if Jest is available\n  if ! command -v npx &> /dev/null; then\n    report_snapshot \"ERROR\" \"npx not available - cannot run Jest\"\n    exit 1\n  fi\n  \n  # Check if Jest is configured in the project\n  JEST_CONFIG_FOUND=false\n  if [ -f \"package.json\" ]; then\n    if grep -q '\"jest\"' package.json 2>/dev/null || grep -q '\"@jest\"' package.json 2>/dev/null; then\n      JEST_CONFIG_FOUND=true\n      echo \"   📋 Jest configuration found in package.json\" >&2\n    fi\n  fi\n  \n  if [ -f \"jest.config.js\" ] || [ -f \"jest.config.ts\" ] || [ -f \"jest.config.json\" ]; then\n    JEST_CONFIG_FOUND=true\n    echo \"   📋 Jest configuration file found\" >&2\n  fi\n  \n  if [ \"$JEST_CONFIG_FOUND\" = false ]; then\n    report_snapshot \"WARNING\" \"No Jest configuration found - snapshots may not be available\"\n    exit 0\n  fi\n  \n  # 1. Find existing snapshot files\n  echo \"🔍 Searching for existing snapshot files...\" >&2\n  \n  SNAPSHOT_DIRS=(\"__snapshots__\" \"snapshots\" \"__tests__/__snapshots__\" \"tests/__snapshots__\")\n  SNAPSHOT_FILES=()\n  \n  for dir in \"${SNAPSHOT_DIRS[@]}\"; do\n    if [ -d \"$FILE_DIR/$dir\" ]; then\n      while IFS= read -r -d '' file; do\n        SNAPSHOT_FILES+=(\"$file\")\n      done < <(find \"$FILE_DIR/$dir\" -name \"*.snap\" -print0 2>/dev/null)\n    fi\n  done\n  \n  # Also check for snapshots in test directories\n  while IFS= read -r -d '' file; do\n    SNAPSHOT_FILES+=(\"$file\")\n  done < <(find . -name \"*.snap\" -path \"*$COMPONENT_NAME*\" -print0 2>/dev/null)\n  \n  SNAPSHOT_FILES_FOUND=${#SNAPSHOT_FILES[@]}\n  \n  if [ \"$SNAPSHOT_FILES_FOUND\" -gt 0 ]; then\n    echo \"   📁 Found $SNAPSHOT_FILES_FOUND snapshot files related to this component\" >&2\n    for snapshot in \"${SNAPSHOT_FILES[@]}\"; do\n      echo \"     - $(basename \"$snapshot\")\" >&2\n    done\n  else\n    echo \"   ℹ️ No existing snapshot files found for this component\" >&2\n  fi\n  \n  # 2. Find test files for this component\n  echo \"🧪 Locating test files...\" >&2\n  \n  TEST_PATTERNS=(\n    \"${COMPONENT_NAME}.test.*\"\n    \"${COMPONENT_NAME}.spec.*\"\n    \"*${COMPONENT_NAME}*.test.*\"\n    \"*${COMPONENT_NAME}*.spec.*\"\n  )\n  \n  TEST_FILES=()\n  for pattern in \"${TEST_PATTERNS[@]}\"; do\n    while IFS= read -r -d '' file; do\n      TEST_FILES+=(\"$file\")\n    done < <(find . -name \"$pattern\" -print0 2>/dev/null)\n  done\n  \n  TEST_FILES_COUNT=${#TEST_FILES[@]}\n  \n  if [ \"$TEST_FILES_COUNT\" -gt 0 ]; then\n    echo \"   🎯 Found $TEST_FILES_COUNT test files\" >&2\n    for test_file in \"${TEST_FILES[@]}\"; do\n      echo \"     - $(basename \"$test_file\")\" >&2\n    done\n  else\n    echo \"   ⚠️ No test files found for component: $COMPONENT_NAME\" >&2\n    report_snapshot \"INFO\" \"Consider creating tests for better component coverage\"\n  fi\n  \n  # 3. Check if component file has been significantly modified\n  echo \"📊 Analyzing component changes...\" >&2\n  \n  # Check git status to see if file was modified\n  if command -v git &> /dev/null && git rev-parse --git-dir > /dev/null 2>&1; then\n    if git status --porcelain \"$FILE_PATH\" | grep -q '^.M'; then\n      echo \"   🔄 Component has been modified since last commit\" >&2\n      \n      # Get the diff to understand the scope of changes\n      LINES_CHANGED=$(git diff \"$FILE_PATH\" 2>/dev/null | grep -c '^[+-]' || echo \"0\")\n      if [ \"$LINES_CHANGED\" -gt 10 ]; then\n        echo \"   📈 Significant changes detected ($LINES_CHANGED lines modified)\" >&2\n        SHOULD_UPDATE_SNAPSHOTS=true\n      else\n        echo \"   📝 Minor changes detected ($LINES_CHANGED lines modified)\" >&2\n        SHOULD_UPDATE_SNAPSHOTS=false\n      fi\n    else\n      echo \"   ✅ Component file is clean (no unsaved changes)\" >&2\n      SHOULD_UPDATE_SNAPSHOTS=false\n    fi\n  else\n    echo \"   ℹ️ Not in a git repository - assuming snapshots should be checked\" >&2\n    SHOULD_UPDATE_SNAPSHOTS=true\n  fi\n  \n  # 4. Run tests and update snapshots if needed\n  if [ \"$TEST_FILES_COUNT\" -gt 0 ]; then\n    echo \"🧪 Running tests for component...\" >&2\n    \n    # Determine the test command\n    TEST_COMMAND=\"npm test\"\n    if [ -f \"yarn.lock\" ]; then\n      TEST_COMMAND=\"yarn test\"\n    elif [ -f \"pnpm-lock.yaml\" ]; then\n      TEST_COMMAND=\"pnpm test\"\n    fi\n    \n    # Create test patterns for Jest\n    TEST_PATTERN=\"$COMPONENT_NAME\"\n    \n    echo \"   🚀 Running: $TEST_COMMAND -- --testNamePattern='$TEST_PATTERN' --coverage=false --watchAll=false\" >&2\n    \n    # Run tests without updating snapshots first\n    TEST_OUTPUT_FILE=\"/tmp/jest_output_$$\"\n    if $TEST_COMMAND -- --testNamePattern=\"$TEST_PATTERN\" --coverage=false --watchAll=false --verbose=false > \"$TEST_OUTPUT_FILE\" 2>&1; then\n      TESTS_PASSED=$(grep -c 'PASS' \"$TEST_OUTPUT_FILE\" 2>/dev/null || echo \"0\")\n      report_snapshot \"SUCCESS\" \"Tests passed ($TESTS_PASSED test suites)\"\n      \n      # Check if snapshots are outdated\n      if grep -q 'snapshot.*failed' \"$TEST_OUTPUT_FILE\" 2>/dev/null || grep -q 'snapshot.*obsolete' \"$TEST_OUTPUT_FILE\" 2>/dev/null; then\n        echo \"   📸 Outdated snapshots detected\" >&2\n        SHOULD_UPDATE_SNAPSHOTS=true\n      fi\n      \n    else\n      TESTS_FAILED=$(grep -c 'FAIL' \"$TEST_OUTPUT_FILE\" 2>/dev/null || echo \"1\")\n      echo \"   ❌ Tests failed ($TESTS_FAILED test suites) - checking for snapshot issues\" >&2\n      \n      # Check if failures are due to snapshot mismatches\n      if grep -q 'Snapshot.*differ' \"$TEST_OUTPUT_FILE\" 2>/dev/null; then\n        echo \"   📸 Snapshot mismatches detected - snapshots may need updating\" >&2\n        SHOULD_UPDATE_SNAPSHOTS=true\n      else\n        report_snapshot \"ERROR\" \"Tests failing for reasons other than snapshots\"\n        echo \"   📝 Test output summary:\" >&2\n        tail -10 \"$TEST_OUTPUT_FILE\" | while read line; do\n          echo \"     $line\" >&2\n        done\n      fi\n    fi\n    \n    rm -f \"$TEST_OUTPUT_FILE\"\n  fi\n  \n  # 5. Update snapshots if needed\n  if [ \"$SHOULD_UPDATE_SNAPSHOTS\" = true ] && [ \"$TEST_FILES_COUNT\" -gt 0 ]; then\n    echo \"📸 Updating Jest snapshots...\" >&2\n    \n    # Run with snapshot update flag\n    UPDATE_OUTPUT_FILE=\"/tmp/jest_update_$$\"\n    if $TEST_COMMAND -- --testNamePattern=\"$TEST_PATTERN\" --updateSnapshot --coverage=false --watchAll=false > \"$UPDATE_OUTPUT_FILE\" 2>&1; then\n      \n      # Count updated snapshots\n      SNAPSHOTS_WRITTEN=$(grep -c 'snapshot.*written' \"$UPDATE_OUTPUT_FILE\" 2>/dev/null || echo \"0\")\n      SNAPSHOTS_UPDATED_COUNT=$(grep -c 'snapshot.*updated' \"$UPDATE_OUTPUT_FILE\" 2>/dev/null || echo \"0\")\n      \n      if [ \"$SNAPSHOTS_WRITTEN\" -gt 0 ] || [ \"$SNAPSHOTS_UPDATED_COUNT\" -gt 0 ]; then\n        report_snapshot \"SNAPSHOT\" \"Updated $((SNAPSHOTS_WRITTEN + SNAPSHOTS_UPDATED_COUNT)) snapshots\"\n        \n        # Show which snapshots were affected\n        grep 'snapshot.*written\\|snapshot.*updated' \"$UPDATE_OUTPUT_FILE\" 2>/dev/null | head -5 | while read line; do\n          echo \"     $line\" >&2\n        done\n      else\n        report_snapshot \"INFO\" \"Snapshot update completed - no changes needed\"\n      fi\n      \n    else\n      report_snapshot \"ERROR\" \"Failed to update snapshots\"\n      echo \"   📝 Update error details:\" >&2\n      tail -5 \"$UPDATE_OUTPUT_FILE\" | while read line; do\n        echo \"     $line\" >&2\n      done\n    fi\n    \n    rm -f \"$UPDATE_OUTPUT_FILE\"\n  else\n    echo \"   ℹ️ Snapshot updates not needed at this time\" >&2\n  fi\n  \n  # 6. Clean up orphaned snapshots\n  echo \"🧹 Checking for orphaned snapshots...\" >&2\n  \n  if [ \"$SNAPSHOT_FILES_FOUND\" -gt 0 ]; then\n    # This is a simplified check - in practice, you'd want more sophisticated orphan detection\n    POTENTIALLY_ORPHANED=0\n    \n    for snapshot_file in \"${SNAPSHOT_FILES[@]}\"; do\n      SNAPSHOT_BASE=$(basename \"$snapshot_file\" .snap)\n      \n      # Check if there's a corresponding test or component file\n      if ! find . -name \"*${SNAPSHOT_BASE%.*}*\" -type f \\( -name \"*.test.*\" -o -name \"*.spec.*\" \\) 2>/dev/null | head -1 | grep -q .; then\n        POTENTIALLY_ORPHANED=$((POTENTIALLY_ORPHANED + 1))\n      fi\n    done\n    \n    if [ \"$POTENTIALLY_ORPHANED\" -gt 0 ]; then\n      report_snapshot \"WARNING\" \"$POTENTIALLY_ORPHANED potentially orphaned snapshot files detected\"\n      echo \"   💡 Run 'npm test -- --updateSnapshot' to clean up unused snapshots\" >&2\n    else\n      echo \"   ✅ No orphaned snapshots detected\" >&2\n    fi\n  fi\n  \n  # 7. Generate summary report\n  echo \"\" >&2\n  echo \"📋 Jest Snapshot Management Summary:\" >&2\n  echo \"===================================\" >&2\n  echo \"   📄 Component: $COMPONENT_NAME\" >&2\n  echo \"   🧪 Test files found: $TEST_FILES_COUNT\" >&2\n  echo \"   📸 Snapshot files: $SNAPSHOT_FILES_FOUND\" >&2\n  echo \"   ✅ Tests passed: $TESTS_PASSED\" >&2\n  echo \"   ❌ Tests failed: $TESTS_FAILED\" >&2\n  echo \"   📸 Snapshots updated: $SNAPSHOTS_UPDATED\" >&2\n  \n  if [ \"$SNAPSHOTS_UPDATED\" -gt 0 ]; then\n    echo \"   🎉 Status: SNAPSHOTS UPDATED - Review changes before committing\" >&2\n  elif [ \"$TESTS_FAILED\" -gt 0 ]; then\n    echo \"   ⚠️ Status: TESTS FAILING - Fix issues before proceeding\" >&2\n  elif [ \"$TEST_FILES_COUNT\" -eq 0 ]; then\n    echo \"   📝 Status: NO TESTS - Consider adding snapshot tests\" >&2\n  else\n    echo \"   ✅ Status: ALL GOOD - Snapshots are up to date\" >&2\n  fi\n  \n  echo \"\" >&2\n  echo \"💡 Jest Snapshot Best Practices:\" >&2\n  echo \"   • Review snapshot changes carefully before committing\" >&2\n  echo \"   • Keep snapshots small and focused\" >&2\n  echo \"   • Update snapshots only when UI changes are intentional\" >&2\n  echo \"   • Use descriptive test names for better snapshot organization\" >&2\n  echo \"   • Consider using 'toMatchInlineSnapshot' for small snapshots\" >&2\n  echo \"   • Run 'npm test -- --updateSnapshot' to update all snapshots\" >&2\n  \n  # Exit with error if tests are failing for non-snapshot reasons\n  if [ \"$TESTS_FAILED\" -gt 0 ] && [ \"$SNAPSHOTS_UPDATED\" -eq 0 ]; then\n    echo \"⚠️ Jest tests are failing - please review and fix issues\" >&2\n    exit 1\n  fi\n  \nelse\n  # Not a component file, exit silently\n  exit 0\nfi\n\nexit 0"
      },
      "useCases": [
        "React/Vue component development with automated snapshot testing",
        "UI regression testing and change detection in component libraries",
        "Continuous integration with automated snapshot validation",
        "Frontend refactoring projects with comprehensive test coverage",
        "Team collaboration with consistent snapshot management workflows"
      ],
      "troubleshooting": [
        {
          "issue": "Hook runs tests for every file change even non-test files",
          "solution": "Detection too broad (matches all .js/.ts). Add matchers: 'matchers': ['write:**/*.{test,spec}.{js,ts,jsx,tsx}', 'edit:**/*.{test,spec}.{js,ts,jsx,tsx}'] to trigger only on test files."
        },
        {
          "issue": "Jest runs entire test suite instead of component-specific tests",
          "solution": "testNamePattern with component name unreliable. Use --testPathPattern: '$TEST_COMMAND -- --testPathPattern=\"$COMPONENT_NAME\" --watchAll=false'. Targets files not test descriptions."
        },
        {
          "issue": "Parallel test execution with --maxWorkers causes race conditions",
          "solution": "No worker limit causes resource exhaustion. Add '--maxWorkers=2': '$TEST_COMMAND -- --testPathPattern=\"$TEST_PATTERN\" --maxWorkers=2 --watchAll=false' for stable CI execution."
        },
        {
          "issue": "Snapshot update creates duplicate snapshot files after renaming",
          "solution": "Old snapshots persist when components renamed. Run cleanup: 'npm test -- --updateSnapshot --clearCache' deleting unused snapshots. Or manually remove from __snapshots__ directory."
        },
        {
          "issue": "git diff threshold (10 lines) triggers updates for minor changes",
          "solution": "Conservative threshold causes excessive updates. Increase: 'if [ \"$LINES_CHANGED\" -gt 50 ]; then' for major changes only. Or check specific files: test if modified file is component."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/jest-snapshot-auto-updater"
    },
    {
      "slug": "json-schema-validator",
      "description": "Validates JSON files against their schemas when modified to ensure data integrity",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "json",
        "schema",
        "validation",
        "data-integrity",
        "api"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Comprehensive JSON schema validation using AJV and multiple validators",
        "Intelligent schema discovery with multiple search strategies",
        "JSON syntax validation and format verification",
        "Schema version compatibility checking and migration guidance",
        "Custom validation rule support and error reporting",
        "JSON-LD and specialized format validation",
        "Performance optimization for large JSON files",
        "Detailed error location and suggestion reporting"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/json-schema-validator.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Check if this is a JSON file (exclude schema files)\nif [[ \"$FILE_PATH\" == *.json ]] && [[ \"$FILE_PATH\" != *.schema.json ]] && [[ \"$FILE_PATH\" != *schema*.json ]]; then\n  echo \"📋 JSON Schema Validation for: $(basename \"$FILE_PATH\")\" >&2\n  \n  # Initialize validation counters\n  ERRORS=0\n  WARNINGS=0\n  VALIDATIONS_PASSED=0\n  SCHEMA_FOUND=false\n  \n  # Function to report validation results\n  report_validation() {\n    local level=\"$1\"\n    local message=\"$2\"\n    \n    case \"$level\" in\n      \"ERROR\")\n        echo \"❌ ERROR: $message\" >&2\n        ERRORS=$((ERRORS + 1))\n        ;;\n      \"WARNING\")\n        echo \"⚠️ WARNING: $message\" >&2\n        WARNINGS=$((WARNINGS + 1))\n        ;;\n      \"PASS\")\n        echo \"✅ PASS: $message\" >&2\n        VALIDATIONS_PASSED=$((VALIDATIONS_PASSED + 1))\n        ;;\n      \"INFO\")\n        echo \"ℹ️ INFO: $message\" >&2\n        ;;\n    esac\n  }\n  \n  # Check if file exists and is readable\n  if [ ! -f \"$FILE_PATH\" ]; then\n    report_validation \"ERROR\" \"JSON file not found: $FILE_PATH\"\n    exit 1\n  fi\n  \n  if [ ! -r \"$FILE_PATH\" ]; then\n    report_validation \"ERROR\" \"JSON file is not readable: $FILE_PATH\"\n    exit 1\n  fi\n  \n  # Get file information\n  FILE_NAME=\"$(basename \"$FILE_PATH\")\"\n  FILE_DIR=\"$(dirname \"$FILE_PATH\")\"\n  JSON_NAME=\"${FILE_NAME%.json}\"\n  FILE_SIZE=$(wc -c < \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n  \n  echo \"📊 JSON file: $FILE_NAME ($(( FILE_SIZE / 1024 ))KB)\" >&2\n  \n  # 1. Basic JSON Syntax Validation\n  echo \"🔍 Checking JSON syntax...\" >&2\n  \n  if command -v jq &> /dev/null; then\n    if jq empty \"$FILE_PATH\" 2>/dev/null; then\n      report_validation \"PASS\" \"Valid JSON syntax\"\n      \n      # Get JSON structure info\n      JSON_TYPE=$(jq -r 'type' \"$FILE_PATH\" 2>/dev/null || echo \"unknown\")\n      echo \"   📊 JSON type: $JSON_TYPE\" >&2\n      \n      if [ \"$JSON_TYPE\" = \"object\" ]; then\n        KEY_COUNT=$(jq -r 'keys | length' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n        echo \"   🔑 Object keys: $KEY_COUNT\" >&2\n      elif [ \"$JSON_TYPE\" = \"array\" ]; then\n        ARRAY_LENGTH=$(jq -r 'length' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n        echo \"   📋 Array length: $ARRAY_LENGTH\" >&2\n      fi\n      \n    else\n      report_validation \"ERROR\" \"Invalid JSON syntax - file cannot be parsed\"\n      echo \"   📝 JSON parsing error details:\" >&2\n      jq empty \"$FILE_PATH\" 2>&1 | head -3 | while read line; do\n        echo \"     $line\" >&2\n      done\n      exit 1\n    fi\n  else\n    # Fallback validation using Python\n    if command -v python3 &> /dev/null; then\n      if python3 -c \"import json; json.load(open('$FILE_PATH'))\" 2>/dev/null; then\n        report_validation \"PASS\" \"Valid JSON syntax (Python validator)\"\n      else\n        report_validation \"ERROR\" \"Invalid JSON syntax detected\"\n        exit 1\n      fi\n    else\n      report_validation \"WARNING\" \"No JSON validators available (jq or python3)\"\n    fi\n  fi\n  \n  # 2. Schema Discovery\n  echo \"🔍 Searching for JSON schema...\" >&2\n  \n  SCHEMA_CANDIDATES=()\n  \n  # Strategy 1: Same directory with .schema.json suffix\n  SCHEMA_CANDIDATES+=(\"$FILE_DIR/${JSON_NAME}.schema.json\")\n  \n  # Strategy 2: Same directory with schema/ subdirectory\n  SCHEMA_CANDIDATES+=(\"$FILE_DIR/schema/${JSON_NAME}.schema.json\")\n  SCHEMA_CANDIDATES+=(\"$FILE_DIR/schemas/${JSON_NAME}.schema.json\")\n  \n  # Strategy 3: Root-level schema directories\n  SCHEMA_CANDIDATES+=(\"./schema/${JSON_NAME}.schema.json\")\n  SCHEMA_CANDIDATES+=(\"./schemas/${JSON_NAME}.schema.json\")\n  SCHEMA_CANDIDATES+=(\"./json-schemas/${JSON_NAME}.schema.json\")\n  \n  # Strategy 4: Common schema file names\n  SCHEMA_CANDIDATES+=(\"$FILE_DIR/${JSON_NAME}-schema.json\")\n  SCHEMA_CANDIDATES+=(\"$FILE_DIR/schema.json\")\n  \n  # Strategy 5: Look for $schema property in JSON\n  if command -v jq &> /dev/null; then\n    EMBEDDED_SCHEMA=$(jq -r '.\"$schema\" // empty' \"$FILE_PATH\" 2>/dev/null)\n    if [ -n \"$EMBEDDED_SCHEMA\" ]; then\n      echo \"   🔗 Found embedded schema reference: $EMBEDDED_SCHEMA\" >&2\n      # If it's a file path, add to candidates\n      if [[ \"$EMBEDDED_SCHEMA\" == ./* ]] || [[ \"$EMBEDDED_SCHEMA\" == /* ]]; then\n        SCHEMA_CANDIDATES+=(\"$EMBEDDED_SCHEMA\")\n      fi\n    fi\n  fi\n  \n  # Find the first existing schema file\n  SCHEMA_FILE=\"\"\n  for candidate in \"${SCHEMA_CANDIDATES[@]}\"; do\n    if [ -f \"$candidate\" ]; then\n      SCHEMA_FILE=\"$candidate\"\n      echo \"   📁 Schema found: $candidate\" >&2\n      SCHEMA_FOUND=true\n      break\n    fi\n  done\n  \n  if [ -z \"$SCHEMA_FILE\" ]; then\n    echo \"   ⚠️ No schema file found. Searched locations:\" >&2\n    for candidate in \"${SCHEMA_CANDIDATES[@]}\"; do\n      echo \"     - $candidate\" >&2\n    done\n    report_validation \"INFO\" \"No schema available - performing syntax-only validation\"\n  fi\n  \n  # 3. Schema Validation (if schema found)\n  if [ \"$SCHEMA_FOUND\" = true ] && [ -f \"$SCHEMA_FILE\" ]; then\n    echo \"📋 Validating against schema...\" >&2\n    \n    # Check if schema file is valid JSON\n    if ! jq empty \"$SCHEMA_FILE\" 2>/dev/null; then\n      report_validation \"ERROR\" \"Schema file is not valid JSON: $SCHEMA_FILE\"\n    else\n      echo \"   ✅ Schema file is valid JSON\" >&2\n      \n      # Get schema information\n      SCHEMA_VERSION=$(jq -r '.\"$schema\" // \"draft-07\"' \"$SCHEMA_FILE\" 2>/dev/null)\n      SCHEMA_TITLE=$(jq -r '.title // \"Untitled\"' \"$SCHEMA_FILE\" 2>/dev/null)\n      echo \"   📊 Schema: $SCHEMA_TITLE (version: $SCHEMA_VERSION)\" >&2\n      \n      # Try AJV validation first (most comprehensive)\n      if command -v npx &> /dev/null; then\n        echo \"   🔍 Running AJV validation...\" >&2\n        \n        AJV_OUTPUT_FILE=\"/tmp/ajv_output_$$\"\n        if npx ajv validate -s \"$SCHEMA_FILE\" -d \"$FILE_PATH\" > \"$AJV_OUTPUT_FILE\" 2>&1; then\n          report_validation \"PASS\" \"AJV schema validation successful\"\n        else\n          report_validation \"ERROR\" \"AJV schema validation failed\"\n          echo \"   📝 Validation errors:\" >&2\n          head -10 \"$AJV_OUTPUT_FILE\" | while read line; do\n            echo \"     $line\" >&2\n          done\n        fi\n        rm -f \"$AJV_OUTPUT_FILE\"\n        \n      # Fallback to basic schema checks\n      else\n        echo \"   ⚠️ AJV not available, performing basic schema checks...\" >&2\n        \n        # Check if required properties exist (simplified)\n        if command -v jq &> /dev/null; then\n          REQUIRED_PROPS=$(jq -r '.required[]? // empty' \"$SCHEMA_FILE\" 2>/dev/null)\n          if [ -n \"$REQUIRED_PROPS\" ]; then\n            echo \"   🔑 Checking required properties...\" >&2\n            MISSING_PROPS=0\n            \n            while read -r prop; do\n              if [ -n \"$prop\" ]; then\n                if jq -e \".\\\"$prop\\\"\" \"$FILE_PATH\" > /dev/null 2>&1; then\n                  echo \"     ✅ Required property exists: $prop\" >&2\n                else\n                  echo \"     ❌ Missing required property: $prop\" >&2\n                  MISSING_PROPS=$((MISSING_PROPS + 1))\n                fi\n              fi\n            done <<< \"$REQUIRED_PROPS\"\n            \n            if [ \"$MISSING_PROPS\" -eq 0 ]; then\n              report_validation \"PASS\" \"All required properties present\"\n            else\n              report_validation \"ERROR\" \"$MISSING_PROPS required properties missing\"\n            fi\n          else\n            echo \"   ℹ️ No required properties defined in schema\" >&2\n          fi\n        fi\n      fi\n    fi\n  fi\n  \n  # 4. JSON Format-Specific Validation\n  echo \"🔍 Checking JSON format specifics...\" >&2\n  \n  # Check for common JSON formats\n  if command -v jq &> /dev/null; then\n    # Check for package.json format\n    if [[ \"$FILE_NAME\" == \"package.json\" ]]; then\n      echo \"   📦 Detected package.json - checking NPM format...\" >&2\n      \n      if jq -e '.name' \"$FILE_PATH\" > /dev/null 2>&1; then\n        PKG_NAME=$(jq -r '.name' \"$FILE_PATH\" 2>/dev/null)\n        PKG_VERSION=$(jq -r '.version // \"no version\"' \"$FILE_PATH\" 2>/dev/null)\n        echo \"     📋 Package: $PKG_NAME@$PKG_VERSION\" >&2\n        report_validation \"PASS\" \"Valid package.json structure\"\n      else\n        report_validation \"WARNING\" \"package.json missing required 'name' field\"\n      fi\n      \n    # Check for tsconfig.json format\n    elif [[ \"$FILE_NAME\" == \"tsconfig.json\" ]] || [[ \"$FILE_NAME\" == \"jsconfig.json\" ]]; then\n      echo \"   🔧 Detected TypeScript/JavaScript config - checking format...\" >&2\n      \n      if jq -e '.compilerOptions // .include // .exclude' \"$FILE_PATH\" > /dev/null 2>&1; then\n        report_validation \"PASS\" \"Valid TypeScript/JavaScript config structure\"\n      else\n        report_validation \"WARNING\" \"Config file may be incomplete\"\n      fi\n      \n    # Check for JSON-LD format\n    elif jq -e '.\"@context\"' \"$FILE_PATH\" > /dev/null 2>&1; then\n      echo \"   🔗 Detected JSON-LD format\" >&2\n      CONTEXT_URL=$(jq -r '.\"@context\"' \"$FILE_PATH\" 2>/dev/null)\n      echo \"     🌐 Context: $CONTEXT_URL\" >&2\n      report_validation \"PASS\" \"JSON-LD structure detected\"\n      \n    # Check for GeoJSON format\n    elif jq -e '.type' \"$FILE_PATH\" 2>/dev/null | grep -q '\"Feature\"\\|\"FeatureCollection\"\\|\"Point\"\\|\"LineString\"'; then\n      echo \"   🗺️ Detected GeoJSON format\" >&2\n      GEOM_TYPE=$(jq -r '.type' \"$FILE_PATH\" 2>/dev/null)\n      echo \"     📍 Geometry type: $GEOM_TYPE\" >&2\n      report_validation \"PASS\" \"GeoJSON structure detected\"\n    fi\n  fi\n  \n  # 5. JSON Security and Best Practices\n  echo \"🔒 Security and best practices check...\" >&2\n  \n  # Check file size (warn for very large files)\n  if [ \"$FILE_SIZE\" -gt 10485760 ]; then  # 10MB\n    report_validation \"WARNING\" \"Large JSON file ($(( FILE_SIZE / 1048576 ))MB) - consider optimization\"\n  fi\n  \n  # Check for potential security issues\n  if command -v jq &> /dev/null; then\n    # Check for potentially sensitive data patterns\n    SENSITIVE_PATTERNS=(\"password\" \"secret\" \"token\" \"key\" \"credential\")\n    SENSITIVE_FOUND=false\n    \n    for pattern in \"${SENSITIVE_PATTERNS[@]}\"; do\n      if jq -r 'paths(scalars) as $p | $p | join(\".\")' \"$FILE_PATH\" 2>/dev/null | grep -i \"$pattern\" >/dev/null; then\n        SENSITIVE_FOUND=true\n        break\n      fi\n    done\n    \n    if [ \"$SENSITIVE_FOUND\" = true ]; then\n      report_validation \"WARNING\" \"Potentially sensitive data detected in JSON structure\"\n    fi\n    \n    # Check for excessive nesting depth\n    MAX_DEPTH=$(jq '[paths | length] | max' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n    if [ \"$MAX_DEPTH\" -gt 10 ]; then\n      report_validation \"WARNING\" \"Deep nesting detected ($MAX_DEPTH levels) - consider flattening\"\n    fi\n  fi\n  \n  # 6. Generate Validation Summary\n  echo \"\" >&2\n  echo \"📋 JSON Schema Validation Summary:\" >&2\n  echo \"=================================\" >&2\n  echo \"   📄 File: $FILE_NAME\" >&2\n  echo \"   📏 Size: $(( FILE_SIZE / 1024 ))KB\" >&2\n  echo \"   📋 Schema found: $SCHEMA_FOUND\" >&2\n  [ \"$SCHEMA_FOUND\" = true ] && echo \"   📁 Schema file: $(basename \"$SCHEMA_FILE\")\" >&2\n  echo \"   ✅ Validations passed: $VALIDATIONS_PASSED\" >&2\n  echo \"   ⚠️ Warnings: $WARNINGS\" >&2\n  echo \"   ❌ Errors: $ERRORS\" >&2\n  \n  if [ \"$ERRORS\" -eq 0 ]; then\n    if [ \"$WARNINGS\" -eq 0 ]; then\n      echo \"   🎉 Status: EXCELLENT - JSON is valid and well-formed\" >&2\n    else\n      echo \"   ✅ Status: GOOD - JSON is valid with minor recommendations\" >&2\n    fi\n  else\n    echo \"   ❌ Status: ERRORS - JSON has validation issues that must be fixed\" >&2\n  fi\n  \n  echo \"\" >&2\n  echo \"💡 JSON Schema Best Practices:\" >&2\n  echo \"   • Use descriptive schema titles and descriptions\" >&2\n  echo \"   • Define required properties clearly\" >&2\n  echo \"   • Validate data types and formats\" >&2\n  echo \"   • Keep schemas versioned and documented\" >&2\n  echo \"   • Use meaningful property names\" >&2\n  echo \"   • Avoid excessive nesting\" >&2\n  \n  # Exit with error if there are critical validation issues\n  if [ \"$ERRORS\" -gt 0 ]; then\n    echo \"⚠️ JSON validation completed with errors\" >&2\n    exit 1\n  fi\n  \nelse\n  # Not a JSON file or is a schema file, exit silently\n  exit 0\nfi\n\nexit 0"
      },
      "useCases": [
        "API development with automated JSON payload validation",
        "Configuration file validation and integrity checking",
        "Data pipeline quality assurance with schema enforcement",
        "CI/CD integration with automated JSON validation",
        "Multi-environment configuration consistency validation"
      ],
      "troubleshooting": [
        {
          "issue": "Hook runs on schema files causing validation loops",
          "solution": "The script excludes *.schema.json and *schema*.json files by default. Ensure your schema files follow this naming convention to prevent recursive validation."
        },
        {
          "issue": "AJV validation fails with module not found error",
          "solution": "Install AJV globally with 'npm install -g ajv-cli' or ensure npx can access it in your project's node_modules. The hook falls back to basic checks if unavailable."
        },
        {
          "issue": "Schema discovery fails for custom directory structures",
          "solution": "Add a '$schema' property to your JSON file pointing to the schema location, or place schemas in ./schema/, ./schemas/, or ./json-schemas/ directories with .schema.json suffix."
        },
        {
          "issue": "Large JSON files cause hook timeout or slowness",
          "solution": "For files over 10MB, consider splitting into smaller files or using streaming validation. The hook warns about large files but still validates them with basic syntax checks."
        },
        {
          "issue": "Validation passes but schema compatibility warnings appear",
          "solution": "Check the '$schema' version in your schema file. The hook reports version mismatches. Update schemas to use compatible JSON Schema draft versions (draft-07 recommended)."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/json-schema-validator"
    },
    {
      "slug": "kubernetes-manifest-validator",
      "description": "Validates Kubernetes YAML manifests for syntax and best practices when modified",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "kubernetes",
        "k8s",
        "yaml",
        "validation",
        "devops"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Comprehensive Kubernetes manifest validation using kubectl dry-run",
        "Multi-tool validation support (kubeval, kube-score, polaris)",
        "Security policy enforcement and best practices checking",
        "Resource quota and limits validation",
        "API version compatibility and deprecation warnings",
        "Network policy and RBAC configuration validation",
        "Multi-cluster context support and environment-specific validation",
        "Helm chart and Kustomize manifest validation"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/kubernetes-manifest-validator.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Check if this is a YAML file that might be a Kubernetes manifest\nif [[ \"$FILE_PATH\" == *.yaml ]] || [[ \"$FILE_PATH\" == *.yml ]]; then\n  # Check if it's a Kubernetes manifest by looking for apiVersion and kind\n  if grep -q 'apiVersion:\\|kind:' \"$FILE_PATH\" 2>/dev/null; then\n    echo \"☸️ Kubernetes Manifest Validation for: $(basename \"$FILE_PATH\")\" >&2\n    \n    # Initialize validation counters\n    ERRORS=0\n    WARNINGS=0\n    VALIDATIONS_PASSED=0\n    KUBECTL_AVAILABLE=false\n    \n    # Function to report validation results\n    report_validation() {\n      local level=\"$1\"\n      local message=\"$2\"\n      \n      case \"$level\" in\n        \"ERROR\")\n          echo \"❌ ERROR: $message\" >&2\n          ERRORS=$((ERRORS + 1))\n          ;;\n        \"WARNING\")\n          echo \"⚠️ WARNING: $message\" >&2\n          WARNINGS=$((WARNINGS + 1))\n          ;;\n        \"PASS\")\n          echo \"✅ PASS: $message\" >&2\n          VALIDATIONS_PASSED=$((VALIDATIONS_PASSED + 1))\n          ;;\n        \"INFO\")\n          echo \"ℹ️ INFO: $message\" >&2\n          ;;\n      esac\n    }\n    \n    # Check if file exists and is readable\n    if [ ! -f \"$FILE_PATH\" ]; then\n      report_validation \"ERROR\" \"Manifest file not found: $FILE_PATH\"\n      exit 1\n    fi\n    \n    if [ ! -r \"$FILE_PATH\" ]; then\n      report_validation \"ERROR\" \"Manifest file is not readable: $FILE_PATH\"\n      exit 1\n    fi\n    \n    # Get file information\n    FILE_NAME=\"$(basename \"$FILE_PATH\")\"\n    FILE_SIZE=$(wc -c < \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n    \n    echo \"📊 Kubernetes manifest: $FILE_NAME ($(( FILE_SIZE / 1024 ))KB)\" >&2\n    \n    # 1. Basic YAML Syntax Validation\n    echo \"📋 Checking YAML syntax...\" >&2\n    \n    # Use Python YAML parser for syntax validation\n    if command -v python3 &> /dev/null; then\n      if python3 -c \"import yaml; yaml.safe_load_all(open('$FILE_PATH'))\" 2>/dev/null; then\n        report_validation \"PASS\" \"Valid YAML syntax\"\n      else\n        report_validation \"ERROR\" \"Invalid YAML syntax detected\"\n        python3 -c \"import yaml; yaml.safe_load_all(open('$FILE_PATH'))\" 2>&1 | head -3 >&2\n        exit 1\n      fi\n    else\n      report_validation \"WARNING\" \"Python not available for YAML validation\"\n    fi\n    \n    # 2. Kubernetes Manifest Structure Analysis\n    echo \"🔍 Analyzing Kubernetes manifest structure...\" >&2\n    \n    # Extract resource information\n    API_VERSION=$(grep '^apiVersion:' \"$FILE_PATH\" | head -1 | cut -d':' -f2 | xargs 2>/dev/null || echo \"unknown\")\n    KIND=$(grep '^kind:' \"$FILE_PATH\" | head -1 | cut -d':' -f2 | xargs 2>/dev/null || echo \"unknown\")\n    RESOURCE_NAME=$(grep 'name:' \"$FILE_PATH\" | head -1 | cut -d':' -f2 | xargs 2>/dev/null || echo \"unnamed\")\n    NAMESPACE=$(grep 'namespace:' \"$FILE_PATH\" | head -1 | cut -d':' -f2 | xargs 2>/dev/null || echo \"default\")\n    \n    echo \"   📊 Resource: $KIND/$RESOURCE_NAME\" >&2\n    echo \"   🔧 API Version: $API_VERSION\" >&2\n    echo \"   📁 Namespace: $NAMESPACE\" >&2\n    \n    # Check for multiple resources in single file\n    RESOURCE_COUNT=$(grep -c '^apiVersion:' \"$FILE_PATH\" 2>/dev/null || echo \"1\")\n    if [ \"$RESOURCE_COUNT\" -gt 1 ]; then\n      echo \"   📋 Multi-resource file: $RESOURCE_COUNT resources\" >&2\n    fi\n    \n    # 3. kubectl Validation (if available)\n    echo \"☸️ Running kubectl validation...\" >&2\n    \n    if command -v kubectl &> /dev/null; then\n      KUBECTL_AVAILABLE=true\n      echo \"   🔧 kubectl found - running dry-run validation\" >&2\n      \n      # Check kubectl connection (but don't fail if no cluster)\n      KUBECTL_OUTPUT_FILE=\"/tmp/kubectl_output_$$\"\n      if kubectl apply --dry-run=client -f \"$FILE_PATH\" > \"$KUBECTL_OUTPUT_FILE\" 2>&1; then\n        report_validation \"PASS\" \"kubectl dry-run validation successful\"\n        \n        # Show what would be created/updated\n        grep -E 'created|configured|unchanged' \"$KUBECTL_OUTPUT_FILE\" 2>/dev/null | head -3 | while read line; do\n          echo \"     $line\" >&2\n        done\n        \n      else\n        # Check if it's a connection error or manifest error\n        if grep -q 'connection refused\\|unable to connect' \"$KUBECTL_OUTPUT_FILE\" 2>/dev/null; then\n          report_validation \"WARNING\" \"kubectl validation skipped - no cluster connection\"\n        else\n          report_validation \"ERROR\" \"kubectl dry-run validation failed\"\n          echo \"   📝 kubectl error details:\" >&2\n          head -5 \"$KUBECTL_OUTPUT_FILE\" | while read line; do\n            echo \"     $line\" >&2\n          done\n        fi\n      fi\n      \n      rm -f \"$KUBECTL_OUTPUT_FILE\"\n    else\n      report_validation \"WARNING\" \"kubectl not available - install for comprehensive validation\"\n    fi\n    \n    # 4. Additional Validation Tools\n    echo \"🔍 Running additional validation tools...\" >&2\n    \n    # kubeval validation\n    if command -v kubeval &> /dev/null; then\n      echo \"   🔍 Running kubeval validation...\" >&2\n      \n      KUBEVAL_OUTPUT_FILE=\"/tmp/kubeval_output_$$\"\n      if kubeval \"$FILE_PATH\" > \"$KUBEVAL_OUTPUT_FILE\" 2>&1; then\n        report_validation \"PASS\" \"kubeval validation successful\"\n      else\n        report_validation \"WARNING\" \"kubeval found issues\"\n        head -5 \"$KUBEVAL_OUTPUT_FILE\" | while read line; do\n          echo \"     $line\" >&2\n        done\n      fi\n      rm -f \"$KUBEVAL_OUTPUT_FILE\"\n    else\n      echo \"   💡 kubeval not installed - consider installing for schema validation\" >&2\n    fi\n    \n    # kube-score validation (best practices)\n    if command -v kube-score &> /dev/null; then\n      echo \"   📊 Running kube-score best practices check...\" >&2\n      \n      KUBESCORE_OUTPUT_FILE=\"/tmp/kubescore_output_$$\"\n      if kube-score score \"$FILE_PATH\" > \"$KUBESCORE_OUTPUT_FILE\" 2>&1; then\n        # kube-score shows recommendations, not just pass/fail\n        CRITICAL_COUNT=$(grep -c 'CRITICAL' \"$KUBESCORE_OUTPUT_FILE\" 2>/dev/null || echo \"0\")\n        WARNING_COUNT=$(grep -c 'WARNING' \"$KUBESCORE_OUTPUT_FILE\" 2>/dev/null || echo \"0\")\n        \n        if [ \"$CRITICAL_COUNT\" -eq 0 ]; then\n          report_validation \"PASS\" \"kube-score validation passed (no critical issues)\"\n        else\n          report_validation \"WARNING\" \"kube-score found $CRITICAL_COUNT critical issues\"\n        fi\n        \n        if [ \"$WARNING_COUNT\" -gt 0 ]; then\n          echo \"   ⚠️ kube-score warnings: $WARNING_COUNT\" >&2\n        fi\n      fi\n      rm -f \"$KUBESCORE_OUTPUT_FILE\"\n    else\n      echo \"   💡 kube-score not installed - consider installing for best practices validation\" >&2\n    fi\n    \n    # 5. Resource-Specific Validation\n    echo \"🔧 Performing resource-specific validation...\" >&2\n    \n    case \"$KIND\" in\n      \"Deployment\")\n        echo \"   🚀 Deployment-specific checks...\" >&2\n        \n        # Check for resource limits\n        if grep -q 'resources:' \"$FILE_PATH\" 2>/dev/null; then\n          if grep -q 'limits:\\|requests:' \"$FILE_PATH\" 2>/dev/null; then\n            report_validation \"PASS\" \"Resource limits/requests defined\"\n          else\n            report_validation \"WARNING\" \"Resource limits/requests not fully specified\"\n          fi\n        else\n          report_validation \"WARNING\" \"No resource limits defined - consider adding for production\"\n        fi\n        \n        # Check for replicas\n        REPLICAS=$(grep 'replicas:' \"$FILE_PATH\" | head -1 | cut -d':' -f2 | xargs 2>/dev/null || echo \"1\")\n        if [ \"$REPLICAS\" -eq 1 ]; then\n          report_validation \"WARNING\" \"Single replica deployment - consider multiple replicas for HA\"\n        else\n          echo \"   📊 Replicas: $REPLICAS\" >&2\n        fi\n        \n        # Check for readiness/liveness probes\n        if grep -q 'livenessProbe:\\|readinessProbe:' \"$FILE_PATH\" 2>/dev/null; then\n          report_validation \"PASS\" \"Health probes configured\"\n        else\n          report_validation \"WARNING\" \"No health probes defined - consider adding for reliability\"\n        fi\n        ;;\n        \n      \"Service\")\n        echo \"   🌐 Service-specific checks...\" >&2\n        \n        # Check service type\n        SERVICE_TYPE=$(grep 'type:' \"$FILE_PATH\" | head -1 | cut -d':' -f2 | xargs 2>/dev/null || echo \"ClusterIP\")\n        echo \"   🔧 Service type: $SERVICE_TYPE\" >&2\n        \n        if [ \"$SERVICE_TYPE\" = \"LoadBalancer\" ]; then\n          report_validation \"WARNING\" \"LoadBalancer service - ensure cloud provider support\"\n        fi\n        \n        # Check for selector\n        if grep -q 'selector:' \"$FILE_PATH\" 2>/dev/null; then\n          report_validation \"PASS\" \"Service selector defined\"\n        else\n          report_validation \"ERROR\" \"Service missing selector - will not route traffic\"\n        fi\n        ;;\n        \n      \"ConfigMap\"|\"Secret\")\n        echo \"   🔐 Configuration resource checks...\" >&2\n        \n        # Check for data section\n        if grep -q 'data:' \"$FILE_PATH\" 2>/dev/null; then\n          DATA_KEYS=$(grep -A 10 'data:' \"$FILE_PATH\" | grep -c '^  [^:]*:' || echo \"0\")\n          echo \"   📊 Data keys: $DATA_KEYS\" >&2\n          report_validation \"PASS\" \"Configuration data present\"\n        else\n          report_validation \"WARNING\" \"No data section found in $KIND\"\n        fi\n        ;;\n        \n      \"Ingress\")\n        echo \"   🌍 Ingress-specific checks...\" >&2\n        \n        # Check for rules\n        if grep -q 'rules:' \"$FILE_PATH\" 2>/dev/null; then\n          report_validation \"PASS\" \"Ingress rules defined\"\n        else\n          report_validation \"ERROR\" \"Ingress missing rules section\"\n        fi\n        \n        # Check for TLS\n        if grep -q 'tls:' \"$FILE_PATH\" 2>/dev/null; then\n          report_validation \"PASS\" \"TLS configuration present\"\n        else\n          report_validation \"WARNING\" \"No TLS configuration - consider HTTPS\"\n        fi\n        ;;\n    esac\n    \n    # 6. Security and Best Practices\n    echo \"🔒 Security and best practices check...\" >&2\n    \n    # Check for security context\n    if grep -q 'securityContext:' \"$FILE_PATH\" 2>/dev/null; then\n      report_validation \"PASS\" \"Security context defined\"\n      \n      # Check for non-root user\n      if grep -q 'runAsNonRoot: true\\|runAsUser:' \"$FILE_PATH\" 2>/dev/null; then\n        report_validation \"PASS\" \"Non-root security configuration\"\n      else\n        report_validation \"WARNING\" \"Consider running as non-root user\"\n      fi\n    else\n      report_validation \"WARNING\" \"No security context defined - consider adding for security\"\n    fi\n    \n    # Check for privileged containers\n    if grep -q 'privileged: true' \"$FILE_PATH\" 2>/dev/null; then\n      report_validation \"WARNING\" \"Privileged container detected - security risk\"\n    fi\n    \n    # Check for host network/PID\n    if grep -q 'hostNetwork: true\\|hostPID: true' \"$FILE_PATH\" 2>/dev/null; then\n      report_validation \"WARNING\" \"Host network/PID access detected - security risk\"\n    fi\n    \n    # Check for latest tag usage\n    if grep -q 'image:.*:latest' \"$FILE_PATH\" 2>/dev/null; then\n      report_validation \"WARNING\" \"Using 'latest' tag - consider specific version tags\"\n    fi\n    \n    # 7. Generate Validation Summary\n    echo \"\" >&2\n    echo \"📋 Kubernetes Manifest Validation Summary:\" >&2\n    echo \"==========================================\" >&2\n    echo \"   📄 File: $FILE_NAME\" >&2\n    echo \"   ☸️ Resource: $KIND/$RESOURCE_NAME\" >&2\n    echo \"   🔧 API Version: $API_VERSION\" >&2\n    echo \"   📁 Namespace: $NAMESPACE\" >&2\n    echo \"   ✅ Validations passed: $VALIDATIONS_PASSED\" >&2\n    echo \"   ⚠️ Warnings: $WARNINGS\" >&2\n    echo \"   ❌ Errors: $ERRORS\" >&2\n    \n    if [ \"$ERRORS\" -eq 0 ]; then\n      if [ \"$WARNINGS\" -eq 0 ]; then\n        echo \"   🎉 Status: EXCELLENT - Manifest is valid and follows best practices\" >&2\n      else\n        echo \"   ✅ Status: GOOD - Manifest is valid with minor recommendations\" >&2\n      fi\n    else\n      echo \"   ❌ Status: ERRORS - Manifest has critical issues that must be fixed\" >&2\n    fi\n    \n    echo \"\" >&2\n    echo \"💡 Kubernetes Best Practices:\" >&2\n    echo \"   • Use specific image tags instead of 'latest'\" >&2\n    echo \"   • Define resource limits and requests\" >&2\n    echo \"   • Configure health probes for applications\" >&2\n    echo \"   • Use security contexts and non-root users\" >&2\n    echo \"   • Implement RBAC for access control\" >&2\n    echo \"   • Use multiple replicas for high availability\" >&2\n    \n    # Exit with error if there are critical validation issues\n    if [ \"$ERRORS\" -gt 0 ]; then\n      echo \"⚠️ Kubernetes manifest validation completed with errors\" >&2\n      exit 1\n    fi\n    \n  else\n    # YAML file but not a Kubernetes manifest\n    exit 0\n  fi\nelse\n  # Not a YAML file\n  exit 0\nfi\n\nexit 0"
      },
      "useCases": [
        "DevOps pipeline integration with automated manifest validation",
        "Kubernetes cluster deployment safety and configuration verification",
        "Multi-environment deployment validation and consistency checking",
        "Security policy enforcement and compliance validation",
        "Infrastructure as Code quality assurance and best practices"
      ],
      "troubleshooting": [
        {
          "issue": "kubectl dry-run fails with 'no configuration found' error",
          "solution": "Check kubectl context: kubectl config current-context. Set context if missing: kubectl config use-context <context-name>. For validation without cluster, use --dry-run=client instead of --dry-run=server."
        },
        {
          "issue": "Validation detects Kubernetes manifest in non-k8s YAML files",
          "solution": "Strengthen detection logic: grep -q '^apiVersion:.*v1' && grep -q '^kind: (Pod|Deployment|Service)'. Skip YAML files in non-k8s directories: [[ \"$FILE_PATH\" =~ /k8s/|/manifests/|/deploy/ ]] || exit 0."
        },
        {
          "issue": "Multi-document YAML causes validation to check only first resource",
          "solution": "Use kubectl apply --dry-run for all documents. Split YAML: csplit -z \"$FILE_PATH\" '/^---$/' '{*}' && for f in xx*; do kubectl apply --dry-run=client -f $f; done. Handle --- document separators properly."
        },
        {
          "issue": "Security context warnings trigger on valid init containers",
          "solution": "Check container type before warning: grep -A5 'initContainers:' to identify init containers. Init containers may legitimately need privileged access. Add context-aware checks for runAsNonRoot based on container type."
        },
        {
          "issue": "Hook exits with error preventing further operations after validation",
          "solution": "Change exit strategy: collect validation errors but exit 0 for warnings. Use: [ \"$ERRORS\" -gt 0 ] && echo 'Validation errors' >&2 || exit 0. Only fail on critical errors, warn on best practices."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/kubernetes-manifest-validator"
    },
    {
      "slug": "markdown-link-checker",
      "description": "Validates all links in markdown files to detect broken links and references",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "markdown",
        "documentation",
        "links",
        "validation",
        "broken-links"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Comprehensive markdown link validation using markdown-link-check",
        "Internal reference validation for local file paths and anchors",
        "External URL validation with configurable retry and timeout",
        "Image link validation and accessibility checking",
        "Anchor link validation within the same document",
        "Relative path resolution and validation",
        "Custom configuration support for link checking rules",
        "Detailed reporting with line numbers and link types"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/markdown-link-checker.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Check if this is a markdown file\nif [[ \"$FILE_PATH\" == *.md ]] || [[ \"$FILE_PATH\" == *.mdx ]] || [[ \"$FILE_PATH\" == *.markdown ]]; then\n  echo \"🔗 Markdown Link Validation for: $(basename \"$FILE_PATH\")\" >&2\n  \n  # Initialize validation counters\n  ERRORS=0\n  WARNINGS=0\n  VALIDATIONS_PASSED=0\n  TOTAL_LINKS=0\n  EXTERNAL_LINKS=0\n  INTERNAL_LINKS=0\n  \n  # Function to report validation results\n  report_validation() {\n    local level=\"$1\"\n    local message=\"$2\"\n    \n    case \"$level\" in\n      \"ERROR\")\n        echo \"❌ ERROR: $message\" >&2\n        ERRORS=$((ERRORS + 1))\n        ;;\n      \"WARNING\")\n        echo \"⚠️ WARNING: $message\" >&2\n        WARNINGS=$((WARNINGS + 1))\n        ;;\n      \"PASS\")\n        echo \"✅ PASS: $message\" >&2\n        VALIDATIONS_PASSED=$((VALIDATIONS_PASSED + 1))\n        ;;\n      \"INFO\")\n        echo \"ℹ️ INFO: $message\" >&2\n        ;;\n    esac\n  }\n  \n  # Check if file exists and is readable\n  if [ ! -f \"$FILE_PATH\" ]; then\n    report_validation \"ERROR\" \"Markdown file not found: $FILE_PATH\"\n    exit 1\n  fi\n  \n  if [ ! -r \"$FILE_PATH\" ]; then\n    report_validation \"ERROR\" \"Markdown file is not readable: $FILE_PATH\"\n    exit 1\n  fi\n  \n  # Get file information\n  FILE_NAME=\"$(basename \"$FILE_PATH\")\"\n  FILE_DIR=\"$(dirname \"$FILE_PATH\")\"\n  FILE_SIZE=$(wc -c < \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n  LINE_COUNT=$(wc -l < \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n  \n  echo \"📊 Markdown file: $FILE_NAME ($(( FILE_SIZE / 1024 ))KB, $LINE_COUNT lines)\" >&2\n  \n  # 1. Extract All Links from Markdown\n  echo \"🔍 Extracting links from markdown...\" >&2\n  \n  # Create temporary files for link analysis\n  TEMP_LINKS=\"/tmp/markdown_links_$$\"\n  TEMP_IMAGES=\"/tmp/markdown_images_$$\"\n  TEMP_ANCHORS=\"/tmp/markdown_anchors_$$\"\n  \n  # Extract markdown links [text](url)\n  grep -oE '\\[([^\\]]+)\\]\\(([^)]+)\\)' \"$FILE_PATH\" | sed 's/\\[.*\\](\\(.*\\))/\\1/' > \"$TEMP_LINKS\" 2>/dev/null || true\n  \n  # Extract image links ![alt](url)\n  grep -oE '!\\[([^\\]]*)\\]\\(([^)]+)\\)' \"$FILE_PATH\" | sed 's/!\\[.*\\](\\(.*\\))/\\1/' > \"$TEMP_IMAGES\" 2>/dev/null || true\n  \n  # Extract reference-style links\n  grep -oE '\\[([^\\]]+)\\]\\[([^\\]]+)\\]' \"$FILE_PATH\" | sed 's/\\[.*\\]\\[\\(.*\\)\\]/\\1/' >> \"$TEMP_LINKS\" 2>/dev/null || true\n  \n  # Count total links\n  TOTAL_LINKS=$(cat \"$TEMP_LINKS\" \"$TEMP_IMAGES\" 2>/dev/null | wc -l || echo \"0\")\n  \n  if [ \"$TOTAL_LINKS\" -eq 0 ]; then\n    echo \"   📋 No links found in markdown file\" >&2\n    report_validation \"INFO\" \"No links to validate\"\n  else\n    echo \"   📊 Found $TOTAL_LINKS total links/images\" >&2\n  fi\n  \n  # 2. Validate External Links\n  echo \"🌐 Validating external links...\" >&2\n  \n  # Try using markdown-link-check if available\n  if command -v npx &> /dev/null; then\n    echo \"   🔍 Using markdown-link-check for comprehensive validation...\" >&2\n    \n    # Create a temporary config if none exists\n    CONFIG_FILE=\".markdown-link-check.json\"\n    TEMP_CONFIG=false\n    \n    if [ ! -f \"$CONFIG_FILE\" ]; then\n      TEMP_CONFIG=true\n      CONFIG_FILE=\"/tmp/markdown_link_config_$$\"\n      cat > \"$CONFIG_FILE\" << 'EOF'\n{\n  \"timeout\": \"30s\",\n  \"retryOn429\": true,\n  \"retryCount\": 3,\n  \"fallbackProtocols\": [\"http\", \"https\"],\n  \"ignorePatterns\": [\n    { \"pattern\": \"^http://localhost\" },\n    { \"pattern\": \"^https://localhost\" },\n    { \"pattern\": \"^http://127.0.0.1\" },\n    { \"pattern\": \"^#\" }\n  ]\n}\nEOF\n    fi\n    \n    MLC_OUTPUT_FILE=\"/tmp/mlc_output_$$\"\n    if timeout 60s npx markdown-link-check \"$FILE_PATH\" --config \"$CONFIG_FILE\" > \"$MLC_OUTPUT_FILE\" 2>&1; then\n      # Parse results\n      DEAD_LINKS=$(grep -c '✖' \"$MLC_OUTPUT_FILE\" 2>/dev/null || echo \"0\")\n      ALIVE_LINKS=$(grep -c '✓' \"$MLC_OUTPUT_FILE\" 2>/dev/null || echo \"0\")\n      \n      if [ \"$DEAD_LINKS\" -eq 0 ]; then\n        report_validation \"PASS\" \"All external links are valid ($ALIVE_LINKS checked)\"\n      else\n        report_validation \"ERROR\" \"Found $DEAD_LINKS dead external links\"\n        echo \"   📝 Dead links details:\" >&2\n        grep '✖' \"$MLC_OUTPUT_FILE\" | head -5 | while read line; do\n          echo \"     $line\" >&2\n        done\n      fi\n    else\n      # Fallback to basic URL validation\n      echo \"   ⚠️ markdown-link-check failed, using basic validation...\" >&2\n      \n      # Extract HTTP/HTTPS URLs\n      EXTERNAL_URLS=$(grep -oE 'https?://[^)]+' \"$TEMP_LINKS\" 2>/dev/null || true)\n      \n      if [ -n \"$EXTERNAL_URLS\" ]; then\n        EXTERNAL_COUNT=$(echo \"$EXTERNAL_URLS\" | wc -l)\n        echo \"   🌐 Found $EXTERNAL_COUNT external URLs to validate\" >&2\n        \n        # Basic URL validation using curl\n        if command -v curl &> /dev/null; then\n          EXTERNAL_ERRORS=0\n          echo \"$EXTERNAL_URLS\" | head -10 | while read -r url; do\n            if [ -n \"$url\" ]; then\n              if curl -s --head --max-time 10 \"$url\" >/dev/null 2>&1; then\n                echo \"     ✅ Valid: $url\" >&2\n              else\n                echo \"     ❌ Invalid: $url\" >&2\n                EXTERNAL_ERRORS=$((EXTERNAL_ERRORS + 1))\n              fi\n            fi\n          done\n        else\n          echo \"   ⚠️ curl not available for URL validation\" >&2\n        fi\n      else\n        echo \"   📋 No external URLs found\" >&2\n      fi\n    fi\n    \n    # Clean up temporary config if created\n    [ \"$TEMP_CONFIG\" = true ] && rm -f \"$CONFIG_FILE\"\n    rm -f \"$MLC_OUTPUT_FILE\"\n    \n  else\n    echo \"   ⚠️ npx not available, using basic link validation\" >&2\n  fi\n  \n  # 3. Validate Internal Links\n  echo \"📁 Validating internal links and references...\" >&2\n  \n  # Extract internal links (relative paths)\n  INTERNAL_URLS=$(cat \"$TEMP_LINKS\" \"$TEMP_IMAGES\" 2>/dev/null | grep -E '^\\./|^\\.\\./' || true)\n  ABSOLUTE_PATHS=$(cat \"$TEMP_LINKS\" \"$TEMP_IMAGES\" 2>/dev/null | grep -E '^/' || true)\n  \n  INTERNAL_ERRORS=0\n  \n  # Check relative path links\n  if [ -n \"$INTERNAL_URLS\" ]; then\n    echo \"   📂 Checking relative path links...\" >&2\n    \n    echo \"$INTERNAL_URLS\" | while read -r link; do\n      if [ -n \"$link\" ]; then\n        # Remove anchor if present\n        FILE_PART=$(echo \"$link\" | cut -d'#' -f1)\n        ANCHOR_PART=$(echo \"$link\" | cut -d'#' -f2)\n        \n        if [ -n \"$FILE_PART\" ]; then\n          # Resolve relative path\n          RESOLVED_PATH=\"$(cd \"$FILE_DIR\" && realpath \"$FILE_PART\" 2>/dev/null || echo \"$FILE_PART\")\"\n          \n          if [ -f \"$RESOLVED_PATH\" ] || [ -d \"$RESOLVED_PATH\" ]; then\n            echo \"     ✅ Valid: $link\" >&2\n          else\n            echo \"     ❌ Broken: $link (resolved to: $RESOLVED_PATH)\" >&2\n            INTERNAL_ERRORS=$((INTERNAL_ERRORS + 1))\n          fi\n        fi\n        \n        # Check anchor if present (simplified check)\n        if [ \"$link\" != \"$FILE_PART\" ] && [ -n \"$ANCHOR_PART\" ]; then\n          echo \"     ℹ️ Anchor found: #$ANCHOR_PART\" >&2\n        fi\n      fi\n    done\n  fi\n  \n  # Check absolute path links\n  if [ -n \"$ABSOLUTE_PATHS\" ]; then\n    echo \"   📁 Checking absolute path links...\" >&2\n    \n    echo \"$ABSOLUTE_PATHS\" | while read -r link; do\n      if [ -n \"$link\" ]; then\n        FILE_PART=$(echo \"$link\" | cut -d'#' -f1)\n        \n        if [ -f \"$FILE_PART\" ] || [ -d \"$FILE_PART\" ]; then\n          echo \"     ✅ Valid: $link\" >&2\n        else\n          echo \"     ❌ Broken: $link\" >&2\n          INTERNAL_ERRORS=$((INTERNAL_ERRORS + 1))\n        fi\n      fi\n    done\n  fi\n  \n  if [ \"$INTERNAL_ERRORS\" -eq 0 ]; then\n    report_validation \"PASS\" \"All internal links are valid\"\n  else\n    report_validation \"ERROR\" \"Found $INTERNAL_ERRORS broken internal links\"\n  fi\n  \n  # 4. Validate Image Links\n  echo \"🖼️ Validating image links...\" >&2\n  \n  IMAGE_COUNT=$(cat \"$TEMP_IMAGES\" 2>/dev/null | wc -l || echo \"0\")\n  \n  if [ \"$IMAGE_COUNT\" -gt 0 ]; then\n    echo \"   📊 Found $IMAGE_COUNT image links\" >&2\n    \n    IMAGE_ERRORS=0\n    \n    cat \"$TEMP_IMAGES\" | while read -r img_link; do\n      if [ -n \"$img_link\" ]; then\n        if [[ \"$img_link\" == http* ]]; then\n          echo \"     🌐 External image: $img_link\" >&2\n        else\n          # Local image file\n          if [[ \"$img_link\" == /* ]]; then\n            IMG_PATH=\"$img_link\"\n          else\n            IMG_PATH=\"$FILE_DIR/$img_link\"\n          fi\n          \n          if [ -f \"$IMG_PATH\" ]; then\n            echo \"     ✅ Valid image: $img_link\" >&2\n          else\n            echo \"     ❌ Missing image: $img_link\" >&2\n            IMAGE_ERRORS=$((IMAGE_ERRORS + 1))\n          fi\n        fi\n      fi\n    done\n    \n    if [ \"$IMAGE_ERRORS\" -eq 0 ]; then\n      report_validation \"PASS\" \"All local images found\"\n    else\n      report_validation \"ERROR\" \"$IMAGE_ERRORS local images missing\"\n    fi\n  else\n    echo \"   📋 No image links found\" >&2\n  fi\n  \n  # 5. Validate Internal Anchors\n  echo \"⚓ Validating document anchors...\" >&2\n  \n  # Extract anchor-only links (starting with #)\n  ANCHOR_LINKS=$(cat \"$TEMP_LINKS\" | grep '^#' 2>/dev/null || true)\n  \n  if [ -n \"$ANCHOR_LINKS\" ]; then\n    echo \"   🔗 Found anchor links to validate\" >&2\n    \n    # Extract headers from markdown to validate anchors\n    HEADERS_FILE=\"/tmp/markdown_headers_$$\"\n    grep -E '^#{1,6} ' \"$FILE_PATH\" | sed 's/^#* *//' | tr '[:upper:]' '[:lower:]' | sed 's/[^a-z0-9 -]//g' | sed 's/ /-/g' > \"$HEADERS_FILE\" 2>/dev/null || true\n    \n    ANCHOR_ERRORS=0\n    \n    echo \"$ANCHOR_LINKS\" | while read -r anchor; do\n      if [ -n \"$anchor\" ]; then\n        CLEAN_ANCHOR=$(echo \"$anchor\" | sed 's/^#//' | tr '[:upper:]' '[:lower:]')\n        \n        if grep -q \"^$CLEAN_ANCHOR$\" \"$HEADERS_FILE\" 2>/dev/null; then\n          echo \"     ✅ Valid anchor: $anchor\" >&2\n        else\n          echo \"     ❌ Invalid anchor: $anchor\" >&2\n          ANCHOR_ERRORS=$((ANCHOR_ERRORS + 1))\n        fi\n      fi\n    done\n    \n    rm -f \"$HEADERS_FILE\"\n    \n    if [ \"$ANCHOR_ERRORS\" -eq 0 ]; then\n      report_validation \"PASS\" \"All document anchors valid\"\n    else\n      report_validation \"ERROR\" \"$ANCHOR_ERRORS invalid document anchors\"\n    fi\n  else\n    echo \"   📋 No document anchors found\" >&2\n  fi\n  \n  # 6. Markdown Quality Checks\n  echo \"📝 Markdown quality and accessibility checks...\" >&2\n  \n  # Check for alt text in images\n  IMAGES_WITHOUT_ALT=$(grep -c '!\\[\\](' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n  \n  if [ \"$IMAGES_WITHOUT_ALT\" -gt 0 ]; then\n    report_validation \"WARNING\" \"$IMAGES_WITHOUT_ALT images missing alt text for accessibility\"\n  else\n    if [ \"$IMAGE_COUNT\" -gt 0 ]; then\n      report_validation \"PASS\" \"All images have alt text\"\n    fi\n  fi\n  \n  # Check for bare URLs (not wrapped in markdown links)\n  BARE_URLS=$(grep -oE 'https?://[^\\s\\)\\]]+' \"$FILE_PATH\" | grep -v '](http' | head -5 | wc -l || echo \"0\")\n  \n  if [ \"$BARE_URLS\" -gt 0 ]; then\n    report_validation \"WARNING\" \"Found $BARE_URLS bare URLs - consider wrapping in markdown links\"\n  fi\n  \n  # 7. Generate Validation Summary\n  echo \"\" >&2\n  echo \"📋 Markdown Link Validation Summary:\" >&2\n  echo \"===================================\" >&2\n  echo \"   📄 File: $FILE_NAME\" >&2\n  echo \"   📏 Size: $(( FILE_SIZE / 1024 ))KB, $LINE_COUNT lines\" >&2\n  echo \"   🔗 Total links: $TOTAL_LINKS\" >&2\n  echo \"   🖼️ Images: $IMAGE_COUNT\" >&2\n  echo \"   ✅ Validations passed: $VALIDATIONS_PASSED\" >&2\n  echo \"   ⚠️ Warnings: $WARNINGS\" >&2\n  echo \"   ❌ Errors: $ERRORS\" >&2\n  \n  if [ \"$ERRORS\" -eq 0 ]; then\n    if [ \"$WARNINGS\" -eq 0 ]; then\n      echo \"   🎉 Status: EXCELLENT - All links are valid and accessible\" >&2\n    else\n      echo \"   ✅ Status: GOOD - Links are valid with minor accessibility recommendations\" >&2\n    fi\n  else\n    echo \"   ❌ Status: ERRORS - Found broken links that must be fixed\" >&2\n  fi\n  \n  echo \"\" >&2\n  echo \"💡 Markdown Link Best Practices:\" >&2\n  echo \"   • Use descriptive link text instead of 'click here'\" >&2\n  echo \"   • Add alt text to all images for accessibility\" >&2\n  echo \"   • Use relative paths for internal documentation\" >&2\n  echo \"   • Validate external links regularly\" >&2\n  echo \"   • Keep anchor links synchronized with headers\" >&2\n  echo \"   • Consider using reference-style links for readability\" >&2\n  \n  # Clean up temporary files\n  rm -f \"$TEMP_LINKS\" \"$TEMP_IMAGES\" \"$TEMP_ANCHORS\"\n  \n  # Exit with error if there are critical link issues\n  if [ \"$ERRORS\" -gt 0 ]; then\n    echo \"⚠️ Markdown link validation completed with errors\" >&2\n    exit 1\n  fi\n  \nelse\n  # Not a markdown file\n  exit 0\nfi\n\nexit 0"
      },
      "useCases": [
        "Documentation maintenance and quality assurance automation",
        "Technical writing workflow integration with link validation",
        "Content management system link integrity checking",
        "Static site generation with automated link verification",
        "Multi-language documentation consistency validation"
      ],
      "troubleshooting": [
        {
          "issue": "Hook times out on markdown files with many links",
          "solution": "Increase timeout in markdown-link-check config from 30s to 60s. Reduce retryCount from 3 to 1 for faster failures. Use --quiet flag or limit external link checking to critical links only."
        },
        {
          "issue": "False positives for localhost or development URLs",
          "solution": "Add localhost patterns to ignorePatterns in .markdown-link-check.json config. Hook creates temp config with common exclusions but customize project config for development server URLs."
        },
        {
          "issue": "Anchor validation fails for generated heading IDs",
          "solution": "Heading ID generation varies by markdown processor. Update anchor cleaning logic in hook to match your tool's slug generation (GitHub uses lowercase with dashes, Jekyll may differ)."
        },
        {
          "issue": "Image links show as broken but files exist",
          "solution": "Check path resolution relative to markdown file location. Hook resolves paths from file directory, not repo root. Use absolute paths from repo root with leading slash for consistency."
        },
        {
          "issue": "External link validation causes rate limiting errors",
          "solution": "Enable retryOn429 in config and increase timeout. Add rate-limited domains to ignorePatterns temporarily. Consider running full external validation in CI only, not on every file edit."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/markdown-link-checker"
    },
    {
      "slug": "memory-usage-monitor",
      "description": "Monitors memory usage and alerts when thresholds are exceeded",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "memory",
        "performance",
        "monitoring",
        "notification",
        "resources"
      ],
      "hookType": "Notification",
      "features": [
        "Real-time memory usage monitoring across multiple programming languages",
        "Process-specific memory tracking for Node.js, Python, Java, and Ruby",
        "Configurable memory threshold alerts and warnings",
        "Swap usage monitoring and excessive swap detection",
        "Memory leak detection with historical usage tracking",
        "Container memory monitoring for Docker environments",
        "Cross-platform memory monitoring (Linux, macOS, Windows)",
        "Memory pressure analysis and system health reporting"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "notification": {
              "script": "./.claude/hooks/memory-usage-monitor.sh",
              "timeout": 5000
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Memory Usage Monitor Hook\n# Monitors system and process memory usage during development activities\n\necho \"💾 Memory Usage Monitor\" >&2\n\n# Initialize monitoring variables\nTOTAL_MEMORY_KB=0\nUSED_MEMORY_KB=0\nMEMORY_PERCENT=0\nSWAP_PERCENT=0\nHIGH_MEMORY_THRESHOLD=75\nCRITICAL_MEMORY_THRESHOLD=90\nHIGH_SWAP_THRESHOLD=25\nWARNINGS=0\nERRORS=0\n\n# Function to report memory status\nreport_memory() {\n  local level=\"$1\"\n  local message=\"$2\"\n  \n  case \"$level\" in\n    \"ERROR\")\n      echo \"❌ CRITICAL: $message\" >&2\n      ERRORS=$((ERRORS + 1))\n      ;;\n    \"WARNING\")\n      echo \"⚠️ WARNING: $message\" >&2\n      WARNINGS=$((WARNINGS + 1))\n      ;;\n    \"INFO\")\n      echo \"ℹ️ INFO: $message\" >&2\n      ;;\n    \"PASS\")\n      echo \"✅ OK: $message\" >&2\n      ;;\n  esac\n}\n\n# Function to format bytes to human readable\nformat_bytes() {\n  local bytes=$1\n  local units=(\"B\" \"KB\" \"MB\" \"GB\" \"TB\")\n  local unit=0\n  \n  while (( bytes > 1024 && unit < 4 )); do\n    bytes=$((bytes / 1024))\n    unit=$((unit + 1))\n  done\n  \n  echo \"${bytes}${units[$unit]}\"\n}\n\n# 1. System Memory Analysis\necho \"📊 Analyzing system memory usage...\" >&2\n\n# Detect operating system for platform-specific commands\nOS_TYPE=$(uname -s)\n\ncase \"$OS_TYPE\" in\n  \"Linux\")\n    # Linux memory information\n    if [ -f /proc/meminfo ]; then\n      TOTAL_MEMORY_KB=$(grep '^MemTotal:' /proc/meminfo | awk '{print $2}')\n      AVAILABLE_MEMORY_KB=$(grep '^MemAvailable:' /proc/meminfo | awk '{print $2}' || echo \"0\")\n      \n      if [ \"$AVAILABLE_MEMORY_KB\" -eq 0 ]; then\n        # Fallback calculation for older systems\n        FREE_MEMORY_KB=$(grep '^MemFree:' /proc/meminfo | awk '{print $2}')\n        BUFFERS_KB=$(grep '^Buffers:' /proc/meminfo | awk '{print $2}')\n        CACHED_KB=$(grep '^Cached:' /proc/meminfo | awk '{print $2}')\n        AVAILABLE_MEMORY_KB=$((FREE_MEMORY_KB + BUFFERS_KB + CACHED_KB))\n      fi\n      \n      USED_MEMORY_KB=$((TOTAL_MEMORY_KB - AVAILABLE_MEMORY_KB))\n      MEMORY_PERCENT=$((USED_MEMORY_KB * 100 / TOTAL_MEMORY_KB))\n      \n      echo \"   🖥️ Total Memory: $(format_bytes $((TOTAL_MEMORY_KB * 1024)))\" >&2\n      echo \"   📈 Used Memory: $(format_bytes $((USED_MEMORY_KB * 1024))) ($MEMORY_PERCENT%)\" >&2\n      \n      # Check swap usage\n      if [ -f /proc/swaps ]; then\n        SWAP_TOTAL_KB=$(awk 'NR>1 {sum+=$3} END {print sum+0}' /proc/swaps)\n        SWAP_USED_KB=$(awk 'NR>1 {sum+=$4} END {print sum+0}' /proc/swaps)\n        \n        if [ \"$SWAP_TOTAL_KB\" -gt 0 ]; then\n          SWAP_PERCENT=$((SWAP_USED_KB * 100 / SWAP_TOTAL_KB))\n          echo \"   💿 Swap Usage: $(format_bytes $((SWAP_USED_KB * 1024))) / $(format_bytes $((SWAP_TOTAL_KB * 1024))) ($SWAP_PERCENT%)\" >&2\n        else\n          echo \"   💿 Swap: Not configured\" >&2\n        fi\n      fi\n    else\n      report_memory \"WARNING\" \"Unable to read /proc/meminfo - memory monitoring limited\"\n    fi\n    ;;\n    \n  \"Darwin\")\n    # macOS memory information\n    if command -v vm_stat &> /dev/null; then\n      # Get page size\n      PAGE_SIZE=$(vm_stat | grep 'page size of' | awk '{print $8}' || echo \"4096\")\n      \n      # Get memory statistics\n      VM_STAT_OUTPUT=$(vm_stat)\n      PAGES_FREE=$(echo \"$VM_STAT_OUTPUT\" | grep 'Pages free:' | awk '{print $3}' | tr -d '.')\n      PAGES_ACTIVE=$(echo \"$VM_STAT_OUTPUT\" | grep 'Pages active:' | awk '{print $3}' | tr -d '.')\n      PAGES_INACTIVE=$(echo \"$VM_STAT_OUTPUT\" | grep 'Pages inactive:' | awk '{print $3}' | tr -d '.')\n      PAGES_SPECULATIVE=$(echo \"$VM_STAT_OUTPUT\" | grep 'Pages speculative:' | awk '{print $3}' | tr -d '.' || echo \"0\")\n      PAGES_WIRED=$(echo \"$VM_STAT_OUTPUT\" | grep 'Pages wired down:' | awk '{print $4}' | tr -d '.')\n      \n      # Calculate memory usage\n      TOTAL_PAGES=$((PAGES_FREE + PAGES_ACTIVE + PAGES_INACTIVE + PAGES_SPECULATIVE + PAGES_WIRED))\n      USED_PAGES=$((PAGES_ACTIVE + PAGES_INACTIVE + PAGES_SPECULATIVE + PAGES_WIRED))\n      TOTAL_MEMORY_KB=$((TOTAL_PAGES * PAGE_SIZE / 1024))\n      USED_MEMORY_KB=$((USED_PAGES * PAGE_SIZE / 1024))\n      MEMORY_PERCENT=$((USED_MEMORY_KB * 100 / TOTAL_MEMORY_KB))\n      \n      echo \"   🖥️ Total Memory: $(format_bytes $((TOTAL_MEMORY_KB * 1024)))\" >&2\n      echo \"   📈 Used Memory: $(format_bytes $((USED_MEMORY_KB * 1024))) ($MEMORY_PERCENT%)\" >&2\n      \n      # Check swap usage on macOS\n      if command -v sysctl &> /dev/null; then\n        SWAP_USAGE=$(sysctl vm.swapusage 2>/dev/null | grep -oE 'used = [0-9.]+[KMGT]?' | awk '{print $3}' || echo \"0\")\n        SWAP_TOTAL=$(sysctl vm.swapusage 2>/dev/null | grep -oE 'total = [0-9.]+[KMGT]?' | awk '{print $3}' || echo \"0\")\n        echo \"   💿 Swap Usage: $SWAP_USAGE / $SWAP_TOTAL\" >&2\n      fi\n    else\n      report_memory \"WARNING\" \"vm_stat command not available - memory monitoring limited\"\n    fi\n    ;;\n    \n  *)\n    report_memory \"WARNING\" \"Unsupported operating system ($OS_TYPE) - limited memory monitoring\"\n    ;;\nesac\n\n# 2. Process-Specific Memory Analysis\necho \"🔍 Analyzing development process memory usage...\" >&2\n\n# Define process patterns for different development environments\nDEV_PROCESSES=(\"node\" \"python\" \"java\" \"ruby\" \"php\" \"go\" \"rust\" \"dotnet\" \"code\" \"claude\")\nTOTAL_DEV_MEMORY_KB=0\nPROCESS_COUNT=0\n\nfor process in \"${DEV_PROCESSES[@]}\"; do\n  if command -v pgrep &> /dev/null; then\n    # Use pgrep for more accurate process detection\n    PIDS=$(pgrep -f \"$process\" 2>/dev/null || true)\n    \n    if [ -n \"$PIDS\" ]; then\n      PROCESS_MEMORY=0\n      PROC_COUNT=0\n      \n      # Calculate memory for all matching processes\n      for pid in $PIDS; do\n        if [ -f \"/proc/$pid/status\" ]; then\n          # Linux: Read from /proc/pid/status\n          PID_MEMORY=$(grep '^VmRSS:' \"/proc/$pid/status\" 2>/dev/null | awk '{print $2}' || echo \"0\")\n        elif command -v ps &> /dev/null; then\n          # macOS/Other: Use ps command\n          PID_MEMORY=$(ps -o rss= -p \"$pid\" 2>/dev/null | awk '{print $1}' || echo \"0\")\n        else\n          PID_MEMORY=0\n        fi\n        \n        PROCESS_MEMORY=$((PROCESS_MEMORY + PID_MEMORY))\n        PROC_COUNT=$((PROC_COUNT + 1))\n      done\n      \n      if [ \"$PROCESS_MEMORY\" -gt 0 ]; then\n        echo \"   🔧 $process processes: $PROC_COUNT running, $(format_bytes $((PROCESS_MEMORY * 1024))) memory\" >&2\n        TOTAL_DEV_MEMORY_KB=$((TOTAL_DEV_MEMORY_KB + PROCESS_MEMORY))\n        PROCESS_COUNT=$((PROCESS_COUNT + PROC_COUNT))\n      fi\n    fi\n  fi\ndone\n\nif [ \"$TOTAL_DEV_MEMORY_KB\" -gt 0 ]; then\n  DEV_MEMORY_PERCENT=$((TOTAL_DEV_MEMORY_KB * 100 / TOTAL_MEMORY_KB))\n  echo \"   📊 Total dev processes: $PROCESS_COUNT processes, $(format_bytes $((TOTAL_DEV_MEMORY_KB * 1024))) ($DEV_MEMORY_PERCENT% of system)\" >&2\nelse\n  echo \"   📋 No development processes detected\" >&2\nfi\n\n# 3. Container Memory Monitoring (if applicable)\necho \"🐳 Checking container memory usage...\" >&2\n\nif command -v docker &> /dev/null && docker info >/dev/null 2>&1; then\n  # Check Docker container memory usage\n  RUNNING_CONTAINERS=$(docker ps --format \"table {{.Names}}\" --no-trunc 2>/dev/null | tail -n +2 | wc -l || echo \"0\")\n  \n  if [ \"$RUNNING_CONTAINERS\" -gt 0 ]; then\n    echo \"   🐳 Docker containers: $RUNNING_CONTAINERS running\" >&2\n    \n    # Get container memory stats (basic)\n    CONTAINER_STATS=$(docker stats --no-stream --format \"table {{.Container}}\\t{{.MemUsage}}\" 2>/dev/null | tail -n +2 | head -5 || true)\n    \n    if [ -n \"$CONTAINER_STATS\" ]; then\n      echo \"   📊 Top container memory usage:\" >&2\n      echo \"$CONTAINER_STATS\" | while read line; do\n        echo \"     $line\" >&2\n      done\n    fi\n  else\n    echo \"   🐳 No running Docker containers\" >&2\n  fi\nelse\n  echo \"   🐳 Docker not available or not running\" >&2\nfi\n\n# 4. Memory Threshold Analysis\necho \"⚠️ Analyzing memory thresholds...\" >&2\n\n# Check system memory thresholds\nif [ \"$MEMORY_PERCENT\" -ge \"$CRITICAL_MEMORY_THRESHOLD\" ]; then\n  report_memory \"ERROR\" \"Critical system memory usage: $MEMORY_PERCENT% (threshold: $CRITICAL_MEMORY_THRESHOLD%)\"\nelif [ \"$MEMORY_PERCENT\" -ge \"$HIGH_MEMORY_THRESHOLD\" ]; then\n  report_memory \"WARNING\" \"High system memory usage: $MEMORY_PERCENT% (threshold: $HIGH_MEMORY_THRESHOLD%)\"\nelse\n  report_memory \"PASS\" \"System memory usage within normal range: $MEMORY_PERCENT%\"\nfi\n\n# Check swap usage\nif [ \"$SWAP_PERCENT\" -ge \"$HIGH_SWAP_THRESHOLD\" ]; then\n  report_memory \"WARNING\" \"High swap usage detected: $SWAP_PERCENT% (threshold: $HIGH_SWAP_THRESHOLD%)\"\nelse\n  if [ \"$SWAP_PERCENT\" -gt 0 ]; then\n    report_memory \"INFO\" \"Swap usage normal: $SWAP_PERCENT%\"\n  fi\nfi\n\n# Check for potential memory leaks (high dev process usage)\nif [ \"$TOTAL_DEV_MEMORY_KB\" -gt 0 ] && [ \"$DEV_MEMORY_PERCENT\" -ge 50 ]; then\n  report_memory \"WARNING\" \"Development processes using significant memory: $DEV_MEMORY_PERCENT% of system\"\nelif [ \"$TOTAL_DEV_MEMORY_KB\" -gt 0 ]; then\n  report_memory \"INFO\" \"Development process memory usage normal: $DEV_MEMORY_PERCENT% of system\"\nfi\n\n# 5. Memory Recommendations\necho \"💡 Memory optimization recommendations...\" >&2\n\nif [ \"$MEMORY_PERCENT\" -ge \"$HIGH_MEMORY_THRESHOLD\" ]; then\n  echo \"   • Consider closing unused applications and browser tabs\" >&2\n  echo \"   • Restart development servers to free up memory\" >&2\n  echo \"   • Check for memory leaks in your applications\" >&2\nfi\n\nif [ \"$SWAP_PERCENT\" -ge \"$HIGH_SWAP_THRESHOLD\" ]; then\n  echo \"   • High swap usage may slow down development\" >&2\n  echo \"   • Consider adding more RAM or closing applications\" >&2\nfi\n\nif [ \"$PROCESS_COUNT\" -gt 10 ]; then\n  echo \"   • Many development processes running ($PROCESS_COUNT)\" >&2\n  echo \"   • Consider stopping unused development servers\" >&2\nfi\n\n# 6. Generate Memory Summary\necho \"\" >&2\necho \"📋 Memory Usage Summary:\" >&2\necho \"========================\" >&2\necho \"   💾 System Memory: $MEMORY_PERCENT% used ($(format_bytes $((USED_MEMORY_KB * 1024))) / $(format_bytes $((TOTAL_MEMORY_KB * 1024))))\" >&2\n[ \"$SWAP_PERCENT\" -gt 0 ] && echo \"   💿 Swap Usage: $SWAP_PERCENT%\" >&2\necho \"   🔧 Dev Processes: $PROCESS_COUNT running ($(format_bytes $((TOTAL_DEV_MEMORY_KB * 1024))))\" >&2\necho \"   ⚠️ Warnings: $WARNINGS\" >&2\necho \"   ❌ Critical Issues: $ERRORS\" >&2\n\nif [ \"$ERRORS\" -eq 0 ] && [ \"$WARNINGS\" -eq 0 ]; then\n  echo \"   🎉 Status: OPTIMAL - Memory usage is healthy\" >&2\nelif [ \"$ERRORS\" -eq 0 ]; then\n  echo \"   ✅ Status: GOOD - Memory usage acceptable with minor warnings\" >&2\nelse\n  echo \"   ❌ Status: CRITICAL - Memory usage requires immediate attention\" >&2\nfi\n\necho \"\" >&2\necho \"💡 Memory Best Practices:\" >&2\necho \"   • Monitor memory usage regularly during development\" >&2\necho \"   • Use memory profiling tools to identify leaks\" >&2\necho \"   • Restart development servers periodically\" >&2\necho \"   • Consider using lighter development tools when memory is limited\" >&2\necho \"   • Close unused applications and browser tabs\" >&2\n\n# Memory monitoring complete\nexit 0"
      },
      "useCases": [
        "Development environment performance optimization and monitoring",
        "Memory leak detection and prevention in long-running development sessions",
        "System resource management and capacity planning",
        "Container and microservices memory monitoring",
        "CI/CD pipeline resource usage tracking and optimization"
      ],
      "troubleshooting": [
        {
          "issue": "Memory percentage calculation shows values over 100% or negative",
          "solution": "MemAvailable fallback calculation adds cached memory twice. For older Linux: 'USED_MEMORY_KB=$((TOTAL_MEMORY_KB - FREE_MEMORY_KB))' excluding buffers/cache. Or upgrade kernel to 3.14+ with MemAvailable support."
        },
        {
          "issue": "macOS vm_stat parsing fails showing zero memory usage",
          "solution": "PAGE_SIZE extraction fails when format changes. Hardcode: 'PAGE_SIZE=4096' (Intel) or 'PAGE_SIZE=16384' (Apple Silicon M1/M2). Or use: 'sysctl hw.pagesize | awk '{print $2}''."
        },
        {
          "issue": "pgrep returns processes from other users causing inflated dev memory",
          "solution": "pgrep matches all users. Restrict: 'pgrep -u $USER -f \"$process\"' showing only current user's processes. Or filter: 'ps -u $USER -o pid,comm,rss' for ownership validation."
        },
        {
          "issue": "Docker stats command hangs indefinitely when containers unhealthy",
          "solution": "docker stats --no-stream blocks on slow containers. Add timeout: 'timeout 5 docker stats --no-stream' or skip: 'docker stats --no-stream --format json 2>/dev/null | head -n 1' limiting output."
        },
        {
          "issue": "Hook execution time exceeds timeout (5000ms) on large systems",
          "solution": "Process enumeration slow with 100+ dev processes. Increase timeout: '\"timeout\": 10000' in hookConfig. Or limit: 'pgrep -f \"$process\" | head -20' checking only top processes."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/memory-usage-monitor"
    },
    {
      "slug": "nextjs-route-analyzer",
      "description": "Analyzes Next.js page routes and generates a route map when pages are added or modified",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "nextjs",
        "routing",
        "pages",
        "analysis",
        "documentation"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Comprehensive Next.js route analysis for both Pages and App Router",
        "Dynamic route detection with parameter mapping",
        "API endpoint discovery and documentation generation",
        "Route hierarchy visualization and structure analysis",
        "Catch-all and optional catch-all route detection",
        "Route groups and parallel routes analysis",
        "Static and dynamic route classification",
        "Route map generation with export capabilities"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/nextjs-route-analyzer.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Check if this is a Next.js page, component, or route file\nif [[ \"$FILE_PATH\" == *pages/*.* ]] || [[ \"$FILE_PATH\" == *app/*.* ]] || [[ \"$FILE_PATH\" == *src/pages/*.* ]] || [[ \"$FILE_PATH\" == *src/app/*.* ]]; then\n  echo \"🗺️ Next.js Route Analysis for: $(basename \"$FILE_PATH\")\" >&2\n  \n  # Initialize analysis counters\n  TOTAL_ROUTES=0\n  STATIC_ROUTES=0\n  DYNAMIC_ROUTES=0\n  API_ROUTES=0\n  CATCH_ALL_ROUTES=0\n  ERRORS=0\n  WARNINGS=0\n  \n  # Function to report analysis results\n  report_analysis() {\n    local level=\"$1\"\n    local message=\"$2\"\n    \n    case \"$level\" in\n      \"ERROR\")\n        echo \"❌ ERROR: $message\" >&2\n        ERRORS=$((ERRORS + 1))\n        ;;\n      \"WARNING\")\n        echo \"⚠️ WARNING: $message\" >&2\n        WARNINGS=$((WARNINGS + 1))\n        ;;\n      \"INFO\")\n        echo \"ℹ️ INFO: $message\" >&2\n        ;;\n      \"FOUND\")\n        echo \"✅ FOUND: $message\" >&2\n        ;;\n    esac\n  }\n  \n  # Detect Next.js project structure\n  PROJECT_ROOT=\".\"\n  PAGES_DIR=\"\"\n  APP_DIR=\"\"\n  SRC_PAGES_DIR=\"\"\n  SRC_APP_DIR=\"\"\n  \n  # Find project root and routing directories\n  if [ -f \"./package.json\" ]; then\n    # Check if this is a Next.js project\n    if grep -q '\"next\"' \"./package.json\" 2>/dev/null; then\n      echo \"   📦 Next.js project detected\" >&2\n      \n      # Check for different routing structures\n      [ -d \"./pages\" ] && PAGES_DIR=\"./pages\"\n      [ -d \"./app\" ] && APP_DIR=\"./app\"\n      [ -d \"./src/pages\" ] && SRC_PAGES_DIR=\"./src/pages\"\n      [ -d \"./src/app\" ] && SRC_APP_DIR=\"./src/app\"\n      \n      if [ -n \"$APP_DIR\" ] || [ -n \"$SRC_APP_DIR\" ]; then\n        echo \"   🔧 App Router structure detected\" >&2\n      fi\n      \n      if [ -n \"$PAGES_DIR\" ] || [ -n \"$SRC_PAGES_DIR\" ]; then\n        echo \"   📄 Pages Router structure detected\" >&2\n      fi\n    else\n      report_analysis \"WARNING\" \"Not a Next.js project (no Next.js dependency found)\"\n    fi\n  else\n    report_analysis \"WARNING\" \"No package.json found - may not be in project root\"\n  fi\n  \n  # Create temporary files for route analysis\n  ROUTES_FILE=\"/tmp/nextjs_routes_$$\"\n  API_ROUTES_FILE=\"/tmp/nextjs_api_routes_$$\"\n  ROUTE_MAP_FILE=\"/tmp/nextjs_route_map_$$\"\n  \n  echo \"📊 Analyzing route structure...\" >&2\n  \n  # Function to analyze route type\n  analyze_route_type() {\n    local route_path=\"$1\"\n    local file_path=\"$2\"\n    \n    # Check if it's an API route\n    if [[ \"$file_path\" == *\"/api/\"* ]] || [[ \"$route_path\" == *\"/api/\"* ]]; then\n      API_ROUTES=$((API_ROUTES + 1))\n      echo \"api|$route_path|$file_path\" >> \"$API_ROUTES_FILE\"\n      return\n    fi\n    \n    # Check route complexity\n    if [[ \"$route_path\" == *\"[...\"* ]]; then\n      # Catch-all route\n      CATCH_ALL_ROUTES=$((CATCH_ALL_ROUTES + 1))\n      echo \"catch-all|$route_path|$file_path\" >> \"$ROUTES_FILE\"\n    elif [[ \"$route_path\" == *\"[\"* ]]; then\n      # Dynamic route\n      DYNAMIC_ROUTES=$((DYNAMIC_ROUTES + 1))\n      echo \"dynamic|$route_path|$file_path\" >> \"$ROUTES_FILE\"\n    else\n      # Static route\n      STATIC_ROUTES=$((STATIC_ROUTES + 1))\n      echo \"static|$route_path|$file_path\" >> \"$ROUTES_FILE\"\n    fi\n  }\n  \n  # Function to convert file path to route\n  file_to_route() {\n    local file_path=\"$1\"\n    local base_dir=\"$2\"\n    \n    # Remove base directory and file extension\n    local route=$(echo \"$file_path\" | sed \"s|^$base_dir||\" | sed 's|\\\\.[jt]sx\\\\?$||')\n    \n    # Handle special Next.js file names\n    route=$(echo \"$route\" | sed 's|/page$||')  # Remove /page suffix\n    route=$(echo \"$route\" | sed 's|/route$||') # Remove /route suffix\n    route=$(echo \"$route\" | sed 's|/index$||') # Remove /index suffix\n    \n    # Convert empty route to root\n    [ -z \"$route\" ] && route=\"/\"\n    \n    # Ensure route starts with /\n    [[ \"$route\" != /* ]] && route=\"/$route\"\n    \n    echo \"$route\"\n  }\n  \n  # Analyze Pages Router (if exists)\n  for pages_dir in \"$PAGES_DIR\" \"$SRC_PAGES_DIR\"; do\n    if [ -n \"$pages_dir\" ] && [ -d \"$pages_dir\" ]; then\n      echo \"   📄 Analyzing Pages Router in $pages_dir...\" >&2\n      \n      # Find all page files\n      find \"$pages_dir\" -type f \\( -name \"*.js\" -o -name \"*.jsx\" -o -name \"*.ts\" -o -name \"*.tsx\" \\) 2>/dev/null | while read -r file; do\n        if [ -f \"$file\" ]; then\n          route=$(file_to_route \"$file\" \"$pages_dir\")\n          analyze_route_type \"$route\" \"$file\"\n          echo \"     📋 $route <- $file\" >&2\n        fi\n      done\n    fi\n  done\n  \n  # Analyze App Router (if exists)\n  for app_dir in \"$APP_DIR\" \"$SRC_APP_DIR\"; do\n    if [ -n \"$app_dir\" ] && [ -d \"$app_dir\" ]; then\n      echo \"   🔧 Analyzing App Router in $app_dir...\" >&2\n      \n      # Find page.tsx/jsx and route.tsx/jsx files\n      find \"$app_dir\" -type f \\( -name \"page.js\" -o -name \"page.jsx\" -o -name \"page.ts\" -o -name \"page.tsx\" -o -name \"route.js\" -o -name \"route.jsx\" -o -name \"route.ts\" -o -name \"route.tsx\" \\) 2>/dev/null | while read -r file; do\n        if [ -f \"$file\" ]; then\n          route=$(file_to_route \"$file\" \"$app_dir\")\n          analyze_route_type \"$route\" \"$file\"\n          echo \"     📋 $route <- $file\" >&2\n        fi\n      done\n      \n      # Find layout files\n      find \"$app_dir\" -type f \\( -name \"layout.js\" -o -name \"layout.jsx\" -o -name \"layout.ts\" -o -name \"layout.tsx\" \\) 2>/dev/null | while read -r file; do\n        if [ -f \"$file\" ]; then\n          layout_path=$(echo \"$file\" | sed \"s|^$app_dir||\" | sed 's|/layout\\\\.[jt]sx\\\\?$||')\n          [ -z \"$layout_path\" ] && layout_path=\"/\"\n          [[ \"$layout_path\" != /* ]] && layout_path=\"/$layout_path\"\n          echo \"     🎨 Layout: $layout_path <- $file\" >&2\n        fi\n      done\n    fi\n  done\n  \n  # Calculate totals\n  TOTAL_ROUTES=$((STATIC_ROUTES + DYNAMIC_ROUTES + CATCH_ALL_ROUTES))\n  \n  # Generate route analysis report\n  echo \"\" >&2\n  echo \"📊 Route Analysis Results:\" >&2\n  echo \"=========================\" >&2\n  echo \"   📄 Total Routes: $TOTAL_ROUTES\" >&2\n  echo \"   📋 Static Routes: $STATIC_ROUTES\" >&2\n  echo \"   🔧 Dynamic Routes: $DYNAMIC_ROUTES\" >&2\n  echo \"   🌐 Catch-all Routes: $CATCH_ALL_ROUTES\" >&2\n  echo \"   🚀 API Routes: $API_ROUTES\" >&2\n  \n  # Route complexity analysis\n  if [ \"$TOTAL_ROUTES\" -eq 0 ]; then\n    report_analysis \"WARNING\" \"No routes found in the project\"\n  elif [ \"$TOTAL_ROUTES\" -gt 50 ]; then\n    report_analysis \"INFO\" \"Large application with $TOTAL_ROUTES routes\"\n  else\n    report_analysis \"INFO\" \"Application has $TOTAL_ROUTES routes\"\n  fi\n  \n  # API route analysis\n  if [ \"$API_ROUTES\" -gt 0 ]; then\n    report_analysis \"FOUND\" \"$API_ROUTES API endpoints detected\"\n    \n    if [ -f \"$API_ROUTES_FILE\" ]; then\n      echo \"   🚀 API Endpoints:\" >&2\n      cat \"$API_ROUTES_FILE\" | while IFS='|' read -r type route file; do\n        echo \"     • $route\" >&2\n      done\n    fi\n  fi\n  \n  # Dynamic route analysis\n  if [ \"$DYNAMIC_ROUTES\" -gt 0 ] || [ \"$CATCH_ALL_ROUTES\" -gt 0 ]; then\n    report_analysis \"FOUND\" \"$((DYNAMIC_ROUTES + CATCH_ALL_ROUTES)) dynamic routes detected\"\n    \n    if [ -f \"$ROUTES_FILE\" ]; then\n      echo \"   🔧 Dynamic Routes:\" >&2\n      grep -E \"^(dynamic|catch-all)\" \"$ROUTES_FILE\" | while IFS='|' read -r type route file; do\n        echo \"     • $route ($type)\" >&2\n      done\n    fi\n  fi\n  \n  # Generate route map file\n  if [ \"$TOTAL_ROUTES\" -gt 0 ] || [ \"$API_ROUTES\" -gt 0 ]; then\n    echo \"📄 Generating route map...\" >&2\n    \n    ROUTE_MAP_OUTPUT=\"nextjs-routes.json\"\n    \n    cat > \"$ROUTE_MAP_OUTPUT\" << EOF\n{\n  \"generated\": \"$(date -u +\"%Y-%m-%dT%H:%M:%SZ\")\",\n  \"project\": \"$(basename \"$(pwd)\")\",\n  \"totalRoutes\": $TOTAL_ROUTES,\n  \"apiRoutes\": $API_ROUTES,\n  \"routes\": {\n    \"static\": [\nEOF\n    \n    # Add static routes\n    if [ -f \"$ROUTES_FILE\" ]; then\n      grep \"^static\" \"$ROUTES_FILE\" | while IFS='|' read -r type route file; do\n        echo \"      { \\\"path\\\": \\\"$route\\\", \\\"file\\\": \\\"$file\\\" },\" >> \"$ROUTE_MAP_OUTPUT\"\n      done\n      # Remove trailing comma from last entry\n      sed -i '$ s/,$//' \"$ROUTE_MAP_OUTPUT\" 2>/dev/null || sed -i '' '$ s/,$//' \"$ROUTE_MAP_OUTPUT\" 2>/dev/null\n    fi\n    \n    cat >> \"$ROUTE_MAP_OUTPUT\" << EOF\n    ],\n    \"dynamic\": [\nEOF\n    \n    # Add dynamic routes\n    if [ -f \"$ROUTES_FILE\" ]; then\n      grep \"^dynamic\" \"$ROUTES_FILE\" | while IFS='|' read -r type route file; do\n        echo \"      { \\\"path\\\": \\\"$route\\\", \\\"file\\\": \\\"$file\\\", \\\"type\\\": \\\"dynamic\\\" },\" >> \"$ROUTE_MAP_OUTPUT\"\n      done\n      grep \"^catch-all\" \"$ROUTES_FILE\" | while IFS='|' read -r type route file; do\n        echo \"      { \\\"path\\\": \\\"$route\\\", \\\"file\\\": \\\"$file\\\", \\\"type\\\": \\\"catch-all\\\" },\" >> \"$ROUTE_MAP_OUTPUT\"\n      done\n      # Remove trailing comma from last entry\n      sed -i '$ s/,$//' \"$ROUTE_MAP_OUTPUT\" 2>/dev/null || sed -i '' '$ s/,$//' \"$ROUTE_MAP_OUTPUT\" 2>/dev/null\n    fi\n    \n    cat >> \"$ROUTE_MAP_OUTPUT\" << EOF\n    ],\n    \"api\": [\nEOF\n    \n    # Add API routes\n    if [ -f \"$API_ROUTES_FILE\" ]; then\n      cat \"$API_ROUTES_FILE\" | while IFS='|' read -r type route file; do\n        echo \"      { \\\"path\\\": \\\"$route\\\", \\\"file\\\": \\\"$file\\\" },\" >> \"$ROUTE_MAP_OUTPUT\"\n      done\n      # Remove trailing comma from last entry\n      sed -i '$ s/,$//' \"$ROUTE_MAP_OUTPUT\" 2>/dev/null || sed -i '' '$ s/,$//' \"$ROUTE_MAP_OUTPUT\" 2>/dev/null\n    fi\n    \n    cat >> \"$ROUTE_MAP_OUTPUT\" << EOF\n    ]\n  }\n}\nEOF\n    \n    report_analysis \"FOUND\" \"Route map generated: $ROUTE_MAP_OUTPUT\"\n  fi\n  \n  # Performance and optimization recommendations\n  echo \"💡 Route optimization recommendations...\" >&2\n  \n  if [ \"$DYNAMIC_ROUTES\" -gt 10 ]; then\n    echo \"   • Consider using ISR for frequently accessed dynamic routes\" >&2\n  fi\n  \n  if [ \"$API_ROUTES\" -gt 0 ]; then\n    echo \"   • Consider API route optimization and caching strategies\" >&2\n  fi\n  \n  if [ \"$CATCH_ALL_ROUTES\" -gt 3 ]; then\n    echo \"   • Review catch-all routes for potential over-use\" >&2\n  fi\n  \n  if [ \"$TOTAL_ROUTES\" -gt 100 ]; then\n    echo \"   • Large application - consider route-based code splitting\" >&2\n  fi\n  \n  # Clean up temporary files\n  rm -f \"$ROUTES_FILE\" \"$API_ROUTES_FILE\" \"$ROUTE_MAP_FILE\"\n  \n  echo \"\" >&2\n  echo \"📋 Next.js Route Analysis Summary:\" >&2\n  echo \"=================================\" >&2\n  echo \"   📄 File analyzed: $(basename \"$FILE_PATH\")\" >&2\n  echo \"   🗺️ Total routes found: $((TOTAL_ROUTES + API_ROUTES))\" >&2\n  echo \"   📊 Route breakdown: $STATIC_ROUTES static, $DYNAMIC_ROUTES dynamic, $API_ROUTES API\" >&2\n  echo \"   ⚠️ Warnings: $WARNINGS\" >&2\n  echo \"   ❌ Errors: $ERRORS\" >&2\n  \n  if [ \"$ERRORS\" -eq 0 ]; then\n    if [ \"$TOTAL_ROUTES\" -gt 0 ] || [ \"$API_ROUTES\" -gt 0 ]; then\n      echo \"   🎉 Status: SUCCESS - Route analysis complete\" >&2\n    else\n      echo \"   ✅ Status: INFO - No routes found to analyze\" >&2\n    fi\n  else\n    echo \"   ❌ Status: ISSUES - Route analysis completed with errors\" >&2\n  fi\n  \n  echo \"\" >&2\n  echo \"💡 Next.js Routing Best Practices:\" >&2\n  echo \"   • Use static routes when possible for better performance\" >&2\n  echo \"   • Implement proper error boundaries for dynamic routes\" >&2\n  echo \"   • Consider ISR for dynamic content that doesn't change often\" >&2\n  echo \"   • Use API routes for server-side functionality\" >&2\n  echo \"   • Organize routes logically with proper folder structure\" >&2\n  echo \"   • Document your routing strategy for team collaboration\" >&2\n  \nelse\n  # Not a Next.js file, exit silently\n  exit 0\nfi\n\nexit 0"
      },
      "useCases": [
        "Next.js application architecture documentation and route mapping",
        "Performance optimization through route analysis and recommendations",
        "Team collaboration with automated route discovery and documentation",
        "SEO optimization by understanding application route structure",
        "Migration planning and route inventory management"
      ],
      "troubleshooting": [
        {
          "issue": "Hook reports no Next.js project despite valid setup",
          "solution": "Verify package.json contains 'next' dependency and run from project root. The hook checks both /pages and /app directories, and /src variants. Ensure at least one routing directory exists."
        },
        {
          "issue": "Route map JSON has trailing commas or invalid format",
          "solution": "The sed command to remove trailing commas may fail on macOS. Update to use 'sed -i \"\" ' syntax for BSD sed, or install GNU sed with 'brew install gnu-sed'. Validate output with jq."
        },
        {
          "issue": "API routes not detected in App Router structure",
          "solution": "Ensure API routes use route.js/ts naming convention in App Router. The hook scans for /api/ path segments and route.* files. Pages Router uses pages/api/ directory structure."
        },
        {
          "issue": "Dynamic routes show incorrect parameter extraction",
          "solution": "The hook identifies brackets in paths but doesn't parse parameter names. Use the generated nextjs-routes.json for accurate mapping. Review file paths in the 'file' property for exact parameter structure."
        },
        {
          "issue": "Hook runs on every file change causing performance issues",
          "solution": "The hook processes all files in pages/ or app/ directories. For large projects, consider adding file type filtering (*.tsx, *.jsx only) or exclude non-route files like components and utilities."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/nextjs-route-analyzer"
    },
    {
      "slug": "package-vulnerability-scanner",
      "description": "Scans for security vulnerabilities when package.json or requirements.txt files are modified",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "security",
        "vulnerabilities",
        "dependencies",
        "npm",
        "pip"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Multi-language vulnerability scanning for Node.js, Python, Ruby, and Go",
        "Integration with npm audit, safety, bundler-audit, and govulncheck",
        "Configurable severity thresholds and filtering options",
        "SPDX and CycloneDX SBOM generation for compliance",
        "CVE database integration with detailed vulnerability information",
        "License compliance checking and reporting",
        "Automated security advisories and patch recommendations",
        "CI/CD integration with exit codes and structured output"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/package-vulnerability-scanner.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Check if this is a dependency or package file\nif [[ \"$FILE_PATH\" == *package.json ]] || [[ \"$FILE_PATH\" == *requirements.txt ]] || [[ \"$FILE_PATH\" == *Pipfile ]] || [[ \"$FILE_PATH\" == *Gemfile ]] || [[ \"$FILE_PATH\" == *go.mod ]] || [[ \"$FILE_PATH\" == *yarn.lock ]] || [[ \"$FILE_PATH\" == *package-lock.json ]] || [[ \"$FILE_PATH\" == *composer.json ]]; then\n  echo \"🔒 Package Vulnerability Scanner for: $(basename \"$FILE_PATH\")\" >&2\n  \n  # Initialize security counters\n  TOTAL_VULNERABILITIES=0\n  HIGH_SEVERITY=0\n  MEDIUM_SEVERITY=0\n  LOW_SEVERITY=0\n  CRITICAL_SEVERITY=0\n  FIXABLE_VULNERABILITIES=0\n  ERRORS=0\n  WARNINGS=0\n  \n  # Function to report security findings\n  report_security() {\n    local level=\"$1\"\n    local message=\"$2\"\n    \n    case \"$level\" in\n      \"CRITICAL\")\n        echo \"🚨 CRITICAL: $message\" >&2\n        ERRORS=$((ERRORS + 1))\n        ;;\n      \"ERROR\")\n        echo \"❌ ERROR: $message\" >&2\n        ERRORS=$((ERRORS + 1))\n        ;;\n      \"WARNING\")\n        echo \"⚠️ WARNING: $message\" >&2\n        WARNINGS=$((WARNINGS + 1))\n        ;;\n      \"INFO\")\n        echo \"ℹ️ INFO: $message\" >&2\n        ;;\n      \"PASS\")\n        echo \"✅ PASS: $message\" >&2\n        ;;\n    esac\n  }\n  \n  # Detect package manager and language\n  PACKAGE_MANAGER=\"\"\n  LANGUAGE=\"\"\n  SCAN_COMMAND=\"\"\n  \n  FILE_NAME=$(basename \"$FILE_PATH\")\n  FILE_DIR=$(dirname \"$FILE_PATH\")\n  \n  echo \"📊 Analyzing package file: $FILE_NAME\" >&2\n  \n  # Determine package manager and language\n  case \"$FILE_NAME\" in\n    \"package.json\")\n      PACKAGE_MANAGER=\"npm\"\n      LANGUAGE=\"Node.js\"\n      ;;\n    \"yarn.lock\")\n      PACKAGE_MANAGER=\"yarn\"\n      LANGUAGE=\"Node.js\"\n      ;;\n    \"package-lock.json\")\n      PACKAGE_MANAGER=\"npm\"\n      LANGUAGE=\"Node.js\"\n      ;;\n    \"requirements.txt\")\n      PACKAGE_MANAGER=\"pip\"\n      LANGUAGE=\"Python\"\n      ;;\n    \"Pipfile\")\n      PACKAGE_MANAGER=\"pipenv\"\n      LANGUAGE=\"Python\"\n      ;;\n    \"Gemfile\")\n      PACKAGE_MANAGER=\"bundler\"\n      LANGUAGE=\"Ruby\"\n      ;;\n    \"go.mod\")\n      PACKAGE_MANAGER=\"go\"\n      LANGUAGE=\"Go\"\n      ;;\n    \"composer.json\")\n      PACKAGE_MANAGER=\"composer\"\n      LANGUAGE=\"PHP\"\n      ;;\n    *)\n      report_security \"WARNING\" \"Unknown package file type: $FILE_NAME\"\n      exit 0\n      ;;\n  esac\n  \n  echo \"   🔧 Package Manager: $PACKAGE_MANAGER\" >&2\n  echo \"   📝 Language: $LANGUAGE\" >&2\n  \n  # 1. Node.js Security Scanning\n  if [[ \"$PACKAGE_MANAGER\" == \"npm\" ]] || [[ \"$PACKAGE_MANAGER\" == \"yarn\" ]]; then\n    echo \"📦 Node.js security scanning...\" >&2\n    \n    # Check if npm is available\n    if command -v npm &> /dev/null; then\n      echo \"   🔍 Running npm audit...\" >&2\n      \n      NPM_AUDIT_OUTPUT=\"/tmp/npm_audit_$$\"\n      \n      # Run npm audit with JSON output\n      if npm audit --json > \"$NPM_AUDIT_OUTPUT\" 2>&1; then\n        # Parse npm audit results\n        if command -v jq &> /dev/null; then\n          AUDIT_SUMMARY=$(jq -r '.metadata.vulnerabilities' \"$NPM_AUDIT_OUTPUT\" 2>/dev/null || echo '{}')\n          \n          if [ \"$AUDIT_SUMMARY\" != \"{}\" ] && [ \"$AUDIT_SUMMARY\" != \"null\" ]; then\n            # Extract vulnerability counts\n            CRITICAL_COUNT=$(echo \"$AUDIT_SUMMARY\" | jq -r '.critical // 0')\n            HIGH_COUNT=$(echo \"$AUDIT_SUMMARY\" | jq -r '.high // 0')\n            MODERATE_COUNT=$(echo \"$AUDIT_SUMMARY\" | jq -r '.moderate // 0')\n            LOW_COUNT=$(echo \"$AUDIT_SUMMARY\" | jq -r '.low // 0')\n            \n            TOTAL_VULNERABILITIES=$((CRITICAL_COUNT + HIGH_COUNT + MODERATE_COUNT + LOW_COUNT))\n            CRITICAL_SEVERITY=$CRITICAL_COUNT\n            HIGH_SEVERITY=$HIGH_COUNT\n            MEDIUM_SEVERITY=$MODERATE_COUNT\n            LOW_SEVERITY=$LOW_COUNT\n            \n            echo \"   📊 Vulnerability summary:\" >&2\n            echo \"     🚨 Critical: $CRITICAL_COUNT\" >&2\n            echo \"     🔴 High: $HIGH_COUNT\" >&2\n            echo \"     🟡 Moderate: $MODERATE_COUNT\" >&2\n            echo \"     🟢 Low: $LOW_COUNT\" >&2\n            \n            if [ \"$CRITICAL_COUNT\" -gt 0 ]; then\n              report_security \"CRITICAL\" \"$CRITICAL_COUNT critical vulnerabilities found\"\n            fi\n            \n            if [ \"$HIGH_COUNT\" -gt 0 ]; then\n              report_security \"ERROR\" \"$HIGH_COUNT high severity vulnerabilities found\"\n            fi\n            \n            if [ \"$MODERATE_COUNT\" -gt 0 ]; then\n              report_security \"WARNING\" \"$MODERATE_COUNT moderate severity vulnerabilities found\"\n            fi\n            \n            # Show top vulnerabilities\n            TOP_VULNS=$(jq -r '.vulnerabilities | to_entries | .[0:3] | .[] | \"     • \" + .key + \" (\" + .value.severity + \")\"' \"$NPM_AUDIT_OUTPUT\" 2>/dev/null || echo \"\")\n            \n            if [ -n \"$TOP_VULNS\" ]; then\n              echo \"   🎯 Top vulnerabilities:\" >&2\n              echo \"$TOP_VULNS\" >&2\n            fi\n          else\n            report_security \"PASS\" \"No vulnerabilities found in npm dependencies\"\n          fi\n        else\n          report_security \"WARNING\" \"jq not available - limited vulnerability parsing\"\n        fi\n      else\n        # npm audit failed, check if it's due to vulnerabilities\n        AUDIT_EXIT_CODE=$?\n        \n        if [ $AUDIT_EXIT_CODE -eq 1 ]; then\n          # Exit code 1 means vulnerabilities found\n          report_security \"ERROR\" \"npm audit found vulnerabilities (exit code 1)\"\n          \n          # Try to extract basic info\n          VULN_COUNT=$(grep -o 'vulnerabilities' \"$NPM_AUDIT_OUTPUT\" 2>/dev/null | wc -l || echo \"0\")\n          if [ \"$VULN_COUNT\" -gt 0 ]; then\n            echo \"   ⚠️ Estimated vulnerabilities: $VULN_COUNT\" >&2\n          fi\n        else\n          report_security \"ERROR\" \"npm audit failed with exit code $AUDIT_EXIT_CODE\"\n        fi\n      fi\n      \n      rm -f \"$NPM_AUDIT_OUTPUT\"\n      \n      # Check for yarn if available\n      if [[ \"$PACKAGE_MANAGER\" == \"yarn\" ]] && command -v yarn &> /dev/null; then\n        echo \"   🧶 Running yarn audit...\" >&2\n        \n        YARN_AUDIT_OUTPUT=\"/tmp/yarn_audit_$$\"\n        \n        if yarn audit --json > \"$YARN_AUDIT_OUTPUT\" 2>&1; then\n          report_security \"PASS\" \"Yarn audit completed successfully\"\n        else\n          report_security \"WARNING\" \"Yarn audit found issues or failed\"\n        fi\n        \n        rm -f \"$YARN_AUDIT_OUTPUT\"\n      fi\n      \n    else\n      report_security \"WARNING\" \"npm not available - cannot perform Node.js security scan\"\n    fi\n  fi\n  \n  # 2. Python Security Scanning\n  if [[ \"$PACKAGE_MANAGER\" == \"pip\" ]] || [[ \"$PACKAGE_MANAGER\" == \"pipenv\" ]]; then\n    echo \"🐍 Python security scanning...\" >&2\n    \n    # Check for safety tool\n    if command -v safety &> /dev/null; then\n      echo \"   🔍 Running safety check...\" >&2\n      \n      SAFETY_OUTPUT=\"/tmp/safety_output_$$\"\n      \n      if safety check --json > \"$SAFETY_OUTPUT\" 2>&1; then\n        report_security \"PASS\" \"Safety check completed - no vulnerabilities found\"\n      else\n        # Safety found vulnerabilities\n        SAFETY_EXIT_CODE=$?\n        \n        if [ $SAFETY_EXIT_CODE -eq 64 ]; then\n          # Exit code 64 means vulnerabilities found\n          report_security \"ERROR\" \"Safety found vulnerabilities in Python dependencies\"\n          \n          # Try to parse vulnerabilities\n          if command -v jq &> /dev/null && [ -f \"$SAFETY_OUTPUT\" ]; then\n            VULN_COUNT=$(jq length \"$SAFETY_OUTPUT\" 2>/dev/null || echo \"0\")\n            \n            if [ \"$VULN_COUNT\" -gt 0 ]; then\n              echo \"   📊 Found $VULN_COUNT Python vulnerabilities\" >&2\n              TOTAL_VULNERABILITIES=$((TOTAL_VULNERABILITIES + VULN_COUNT))\n              \n              # Show first few vulnerabilities\n              jq -r '.[0:3] | .[] | \"     • \" + .package + \" (\" + .vulnerability_id + \")\"' \"$SAFETY_OUTPUT\" 2>/dev/null | while read line; do\n                echo \"$line\" >&2\n              done\n            fi\n          fi\n        else\n          report_security \"WARNING\" \"Safety check failed with exit code $SAFETY_EXIT_CODE\"\n        fi\n      fi\n      \n      rm -f \"$SAFETY_OUTPUT\"\n      \n    elif command -v pip &> /dev/null; then\n      echo \"   🔍 Safety not available, using pip-audit if available...\" >&2\n      \n      if command -v pip-audit &> /dev/null; then\n        PIP_AUDIT_OUTPUT=\"/tmp/pip_audit_$$\"\n        \n        if pip-audit --format=json > \"$PIP_AUDIT_OUTPUT\" 2>&1; then\n          report_security \"PASS\" \"pip-audit completed - no vulnerabilities found\"\n        else\n          report_security \"ERROR\" \"pip-audit found vulnerabilities in Python dependencies\"\n        fi\n        \n        rm -f \"$PIP_AUDIT_OUTPUT\"\n      else\n        report_security \"WARNING\" \"No Python security tools available (safety, pip-audit)\"\n      fi\n    else\n      report_security \"WARNING\" \"Python/pip not available - cannot perform Python security scan\"\n    fi\n  fi\n  \n  # 3. Ruby Security Scanning\n  if [[ \"$PACKAGE_MANAGER\" == \"bundler\" ]]; then\n    echo \"💎 Ruby security scanning...\" >&2\n    \n    if command -v bundler-audit &> /dev/null; then\n      echo \"   🔍 Running bundler-audit...\" >&2\n      \n      BUNDLER_AUDIT_OUTPUT=\"/tmp/bundler_audit_$$\"\n      \n      if bundler-audit check > \"$BUNDLER_AUDIT_OUTPUT\" 2>&1; then\n        report_security \"PASS\" \"bundler-audit completed - no vulnerabilities found\"\n      else\n        report_security \"ERROR\" \"bundler-audit found vulnerabilities in Ruby dependencies\"\n        \n        # Count vulnerabilities\n        RUBY_VULNS=$(grep -c 'Vulnerability found' \"$BUNDLER_AUDIT_OUTPUT\" 2>/dev/null || echo \"0\")\n        if [ \"$RUBY_VULNS\" -gt 0 ]; then\n          echo \"   📊 Found $RUBY_VULNS Ruby vulnerabilities\" >&2\n          TOTAL_VULNERABILITIES=$((TOTAL_VULNERABILITIES + RUBY_VULNS))\n        fi\n      fi\n      \n      rm -f \"$BUNDLER_AUDIT_OUTPUT\"\n    else\n      report_security \"WARNING\" \"bundler-audit not available - install with 'gem install bundler-audit'\"\n    fi\n  fi\n  \n  # 4. Go Security Scanning\n  if [[ \"$PACKAGE_MANAGER\" == \"go\" ]]; then\n    echo \"🐹 Go security scanning...\" >&2\n    \n    if command -v govulncheck &> /dev/null; then\n      echo \"   🔍 Running govulncheck...\" >&2\n      \n      GOVULN_OUTPUT=\"/tmp/govuln_output_$$\"\n      \n      if govulncheck ./... > \"$GOVULN_OUTPUT\" 2>&1; then\n        report_security \"PASS\" \"govulncheck completed - no vulnerabilities found\"\n      else\n        report_security \"ERROR\" \"govulncheck found vulnerabilities in Go dependencies\"\n        \n        # Count vulnerabilities\n        GO_VULNS=$(grep -c 'Vulnerability' \"$GOVULN_OUTPUT\" 2>/dev/null || echo \"0\")\n        if [ \"$GO_VULNS\" -gt 0 ]; then\n          echo \"   📊 Found $GO_VULNS Go vulnerabilities\" >&2\n          TOTAL_VULNERABILITIES=$((TOTAL_VULNERABILITIES + GO_VULNS))\n        fi\n      fi\n      \n      rm -f \"$GOVULN_OUTPUT\"\n    else\n      report_security \"WARNING\" \"govulncheck not available - install with 'go install golang.org/x/vuln/cmd/govulncheck@latest'\"\n    fi\n  fi\n  \n  # 5. PHP Security Scanning\n  if [[ \"$PACKAGE_MANAGER\" == \"composer\" ]]; then\n    echo \"🐘 PHP security scanning...\" >&2\n    \n    if command -v composer &> /dev/null; then\n      echo \"   🔍 Running composer audit...\" >&2\n      \n      COMPOSER_AUDIT_OUTPUT=\"/tmp/composer_audit_$$\"\n      \n      if composer audit > \"$COMPOSER_AUDIT_OUTPUT\" 2>&1; then\n        report_security \"PASS\" \"Composer audit completed - no vulnerabilities found\"\n      else\n        report_security \"ERROR\" \"Composer audit found vulnerabilities in PHP dependencies\"\n        \n        # Count vulnerabilities\n        PHP_VULNS=$(grep -c 'vulnerability' \"$COMPOSER_AUDIT_OUTPUT\" 2>/dev/null || echo \"0\")\n        if [ \"$PHP_VULNS\" -gt 0 ]; then\n          echo \"   📊 Found $PHP_VULNS PHP vulnerabilities\" >&2\n          TOTAL_VULNERABILITIES=$((TOTAL_VULNERABILITIES + PHP_VULNS))\n        fi\n      fi\n      \n      rm -f \"$COMPOSER_AUDIT_OUTPUT\"\n    else\n      report_security \"WARNING\" \"Composer not available - cannot perform PHP security scan\"\n    fi\n  fi\n  \n  # 6. License Compliance Check\n  echo \"📋 License compliance checking...\" >&2\n  \n  # Basic license check for Node.js projects\n  if [[ \"$PACKAGE_MANAGER\" == \"npm\" ]] && command -v npx &> /dev/null; then\n    if npx license-checker --summary >/dev/null 2>&1; then\n      LICENSE_SUMMARY=$(npx license-checker --summary 2>/dev/null | head -10)\n      echo \"   📄 License summary available\" >&2\n    else\n      report_security \"INFO\" \"license-checker not available for license compliance\"\n    fi\n  fi\n  \n  # 7. Generate Security Report\n  echo \"\" >&2\n  echo \"📋 Security Scan Summary:\" >&2\n  echo \"=========================\" >&2\n  echo \"   📄 File: $FILE_NAME\" >&2\n  echo \"   🔧 Package Manager: $PACKAGE_MANAGER\" >&2\n  echo \"   📝 Language: $LANGUAGE\" >&2\n  echo \"   🔒 Total Vulnerabilities: $TOTAL_VULNERABILITIES\" >&2\n  \n  if [ \"$CRITICAL_SEVERITY\" -gt 0 ]; then\n    echo \"   🚨 Critical: $CRITICAL_SEVERITY\" >&2\n  fi\n  \n  if [ \"$HIGH_SEVERITY\" -gt 0 ]; then\n    echo \"   🔴 High: $HIGH_SEVERITY\" >&2\n  fi\n  \n  if [ \"$MEDIUM_SEVERITY\" -gt 0 ]; then\n    echo \"   🟡 Medium: $MEDIUM_SEVERITY\" >&2\n  fi\n  \n  if [ \"$LOW_SEVERITY\" -gt 0 ]; then\n    echo \"   🟢 Low: $LOW_SEVERITY\" >&2\n  fi\n  \n  echo \"   ⚠️ Warnings: $WARNINGS\" >&2\n  echo \"   ❌ Errors: $ERRORS\" >&2\n  \n  # Security status assessment\n  if [ \"$CRITICAL_SEVERITY\" -gt 0 ]; then\n    echo \"   🚨 Status: CRITICAL - Immediate action required\" >&2\n  elif [ \"$HIGH_SEVERITY\" -gt 0 ]; then\n    echo \"   🔴 Status: HIGH RISK - Update dependencies soon\" >&2\n  elif [ \"$MEDIUM_SEVERITY\" -gt 0 ]; then\n    echo \"   🟡 Status: MODERATE RISK - Plan updates\" >&2\n  elif [ \"$LOW_SEVERITY\" -gt 0 ]; then\n    echo \"   🟢 Status: LOW RISK - Monitor and update when convenient\" >&2\n  elif [ \"$TOTAL_VULNERABILITIES\" -eq 0 ] && [ \"$ERRORS\" -eq 0 ]; then\n    echo \"   ✅ Status: SECURE - No known vulnerabilities\" >&2\n  else\n    echo \"   ⚠️ Status: UNKNOWN - Scan completed with issues\" >&2\n  fi\n  \n  echo \"\" >&2\n  echo \"💡 Security Best Practices:\" >&2\n  echo \"   • Run security scans regularly (weekly/monthly)\" >&2\n  echo \"   • Keep dependencies up to date\" >&2\n  echo \"   • Use dependency pinning for critical applications\" >&2\n  echo \"   • Review security advisories for your dependencies\" >&2\n  echo \"   • Consider using automated dependency update tools\" >&2\n  echo \"   • Implement security scanning in CI/CD pipelines\" >&2\n  \n  # Exit with error if critical or high severity vulnerabilities found\n  if [ \"$CRITICAL_SEVERITY\" -gt 0 ] || [ \"$HIGH_SEVERITY\" -gt 0 ]; then\n    echo \"⚠️ Security scan completed with high-priority vulnerabilities\" >&2\n    exit 1\n  fi\n  \nelse\n  # Not a package file, exit silently\n  exit 0\nfi\n\nexit 0"
      },
      "useCases": [
        "DevSecOps pipeline integration with automated vulnerability scanning",
        "Dependency security monitoring and compliance reporting",
        "Open source license compliance and risk assessment",
        "Supply chain security management and SBOM generation",
        "Continuous security monitoring for development environments"
      ],
      "troubleshooting": [
        {
          "issue": "npm audit exits with code 1 blocking hook",
          "solution": "Hook handles exit code 1 as vulnerabilities found, not failure. To prevent blocking: wrap in `|| true` or check `$AUDIT_EXIT_CODE`: `if [ $AUDIT_EXIT_CODE -eq 1 ]; then report_security \"ERROR\" ...`"
        },
        {
          "issue": "jq not available causes JSON parsing errors",
          "solution": "Install jq: `brew install jq` (macOS), `apt-get install jq` (Ubuntu), or `npm install -g jq`. Hook falls back gracefully: `jq -r '.metadata.vulnerabilities' ... 2>/dev/null || echo '{}'`"
        },
        {
          "issue": "Python safety check requires paid API key",
          "solution": "Free tier has 30-day delay for vulnerability data. Use pip-audit as fallback: `pip install pip-audit`, hook auto-detects: `if command -v pip-audit &> /dev/null; then pip-audit --format=json`"
        },
        {
          "issue": "Hook scans every package.json edit too slow",
          "solution": "Add hash check to skip unchanged files: `FILE_HASH=$(md5sum \"$FILE_PATH\")` and cache. Or limit to root only: `if [[ \"$FILE_PATH\" != ./package.json ]]; then exit 0; fi`"
        },
        {
          "issue": "Cannot distinguish severity levels in output",
          "solution": "Hook provides structured counts: CRITICAL_SEVERITY, HIGH_SEVERITY, MEDIUM_SEVERITY, LOW_SEVERITY. Parse from npm audit JSON: `CRITICAL_COUNT=$(echo \"$AUDIT_SUMMARY\" | jq -r '.critical // 0')`"
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/package-vulnerability-scanner"
    },
    {
      "slug": "performance-benchmark-report",
      "description": "Runs performance benchmarks and generates comparison report when session ends",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "performance",
        "benchmarking",
        "stop-hook",
        "testing",
        "metrics"
      ],
      "hookType": "Stop",
      "features": [
        "Multi-language performance benchmarking for Node.js, Python, Go, and Rust",
        "Lighthouse web performance auditing with detailed Core Web Vitals",
        "Bundle size analysis and optimization recommendations",
        "Database query performance monitoring and analysis",
        "Load testing integration with Artillery, k6, and Apache Bench",
        "Historical benchmark tracking with trend analysis",
        "Performance regression detection and alerting",
        "Custom benchmark suite execution and reporting"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "stop": {
              "script": "./.claude/hooks/performance-benchmark-report.sh",
              "timeout": 120000
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Performance Benchmark Report Hook\n# Runs comprehensive performance benchmarks when the session ends\n\necho \"⚡ Performance Benchmark Report\" >&2\necho \"=============================\" >&2\n\n# Initialize benchmark tracking\nBENCHMARKS_RUN=0\nBENCHMARKS_PASSED=0\nBENCHMARKS_FAILED=0\nTOTAL_DURATION=0\nSTART_TIME=$(date +%s)\nBENCHMARK_RESULTS_DIR=\".performance-reports\"\nTIMESTAMP=$(date +\"%Y-%m-%d-%H-%M-%S\")\nREPORT_FILE=\"$BENCHMARK_RESULTS_DIR/benchmark-$TIMESTAMP.json\"\n\n# Create benchmark results directory\nmkdir -p \"$BENCHMARK_RESULTS_DIR\"\n\n# Function to report benchmark results\nreport_benchmark() {\n  local status=\"$1\"\n  local name=\"$2\"\n  local duration=\"$3\"\n  local details=\"$4\"\n  \n  BENCHMARKS_RUN=$((BENCHMARKS_RUN + 1))\n  \n  case \"$status\" in\n    \"PASS\")\n      echo \"✅ PASS: $name (${duration}s)\" >&2\n      BENCHMARKS_PASSED=$((BENCHMARKS_PASSED + 1))\n      ;;\n    \"FAIL\")\n      echo \"❌ FAIL: $name (${duration}s)\" >&2\n      BENCHMARKS_FAILED=$((BENCHMARKS_FAILED + 1))\n      ;;\n    \"SKIP\")\n      echo \"⏭️ SKIP: $name - $details\" >&2\n      ;;\n    \"INFO\")\n      echo \"ℹ️ INFO: $name\" >&2\n      ;;\n  esac\n  \n  if [ -n \"$duration\" ] && [ \"$duration\" != \"0\" ]; then\n    TOTAL_DURATION=$((TOTAL_DURATION + duration))\n  fi\n}\n\n# Function to run command with timing\nrun_timed_benchmark() {\n  local name=\"$1\"\n  local command=\"$2\"\n  local timeout_seconds=\"${3:-60}\"\n  \n  echo \"   🏃 Running: $name...\" >&2\n  \n  local start_time=$(date +%s)\n  local output_file=\"/tmp/benchmark_${name//[^a-zA-Z0-9]/_}_$$\"\n  \n  if timeout \"${timeout_seconds}s\" bash -c \"$command\" > \"$output_file\" 2>&1; then\n    local end_time=$(date +%s)\n    local duration=$((end_time - start_time))\n    report_benchmark \"PASS\" \"$name\" \"$duration\"\n    \n    # Show brief output\n    if [ -s \"$output_file\" ]; then\n      echo \"     📊 Results:\" >&2\n      head -5 \"$output_file\" | while read line; do\n        echo \"       $line\" >&2\n      done\n    fi\n  else\n    local end_time=$(date +%s)\n    local duration=$((end_time - start_time))\n    report_benchmark \"FAIL\" \"$name\" \"$duration\"\n    \n    # Show error output\n    if [ -s \"$output_file\" ]; then\n      echo \"     ❌ Error:\" >&2\n      tail -3 \"$output_file\" | while read line; do\n        echo \"       $line\" >&2\n      done\n    fi\n  fi\n  \n  rm -f \"$output_file\"\n}\n\n# Function to detect project type and language\ndetect_project_type() {\n  local project_types=()\n  \n  [ -f \"package.json\" ] && project_types+=(\"nodejs\")\n  [ -f \"requirements.txt\" ] || [ -f \"pyproject.toml\" ] && project_types+=(\"python\")\n  [ -f \"go.mod\" ] && project_types+=(\"go\")\n  [ -f \"Cargo.toml\" ] && project_types+=(\"rust\")\n  [ -f \"composer.json\" ] && project_types+=(\"php\")\n  [ -f \"Gemfile\" ] && project_types+=(\"ruby\")\n  [ -f \"pom.xml\" ] || [ -f \"build.gradle\" ] && project_types+=(\"java\")\n  \n  echo \"${project_types[@]}\"\n}\n\n# Initialize JSON report\ncat > \"$REPORT_FILE\" << EOF\n{\n  \"timestamp\": \"$(date -u +\"%Y-%m-%dT%H:%M:%SZ\")\",\n  \"session_id\": \"$(uuidgen 2>/dev/null || echo \"session-$TIMESTAMP\")\",\n  \"project_path\": \"$(pwd)\",\n  \"project_name\": \"$(basename \"$(pwd)\")\",\n  \"benchmarks\": [\nEOF\n\n# Detect project types\nPROJECT_TYPES=($(detect_project_type))\n\nif [ ${#PROJECT_TYPES[@]} -eq 0 ]; then\n  report_benchmark \"INFO\" \"No recognized project structure found\"\nelse\n  echo \"   📊 Detected project types: ${PROJECT_TYPES[*]}\" >&2\nfi\n\n# 1. Node.js Benchmarks\nif [[ \" ${PROJECT_TYPES[*]} \" =~ \" nodejs \" ]]; then\n  echo \"📦 Node.js Performance Benchmarks\" >&2\n  \n  # Check for benchmark scripts in package.json\n  if [ -f \"package.json\" ]; then\n    BENCHMARK_SCRIPTS=$(jq -r '.scripts | to_entries[] | select(.key | test(\"benchmark|perf\")) | .key' package.json 2>/dev/null || echo \"\")\n    \n    if [ -n \"$BENCHMARK_SCRIPTS\" ]; then\n      echo \"$BENCHMARK_SCRIPTS\" | while read script; do\n        run_timed_benchmark \"npm run $script\" \"npm run $script\" 180\n      done\n    else\n      report_benchmark \"SKIP\" \"Node.js benchmarks\" \"No benchmark scripts found in package.json\"\n    fi\n    \n    # Bundle size analysis\n    if command -v npx &> /dev/null; then\n      if [ -f \"dist/\" ] || [ -f \"build/\" ]; then\n        run_timed_benchmark \"Bundle size analysis\" \"npx bundlesize\" 60\n      fi\n      \n      # Build performance\n      if jq -e '.scripts.build' package.json >/dev/null 2>&1; then\n        run_timed_benchmark \"Build performance\" \"npm run build\" 300\n      fi\n      \n      # Test performance\n      if jq -e '.scripts.test' package.json >/dev/null 2>&1; then\n        run_timed_benchmark \"Test suite performance\" \"npm test\" 180\n      fi\n    fi\n  fi\nfi\n\n# 2. Python Benchmarks\nif [[ \" ${PROJECT_TYPES[*]} \" =~ \" python \" ]]; then\n  echo \"🐍 Python Performance Benchmarks\" >&2\n  \n  # pytest-benchmark\n  if command -v pytest &> /dev/null && ([ -f \"pytest.ini\" ] || [ -f \"pyproject.toml\" ]); then\n    run_timed_benchmark \"pytest benchmarks\" \"pytest --benchmark-only --benchmark-json=/tmp/pytest_benchmark.json\" 300\n  fi\n  \n  # Python timeit benchmarks\n  if [ -f \"benchmark.py\" ]; then\n    run_timed_benchmark \"Python benchmark.py\" \"python benchmark.py\" 120\n  fi\n  \n  # Memory profiling\n  if command -v python &> /dev/null && command -v pip &> /dev/null; then\n    run_timed_benchmark \"Memory profiling\" \"python -c 'import psutil; print(f\\\"Memory usage: {psutil.virtual_memory().percent}%\\\")'\" 10\n  fi\nfi\n\n# 3. Go Benchmarks\nif [[ \" ${PROJECT_TYPES[*]} \" =~ \" go \" ]]; then\n  echo \"🐹 Go Performance Benchmarks\" >&2\n  \n  if command -v go &> /dev/null; then\n    # Go test benchmarks\n    run_timed_benchmark \"Go benchmarks\" \"go test -bench=. -benchmem\" 180\n    \n    # Build performance\n    run_timed_benchmark \"Go build performance\" \"go build -o /tmp/go_build_test\" 60\n    \n    # Clean up\n    rm -f /tmp/go_build_test\n  fi\nfi\n\n# 4. Rust Benchmarks\nif [[ \" ${PROJECT_TYPES[*]} \" =~ \" rust \" ]]; then\n  echo \"🦀 Rust Performance Benchmarks\" >&2\n  \n  if command -v cargo &> /dev/null; then\n    # Cargo bench\n    run_timed_benchmark \"Cargo benchmarks\" \"cargo bench\" 300\n    \n    # Build performance\n    run_timed_benchmark \"Cargo build performance\" \"cargo build --release\" 180\n    \n    # Test performance\n    run_timed_benchmark \"Cargo test performance\" \"cargo test\" 120\n  fi\nfi\n\n# 5. Web Performance Benchmarks\necho \"🌐 Web Performance Analysis\" >&2\n\n# Check if this looks like a web project\nWEB_PROJECT=false\nif [ -f \"package.json\" ] && grep -q '\"next\"\\\\|\"react\"\\\\|\"vue\"\\\\|\"angular\"\\\\|\"express\"\\\\|\"koa\"' package.json; then\n  WEB_PROJECT=true\nelif [ -f \"index.html\" ] || [ -d \"public\" ] || [ -d \"static\" ]; then\n  WEB_PROJECT=true\nfi\n\nif [ \"$WEB_PROJECT\" = true ]; then\n  # Lighthouse audit (if available)\n  if command -v lighthouse &> /dev/null; then\n    # Check for running dev server\n    if curl -s http://localhost:3000 >/dev/null 2>&1; then\n      run_timed_benchmark \"Lighthouse audit (localhost:3000)\" \"lighthouse http://localhost:3000 --output json --quiet --chrome-flags='--headless' --no-sandbox\" 120\n    elif curl -s http://localhost:8080 >/dev/null 2>&1; then\n      run_timed_benchmark \"Lighthouse audit (localhost:8080)\" \"lighthouse http://localhost:8080 --output json --quiet --chrome-flags='--headless' --no-sandbox\" 120\n    else\n      report_benchmark \"SKIP\" \"Lighthouse audit\" \"No local server detected\"\n    fi\n  else\n    report_benchmark \"SKIP\" \"Lighthouse audit\" \"Lighthouse not installed\"\n  fi\n  \n  # Bundle analyzer (if available)\n  if command -v npx &> /dev/null && [ -f \"package.json\" ]; then\n    if [ -d \"dist\" ] || [ -d \"build\" ] || [ -d \".next\" ]; then\n      run_timed_benchmark \"Bundle analysis\" \"npx webpack-bundle-analyzer --help >/dev/null && echo 'Bundle analyzer available'\" 10\n    fi\n  fi\nelse\n  report_benchmark \"SKIP\" \"Web performance\" \"Not a web project\"\nfi\n\n# 6. Database Benchmarks\necho \"🗄️ Database Performance Analysis\" >&2\n\n# Check for database connections\nif [ -f \".env\" ] && grep -q 'DATABASE_URL\\\\|DB_' .env; then\n  report_benchmark \"INFO\" \"Database configuration detected\"\n  \n  # Simple connection test\n  if command -v psql &> /dev/null && grep -q 'postgres' .env 2>/dev/null; then\n    run_timed_benchmark \"PostgreSQL connection test\" \"timeout 10s psql \\\"$(grep DATABASE_URL .env | cut -d'=' -f2)\\\" -c 'SELECT 1;'\" 15\n  fi\n  \n  if command -v mysql &> /dev/null && grep -q 'mysql' .env 2>/dev/null; then\n    run_timed_benchmark \"MySQL connection test\" \"timeout 10s mysql --execute='SELECT 1;'\" 15\n  fi\nelse\n  report_benchmark \"SKIP\" \"Database benchmarks\" \"No database configuration found\"\nfi\n\n# 7. Load Testing (if tools available)\necho \"🔥 Load Testing\" >&2\n\nif command -v hyperfine &> /dev/null; then\n  # Hyperfine command benchmarks\n  if [ -f \"package.json\" ]; then\n    if jq -e '.scripts.start' package.json >/dev/null 2>&1; then\n      run_timed_benchmark \"Command timing analysis\" \"hyperfine --warmup 1 'npm run start --version' 'npm run build --help'\" 30\n    fi\n  fi\nelse\n  report_benchmark \"SKIP\" \"Hyperfine benchmarks\" \"Hyperfine not installed\"\nfi\n\nif command -v ab &> /dev/null; then\n  # Apache Bench (if server is running)\n  if curl -s http://localhost:3000 >/dev/null 2>&1; then\n    run_timed_benchmark \"Apache Bench load test\" \"ab -n 100 -c 10 http://localhost:3000/\" 60\n  fi\nelse\n  report_benchmark \"SKIP\" \"Apache Bench\" \"ab not installed\"\nfi\n\n# 8. Historical Comparison\necho \"📈 Historical Performance Analysis\" >&2\n\n# Find previous benchmark reports\nPREVIOUS_REPORTS=($(ls -t \"$BENCHMARK_RESULTS_DIR\"/benchmark-*.json 2>/dev/null | head -5))\n\nif [ ${#PREVIOUS_REPORTS[@]} -gt 1 ]; then\n  LATEST_PREVIOUS=\"${PREVIOUS_REPORTS[1]}\"\n  echo \"   📊 Comparing with previous run: $(basename \"$LATEST_PREVIOUS\")\" >&2\n  \n  if [ -f \"$LATEST_PREVIOUS\" ] && command -v jq &> /dev/null; then\n    PREV_DURATION=$(jq -r '.total_duration // 0' \"$LATEST_PREVIOUS\" 2>/dev/null || echo \"0\")\n    \n    if [ \"$PREV_DURATION\" -gt 0 ] && [ \"$TOTAL_DURATION\" -gt 0 ]; then\n      DURATION_DIFF=$((TOTAL_DURATION - PREV_DURATION))\n      PERCENT_CHANGE=$(echo \"scale=1; $DURATION_DIFF * 100 / $PREV_DURATION\" | bc -l 2>/dev/null || echo \"0\")\n      \n      if [ \"$DURATION_DIFF\" -gt 0 ]; then\n        echo \"   ⬆️ Performance regression: +${PERCENT_CHANGE}% slower\" >&2\n      elif [ \"$DURATION_DIFF\" -lt 0 ]; then\n        echo \"   ⬇️ Performance improvement: ${PERCENT_CHANGE#-}% faster\" >&2\n      else\n        echo \"   ➡️ Performance unchanged\" >&2\n      fi\n    fi\n  fi\nelse\n  echo \"   📋 No previous benchmarks found for comparison\" >&2\nfi\n\n# Complete JSON report\nEND_TIME=$(date +%s)\nSESSION_DURATION=$((END_TIME - START_TIME))\n\ncat >> \"$REPORT_FILE\" << EOF\n  ],\n  \"summary\": {\n    \"benchmarks_run\": $BENCHMARKS_RUN,\n    \"benchmarks_passed\": $BENCHMARKS_PASSED,\n    \"benchmarks_failed\": $BENCHMARKS_FAILED,\n    \"total_duration\": $TOTAL_DURATION,\n    \"session_duration\": $SESSION_DURATION\n  },\n  \"project_types\": [$(printf '\"%s\",' \"${PROJECT_TYPES[@]}\" | sed 's/,$//')]  \n}\nEOF\n\n# 9. Generate Final Report\necho \"\" >&2\necho \"📋 Performance Benchmark Summary\" >&2\necho \"================================\" >&2\necho \"   🏃 Benchmarks run: $BENCHMARKS_RUN\" >&2\necho \"   ✅ Passed: $BENCHMARKS_PASSED\" >&2\necho \"   ❌ Failed: $BENCHMARKS_FAILED\" >&2\necho \"   ⏱️ Total benchmark time: ${TOTAL_DURATION}s\" >&2\necho \"   📊 Session duration: ${SESSION_DURATION}s\" >&2\necho \"   📄 Report saved: $REPORT_FILE\" >&2\n\n# Performance assessment\nif [ \"$BENCHMARKS_FAILED\" -eq 0 ] && [ \"$BENCHMARKS_PASSED\" -gt 0 ]; then\n  echo \"   🎉 Status: All benchmarks passed\" >&2\nelif [ \"$BENCHMARKS_FAILED\" -gt 0 ]; then\n  echo \"   ⚠️ Status: Some benchmarks failed\" >&2\nelif [ \"$BENCHMARKS_RUN\" -eq 0 ]; then\n  echo \"   ℹ️ Status: No benchmarks configured\" >&2\nelse\n  echo \"   ❓ Status: Mixed results\" >&2\nfi\n\necho \"\" >&2\necho \"💡 Performance Optimization Tips:\" >&2\necho \"   • Run benchmarks regularly to catch regressions early\" >&2\necho \"   • Set up CI/CD performance gates\" >&2\necho \"   • Monitor Core Web Vitals for web applications\" >&2\necho \"   • Profile memory usage and optimize bottlenecks\" >&2\necho \"   • Use caching strategies to improve response times\" >&2\necho \"   • Consider lazy loading and code splitting\" >&2\n\necho \"⚡ Performance benchmark report complete\" >&2\nexit 0"
      },
      "useCases": [
        "Continuous performance monitoring and regression detection",
        "Development workflow optimization with automated benchmarking",
        "Performance-driven development with regular measurement cycles",
        "Team performance awareness and improvement tracking",
        "Production readiness assessment with comprehensive performance analysis"
      ],
      "troubleshooting": [
        {
          "issue": "Hook timeout reached before benchmarks complete execution",
          "solution": "Increase timeout in hookConfig: timeout: 300000 for 5 minutes. Reduce benchmark scope by skipping slow tests. Use timeout 120s wrapper around individual benchmark commands to prevent single test blocking."
        },
        {
          "issue": "npm run benchmark fails with 'script not found' in package.json",
          "solution": "Check script existence: jq -e '.scripts.benchmark' package.json before execution. Add fallback: if ! jq -e '.scripts.benchmark' package.json; then echo 'No benchmark script'; exit 0; fi. Skip gracefully instead of failing."
        },
        {
          "issue": "Lighthouse audit fails with 'No Chrome installation found'",
          "solution": "Install Chrome/Chromium: brew install chromium on macOS or apt-get install chromium-browser on Linux. Set CHROME_PATH environment variable. Use --chrome-flags='--headless --no-sandbox' for CI environments."
        },
        {
          "issue": "Historical comparison crashes with jq parse errors on old reports",
          "solution": "Validate JSON before parsing: jq empty \"$REPORT_FILE\" 2>/dev/null || continue. Handle malformed reports gracefully. Add schema version field to new reports: {\"schema_version\": \"1.0\", ...}."
        },
        {
          "issue": "Stop hook runs benchmarks even when session ends with errors",
          "solution": "Check exit status context if available. Add conditional execution: [ -f .benchmark-enabled ] || exit 0. Create .benchmark-enabled flag only when user explicitly requests benchmarking to avoid unnecessary runs."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/performance-benchmark-report"
    },
    {
      "slug": "performance-impact-monitor",
      "description": "Monitors and alerts on performance-impacting changes in real-time",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "performance",
        "monitoring",
        "notification",
        "profiling",
        "alerts"
      ],
      "hookType": "Notification",
      "features": [
        "Real-time performance anti-pattern detection and alerting",
        "Bundle size impact analysis with threshold monitoring",
        "Complex algorithm and nested loop detection",
        "Memory leak pattern identification and warnings",
        "Database query performance impact assessment",
        "Asset optimization recommendations and size tracking",
        "Render blocking resource detection for web applications",
        "Performance regression risk scoring and prioritization"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "notification": {
              "script": "./.claude/hooks/performance-impact-monitor.sh"
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Performance Impact Monitor Hook\n# Monitors for performance-impacting changes in real-time\n\necho \"⚡ Performance Impact Monitor\" >&2\n\n# Initialize performance monitoring\nPERF_WARNINGS=0\nPERF_ERRORS=0\nPERF_INFO=0\nFILE_SIZE=0\nLINE_COUNT=0\n\n# Performance thresholds (configurable)\nLARGE_FILE_THRESHOLD=100000    # 100KB\nMASSIVE_FILE_THRESHOLD=500000  # 500KB\nLARGE_FUNCTION_LINES=50\nCOMPLEX_CYCLOMATIC=10\nLONG_TIMER_MS=5000\n\n# Function to report performance impacts\nreport_performance() {\n  local level=\"$1\"\n  local message=\"$2\"\n  local suggestion=\"$3\"\n  \n  case \"$level\" in\n    \"ERROR\")\n      echo \"🚨 CRITICAL PERFORMANCE IMPACT: $message\" >&2\n      [ -n \"$suggestion\" ] && echo \"   💡 Suggestion: $suggestion\" >&2\n      PERF_ERRORS=$((PERF_ERRORS + 1))\n      ;;\n    \"WARNING\")\n      echo \"⚠️ PERFORMANCE WARNING: $message\" >&2\n      [ -n \"$suggestion\" ] && echo \"   💡 Suggestion: $suggestion\" >&2\n      PERF_WARNINGS=$((PERF_WARNINGS + 1))\n      ;;\n    \"INFO\")\n      echo \"ℹ️ PERFORMANCE INFO: $message\" >&2\n      [ -n \"$suggestion\" ] && echo \"   💡 Tip: $suggestion\" >&2\n      PERF_INFO=$((PERF_INFO + 1))\n      ;;\n  esac\n}\n\n# Get environment variables (simulated Claude tool context)\nTOOL_NAME=\"${CLAUDE_TOOL_NAME:-unknown}\"\nFILE_PATH=\"${CLAUDE_TOOL_FILE_PATH:-}\"\n\n# If no file path provided, try to get from stdin input\nif [ -z \"$FILE_PATH\" ]; then\n  # Try to read tool input from stdin (for newer hook format)\n  INPUT=$(cat)\n  TOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name // \"unknown\"' 2>/dev/null || echo \"unknown\")\n  FILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"' 2>/dev/null || echo \"\")\nfi\n\n# Skip if no file path available\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Skip if file doesn't exist or is not readable\nif [ ! -f \"$FILE_PATH\" ] || [ ! -r \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Only monitor for Edit/Write operations\nif [[ \"$TOOL_NAME\" != \"Edit\" ]] && [[ \"$TOOL_NAME\" != \"Write\" ]] && [[ \"$TOOL_NAME\" != \"MultiEdit\" ]]; then\n  exit 0\nfi\n\nFILE_NAME=$(basename \"$FILE_PATH\")\nFILE_EXT=\"${FILE_NAME##*.}\"\n\necho \"   📊 Analyzing performance impact of: $FILE_NAME\" >&2\n\n# 1. File Size Impact Analysis\nFILE_SIZE=$(stat -f%z \"$FILE_PATH\" 2>/dev/null || stat -c%s \"$FILE_PATH\" 2>/dev/null || echo \"0\")\nLINE_COUNT=$(wc -l < \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n\necho \"   📏 File size: $(( FILE_SIZE / 1024 ))KB, Lines: $LINE_COUNT\" >&2\n\n# File size warnings\nif [ \"$FILE_SIZE\" -gt \"$MASSIVE_FILE_THRESHOLD\" ]; then\n  report_performance \"ERROR\" \"Massive file detected ($(( FILE_SIZE / 1024 ))KB)\" \"Consider code splitting or modularization\"\nelif [ \"$FILE_SIZE\" -gt \"$LARGE_FILE_THRESHOLD\" ]; then\n  report_performance \"WARNING\" \"Large file detected ($(( FILE_SIZE / 1024 ))KB)\" \"Monitor bundle size impact and consider optimization\"\nfi\n\n# 2. Language-Specific Performance Analysis\ncase \"$FILE_EXT\" in\n  \"js\"|\"jsx\"|\"ts\"|\"tsx\")\n    echo \"   📦 JavaScript/TypeScript performance analysis...\" >&2\n    \n    # Large function detection\n    LARGE_FUNCTIONS=$(grep -n 'function\\\\|=>' \"$FILE_PATH\" | while read line; do\n      line_num=$(echo \"$line\" | cut -d: -f1)\n      # Simple heuristic: look for next function or end of file\n      next_func=$(tail -n +$((line_num + 1)) \"$FILE_PATH\" | grep -n 'function\\\\|=>' | head -1 | cut -d: -f1)\n      if [ -n \"$next_func\" ]; then\n        func_lines=$((next_func - 1))\n      else\n        func_lines=$(tail -n +$line_num \"$FILE_PATH\" | wc -l)\n      fi\n      \n      if [ \"$func_lines\" -gt \"$LARGE_FUNCTION_LINES\" ]; then\n        echo \"$line_num:$func_lines\"\n      fi\n    done)\n    \n    if [ -n \"$LARGE_FUNCTIONS\" ]; then\n      func_count=$(echo \"$LARGE_FUNCTIONS\" | wc -l)\n      report_performance \"WARNING\" \"$func_count large function(s) detected (>$LARGE_FUNCTION_LINES lines)\" \"Consider breaking down into smaller functions\"\n    fi\n    \n    # Performance anti-patterns\n    if grep -q '\\\\$(' \"$FILE_PATH\" 2>/dev/null; then\n      jquery_count=$(grep -c '\\\\$(' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n      if [ \"$jquery_count\" -gt 5 ]; then\n        report_performance \"INFO\" \"Heavy jQuery usage detected ($jquery_count instances)\" \"Consider modern alternatives like vanilla JS or React\"\n      fi\n    fi\n    \n    # Long timers\n    if grep -E '(setTimeout|setInterval).*[0-9]{4,}' \"$FILE_PATH\" 2>/dev/null; then\n      report_performance \"WARNING\" \"Long timer intervals detected (>=${LONG_TIMER_MS}ms)\" \"Verify if long delays are intentional\"\n    fi\n    \n    # Nested loops\n    NESTED_LOOPS=$(grep -E 'for.*{[^}]*for.*{[^}]*for' \"$FILE_PATH\" 2>/dev/null || echo \"\")\n    if [ -n \"$NESTED_LOOPS\" ]; then\n      report_performance \"ERROR\" \"Triple nested loops detected - O(n³) complexity\" \"Consider algorithm optimization or data structure changes\"\n    elif grep -E 'for.*{[^}]*for' \"$FILE_PATH\" 2>/dev/null; then\n      nested_count=$(grep -c 'for.*{[^}]*for' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n      if [ \"$nested_count\" -gt 3 ]; then\n        report_performance \"WARNING\" \"Multiple nested loops detected\" \"Review algorithmic complexity\"\n      fi\n    fi\n    \n    # Memory leak patterns\n    if grep -q 'addEventListener.*function' \"$FILE_PATH\" 2>/dev/null; then\n      if ! grep -q 'removeEventListener' \"$FILE_PATH\" 2>/dev/null; then\n        report_performance \"WARNING\" \"Event listeners without cleanup detected\" \"Add removeEventListener calls to prevent memory leaks\"\n      fi\n    fi\n    \n    # Global variable pollution\n    GLOBAL_VARS=$(grep -c '^var\\\\|^let\\\\|^const' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n    if [ \"$GLOBAL_VARS\" -gt 20 ]; then\n      report_performance \"INFO\" \"Many global variables detected ($GLOBAL_VARS)\" \"Consider using modules or namespacing\"\n    fi\n    \n    # Bundle size impact for dependencies\n    if grep -q 'import.*from' \"$FILE_PATH\" 2>/dev/null; then\n      LARGE_IMPORTS=$(grep -E 'import.*(lodash|moment|rxjs)' \"$FILE_PATH\" 2>/dev/null || echo \"\")\n      if [ -n \"$LARGE_IMPORTS\" ]; then\n        report_performance \"INFO\" \"Large library imports detected\" \"Consider tree shaking or lighter alternatives\"\n      fi\n    fi\n    ;;\n    \n  \"py\")\n    echo \"   🐍 Python performance analysis...\" >&2\n    \n    # List comprehensions vs loops\n    if grep -q 'for.*in.*:' \"$FILE_PATH\" 2>/dev/null; then\n      list_comp_count=$(grep -c '\\\\[.*for.*in.*\\\\]' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n      loop_count=$(grep -c 'for.*in.*:' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n      \n      if [ \"$loop_count\" -gt 0 ] && [ \"$list_comp_count\" -eq 0 ]; then\n        report_performance \"INFO\" \"Consider using list comprehensions for better performance\" \"List comprehensions are often faster than explicit loops\"\n      fi\n    fi\n    \n    # Global imports inside functions\n    if grep -A 5 'def ' \"$FILE_PATH\" | grep -q 'import' 2>/dev/null; then\n      report_performance \"WARNING\" \"Imports inside functions detected\" \"Move imports to module level for better performance\"\n    fi\n    \n    # String concatenation\n    if grep -q '+.*+.*+' \"$FILE_PATH\" 2>/dev/null; then\n      report_performance \"INFO\" \"String concatenation chains detected\" \"Consider using f-strings or join() for better performance\"\n    fi\n    ;;\n    \n  \"sql\")\n    echo \"   🗄️ SQL performance analysis...\" >&2\n    \n    # Missing indexes (basic heuristics)\n    if grep -qi 'where.*=' \"$FILE_PATH\" 2>/dev/null; then\n      if ! grep -qi 'index' \"$FILE_PATH\" 2>/dev/null; then\n        report_performance \"WARNING\" \"WHERE clauses without visible indexes\" \"Ensure proper indexing for query performance\"\n      fi\n    fi\n    \n    # SELECT * usage\n    if grep -qi 'select \\\\*' \"$FILE_PATH\" 2>/dev/null; then\n      select_star_count=$(grep -ci 'select \\\\*' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n      report_performance \"WARNING\" \"SELECT * queries detected ($select_star_count)\" \"Specify only needed columns for better performance\"\n    fi\n    \n    # Cartesian products\n    if grep -qi 'from.*,.*where' \"$FILE_PATH\" 2>/dev/null; then\n      if ! grep -qi 'join' \"$FILE_PATH\" 2>/dev/null; then\n        report_performance \"ERROR\" \"Potential cartesian product detected\" \"Use explicit JOINs instead of comma-separated tables\"\n      fi\n    fi\n    ;;\n    \n  \"css\"|\"scss\"|\"sass\")\n    echo \"   🎨 CSS performance analysis...\" >&2\n    \n    # Complex selectors\n    COMPLEX_SELECTORS=$(grep -c '[[:space:]].*[[:space:]].*[[:space:]].*[[:space:]]' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n    if [ \"$COMPLEX_SELECTORS\" -gt 5 ]; then\n      report_performance \"WARNING\" \"Complex CSS selectors detected ($COMPLEX_SELECTORS)\" \"Simplify selectors for better rendering performance\"\n    fi\n    \n    # Expensive properties\n    if grep -q 'box-shadow.*,.*,' \"$FILE_PATH\" 2>/dev/null; then\n      report_performance \"INFO\" \"Complex box-shadow detected\" \"Consider simpler shadow effects for better performance\"\n    fi\n    \n    if grep -q '@import' \"$FILE_PATH\" 2>/dev/null; then\n      import_count=$(grep -c '@import' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n      if [ \"$import_count\" -gt 3 ]; then\n        report_performance \"WARNING\" \"Multiple CSS @imports detected ($import_count)\" \"Consider bundling CSS files to reduce HTTP requests\"\n      fi\n    fi\n    ;;\n    \n  \"html\")\n    echo \"   🌐 HTML performance analysis...\" >&2\n    \n    # Inline styles\n    INLINE_STYLES=$(grep -c 'style=' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n    if [ \"$INLINE_STYLES\" -gt 10 ]; then\n      report_performance \"WARNING\" \"Many inline styles detected ($INLINE_STYLES)\" \"Move styles to CSS files for better caching\"\n    fi\n    \n    # Large images without attributes\n    if grep -q '<img' \"$FILE_PATH\" 2>/dev/null; then\n      if ! grep -q 'width=\\\\|height=' \"$FILE_PATH\" 2>/dev/null; then\n        img_count=$(grep -c '<img' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n        report_performance \"INFO\" \"Images without dimensions detected ($img_count)\" \"Add width/height attributes to prevent layout shifts\"\n      fi\n    fi\n    ;;\nesac\n\n# 3. Asset Performance Analysis\necho \"   🖼️ Asset performance analysis...\" >&2\n\n# Check for asset imports/references\nif [[ \"$FILE_EXT\" =~ ^(js|jsx|ts|tsx|css|scss|html)$ ]]; then\n  # Image references\n  IMAGE_REFS=$(grep -oE '\\\\.(jpg|jpeg|png|gif|svg|webp)' \"$FILE_PATH\" 2>/dev/null | wc -l || echo \"0\")\n  if [ \"$IMAGE_REFS\" -gt 10 ]; then\n    report_performance \"INFO\" \"Many image references detected ($IMAGE_REFS)\" \"Consider image optimization and lazy loading\"\n  fi\n  \n  # Large base64 data\n  if grep -q 'data:image' \"$FILE_PATH\" 2>/dev/null; then\n    BASE64_COUNT=$(grep -c 'data:image' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n    report_performance \"WARNING\" \"Base64 encoded images detected ($BASE64_COUNT)\" \"Consider using separate image files for better caching\"\n  fi\nfi\n\n# 4. Database Query Analysis\nif grep -qi 'select\\\\|insert\\\\|update\\\\|delete' \"$FILE_PATH\" 2>/dev/null; then\n  echo \"   🗄️ Database query analysis...\" >&2\n  \n  # N+1 query patterns\n  if grep -q 'for.*in' \"$FILE_PATH\" 2>/dev/null && grep -q 'select\\\\|query' \"$FILE_PATH\" 2>/dev/null; then\n    report_performance \"WARNING\" \"Potential N+1 query pattern detected\" \"Consider using joins or batch queries\"\n  fi\n  \n  # Missing LIMIT clauses\n  if grep -qi 'select.*from' \"$FILE_PATH\" 2>/dev/null; then\n    if ! grep -qi 'limit\\\\|top\\\\|rownum' \"$FILE_PATH\" 2>/dev/null; then\n      unlimited_queries=$(grep -ci 'select.*from' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n      if [ \"$unlimited_queries\" -gt 2 ]; then\n        report_performance \"WARNING\" \"Queries without LIMIT detected ($unlimited_queries)\" \"Add LIMIT clauses to prevent large result sets\"\n      fi\n    fi\n  fi\nfi\n\n# 5. Framework-Specific Analysis\nif [[ \"$FILE_EXT\" =~ ^(jsx|tsx)$ ]]; then\n  echo \"   ⚛️ React performance analysis...\" >&2\n  \n  # Component re-render patterns\n  if grep -q 'useState\\\\|useEffect' \"$FILE_PATH\" 2>/dev/null; then\n    if ! grep -q 'useMemo\\\\|useCallback\\\\|React.memo' \"$FILE_PATH\" 2>/dev/null; then\n      hooks_count=$(grep -c 'useState\\\\|useEffect' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n      if [ \"$hooks_count\" -gt 5 ]; then\n        report_performance \"INFO\" \"Many React hooks without memoization\" \"Consider useMemo/useCallback for expensive operations\"\n      fi\n    fi\n  fi\n  \n  # Inline object/function creation in props\n  if grep -q '={{' \"$FILE_PATH\" 2>/dev/null; then\n    inline_objects=$(grep -c '={{' \"$FILE_PATH\" 2>/dev/null || echo \"0\")\n    if [ \"$inline_objects\" -gt 5 ]; then\n      report_performance \"WARNING\" \"Many inline objects in JSX props ($inline_objects)\" \"Extract to variables to prevent unnecessary re-renders\"\n    fi\n  fi\nfi\n\n# 6. Generate Performance Impact Summary\necho \"\" >&2\necho \"⚡ Performance Impact Summary\" >&2\necho \"============================\" >&2\necho \"   📄 File: $FILE_NAME ($(( FILE_SIZE / 1024 ))KB)\" >&2\necho \"   🚨 Critical Issues: $PERF_ERRORS\" >&2\necho \"   ⚠️ Warnings: $PERF_WARNINGS\" >&2\necho \"   ℹ️ Optimization Tips: $PERF_INFO\" >&2\n\n# Performance impact assessment\nTOTAL_ISSUES=$((PERF_ERRORS + PERF_WARNINGS))\n\nif [ \"$PERF_ERRORS\" -gt 0 ]; then\n  echo \"   🚨 Impact Level: HIGH - Critical performance issues detected\" >&2\nelif [ \"$PERF_WARNINGS\" -gt 3 ]; then\n  echo \"   ⚠️ Impact Level: MODERATE - Multiple performance concerns\" >&2\nelif [ \"$PERF_WARNINGS\" -gt 0 ]; then\n  echo \"   ⚠️ Impact Level: LOW - Minor performance considerations\" >&2\nelif [ \"$PERF_INFO\" -gt 0 ]; then\n  echo \"   ✅ Impact Level: MINIMAL - Good practices recommended\" >&2\nelse\n  echo \"   🎉 Impact Level: OPTIMAL - No performance issues detected\" >&2\nfi\n\nif [ \"$TOTAL_ISSUES\" -gt 0 ]; then\n  echo \"\" >&2\n  echo \"💡 Performance Optimization Resources:\" >&2\n  echo \"   • Web: Core Web Vitals and Lighthouse audits\" >&2\n  echo \"   • JavaScript: Profiler tools and performance monitoring\" >&2\n  echo \"   • Database: Query optimization and indexing strategies\" >&2\n  echo \"   • Bundle: Code splitting and tree shaking\" >&2\nfi\n\necho \"⚡ Performance impact monitoring complete\" >&2\nexit 0"
      },
      "useCases": [
        "Real-time development feedback with performance impact awareness",
        "Code review automation with performance-focused analysis",
        "Continuous performance monitoring during active development",
        "Team education and awareness about performance best practices",
        "Performance regression prevention with immediate alerts"
      ],
      "troubleshooting": [
        {
          "issue": "Hook runs on every file save slowing workflow",
          "solution": "Use matchers to limit to specific file types or directories, or add file size check: `if [ \"$FILE_SIZE\" -lt 10000 ]; then exit 0; fi` to skip small files under 10KB and reduce overhead."
        },
        {
          "issue": "False positives for nested loop warnings",
          "solution": "Adjust COMPLEX_CYCLOMATIC threshold or refine the regex pattern `grep -E 'for.*{[^}]*for.*{[^}]*for'` to exclude specific comment patterns or multi-line structures that trigger false matches."
        },
        {
          "issue": "Performance thresholds not matching project",
          "solution": "Customize thresholds at script top: set LARGE_FILE_THRESHOLD=200000 for larger projects, LARGE_FUNCTION_LINES=100 for verbose codebases, or LONG_TIMER_MS=10000 for intentional delays."
        },
        {
          "issue": "Cannot access file path from stdin JSON input",
          "solution": "Ensure jq is installed for JSON parsing. The hook reads: `FILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')`. Verify INPUT has valid JSON structure."
        },
        {
          "issue": "Memory leak warnings appear without cleanup",
          "solution": "Hook detects addEventListener without removeEventListener. Add cleanup: `useEffect(() => { el.addEventListener('click', fn); return () => el.removeEventListener('click', fn); }, []);`"
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/performance-impact-monitor"
    },
    {
      "slug": "performance-monitor",
      "description": "Monitors application performance metrics, identifies bottlenecks, and provides optimization recommendations",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-16",
      "tags": [
        "performance",
        "monitoring",
        "optimization",
        "metrics",
        "automation"
      ],
      "hookType": "Stop",
      "features": [
        "Application performance tracking",
        "Database query optimization",
        "Frontend performance monitoring",
        "Infrastructure resource monitoring",
        "Automated performance testing",
        "Performance alerts and recommendations",
        "Web Vitals tracking",
        "Bundle size analysis",
        "Memory leak detection",
        "Response time analysis"
      ],
      "useCases": [
        "Monitor API response times and identify slow endpoints",
        "Track memory usage and detect potential memory leaks",
        "Analyze database query performance and optimization opportunities",
        "Monitor Web Vitals (LCP, FID, CLS) for frontend performance",
        "Set up automated performance testing in CI/CD pipelines",
        "Generate comprehensive performance reports with actionable insights",
        "Monitor infrastructure resources (CPU, memory, disk usage)",
        "Analyze bundle sizes and identify large dependencies",
        "Set up performance alerts for threshold breaches",
        "Track performance trends over time"
      ],
      "configuration": {
        "hookConfig": {
          "scriptContent": "#!/bin/bash\n\necho \"🔍 Performance Monitor - Analyzing system performance...\"\n\n# Performance monitoring areas\necho \"📊 Monitoring Areas:\"\necho \"  • Application Performance Metrics\"\necho \"  • Database Performance\"\necho \"  • Frontend Performance (Web Vitals)\"\necho \"  • Infrastructure Monitoring\"\necho \"  • Automated Performance Testing\"\n\n# Check if performance tools are available\ncommand -v node >/dev/null 2>&1 && echo \"✓ Node.js available for performance profiling\"\ncommand -v lighthouse >/dev/null 2>&1 && echo \"✓ Lighthouse available for web performance\"\ncommand -v artillery >/dev/null 2>&1 && echo \"✓ Artillery available for load testing\"\n\n# System performance check\necho \"\"\necho \"💻 System Performance:\"\n\n# Memory usage\nif command -v free >/dev/null 2>&1; then\n    mem_usage=$(free | grep Mem | awk '{printf \"%.2f\", $3/$2 * 100.0}')\n    echo \"  Memory Usage: ${mem_usage}%\"\n    if (( $(echo \"$mem_usage > 85\" | bc -l) 2>/dev/null )); then\n        echo \"  🚨 High memory usage detected!\"\n    fi\nfi\n\n# Disk usage\ndisk_usage=$(df / | tail -1 | awk '{print $5}' | sed 's/%//')\necho \"  Disk Usage: ${disk_usage}%\"\nif (( disk_usage > 90 )); then\n    echo \"  🚨 High disk usage detected!\"\nfi\n\n# Load average\nif command -v uptime >/dev/null 2>&1; then\n    load_avg=$(uptime | awk -F'load average:' '{print $2}' | awk '{print $1}' | sed 's/,//')\n    echo \"  Load Average: $load_avg\"\nfi\n\n# Performance monitoring recommendations\necho \"\"\necho \"💡 Performance Recommendations:\"\necho \"  • Implement response time tracking for API endpoints\"\necho \"  • Set up Web Vitals monitoring for frontend performance\"\necho \"  • Monitor database query performance\"\necho \"  • Set up automated performance testing\"\necho \"  • Configure performance alerts and thresholds\"\necho \"  • Use profiling tools for bottleneck identification\"\necho \"  • Implement performance budgets for builds\"\n\necho \"\"\necho \"📋 Next Steps:\"\necho \"  1. Set up performance monitoring dashboards\"\necho \"  2. Configure performance alerts\"\necho \"  3. Implement automated performance testing\"\necho \"  4. Review and optimize identified bottlenecks\"\n\necho \"\"\necho \"🎯 Performance monitor analysis complete!\"\necho \"📊 Use monitoring data to drive optimization decisions\"\n\nexit 0",
          "hooks": {
            "Stop": [
              {
                "matchers": [
                  "*"
                ],
                "description": "Monitor performance metrics and provide optimization insights"
              }
            ]
          }
        }
      },
      "troubleshooting": [
        {
          "issue": "Memory usage calculation fails on macOS systems",
          "solution": "Hook uses free command which is Linux-only. On macOS, install free via brew install free or modify hook to use vm_stat | grep 'Pages active' for memory statistics instead."
        },
        {
          "issue": "bc command not found error on minimal systems",
          "solution": "Install bc for floating-point arithmetic (apt-get install bc or brew install bc). Alternatively, modify memory comparison to use integer math with awk instead of bc -l for percentage checks."
        },
        {
          "issue": "Lighthouse or Artillery tools not detected",
          "solution": "Install globally with npm install -g lighthouse @artillery/core or install locally and modify hook to check npx lighthouse and npx artillery instead of direct commands."
        },
        {
          "issue": "Hook shows same performance data every run",
          "solution": "This is a stop hook providing system snapshot at session end. For continuous monitoring, integrate with dedicated APM tools or add timestamped logging to track changes over multiple sessions."
        },
        {
          "issue": "Load average shows very high values but system responsive",
          "solution": "Load average is relative to CPU core count. Value of 8 is normal for 8-core system. Divide load average by core count (sysctl -n hw.ncpu on macOS, nproc on Linux) for actual load percentage."
        }
      ],
      "documentationUrl": "https://web.dev/vitals/",
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/performance-monitor"
    },
    {
      "slug": "playwright-test-runner",
      "description": "Automatically runs Playwright E2E tests when test files or page components are modified",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "playwright",
        "e2e",
        "testing",
        "automation",
        "browser-testing"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Automatic test execution on file changes",
        "Smart test detection for pages and components",
        "E2E regression testing",
        "Playwright integration",
        "Test result reporting",
        "Cross-browser testing support"
      ],
      "useCases": [
        "Run E2E tests when test files are modified",
        "Execute related tests when page components change",
        "Catch UI regressions early in development",
        "Automate browser testing workflows",
        "Validate page functionality after changes",
        "Test component interactions across browsers",
        "Ensure application quality before commits",
        "Monitor UI consistency during development"
      ],
      "troubleshooting": [
        {
          "issue": "Playwright tests fail with 'browser not found' errors",
          "solution": "Browsers not installed after @playwright/test install. Run: 'npx playwright install' downloading Chromium/Firefox/WebKit. Or specific: 'npx playwright install chromium' for single browser."
        },
        {
          "issue": "Component name grep returns no tests despite matching test files",
          "solution": "--grep searches test descriptions not filenames. Use --testPathPattern: 'npx playwright test --testPathPattern=\"$PAGE_NAME\"' or combine: '--grep \"$PAGE_NAME\" --testPathPattern=\".*\"'."
        },
        {
          "issue": "E2E tests fail when run via hook but pass manually",
          "solution": "Hook lacks env variables or server not running. Check baseURL: set in playwright.config.ts. Or start server: add 'npm run dev &' before tests with cleanup: 'kill $!' after."
        },
        {
          "issue": "Hook triggers on every .tsx save running slow E2E tests",
          "solution": "No file type filtering. Restrict matchers: 'matchers': ['write:**/*.spec.{ts,js}', 'edit:**/*.spec.{ts,js}'] running only on test file changes. Or add path check excluding components."
        },
        {
          "issue": "Smoke tests run instead of specific component tests showing wrong results",
          "solution": "Fallback triggers on grep failure. Add existence check: 'if ! npx playwright test --list --grep \"$PAGE_NAME\" | grep -q .; then exit 0; fi' before running. Skip fallback if no matches."
        }
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/playwright-test-runner.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/bin/bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\necho \"🎭 Playwright Test Runner - Analyzing file changes...\"\n\n# Check if this is a test file\nif [[ \"$FILE_PATH\" == *.spec.ts ]] || [[ \"$FILE_PATH\" == *.spec.js ]] || [[ \"$FILE_PATH\" == *e2e*.ts ]]; then\n    echo \"📝 Test file detected: $FILE_PATH\"\n    echo \"🎭 Running specific Playwright test...\"\n    \n    if command -v npx >/dev/null 2>&1; then\n        npx playwright test \"$FILE_PATH\" --reporter=list\n        if [ $? -eq 0 ]; then\n            echo \"✅ E2E tests passed for $FILE_PATH\"\n        else\n            echo \"❌ E2E tests failed for $FILE_PATH\"\n        fi\n    else\n        echo \"⚠️ Playwright not found. Install with: npm install -D @playwright/test\"\n    fi\n    \nelif [[ \"$FILE_PATH\" == *pages/*.tsx ]] || [[ \"$FILE_PATH\" == *app/*.tsx ]] || [[ \"$FILE_PATH\" == *components/*.tsx ]]; then\n    PAGE_NAME=$(basename \"${FILE_PATH%.*}\")\n    echo \"🧩 Component/page detected: $PAGE_NAME\"\n    echo \"🎭 Running related E2E tests...\"\n    \n    if command -v npx >/dev/null 2>&1; then\n        # Try to find and run tests related to this component\n        npx playwright test --grep \"$PAGE_NAME\" --reporter=list 2>/dev/null\n        if [ $? -eq 0 ]; then\n            echo \"✅ Related E2E tests passed for $PAGE_NAME\"\n        else\n            echo \"ℹ️ No specific tests found for $PAGE_NAME or tests failed\"\n            # Run a basic smoke test if available\n            npx playwright test --grep \"smoke\" --reporter=list 2>/dev/null || echo \"ℹ️ No smoke tests available\"\n        fi\n    else\n        echo \"⚠️ Playwright not found. Install with: npm install -D @playwright/test\"\n    fi\nelse\n    echo \"ℹ️ File type not relevant for E2E testing: $FILE_PATH\"\nfi\n\necho \"\"\necho \"💡 Playwright Testing Tips:\"\necho \"  • Test files should end with .spec.ts, .spec.js, or contain 'e2e'\"\necho \"  • Use page-specific test names to enable smart test detection\"\necho \"  • Consider running full test suite before major releases\"\necho \"  • Check Playwright configuration for browser settings\"\n\necho \"\"\necho \"🎯 Test analysis complete!\"\n\nexit 0"
      },
      "documentationUrl": "https://playwright.dev",
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/playwright-test-runner"
    },
    {
      "slug": "prisma-schema-sync",
      "description": "Automatically generates Prisma client and creates migrations when schema.prisma is modified",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "prisma",
        "database",
        "orm",
        "schema",
        "migrations"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Automatic Prisma client generation",
        "Database migration creation",
        "Schema validation and formatting",
        "TypeScript type generation",
        "Database synchronization",
        "Migration safety checks"
      ],
      "useCases": [
        "Keep Prisma client in sync with schema changes",
        "Automatically create database migrations",
        "Validate Prisma schema syntax on changes",
        "Generate TypeScript types for database models",
        "Format Prisma schema files consistently",
        "Ensure database schema consistency",
        "Streamline database development workflow",
        "Catch schema errors early in development"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/prisma-schema-sync.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/bin/bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Check if this is a Prisma schema file\nif [[ \"$FILE_PATH\" == *schema.prisma ]]; then\n    echo \"🔄 Prisma Schema Sync - Processing schema changes...\"\n    echo \"📄 Schema file: $FILE_PATH\"\n    \n    # Check if Prisma is available\n    if ! command -v npx >/dev/null 2>&1; then\n        echo \"⚠️ npx not found. Please install Node.js and npm\"\n        exit 1\n    fi\n    \n    # Step 1: Validate schema\n    echo \"🔍 Validating Prisma schema...\"\n    if npx prisma validate; then\n        echo \"✅ Schema validation passed\"\n    else\n        echo \"❌ Schema validation failed - Please fix errors before proceeding\"\n        exit 1\n    fi\n    \n    # Step 2: Format schema\n    echo \"📝 Formatting Prisma schema...\"\n    if npx prisma format; then\n        echo \"✅ Schema formatted successfully\"\n    else\n        echo \"⚠️ Schema formatting failed\"\n    fi\n    \n    # Step 3: Generate Prisma client\n    echo \"🏗️ Generating Prisma client...\"\n    if npx prisma generate; then\n        echo \"✅ Prisma client generated successfully\"\n    else\n        echo \"❌ Prisma client generation failed\"\n        exit 1\n    fi\n    \n    # Step 4: Create migration (dev mode only)\n    if [ \"$NODE_ENV\" != \"production\" ]; then\n        echo \"🗄️ Creating database migration...\"\n        MIGRATION_NAME=\"auto_migration_$(date +%Y%m%d_%H%M%S)\"\n        \n        if npx prisma migrate dev --name \"$MIGRATION_NAME\" --create-only; then\n            echo \"✅ Migration created: $MIGRATION_NAME\"\n            echo \"⚠️ Please review the migration before applying it to your database\"\n            echo \"💡 Apply with: npx prisma migrate dev\"\n        else\n            echo \"⚠️ Migration creation skipped or failed\"\n        fi\n    else\n        echo \"ℹ️ Production environment - skipping migration creation\"\n    fi\n    \n    echo \"\"\n    echo \"💡 Prisma Sync Tips:\"\n    echo \"  • Review generated migrations before applying\"\n    echo \"  • Use 'npx prisma studio' to explore your database\"\n    echo \"  • Run 'npx prisma db push' for prototyping\"\n    echo \"  • Use 'npx prisma migrate reset' to reset development database\"\n    \n    echo \"\"\n    echo \"🎯 Prisma schema sync complete!\"\n    \nelse\n    echo \"ℹ️ File is not a Prisma schema file: $FILE_PATH\"\nfi\n\nexit 0"
      },
      "troubleshooting": [
        {
          "issue": "npx prisma generate fails with 'generator not found' error",
          "solution": "Prisma client not installed or wrong version. Run: 'npm install @prisma/client' matching schema generator. Verify: 'npx prisma version' showing versions. Re-generate with full schema path."
        },
        {
          "issue": "Migration creation hangs waiting for database connection that fails",
          "solution": "DATABASE_URL missing or incorrect in .env. Verify: 'echo $DATABASE_URL' showing connection. Test: 'npx prisma db pull' for connectivity. Or use '--skip-generate' flag bypassing DB."
        },
        {
          "issue": "Auto-migration creates duplicate migrations for identical schema changes",
          "solution": "Timestamp-based naming always creates new migration. Add check: 'git diff prisma/schema.prisma | grep \"^+model\"' detecting real changes. Or use 'npx prisma migrate diff' to compare first."
        },
        {
          "issue": "prisma format changes schema but hook shows no modifications",
          "solution": "Formatting occurs after file write completing hook execution. Move format before validation: reorder script or use: 'npx prisma format && npx prisma validate' ensuring formatted state checked."
        },
        {
          "issue": "Hook runs in production despite NODE_ENV check skipping migrations",
          "solution": "NODE_ENV not set in deployment defaulting to undefined. Export: 'export NODE_ENV=production' in shell profile. Or check: 'if [ \"$NODE_ENV\" = \"production\" ] || [ -z \"$NODE_ENV\" ]'."
        }
      ],
      "documentationUrl": "https://www.prisma.io/docs",
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/prisma-schema-sync"
    },
    {
      "slug": "python-import-optimizer",
      "description": "Automatically sorts and optimizes Python imports using isort when Python files are modified",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "python",
        "imports",
        "formatting",
        "optimization",
        "isort"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Automatic import sorting with isort",
        "PEP 8 compliant import organization",
        "Unused import removal",
        "Black profile compatibility",
        "Import grouping by type",
        "Code formatting integration"
      ],
      "useCases": [
        "Organize Python imports according to PEP 8 standards",
        "Remove unused imports automatically",
        "Group imports by type (standard library, third-party, local)",
        "Maintain consistent import formatting across projects",
        "Integrate with Black code formatter",
        "Clean up import statements in Python files",
        "Ensure import consistency in team projects",
        "Optimize Python file organization"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/python-import-optimizer.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/bin/bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Check if this is a Python file\nif [[ \"$FILE_PATH\" == *.py ]]; then\n    echo \"🐍 Python Import Optimizer - Processing Python file...\"\n    echo \"📄 File: $FILE_PATH\"\n    \n    # Check if file exists\n    if [ ! -f \"$FILE_PATH\" ]; then\n        echo \"⚠️ File not found: $FILE_PATH\"\n        exit 1\n    fi\n    \n    # Step 1: Sort imports with isort\n    echo \"📋 Sorting imports with isort...\"\n    if command -v isort >/dev/null 2>&1; then\n        if isort \"$FILE_PATH\" --profile black --line-length 88 --check-only --diff; then\n            echo \"✅ Imports are already sorted\"\n        else\n            echo \"🔄 Sorting imports...\"\n            isort \"$FILE_PATH\" --profile black --line-length 88\n            echo \"✅ Imports sorted successfully\"\n        fi\n    else\n        echo \"⚠️ isort not found. Install with: pip install isort\"\n    fi\n    \n    # Step 2: Remove unused imports with autoflake (optional)\n    echo \"🧹 Removing unused imports...\"\n    if command -v autoflake >/dev/null 2>&1; then\n        # Check for unused imports first\n        if autoflake --check \"$FILE_PATH\" --remove-unused-variables --remove-all-unused-imports; then\n            echo \"✅ No unused imports found\"\n        else\n            echo \"🔄 Removing unused imports...\"\n            autoflake --in-place \"$FILE_PATH\" --remove-unused-variables --remove-all-unused-imports\n            echo \"✅ Unused imports removed\"\n        fi\n    else\n        echo \"ℹ️ autoflake not found (optional). Install with: pip install autoflake\"\n    fi\n    \n    # Step 3: Additional import analysis\n    echo \"🔍 Analyzing import structure...\"\n    \n    # Count different types of imports\n    STDLIB_IMPORTS=$(grep -c \"^import \\(os\\|sys\\|re\\|json\\|datetime\\|collections\\|itertools\\|functools\\|pathlib\\)\" \"$FILE_PATH\" 2>/dev/null || echo 0)\n    THIRD_PARTY_IMPORTS=$(grep -c \"^\\(import\\|from\\) \\(numpy\\|pandas\\|requests\\|flask\\|django\\|fastapi\\)\" \"$FILE_PATH\" 2>/dev/null || echo 0)\n    RELATIVE_IMPORTS=$(grep -c \"^from \\.[.]*\" \"$FILE_PATH\" 2>/dev/null || echo 0)\n    \n    echo \"📊 Import Summary:\"\n    echo \"  • Standard Library: $STDLIB_IMPORTS\"\n    echo \"  • Third Party: $THIRD_PARTY_IMPORTS\"\n    echo \"  • Relative: $RELATIVE_IMPORTS\"\n    \n    # Check for potential issues\n    if grep -q \"^import \\*\" \"$FILE_PATH\" 2>/dev/null; then\n        echo \"⚠️ Warning: Star imports detected (import *) - consider specific imports\"\n    fi\n    \n    if [ \"$(grep -c '^import\\|^from' \"$FILE_PATH\" 2>/dev/null || echo 0)\" -gt 20 ]; then\n        echo \"💡 Tip: Consider grouping related imports or using a package structure\"\n    fi\n    \n    echo \"\"\n    echo \"💡 Python Import Tips:\"\n    echo \"  • Use absolute imports when possible\"\n    echo \"  • Group imports: stdlib, third-party, local\"\n    echo \"  • Avoid star imports (import *)\"\n    echo \"  • Use 'from module import specific_function' for clarity\"\n    \n    echo \"\"\n    echo \"🎯 Python import optimization complete!\"\n    \nelse\n    echo \"ℹ️ File is not a Python file: $FILE_PATH\"\nfi\n\nexit 0"
      },
      "troubleshooting": [
        {
          "issue": "isort conflicts with Black formatter settings",
          "solution": "Hook already uses --profile black flag for compatibility. Ensure Black and isort versions are current. Add .isort.cfg with profile = black and line_length = 88 for project-wide consistency."
        },
        {
          "issue": "autoflake removes imports that are actually used",
          "solution": "Add # noqa comments to imports that should be preserved. Configure autoflake to exclude specific files with --exclude in hook script, or use __all__ exports to signal intentional module-level imports."
        },
        {
          "issue": "Hook processes __init__.py and breaks package exports",
          "solution": "Exclude __init__.py from autoflake processing by modifying hook to check filename. Add special handling for package files where import * is intentional for re-exporting."
        },
        {
          "issue": "Relative imports get converted to absolute incorrectly",
          "solution": "Configure isort with known_first_party setting in setup.cfg or pyproject.toml. Use --src-path flag in hook to help isort determine project root for proper import classification."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/python-import-optimizer"
    },
    {
      "slug": "python-linter-integration",
      "description": "Automatically runs pylint on Python files after editing to enforce code quality standards",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "python",
        "linting",
        "code-quality",
        "pylint"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Automatic pylint execution on Python file changes",
        "Code quality assessment and scoring",
        "PEP 8 compliance checking",
        "Error and warning detection",
        "Code complexity analysis",
        "Configurable linting rules"
      ],
      "useCases": [
        "Enforce Python coding standards automatically",
        "Catch potential bugs and code issues early",
        "Maintain consistent code quality across projects",
        "Provide immediate feedback on code changes",
        "Integrate linting into development workflow",
        "Monitor code complexity and maintainability",
        "Ensure PEP 8 compliance",
        "Run quality checks before commits"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/python-linter-integration.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/bin/bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Check if this is a Python file\nif [[ \"$FILE_PATH\" == *.py ]]; then\n    echo \"🔍 Python Linter Integration - Analyzing code quality...\"\n    echo \"📄 File: $FILE_PATH\"\n    \n    # Check if file exists\n    if [ ! -f \"$FILE_PATH\" ]; then\n        echo \"⚠️ File not found: $FILE_PATH\"\n        exit 1\n    fi\n    \n    # Check if pylint is available\n    if command -v pylint >/dev/null 2>&1; then\n        echo \"🔍 Running pylint analysis...\"\n        \n        # Run pylint with custom formatting\n        PYLINT_OUTPUT=$(pylint \"$FILE_PATH\" --score=yes --reports=no --msg-template=\"{line:3d},{column:2d}: {category}: {msg} ({symbol})\" 2>/dev/null)\n        PYLINT_EXIT_CODE=$?\n        \n        if [ $PYLINT_EXIT_CODE -eq 0 ]; then\n            echo \"✅ Pylint analysis passed - No issues found\"\n        else\n            echo \"📋 Pylint Analysis Results:\"\n            echo \"$PYLINT_OUTPUT\" | head -20  # Limit output to first 20 lines\n            \n            # Show summary if there are many issues\n            ISSUE_COUNT=$(echo \"$PYLINT_OUTPUT\" | wc -l)\n            if [ \"$ISSUE_COUNT\" -gt 20 ]; then\n                echo \"... and $((ISSUE_COUNT - 20)) more issues\"\n            fi\n            \n            # Extract score if available\n            SCORE=$(echo \"$PYLINT_OUTPUT\" | grep \"Your code has been rated\" | grep -o '[0-9]\\+\\.[0-9]\\+' | head -1)\n            if [ -n \"$SCORE\" ]; then\n                echo \"📊 Code Quality Score: $SCORE/10\"\n            fi\n        fi\n        \n    elif command -v flake8 >/dev/null 2>&1; then\n        echo \"🔍 Running flake8 analysis (fallback)...\"\n        \n        if flake8 \"$FILE_PATH\" --max-line-length=88; then\n            echo \"✅ Flake8 analysis passed - No style issues found\"\n        else\n            echo \"⚠️ Flake8 found style issues (non-blocking)\"\n        fi\n        \n    elif command -v pycodestyle >/dev/null 2>&1; then\n        echo \"🔍 Running pycodestyle analysis (fallback)...\"\n        \n        if pycodestyle \"$FILE_PATH\" --max-line-length=88; then\n            echo \"✅ Pycodestyle analysis passed - No style issues found\"\n        else\n            echo \"⚠️ Pycodestyle found style issues (non-blocking)\"\n        fi\n        \n    else\n        echo \"⚠️ No Python linters found\"\n        echo \"💡 Install options:\"\n        echo \"  • pip install pylint (recommended)\"\n        echo \"  • pip install flake8 (lightweight)\"\n        echo \"  • pip install pycodestyle (basic)\"\n    fi\n    \n    # Additional code quality checks\n    echo \"\"\n    echo \"📊 Quick Code Analysis:\"\n    \n    # Count lines of code (excluding comments and empty lines)\n    LOC=$(grep -v '^[[:space:]]*#' \"$FILE_PATH\" | grep -v '^[[:space:]]*$' | wc -l)\n    echo \"  • Lines of Code: $LOC\"\n    \n    # Check for potential issues\n    if grep -q \"print(\" \"$FILE_PATH\"; then\n        echo \"  • 💡 Consider using logging instead of print statements\"\n    fi\n    \n    if grep -q \"TODO\\|FIXME\\|XXX\" \"$FILE_PATH\"; then\n        echo \"  • 📝 TODOs/FIXMEs found - consider addressing them\"\n    fi\n    \n    # Check function complexity (rough estimate)\n    FUNCTION_COUNT=$(grep -c \"^def \" \"$FILE_PATH\")\n    if [ \"$FUNCTION_COUNT\" -gt 0 ]; then\n        AVG_LINES_PER_FUNC=$((LOC / FUNCTION_COUNT))\n        echo \"  • Functions: $FUNCTION_COUNT (avg ~$AVG_LINES_PER_FUNC lines each)\"\n        \n        if [ \"$AVG_LINES_PER_FUNC\" -gt 20 ]; then\n            echo \"  • 💡 Consider breaking down large functions\"\n        fi\n    fi\n    \n    echo \"\"\n    echo \"💡 Python Code Quality Tips:\"\n    echo \"  • Follow PEP 8 style guidelines\"\n    echo \"  • Use meaningful variable and function names\"\n    echo \"  • Add docstrings to functions and classes\"\n    echo \"  • Keep functions small and focused\"\n    echo \"  • Use type hints for better code clarity\"\n    \n    echo \"\"\n    echo \"🎯 Code quality analysis complete!\"\n    \nelse\n    echo \"ℹ️ File is not a Python file: $FILE_PATH\"\nfi\n\nexit 0"
      },
      "troubleshooting": [
        {
          "issue": "Hook reports no linters found despite installation",
          "solution": "Ensure linters are in your PATH. Use 'which pylint' or 'which flake8' to verify. Install globally with 'pip install pylint' or activate your virtual environment before running hooks."
        },
        {
          "issue": "Pylint output is truncated showing only first 20 lines",
          "solution": "This is intentional to prevent overwhelming output. For full analysis, run 'pylint <file>' directly. The hook shows summary statistics including total issue count and quality score."
        },
        {
          "issue": "Hook shows warnings but doesn't block file operations",
          "solution": "This is by design - linting runs post-modification as feedback. To block writes, move the hook to preToolUse and add 'exit 1' for failing scores. Consider your workflow before enforcing strict blocks."
        },
        {
          "issue": "False positives or style conflicts with project standards",
          "solution": "Create a .pylintrc or .flake8 config file in your project root to customize rules. Use '--disable=<rule>' for specific suppressions. The hook respects project-level configuration files."
        },
        {
          "issue": "Virtual environment packages cause import errors in pylint",
          "solution": "Ensure the hook runs in the same environment where Python packages are installed. Set 'export VIRTUAL_ENV=/path/to/venv' or activate venv before Claude Code session starts."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/python-linter-integration"
    },
    {
      "slug": "react-component-test-generator",
      "seoTitle": "React Test Generator",
      "description": "Automatically creates or updates test files when React components are modified",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "react",
        "testing",
        "jest",
        "components",
        "automation"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Automatic test file generation for React components",
        "Support for both TypeScript and JavaScript",
        "Jest and React Testing Library integration",
        "Basic render test scaffolding",
        "Component-specific test structure",
        "Test file naming conventions"
      ],
      "useCases": [
        "Generate test files when creating new React components",
        "Ensure every component has corresponding tests",
        "Scaffold basic test structure automatically",
        "Maintain testing consistency across projects",
        "Speed up test-driven development workflow",
        "Create render tests for component validation",
        "Set up testing infrastructure for new components",
        "Encourage testing best practices"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/react-component-test-generator.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/bin/bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Check if this is a React component file (but not a test file)\nif [[ \"$FILE_PATH\" == *.jsx ]] || [[ \"$FILE_PATH\" == *.tsx ]]; then\n    # Skip if this is already a test file\n    if [[ \"$FILE_PATH\" == *.test.* ]] || [[ \"$FILE_PATH\" == *.spec.* ]]; then\n        exit 0\n    fi\n    \n    echo \"⚛️ React Component Test Generator - Processing component...\"\n    echo \"📄 Component: $FILE_PATH\"\n    \n    # Extract component info\n    COMPONENT_DIR=$(dirname \"$FILE_PATH\")\n    COMPONENT_BASENAME=$(basename \"$FILE_PATH\")\n    COMPONENT_NAME=$(basename \"${FILE_PATH%.*}\")\n    COMPONENT_EXT=\"${FILE_PATH##*.}\"\n    \n    # Determine test file path\n    if [[ \"$COMPONENT_EXT\" == \"tsx\" ]]; then\n        TEST_FILE=\"${COMPONENT_DIR}/${COMPONENT_NAME}.test.tsx\"\n    else\n        TEST_FILE=\"${COMPONENT_DIR}/${COMPONENT_NAME}.test.jsx\"\n    fi\n    \n    # Check if test file already exists\n    if [ -f \"$TEST_FILE\" ]; then\n        echo \"ℹ️ Test file already exists: $TEST_FILE\"\n        echo \"💡 Consider updating tests to match component changes\"\n    else\n        echo \"🧪 Generating test file: $TEST_FILE\"\n        \n        # Create test file content\n        cat > \"$TEST_FILE\" << EOF\nimport { render, screen } from '@testing-library/react';\nimport userEvent from '@testing-library/user-event';\nimport $COMPONENT_NAME from './$COMPONENT_BASENAME';\n\ndescribe('$COMPONENT_NAME', () => {\n  it('renders without crashing', () => {\n    render(<$COMPONENT_NAME />);\n  });\n\n  it('displays expected content', () => {\n    render(<$COMPONENT_NAME />);\n    // Add assertions here\n    // expect(screen.getByText('expected text')).toBeInTheDocument();\n  });\n\n  // Add more component-specific tests here\n  // Example: testing props, user interactions, etc.\n  // \n  // it('handles user interactions', async () => {\n  //   const user = userEvent.setup();\n  //   render(<$COMPONENT_NAME />);\n  //   // await user.click(screen.getByRole('button'));\n  //   // expect(...);\n  // });\n});\nEOF\n        \n        if [ $? -eq 0 ]; then\n            echo \"✅ Test file created successfully!\"\n            echo \"📝 Test file: $TEST_FILE\"\n        else\n            echo \"❌ Failed to create test file\"\n        fi\n    fi\n    \n    # Additional suggestions based on component analysis\n    echo \"\"\n    echo \"🔍 Component Analysis:\"\n    \n    if [ -f \"$FILE_PATH\" ]; then\n        # Check for props interface/type\n        if grep -q \"interface.*Props\\|type.*Props\" \"$FILE_PATH\"; then\n            echo \"  • 💡 Props interface detected - consider testing different prop combinations\"\n        fi\n        \n        # Check for hooks usage\n        if grep -q \"useState\\|useEffect\\|useContext\" \"$FILE_PATH\"; then\n            echo \"  • 💡 React hooks detected - consider testing state changes and side effects\"\n        fi\n        \n        # Check for event handlers\n        if grep -q \"onClick\\|onChange\\|onSubmit\" \"$FILE_PATH\"; then\n            echo \"  • 💡 Event handlers detected - consider testing user interactions\"\n        fi\n        \n        # Check for conditional rendering\n        if grep -q \"&&\\|?.*:\" \"$FILE_PATH\"; then\n            echo \"  • 💡 Conditional rendering detected - test different rendering scenarios\"\n        fi\n    fi\n    \n    echo \"\"\n    echo \"💡 Testing Best Practices:\"\n    echo \"  • Test component behavior, not implementation details\"\n    echo \"  • Use accessible queries (getByRole, getByLabelText)\"\n    echo \"  • Test user interactions with userEvent\"\n    echo \"  • Mock external dependencies and API calls\"\n    echo \"  • Test edge cases and error states\"\n    \n    echo \"\"\n    echo \"🎯 Test generation complete!\"\n    \nelse\n    echo \"ℹ️ File is not a React component: $FILE_PATH\"\nfi\n\nexit 0"
      },
      "troubleshooting": [
        {
          "issue": "Generated tests import components incorrectly using default export",
          "solution": "Hook assumes default exports. For named exports, modify the template to use: import { ComponentName } from './file'. Check component export pattern before generation or add detection logic for export type."
        },
        {
          "issue": "Test file created but component requires props causing render failures",
          "solution": "Base template uses empty props <Component />. Extract props interface from component file using grep and generate mock props: const mockProps = { required: 'value' }; before render() call in template."
        },
        {
          "issue": "Generated imports fail when @testing-library not installed in project",
          "solution": "Hook doesn't verify testing dependencies. Add package.json check: grep -q '@testing-library/react' package.json || { echo 'Install testing libraries first'; exit 1; } before generating test files."
        },
        {
          "issue": "Test generation races with file write causing empty component reads",
          "solution": "PostToolUse triggers immediately after tool but writes may be buffered. Add validation: [ -s \"$FILE_PATH\" ] to check file has content before reading. Use sleep 0.05 if race conditions persist in analysis section."
        },
        {
          "issue": "Cat heredoc syntax fails when component name contains special chars",
          "solution": "Template uses unquoted $COMPONENT_NAME in heredoc. Escape special characters: SAFE_NAME=${COMPONENT_NAME//[^a-zA-Z0-9_]/} or use single quotes: cat > \"$TEST_FILE\" <<'EOF' to prevent variable expansion issues."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/react-component-test-generator"
    },
    {
      "slug": "real-time-activity-tracker",
      "description": "Tracks all Claude Code activities in real-time and logs them for monitoring and debugging",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "monitoring",
        "logging",
        "notification",
        "real-time",
        "debugging"
      ],
      "hookType": "Notification",
      "features": [
        "Real-time activity logging",
        "Structured activity records",
        "Daily log rotation",
        "Tool usage tracking",
        "File operation monitoring",
        "Debug information collection"
      ],
      "useCases": [
        "Monitor Claude Code tool usage in real-time",
        "Debug development workflow issues",
        "Track file modification patterns",
        "Audit development activities",
        "Analyze Claude's decision-making process",
        "Monitor project development progress",
        "Create activity reports for team review",
        "Troubleshoot hook execution problems"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "notification": {
              "script": "./.claude/hooks/real-time-activity-tracker.sh",
              "matchers": [
                "*"
              ]
            }
          }
        },
        "scriptContent": "#!/bin/bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\nTOOL_ACTION=$(echo \"$INPUT\" | jq -r '.tool_action // \"unknown\"')\n\necho \"📊 Real-time Activity Tracker - Logging activity...\"\n\n# Create .claude directory if it doesn't exist\nmkdir -p .claude\n\n# Create daily activity log\nACTIVITY_LOG=\".claude/activity-$(date +%Y%m%d).log\"\nACTIVITY_JSON=\".claude/activity-$(date +%Y%m%d).json\"\n\n# Current timestamp\nTIMESTAMP=$(date --iso-8601=seconds 2>/dev/null || date -Iseconds 2>/dev/null || date)\n\n# Log in human-readable format\necho \"[$TIMESTAMP] Tool: $TOOL_NAME | File: $FILE_PATH | Action: $TOOL_ACTION\" >> \"$ACTIVITY_LOG\"\n\n# Log in JSON format for programmatic analysis\ncat >> \"$ACTIVITY_JSON\" << EOF\n{\n  \"timestamp\": \"$TIMESTAMP\",\n  \"tool_name\": \"$TOOL_NAME\",\n  \"file_path\": \"$FILE_PATH\",\n  \"action\": \"$TOOL_ACTION\",\n  \"session_id\": \"$(date +%Y%m%d_%H%M%S)_$$\"\n},\nEOF\n\n# Keep only last 100 entries in activity log to prevent it from growing too large\nif [ -f \"$ACTIVITY_LOG\" ]; then\n    tail -n 100 \"$ACTIVITY_LOG\" > \"$ACTIVITY_LOG.tmp\" && mv \"$ACTIVITY_LOG.tmp\" \"$ACTIVITY_LOG\"\nfi\n\n# Keep only last 100 entries in JSON log\nif [ -f \"$ACTIVITY_JSON\" ]; then\n    tail -n 100 \"$ACTIVITY_JSON\" > \"$ACTIVITY_JSON.tmp\" && mv \"$ACTIVITY_JSON.tmp\" \"$ACTIVITY_JSON\"\nfi\n\n# Activity statistics\nif [ -f \"$ACTIVITY_LOG\" ]; then\n    TOTAL_ACTIVITIES=$(wc -l < \"$ACTIVITY_LOG\")\n    echo \"📈 Session Activity Count: $TOTAL_ACTIVITIES\"\n    \n    # Show recent activity summary\n    echo \"🕒 Recent Activities:\"\n    tail -n 3 \"$ACTIVITY_LOG\" | while read -r line; do\n        echo \"  • $line\"\n    done\n    \n    # File operation summary\n    WRITE_COUNT=$(grep -c \"Write\\|Edit\" \"$ACTIVITY_LOG\" 2>/dev/null || echo 0)\n    read_COUNT=$(grep -c \"Read\" \"$ACTIVITY_LOG\" 2>/dev/null || echo 0)\n    \n    echo \"📊 Today's Summary:\"\n    echo \"  • Write/Edit operations: $WRITE_COUNT\"\n    echo \"  • Read operations: $READ_COUNT\"\nfi\n\n# Weekly activity archive (every Sunday)\nif [ \"$(date +%u)\" = \"7\" ]; then\n    ARCHIVE_DIR=\".claude/archive/$(date +%Y-%m)\"\n    mkdir -p \"$ARCHIVE_DIR\"\n    \n    # Move old logs to archive\n    find .claude -name \"activity-*.log\" -mtime +7 -exec mv {} \"$ARCHIVE_DIR/\" \\;\n    find .claude -name \"activity-*.json\" -mtime +7 -exec mv {} \"$ARCHIVE_DIR/\" \\;\n    \n    echo \"📦 Weekly archive created in $ARCHIVE_DIR\"\nfi\n\necho \"✅ Activity logged to $ACTIVITY_LOG\"\n\nexit 0"
      },
      "troubleshooting": [
        {
          "issue": "Activity logs show incorrect timestamps or 'unknown' dates",
          "solution": "ISO-8601 date varies by platform. Replace 'date --iso-8601=seconds' with portable: 'date -u +\"%Y-%m-%dT%H:%M:%SZ\"'. Works on both Linux and macOS without fallback."
        },
        {
          "issue": "JSON activity log is malformed with trailing commas",
          "solution": "Each append adds trailing comma creating invalid JSON. Wrap in array: initialize with '[', append without trailing comma, close ']' on end. Or rebuild: 'jq -s . file.json'."
        },
        {
          "issue": "Weekly archive triggers fail on macOS (date +%u returns wrong day)",
          "solution": "macOS date lacks %u for weekday. Replace with: 'if [ \"$(date +%w)\" = \"0\" ]; then' (Sunday=0). Or use portable: '[ $(date +%A) = \"Sunday\" ]' for name-based check."
        },
        {
          "issue": "Session IDs duplicate when multiple Claude instances run simultaneously",
          "solution": "Current session_id uses timestamp+PID but PID can conflict. Add random suffix: \"$(date +%Y%m%d_%H%M%S)_$$_$RANDOM\" or use UUID: \"$(uuidgen 2>/dev/null || echo $RANDOM$RANDOM)\"."
        },
        {
          "issue": "Log files locked causing permission denied errors on write",
          "solution": "Concurrent writes from parallel Claude sessions. Use flock: '(flock -x 200; echo \"..\" >> log; ) 200>/var/lock/activity.lock' for atomic append operations."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/real-time-activity-tracker"
    },
    {
      "slug": "redis-cache-invalidator",
      "description": "Automatically clears relevant Redis cache keys when data model files are modified",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "redis",
        "cache",
        "performance",
        "data-models",
        "invalidation"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Intelligent cache key invalidation",
        "Model-based cache clearing",
        "Pattern matching for cache keys",
        "Safe asynchronous cache flushing",
        "Multi-language model support",
        "Cache consistency maintenance"
      ],
      "useCases": [
        "Invalidate cache when data models are modified",
        "Maintain cache consistency in Redis",
        "Clear related cache entries automatically",
        "Prevent stale data in cache after model changes",
        "Optimize cache management workflow",
        "Handle cache invalidation for microservices",
        "Automate cache clearing for API responses",
        "Ensure data consistency across cache layers"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/redis-cache-invalidator.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/bin/bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\necho \"🔄 Redis Cache Invalidator - Analyzing file changes...\"\necho \"📄 File: $FILE_PATH\"\n\n# Check if this is a model or data file that should trigger cache invalidation\nif [[ \"$FILE_PATH\" == *models/*.js ]] || [[ \"$FILE_PATH\" == *models/*.py ]] || [[ \"$FILE_PATH\" == *models/*.ts ]] || [[ \"$FILE_PATH\" == *schemas/*.* ]] || [[ \"$FILE_PATH\" == *entities/*.* ]]; then\n    \n    MODEL_NAME=$(basename \"${FILE_PATH%.*}\")\n    echo \"📊 Model detected: $MODEL_NAME\"\n    \n    # Check if Redis CLI is available\n    if ! command -v redis-cli >/dev/null 2>&1; then\n        echo \"⚠️ redis-cli not found - please install Redis CLI tools\"\n        echo \"💡 Install with: apt-get install redis-tools (Ubuntu) or brew install redis (macOS)\"\n        exit 0\n    fi\n    \n    # Test Redis connection\n    if ! redis-cli ping >/dev/null 2>&1; then\n        echo \"⚠️ Redis server not accessible - skipping cache invalidation\"\n        echo \"💡 Ensure Redis server is running and accessible\"\n        exit 0\n    fi\n    \n    echo \"🔍 Scanning for cache keys related to: $MODEL_NAME\"\n    \n    # Find cache keys related to this model\n    CACHE_KEYS=$(redis-cli --scan --pattern \"*${MODEL_NAME}*\" 2>/dev/null)\n    \n    if [ -n \"$CACHE_KEYS\" ]; then\n        KEY_COUNT=$(echo \"$CACHE_KEYS\" | wc -l)\n        echo \"🗑️ Found $KEY_COUNT cache keys to invalidate:\"\n        \n        # Show first few keys for confirmation\n        echo \"$CACHE_KEYS\" | head -5 | while read -r key; do\n            echo \"  • $key\"\n        done\n        \n        if [ \"$KEY_COUNT\" -gt 5 ]; then\n            echo \"  ... and $((KEY_COUNT - 5)) more keys\"\n        fi\n        \n        # Delete the keys\n        echo \"$CACHE_KEYS\" | xargs -r redis-cli DEL >/dev/null 2>&1\n        echo \"✅ Invalidated $KEY_COUNT cache keys for model: $MODEL_NAME\"\n    else\n        echo \"ℹ️ No cache keys found for model: $MODEL_NAME\"\n    fi\n    \n    # Additional patterns to check\n    echo \"🔍 Checking additional cache patterns...\"\n    \n    # Check for API route caches\n    API_KEYS=$(redis-cli --scan --pattern \"api:*${MODEL_NAME}*\" 2>/dev/null)\n    if [ -n \"$API_KEYS\" ]; then\n        API_COUNT=$(echo \"$API_KEYS\" | wc -l)\n        echo \"$API_KEYS\" | xargs -r redis-cli DEL >/dev/null 2>&1\n        echo \"✅ Invalidated $API_COUNT API cache keys\"\n    fi\n    \n    # Check for query result caches\n    QUERY_KEYS=$(redis-cli --scan --pattern \"query:*${MODEL_NAME}*\" 2>/dev/null)\n    if [ -n \"$QUERY_KEYS\" ]; then\n        QUERY_COUNT=$(echo \"$QUERY_KEYS\" | wc -l)\n        echo \"$QUERY_KEYS\" | xargs -r redis-cli DEL >/dev/null 2>&1\n        echo \"✅ Invalidated $QUERY_COUNT query cache keys\"\n    fi\n    \n    # Check current Redis stats\n    echo \"\"\n    echo \"📊 Redis Cache Statistics:\"\n    TOTAL_KEYS=$(redis-cli DBSIZE 2>/dev/null || echo \"unknown\")\n    MEMORY_USAGE=$(redis-cli INFO memory 2>/dev/null | grep used_memory_human | cut -d: -f2 | tr -d '\\r' || echo \"unknown\")\n    echo \"  • Total keys: $TOTAL_KEYS\"\n    echo \"  • Memory usage: $MEMORY_USAGE\"\n    \n    echo \"\"\n    echo \"💡 Cache Invalidation Tips:\"\n    echo \"  • Use consistent cache key naming patterns\"\n    echo \"  • Consider cache TTL for automatic expiration\"\n    echo \"  • Monitor cache hit/miss ratios\"\n    echo \"  • Use Redis keyspace notifications for advanced invalidation\"\n    \n    echo \"\"\n    echo \"🎯 Cache invalidation complete!\"\n    \nelif [[ \"$FILE_PATH\" == *config/*.* ]] || [[ \"$FILE_PATH\" == *.env ]]; then\n    echo \"⚙️ Configuration file detected - consider full cache flush if needed\"\n    echo \"💡 Run 'redis-cli FLUSHDB' manually if configuration affects cached data\"\n    \nelse\n    echo \"ℹ️ File does not require cache invalidation: $FILE_PATH\"\nfi\n\nexit 0"
      },
      "troubleshooting": [
        {
          "issue": "Hook skips invalidation with redis-cli not found warning",
          "solution": "Install Redis CLI tools using 'apt-get install redis-tools' (Ubuntu/Debian) or 'brew install redis' (macOS). The hook gracefully exits if Redis tools are unavailable."
        },
        {
          "issue": "Redis server not accessible error during invalidation",
          "solution": "Verify Redis is running with 'redis-cli ping'. Check connection settings in redis.conf. The hook tests connectivity before attempting invalidation and exits safely if unreachable."
        },
        {
          "issue": "Too many or too few cache keys being invalidated",
          "solution": "Review cache key naming patterns. The hook uses wildcard matching on model names. Use consistent prefixes like 'api:', 'query:', 'model:' for precise pattern matching and control."
        },
        {
          "issue": "Hook triggers on non-model files causing unnecessary scans",
          "solution": "The hook only processes files in */models/*, */schemas/*, */entities/* directories. Organize your codebase to match these patterns or customize the path matching logic in the script."
        },
        {
          "issue": "Cache invalidation completes but stale data persists",
          "solution": "Check if your application uses multiple Redis databases (DB0, DB1, etc.) or instances. The hook targets the default database. Use 'redis-cli -n <db>' to verify which database stores your cache."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/redis-cache-invalidator"
    },
    {
      "slug": "rust-cargo-check",
      "description": "Automatically runs cargo check and clippy when Rust files are modified",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "rust",
        "cargo",
        "clippy",
        "linting",
        "compilation"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Fast compilation checking with cargo check",
        "Code linting with clippy",
        "Rust best practices enforcement",
        "Dependency validation",
        "Performance optimization suggestions",
        "Security vulnerability detection"
      ],
      "useCases": [
        "Validate Rust code compilation before commits",
        "Catch common Rust programming errors early",
        "Enforce Rust coding standards with clippy",
        "Check dependency compatibility",
        "Identify performance improvement opportunities",
        "Ensure code follows Rust best practices",
        "Run security analysis on Rust code",
        "Validate Cargo.toml configuration changes"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/rust-cargo-check.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/bin/bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Check if this is a Rust file or Cargo configuration\nif [[ \"$FILE_PATH\" == *.rs ]] || [[ \"$FILE_PATH\" == *Cargo.toml ]] || [[ \"$FILE_PATH\" == *Cargo.lock ]]; then\n    echo \"🦀 Rust Cargo Check - Analyzing Rust code...\"\n    echo \"📄 File: $FILE_PATH\"\n    \n    # Check if cargo is available\n    if ! command -v cargo >/dev/null 2>&1; then\n        echo \"⚠️ Cargo not found - please install Rust toolchain\"\n        echo \"💡 Install from: https://rustup.rs/\"\n        exit 1\n    fi\n    \n    # Check if we're in a Rust project\n    if [ ! -f \"Cargo.toml\" ]; then\n        echo \"⚠️ No Cargo.toml found - not a Rust project\"\n        exit 0\n    fi\n    \n    echo \"🔍 Running Rust toolchain checks...\"\n    \n    # Step 1: Run cargo check for fast compilation validation\n    echo \"⚡ Running cargo check (fast compilation check)...\"\n    if cargo check --message-format=short; then\n        echo \"✅ Cargo check passed - code compiles successfully\"\n    else\n        echo \"❌ Cargo check failed - compilation errors found\"\n        echo \"💡 Fix compilation errors before proceeding\"\n        exit 1\n    fi\n    \n    # Step 2: Run clippy for linting (if available)\n    echo \"\"\n    echo \"📋 Running clippy (Rust linter)...\"\n    if command -v cargo-clippy >/dev/null 2>&1 || cargo clippy --version >/dev/null 2>&1; then\n        if cargo clippy --message-format=short -- -W clippy::pedantic -W clippy::nursery; then\n            echo \"✅ Clippy analysis passed - no linting issues\"\n        else\n            echo \"⚠️ Clippy found linting issues (non-blocking)\"\n        fi\n    else\n        echo \"ℹ️ Clippy not available - install with: rustup component add clippy\"\n    fi\n    \n    # Step 3: Check formatting (if rustfmt is available)\n    echo \"\"\n    echo \"🎨 Checking code formatting...\"\n    if command -v rustfmt >/dev/null 2>&1; then\n        if cargo fmt -- --check; then\n            echo \"✅ Code formatting is correct\"\n        else\n            echo \"⚠️ Code formatting issues found\"\n            echo \"💡 Run 'cargo fmt' to fix formatting\"\n        fi\n    else\n        echo \"ℹ️ rustfmt not available - install with: rustup component add rustfmt\"\n    fi\n    \n    # Step 4: Security audit (if cargo-audit is available)\n    echo \"\"\n    echo \"🔒 Running security audit...\"\n    if command -v cargo-audit >/dev/null 2>&1; then\n        if cargo audit; then\n            echo \"✅ No known security vulnerabilities found\"\n        else\n            echo \"⚠️ Security vulnerabilities detected - review dependencies\"\n        fi\n    else\n        echo \"ℹ️ cargo-audit not available - install with: cargo install cargo-audit\"\n    fi\n    \n    # Step 5: Project analysis\n    echo \"\"\n    echo \"📊 Project Analysis:\"\n    \n    # Count Rust files\n    RUST_FILES=$(find . -name \"*.rs\" -not -path \"./target/*\" | wc -l)\n    echo \"  • Rust files: $RUST_FILES\"\n    \n    # Check for tests\n    TEST_FILES=$(find . -name \"*.rs\" -not -path \"./target/*\" -exec grep -l \"#\\[test\\]\\|#\\[cfg(test)\\]\" {} \\; | wc -l)\n    echo \"  • Files with tests: $TEST_FILES\"\n    \n    # Check dependencies\n    DEPENDENCIES=$(grep -c '^[a-zA-Z].*=' Cargo.toml 2>/dev/null || echo 0)\n    echo \"  • Dependencies: $DEPENDENCIES\"\n    \n    # Check for unsafe blocks\n    if find . -name \"*.rs\" -not -path \"./target/*\" -exec grep -l \"unsafe\" {} \\; | head -1 >/dev/null 2>&1; then\n        UNSAFE_COUNT=$(find . -name \"*.rs\" -not -path \"./target/*\" -exec grep -c \"unsafe\" {} \\; | awk '{sum+=$1} END {print sum}')\n        echo \"  • ⚠️ Unsafe blocks found: $UNSAFE_COUNT\"\n    fi\n    \n    echo \"\"\n    echo \"💡 Rust Development Tips:\"\n    echo \"  • Use 'cargo test' to run all tests\"\n    echo \"  • Use 'cargo build --release' for optimized builds\"\n    echo \"  • Use 'cargo doc --open' to generate and view documentation\"\n    echo \"  • Use 'cargo bench' for benchmarking (if available)\"\n    echo \"  • Consider using 'cargo watch' for continuous testing\"\n    \n    echo \"\"\n    echo \"🎯 Rust code analysis complete!\"\n    \nelse\n    echo \"ℹ️ File is not a Rust file: $FILE_PATH\"\nfi\n\nexit 0"
      },
      "troubleshooting": [
        {
          "issue": "Cargo check fails with 'No Cargo.toml found' in monorepos",
          "solution": "Hook searches from file directory upward but may fail in nested workspaces. Add cd logic to find workspace root: while [ ! -f Cargo.toml ] && [ $(pwd) != / ]; do cd ..; done before running cargo commands."
        },
        {
          "issue": "Target directory compilation artifacts cause slow check times",
          "solution": "Cargo check reuses incremental compilation from target/. Ensure .gitignore excludes target/ but preserve it locally. Use cargo clean selectively or CARGO_TARGET_DIR to separate hook builds from development builds."
        },
        {
          "issue": "Cargo audit fails when offline or network restricted environments",
          "solution": "Script treats cargo-audit as optional but doesn't handle network errors. Add CARGO_NET_OFFLINE=true check or wrap in: timeout 5s cargo audit || echo 'Audit skipped (offline)' to prevent hanging on network unavailable."
        },
        {
          "issue": "Multiple Rust files changed simultaneously trigger concurrent checks",
          "solution": "PostToolUse fires per operation causing parallel cargo check processes. Add flock-based locking: { flock -n 200 || exit 0; cargo check; } 200>/tmp/cargo-check.lock to serialize executions and prevent resource contention."
        },
        {
          "issue": "Hook executes before file write completes showing stale errors",
          "solution": "PostToolUse hooks fire after tool completion but file system may buffer writes. Add small delay: sleep 0.1 before cargo check, or verify file timestamp: [ \"$FILE_PATH\" -nt /tmp/last-check ] to ensure fresh content is analyzed."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/rust-cargo-check"
    },
    {
      "slug": "scss-auto-compiler",
      "description": "Automatically compiles SCSS/Sass files to CSS when they are modified",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "scss",
        "sass",
        "css",
        "styling",
        "compilation"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Automatic SCSS/Sass compilation to CSS",
        "Source map generation for debugging",
        "Support for both SCSS and Sass syntax",
        "Customizable output formatting",
        "Error reporting and validation",
        "Watch mode compatibility"
      ],
      "useCases": [
        "Compile SCSS files to CSS automatically",
        "Generate source maps for easier debugging",
        "Maintain CSS output in sync with SCSS changes",
        "Streamline SCSS development workflow",
        "Validate SCSS syntax and catch errors",
        "Support both indented and SCSS syntax",
        "Integrate SCSS compilation into development process",
        "Automate CSS generation for web projects"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/scss-auto-compiler.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/bin/bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Check if this is a SCSS or Sass file\nif [[ \"$FILE_PATH\" == *.scss ]] || [[ \"$FILE_PATH\" == *.sass ]]; then\n    echo \"🎨 SCSS Auto-Compiler - Processing stylesheet...\"\n    echo \"📄 File: $FILE_PATH\"\n    \n    # Check if file exists\n    if [ ! -f \"$FILE_PATH\" ]; then\n        echo \"⚠️ File not found: $FILE_PATH\"\n        exit 1\n    fi\n    \n    # Determine output CSS file path\n    if [[ \"$FILE_PATH\" == *.scss ]]; then\n        CSS_OUTPUT=\"${FILE_PATH%.scss}.css\"\n        MAP_OUTPUT=\"${FILE_PATH%.scss}.css.map\"\n    else  # .sass file\n        CSS_OUTPUT=\"${FILE_PATH%.sass}.css\"\n        MAP_OUTPUT=\"${FILE_PATH%.sass}.css.map\"\n    fi\n    \n    echo \"📁 Output: $CSS_OUTPUT\"\n    \n    # Check if Sass compiler is available\n    if command -v sass >/dev/null 2>&1; then\n        SASS_CMD=\"sass\"\n    elif command -v npx >/dev/null 2>&1 && npx sass --version >/dev/null 2>&1; then\n        SASS_CMD=\"npx sass\"\n    elif command -v node-sass >/dev/null 2>&1; then\n        SASS_CMD=\"node-sass\"\n        echo \"ℹ️ Using node-sass (consider upgrading to Dart Sass)\"\n    else\n        echo \"⚠️ No Sass compiler found\"\n        echo \"💡 Install options:\"\n        echo \"  • npm install -g sass (Dart Sass - recommended)\"\n        echo \"  • npm install sass (project-local)\"\n        echo \"  • brew install sass/sass/sass (macOS)\"\n        exit 1\n    fi\n    \n    echo \"🔧 Compiling with $SASS_CMD...\"\n    \n    # Compile SCSS/Sass to CSS with source maps\n    if [[ \"$SASS_CMD\" == \"node-sass\" ]]; then\n        # node-sass syntax\n        if node-sass \"$FILE_PATH\" \"$CSS_OUTPUT\" --source-map true --source-map-contents; then\n            echo \"✅ SCSS compiled successfully with node-sass\"\n        else\n            echo \"❌ SCSS compilation failed\"\n            exit 1\n        fi\n    else\n        # Dart Sass syntax\n        if $SASS_CMD \"$FILE_PATH\" \"$CSS_OUTPUT\" --source-map; then\n            echo \"✅ SCSS compiled successfully\"\n        else\n            echo \"❌ SCSS compilation failed\"\n            exit 1\n        fi\n    fi\n    \n    # Check output file size\n    if [ -f \"$CSS_OUTPUT\" ]; then\n        CSS_SIZE=$(stat -f%z \"$CSS_OUTPUT\" 2>/dev/null || stat -c%s \"$CSS_OUTPUT\" 2>/dev/null || echo \"unknown\")\n        echo \"📊 Generated CSS: ${CSS_SIZE} bytes\"\n        \n        # Check for source map\n        if [ -f \"$MAP_OUTPUT\" ]; then\n            echo \"🗺️ Source map: $MAP_OUTPUT\"\n        fi\n    fi\n    \n    # Additional analysis\n    echo \"\"\n    echo \"🔍 SCSS Analysis:\"\n    \n    # Count SCSS features used\n    if grep -q '@import\\|@use' \"$FILE_PATH\" 2>/dev/null; then\n        IMPORT_COUNT=$(grep -c '@import\\|@use' \"$FILE_PATH\" 2>/dev/null || echo 0)\n        echo \"  • Imports/Uses: $IMPORT_COUNT\"\n    fi\n    \n    if grep -q '@mixin' \"$FILE_PATH\" 2>/dev/null; then\n        MIXIN_COUNT=$(grep -c '@mixin' \"$FILE_PATH\" 2>/dev/null || echo 0)\n        echo \"  • Mixins defined: $MIXIN_COUNT\"\n    fi\n    \n    if grep -q '@include' \"$FILE_PATH\" 2>/dev/null; then\n        INCLUDE_COUNT=$(grep -c '@include' \"$FILE_PATH\" 2>/dev/null || echo 0)\n        echo \"  • Mixin includes: $INCLUDE_COUNT\"\n    fi\n    \n    if grep -q '\\$[a-zA-Z]' \"$FILE_PATH\" 2>/dev/null; then\n        echo \"  • 💡 Variables detected - using SCSS features\"\n    fi\n    \n    if grep -q '&' \"$FILE_PATH\" 2>/dev/null; then\n        echo \"  • 💡 Nested selectors detected\"\n    fi\n    \n    # Check for common issues\n    echo \"\"\n    echo \"🔍 Code Quality Check:\"\n    \n    if grep -q '!important' \"$FILE_PATH\" 2>/dev/null; then\n        IMPORTANT_COUNT=$(grep -c '!important' \"$FILE_PATH\" 2>/dev/null || echo 0)\n        echo \"  • ⚠️ !important usage: $IMPORTANT_COUNT (consider refactoring)\"\n    fi\n    \n    if grep -q 'color: #[0-9a-fA-F]\\{3,6\\}' \"$FILE_PATH\" 2>/dev/null; then\n        echo \"  • 💡 Consider using CSS custom properties for colors\"\n    fi\n    \n    echo \"\"\n    echo \"💡 SCSS Development Tips:\"\n    echo \"  • Use @use instead of @import for better performance\"\n    echo \"  • Organize styles with partials (_filename.scss)\"\n    echo \"  • Use mixins for reusable style patterns\"\n    echo \"  • Leverage SCSS variables for consistent theming\"\n    echo \"  • Use nested selectors sparingly (max 3-4 levels)\"\n    \n    echo \"\"\n    echo \"🎯 SCSS compilation complete!\"\n    \nelse\n    echo \"ℹ️ File is not a SCSS/Sass file: $FILE_PATH\"\nfi\n\nexit 0"
      },
      "troubleshooting": [
        {
          "issue": "Compilation fails with 'sass command not found'",
          "solution": "Install Dart Sass globally with `npm install -g sass` or locally `npm install sass`, then restart terminal. For project-specific, hook uses `npx sass` which auto-detects local installations."
        },
        {
          "issue": "Source maps not generated in output directory",
          "solution": "Ensure write permissions on output directory. Hook generates maps automatically: `$SASS_CMD \"$FILE_PATH\" \"$CSS_OUTPUT\" --source-map`. Check if MAP_OUTPUT path is writable and not gitignored."
        },
        {
          "issue": "Hook compiles partials creating unwanted CSS",
          "solution": "Add early exit for partials: `if [[ \"$(basename \"$FILE_PATH\")\" == _* ]]; then exit 0; fi` before compilation. SCSS partials (prefixed with _) shouldn't compile to separate CSS files."
        },
        {
          "issue": "node-sass deprecated warnings appear in output",
          "solution": "Migrate to Dart Sass: uninstall `npm uninstall node-sass`, install `npm install sass`. Hook automatically prefers Dart Sass over node-sass when both are available and shows migration notice."
        },
        {
          "issue": "Cannot parse @import vs @use distinction",
          "solution": "Hook uses regex `grep -q '@import\\|@use'` to detect both. For separate counts, use: `IMPORT=$(grep -c '@import' ...)` and `USE=$(grep -c '@use' ...)` to distinguish modern @use from legacy @import."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/scss-auto-compiler"
    },
    {
      "slug": "security-scanner-hook",
      "description": "Automated security vulnerability scanning that integrates with development workflow to detect and prevent security issues before deployment",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-16",
      "tags": [
        "security",
        "vulnerability",
        "scanning",
        "automation",
        "compliance"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Comprehensive security vulnerability scanning",
        "Static code analysis with multiple SAST tools",
        "Dependency vulnerability detection",
        "Secrets and credential scanning",
        "Container security analysis",
        "OWASP Top 10 compliance checking",
        "Automated remediation suggestions",
        "Integration with CI/CD pipelines"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/security-scanner-hook.sh",
              "matchers": [
                "write",
                "edit",
                "multiedit"
              ]
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\necho \"🔒 Running security scans on $FILE_PATH...\"\n\n# Secrets detection\necho \"Scanning for secrets...\"\nif command -v truffleHog &> /dev/null; then\n  truffleHog --regex --entropy=False \"$FILE_PATH\" 2>/dev/null\n  if [ $? -ne 0 ]; then\n    echo \"⚠️ Potential secrets detected in $FILE_PATH\" >&2\n  fi\nfi\n\n# Static analysis with Semgrep\nif command -v semgrep &> /dev/null; then\n  echo \"Running static security analysis...\"\n  semgrep --config=auto \"$FILE_PATH\" 2>/dev/null\n  if [ $? -eq 0 ]; then\n    echo \"✅ No security issues found with Semgrep\" >&2\n  else\n    echo \"⚠️ Security issues detected with Semgrep\" >&2\n  fi\nfi\n\n# Language-specific security checks\nEXT=\"${FILE_PATH##*.}\"\ncase \"$EXT\" in\n  js|jsx|ts|tsx)\n    # Node.js security audit\n    if [ -f \"package.json\" ] && command -v npm &> /dev/null; then\n      echo \"Running npm audit...\"\n      npm audit --audit-level=moderate 2>/dev/null || echo \"⚠️ Vulnerabilities found in dependencies\" >&2\n    fi\n    ;;\n  py)\n    # Python security checks\n    if command -v bandit &> /dev/null; then\n      echo \"Running Bandit security scan...\"\n      bandit \"$FILE_PATH\" 2>/dev/null || echo \"⚠️ Security issues detected with Bandit\" >&2\n    fi\n    ;;\n  go)\n    # Go security checks\n    if command -v gosec &> /dev/null; then\n      echo \"Running gosec security scan...\"\n      gosec \"$FILE_PATH\" 2>/dev/null || echo \"⚠️ Security issues detected with gosec\" >&2\n    fi\n    ;;\nesac\n\necho \"✅ Security scan completed for $FILE_PATH\" >&2\nexit 0"
      },
      "useCases": [
        "Automated security testing in CI/CD pipelines",
        "Pre-commit security validation",
        "Continuous security monitoring during development",
        "OWASP compliance checking",
        "Dependency vulnerability tracking",
        "Secrets and credential leak prevention"
      ],
      "documentationUrl": "https://owasp.org/www-project-top-ten/",
      "troubleshooting": [
        {
          "issue": "truffleHog reports false positives on test data and mock credentials",
          "solution": "Entropy detection flags dummy data. Create .trufflehogignore: add patterns like 'test/**' or '**/fixtures/*'. Or use --exclude: 'truffleHog --exclude test/ --regex' filtering paths."
        },
        {
          "issue": "Semgrep download/install hangs during first hook execution",
          "solution": "Hook waits for semgrep auto-install timing out. Pre-install: 'pip install semgrep' or 'brew install semgrep'. Add timeout: 'timeout 30 semgrep --config=auto' preventing indefinite hangs."
        },
        {
          "issue": "npm audit returns non-zero exit code failing hook on dev dependencies",
          "solution": "Audit treats dev warnings as errors. Filter severity: 'npm audit --audit-level=high --production' ignoring dev deps. Or suppress exit: 'npm audit || echo \"Vulnerabilities logged\"'."
        },
        {
          "issue": "Bandit scans entire project instead of modified FILE_PATH",
          "solution": "Command targets single file but imports scan. Add --skip-imports: 'bandit \"$FILE_PATH\" -ll --skip B404' focusing on direct code. Or scope: 'bandit -r $(dirname \"$FILE_PATH\")' directory-level."
        },
        {
          "issue": "Security scans add 30+ seconds to every file save operation",
          "solution": "Sequential scans without caching. Run async: append '&' to each scan, wait at end. Or cache: 'if [ \"$(stat -c %Y \"$FILE_PATH\")\" -lt 60 ]; then exit; fi' skipping recent scans."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/security-scanner-hook"
    },
    {
      "slug": "sensitive-data-alert-scanner",
      "description": "Scans for potential sensitive data exposure and alerts immediately",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "security",
        "sensitive-data",
        "notification",
        "scanning",
        "privacy"
      ],
      "hookType": "Notification",
      "features": [
        "Real-time sensitive data detection",
        "API key and token scanning",
        "Password exposure prevention",
        "Email address detection",
        "Personal information monitoring",
        "Immediate security alerts"
      ],
      "useCases": [
        "Prevent accidental commits of API keys and secrets",
        "Detect exposed passwords in code files",
        "Monitor for personal information leaks",
        "Alert on potential security vulnerabilities",
        "Scan for hardcoded credentials",
        "Identify email addresses in code",
        "Prevent sensitive data exposure in repositories",
        "Maintain security compliance standards"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "notification": {
              "script": "./.claude/hooks/sensitive-data-alert-scanner.sh",
              "matchers": [
                "*"
              ]
            }
          }
        },
        "scriptContent": "#!/bin/bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Only scan for Write and Edit operations\nif [[ \"$TOOL_NAME\" != \"Write\" && \"$TOOL_NAME\" != \"Edit\" ]]; then\n  exit 0\nfi\n\necho \"🔒 Sensitive Data Alert Scanner - Analyzing file for security risks...\"\necho \"📄 File: $FILE_PATH\"\n\n# Check if file exists and is readable\nif [ ! -f \"$FILE_PATH\" ]; then\n    echo \"⚠️ File not found: $FILE_PATH\"\n    exit 0\nfi\n\n# Skip binary files\nif file \"$FILE_PATH\" | grep -q binary; then\n    echo \"ℹ️ Skipping binary file\"\n    exit 0\nfi\n\nSECURITY_ISSUES=0\nWARNINGS=0\n\necho \"🔍 Scanning for sensitive data patterns...\"\n\n# 1. API Keys and Secrets\necho \"🔑 Checking for API keys and secrets...\"\nAPI_PATTERNS=(\n    \"api[_-]?key\\s*[:=]\\s*[\\\"'][^\\\"']{8,}[\\\"']\"\n    \"secret[_-]?key\\s*[:=]\\s*[\\\"'][^\\\"']{8,}[\\\"']\"\n    \"access[_-]?token\\s*[:=]\\s*[\\\"'][^\\\"']{10,}[\\\"']\"\n    \"private[_-]?key\\s*[:=]\\s*[\\\"'][^\\\"']{20,}[\\\"']\"\n    \"client[_-]?secret\\s*[:=]\\s*[\\\"'][^\\\"']{8,}[\\\"']\"\n)\n\nfor pattern in \"${API_PATTERNS[@]}\"; do\n    if grep -iE \"$pattern\" \"$FILE_PATH\" 2>/dev/null | grep -v -iE \"(\\*\\*\\*|example|placeholder|your[_-]|demo|test|fake|dummy)\"; then\n        echo \"🚨 SECURITY ALERT: Potential API key/secret detected!\"\n        SECURITY_ISSUES=$((SECURITY_ISSUES + 1))\n    fi\ndone\n\n# 2. Password patterns\necho \"🔐 Checking for password exposure...\"\nPASSWORD_PATTERNS=(\n    \"password\\s*[:=]\\s*[\\\"'][^\\\"']{6,}[\\\"']\"\n    \"passwd\\s*[:=]\\s*[\\\"'][^\\\"']{6,}[\\\"']\"\n    \"pwd\\s*[:=]\\s*[\\\"'][^\\\"']{6,}[\\\"']\"\n)\n\nfor pattern in \"${PASSWORD_PATTERNS[@]}\"; do\n    if grep -iE \"$pattern\" \"$FILE_PATH\" 2>/dev/null | grep -v -iE \"(\\*\\*\\*|example|placeholder|your[_-]|demo|test|123456|password)\"; then\n        echo \"🚨 SECURITY ALERT: Potential password detected!\"\n        SECURITY_ISSUES=$((SECURITY_ISSUES + 1))\n    fi\ndone\n\n# 3. Database connection strings\necho \"🗄️ Checking for database credentials...\"\nif grep -iE \"(mysql://|postgresql://|mongodb://|redis://).*:.*@\" \"$FILE_PATH\" 2>/dev/null; then\n    echo \"🚨 SECURITY ALERT: Database connection string with credentials detected!\"\n    SECURITY_ISSUES=$((SECURITY_ISSUES + 1))\nfi\n\n# 4. JWT tokens\necho \"🎫 Checking for JWT tokens...\"\nif grep -E \"eyJ[A-Za-z0-9_-]+\\.[A-Za-z0-9_-]+\\.[A-Za-z0-9_-]+\" \"$FILE_PATH\" 2>/dev/null; then\n    echo \"🚨 SECURITY ALERT: JWT token detected!\"\n    SECURITY_ISSUES=$((SECURITY_ISSUES + 1))\nfi\n\n# 5. SSH private keys\necho \"🔑 Checking for SSH private keys...\"\nif grep -q \"BEGIN.*PRIVATE KEY\" \"$FILE_PATH\" 2>/dev/null; then\n    echo \"🚨 SECURITY ALERT: SSH private key detected!\"\n    SECURITY_ISSUES=$((SECURITY_ISSUES + 1))\nfi\n\n# 6. Email addresses (warning, not critical)\necho \"📧 Checking for email addresses...\"\nif grep -E \"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\" \"$FILE_PATH\" 2>/dev/null | head -3; then\n    echo \"⚠️ Email addresses detected - ensure this is intentional\"\n    WARNINGS=$((WARNINGS + 1))\nfi\n\n# 7. Credit card patterns (basic check)\necho \"💳 Checking for credit card numbers...\"\nif grep -E \"[0-9]{4}[\\s-]?[0-9]{4}[\\s-]?[0-9]{4}[\\s-]?[0-9]{4}\" \"$FILE_PATH\" 2>/dev/null; then\n    echo \"🚨 SECURITY ALERT: Potential credit card number detected!\"\n    SECURITY_ISSUES=$((SECURITY_ISSUES + 1))\nfi\n\n# 8. Social Security Numbers (US format)\necho \"🆔 Checking for SSN patterns...\"\nif grep -E \"[0-9]{3}-[0-9]{2}-[0-9]{4}\" \"$FILE_PATH\" 2>/dev/null; then\n    echo \"🚨 SECURITY ALERT: Potential SSN detected!\"\n    SECURITY_ISSUES=$((SECURITY_ISSUES + 1))\nfi\n\n# 9. Phone numbers\necho \"📞 Checking for phone numbers...\"\nif grep -E \"\\+?[1-9][0-9]{1,3}[\\s-]?\\(?[0-9]{3}\\)?[\\s-]?[0-9]{3}[\\s-]?[0-9]{4}\" \"$FILE_PATH\" 2>/dev/null; then\n    echo \"⚠️ Phone numbers detected - verify if intentional\"\n    WARNINGS=$((WARNINGS + 1))\nfi\n\n# Summary\necho \"\"\necho \"📊 Security Scan Results:\"\necho \"  • Critical Issues: $SECURITY_ISSUES\"\necho \"  • Warnings: $WARNINGS\"\n\nif [ $SECURITY_ISSUES -gt 0 ]; then\n    echo \"\"\n    echo \"🚨 CRITICAL SECURITY ALERT!\"\n    echo \"🛡️ Action Required:\"\n    echo \"  • Review detected sensitive data immediately\"\n    echo \"  • Remove or mask sensitive information\"\n    echo \"  • Use environment variables for secrets\"\n    echo \"  • Consider using a secrets management service\"\n    echo \"  • Check if file should be added to .gitignore\"\nfi\n\nif [ $WARNINGS -gt 0 ]; then\n    echo \"\"\n    echo \"⚠️ Security Warnings:\"\n    echo \"  • Review detected information for necessity\"\n    echo \"  • Consider data privacy implications\"\n    echo \"  • Verify compliance with data protection regulations\"\nfi\n\necho \"\"\necho \"💡 Security Best Practices:\"\necho \"  • Use environment variables for sensitive data\"\necho \"  • Implement proper secrets management\"\necho \"  • Add sensitive files to .gitignore\"\necho \"  • Regular security audits of codebase\"\necho \"  • Use code scanning tools in CI/CD\"\n\necho \"\"\necho \"🎯 Security scan complete!\"\n\nexit 0"
      },
      "troubleshooting": [
        {
          "issue": "False positives on example code and test fixtures with dummy keys",
          "solution": "Exclusion patterns filter common placeholders but miss context-specific ones. Add .securityignore file and check: grep -qF \"$FILE_PATH\" .securityignore && exit 0 to whitelist specific files or patterns."
        },
        {
          "issue": "Notification hook timing runs before file write completes causing empty scans",
          "solution": "Notification hooks fire during operation, not after. File may not exist yet. Add retry loop: for i in {1..5}; do [ -f \"$FILE_PATH\" ] && break; sleep 0.1; done before scanning to ensure file availability."
        },
        {
          "issue": "Notification hook receives different INPUT schema than PostToolUse",
          "solution": "Notification hooks fire mid-operation with partial data. Input may lack file_path or use alternative fields. Extend jq filter: '.file_path // .tool_input.file_path // .path // \"\"' to handle schema variations across hook types."
        },
        {
          "issue": "Grep patterns match commented-out secrets in code documentation",
          "solution": "Current regex doesn't exclude comments. Add language-aware filtering: grep -v '^\\s*[#/]' for basic comment detection, or use awk to skip comment blocks before pattern matching for comprehensive filtering."
        },
        {
          "issue": "Security scan exits zero even when critical issues detected",
          "solution": "Script always exits 0 regardless of SECURITY_ISSUES count. Change final exit: [ $SECURITY_ISSUES -gt 0 ] && exit 1 || exit 0 to fail hook on findings, forcing Claude to acknowledge security alerts before proceeding."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/sensitive-data-alert-scanner"
    },
    {
      "slug": "session-metrics-collector",
      "description": "Collects and reports detailed metrics about the coding session when Claude stops",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "metrics",
        "analytics",
        "stop-hook",
        "performance",
        "statistics"
      ],
      "hookType": "Stop",
      "features": [
        "Comprehensive session analytics",
        "File modification tracking",
        "Language usage statistics",
        "Productivity metrics collection",
        "Session duration measurement",
        "Git integration for change tracking"
      ],
      "useCases": [
        "Track coding session productivity",
        "Analyze development patterns",
        "Measure session effectiveness",
        "Generate development reports",
        "Monitor coding habits over time",
        "Collect team productivity metrics",
        "Analyze language usage trends",
        "Create development insights"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "stop": {
              "script": "./.claude/hooks/session-metrics-collector.sh",
              "matchers": [
                "*"
              ]
            }
          }
        },
        "scriptContent": "#!/bin/bash\n\necho \"📊 Session Metrics Collector - Gathering session analytics...\"\necho \"⏱️ Session ended: $(date)\"\n\n# Create metrics directory\nmkdir -p .metrics\n\n# Session metadata\nSESSION_ID=\"$(date +%Y%m%d_%H%M%S)\"\nMETRICS_FILE=\".metrics/session-${SESSION_ID}.json\"\nEND_TIME=$(date)\nEND_TIMESTAMP=$(date +%s)\n\necho \"💾 Collecting session metrics...\"\n\n# Get session start time (approximate from oldest .claude file or fallback)\nif [ -d \".claude\" ] && [ \"$(find .claude -type f 2>/dev/null | wc -l)\" -gt 0 ]; then\n    START_TIMESTAMP=$(stat -f %B .claude/*.log 2>/dev/null | head -1 || echo $((END_TIMESTAMP - 3600)))\nelse\n    # Fallback: assume 1 hour session\n    START_TIMESTAMP=$((END_TIMESTAMP - 3600))\nfi\n\nSESSION_DURATION=$((END_TIMESTAMP - START_TIMESTAMP))\nSESSION_HOURS=$((SESSION_DURATION / 3600))\nSESSION_MINUTES=$(((SESSION_DURATION % 3600) / 60))\n\necho \"⏱️ Session Duration: ${SESSION_HOURS}h ${SESSION_MINUTES}m\"\n\n# File statistics\necho \"📁 Analyzing file changes...\"\n\n# Git-based analysis (preferred)\nif git rev-parse --git-dir >/dev/null 2>&1; then\n    FILES_MODIFIED=$(git diff --name-only 2>/dev/null | wc -l | tr -d ' ')\n    FILES_ADDED=$(git diff --name-status 2>/dev/null | grep '^A' | wc -l | tr -d ' ')\n    FILES_DELETED=$(git diff --name-status 2>/dev/null | grep '^D' | wc -l | tr -d ' ')\n    \n    # Line statistics\n    LINE_STATS=$(git diff --shortstat 2>/dev/null || echo \"0 files changed\")\n    LINES_ADDED=$(echo \"$LINE_STATS\" | grep -o '[0-9]\\+ insertion' | grep -o '[0-9]\\+' || echo 0)\n    LINES_DELETED=$(echo \"$LINE_STATS\" | grep -o '[0-9]\\+ deletion' | grep -o '[0-9]\\+' || echo 0)\n    \n    # Languages used\n    LANGUAGES=$(git diff --name-only 2>/dev/null | sed 's/.*\\.//' | sort | uniq -c | sort -nr | head -5)\nelse\n    # Fallback: recent file changes\n    FILES_MODIFIED=$(find . -type f -newer .metrics 2>/dev/null | wc -l | tr -d ' ' || echo \"0\")\n    FILES_ADDED=\"unknown\"\n    FILES_DELETED=\"unknown\"\n    LINES_ADDED=\"unknown\"\n    LINES_DELETED=\"unknown\"\n    LANGUAGES=\"unknown\"\nfi\n\necho \"📊 File Statistics:\"\necho \"  • Files Modified: $FILES_MODIFIED\"\necho \"  • Files Added: $FILES_ADDED\"\necho \"  • Files Deleted: $FILES_DELETED\"\necho \"  • Lines Added: $LINES_ADDED\"\necho \"  • Lines Deleted: $LINES_DELETED\"\n\n# Repository analysis\nif git rev-parse --git-dir >/dev/null 2>&1; then\n    REPO_NAME=$(basename \"$(git rev-parse --show-toplevel)\" 2>/dev/null || echo \"unknown\")\n    CURRENT_BRANCH=$(git branch --show-current 2>/dev/null || echo \"unknown\")\n    COMMIT_COUNT=$(git rev-list --count HEAD 2>/dev/null || echo \"unknown\")\n    \n    echo \"📂 Repository Info:\"\n    echo \"  • Repository: $REPO_NAME\"\n    echo \"  • Branch: $CURRENT_BRANCH\"\n    echo \"  • Total Commits: $COMMIT_COUNT\"\nfi\n\n# System information\nCWD=$(pwd)\nUSER=$(whoami 2>/dev/null || echo \"unknown\")\nHOST=$(hostname 2>/dev/null || echo \"unknown\")\n\necho \"🖥️ Environment:\"\necho \"  • User: $USER\"\necho \"  • Host: $HOST\"\necho \"  • Directory: $(basename \"$CWD\")\"\n\n# Activity analysis from .claude logs\nif [ -d \".claude\" ]; then\n    ACTIVITY_COUNT=$(find .claude -name \"*.log\" -exec cat {} \\; 2>/dev/null | wc -l | tr -d ' ')\n    echo \"📈 Activity: $ACTIVITY_COUNT logged actions\"\nfi\n\n# Generate JSON metrics\necho \"💾 Saving detailed metrics to: $METRICS_FILE\"\n\ncat > \"$METRICS_FILE\" << EOF\n{\n  \"session\": {\n    \"id\": \"$SESSION_ID\",\n    \"start_time\": \"$(date -r $START_TIMESTAMP 2>/dev/null || echo 'unknown')\",\n    \"end_time\": \"$END_TIME\",\n    \"duration_seconds\": $SESSION_DURATION,\n    \"duration_formatted\": \"${SESSION_HOURS}h ${SESSION_MINUTES}m\"\n  },\n  \"files\": {\n    \"modified\": $FILES_MODIFIED,\n    \"added\": $FILES_ADDED,\n    \"deleted\": $FILES_DELETED\n  },\n  \"lines\": {\n    \"added\": $LINES_ADDED,\n    \"deleted\": $LINES_DELETED\n  },\n  \"repository\": {\n    \"name\": \"$REPO_NAME\",\n    \"branch\": \"$CURRENT_BRANCH\",\n    \"total_commits\": $COMMIT_COUNT\n  },\n  \"environment\": {\n    \"user\": \"$USER\",\n    \"host\": \"$HOST\",\n    \"working_directory\": \"$CWD\"\n  },\n  \"productivity\": {\n    \"files_per_hour\": $(echo \"scale=2; $FILES_MODIFIED * 3600 / $SESSION_DURATION\" | bc -l 2>/dev/null || echo 0),\n    \"lines_per_hour\": $(echo \"scale=2; ($LINES_ADDED + $LINES_DELETED) * 3600 / $SESSION_DURATION\" | bc -l 2>/dev/null || echo 0)\n  }\n}\nEOF\n\n# Summary statistics\necho \"\"\necho \"📊 Session Summary:\"\necho \"  • Duration: ${SESSION_HOURS}h ${SESSION_MINUTES}m\"\necho \"  • Productivity: $(echo \"scale=1; $FILES_MODIFIED * 3600 / $SESSION_DURATION\" | bc -l 2>/dev/null || echo '0') files/hour\"\necho \"  • Total Changes: $((LINES_ADDED + LINES_DELETED)) lines\"\n\n# Historical comparison\nif [ \"$(find .metrics -name 'session-*.json' 2>/dev/null | wc -l)\" -gt 1 ]; then\n    PREV_SESSION=$(find .metrics -name 'session-*.json' | sort | tail -2 | head -1)\n    if [ -f \"$PREV_SESSION\" ]; then\n        echo \"📈 Compared to last session:\"\n        echo \"  • Previous session available for comparison\"\n    fi\nfi\n\n# Cleanup old metrics (keep last 30 sessions)\nfind .metrics -name 'session-*.json' | sort | head -n -30 | xargs rm -f 2>/dev/null\n\necho \"\"\necho \"💡 Productivity Tips:\"\necho \"  • Review metrics regularly to identify patterns\"\necho \"  • Set productivity goals for future sessions\"\necho \"  • Use metrics to optimize development workflow\"\necho \"  • Compare sessions to track improvement\"\n\necho \"\"\necho \"🎯 Session metrics collection complete!\"\necho \"📄 Full report saved to: $METRICS_FILE\"\n\nexit 0"
      },
      "troubleshooting": [
        {
          "issue": "Session metrics show 'unknown' duration or incorrect timing data",
          "solution": "Hook relies on .claude directory timestamps. Ensure .claude exists before sessions. On Linux use 'stat -c %Y' instead of macOS 'stat -f %B' for timestamp extraction compatibility."
        },
        {
          "issue": "Git-based statistics return zero despite file modifications",
          "solution": "Run 'git add .' before stopping to stage changes. Hook uses 'git diff' showing only unstaged. Modify script to use 'git diff HEAD' for all uncommitted changes instead."
        },
        {
          "issue": "bc command errors: 'command not found' during metrics calculation",
          "solution": "Install bc: 'brew install bc' (macOS) or 'apt-get install bc' (Linux). Or replace with awk: 'awk \"BEGIN {printf \\\"%.2f\\\", $FILES_MODIFIED * 3600 / $SESSION_DURATION}\"'."
        },
        {
          "issue": "JSON metrics file has invalid format breaking parsers",
          "solution": "Script appends without validation. Variables with special chars break JSON. Escape values: use jq for generation: 'jq -n --arg id \"$SESSION_ID\" '{session: {id: $id}}' > \"$METRICS_FILE\"'."
        },
        {
          "issue": "Productivity calculations show zero or negative values",
          "solution": "Division by zero when SESSION_DURATION=0. Add check: 'if [ \"$SESSION_DURATION\" -lt 60 ]; then SESSION_DURATION=60; fi' setting minimum 1-minute before calculations."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/session-metrics-collector"
    },
    {
      "slug": "slack-progress-notifier",
      "description": "Sends progress updates to Slack channel for team visibility on Claude's activities",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "slack",
        "notifications",
        "team",
        "collaboration",
        "monitoring"
      ],
      "hookType": "Notification",
      "features": [
        "Real-time Slack notifications for Claude activities",
        "Contextual emoji selection based on activity type",
        "Webhook-based integration with Slack channels",
        "Team collaboration and visibility enhancement",
        "Non-blocking notification delivery",
        "Customizable message formatting"
      ],
      "useCases": [
        "Keep team informed about automated code changes",
        "Monitor Claude Code activity in real-time",
        "Track development progress across team channels",
        "Notify team of test runs and build activities",
        "Enhance team collaboration and awareness",
        "Create audit trail of automated actions",
        "Alert team to significant file modifications",
        "Coordinate development activities across team members"
      ],
      "troubleshooting": [
        {
          "issue": "Notifications fail with 'invalid_payload' error from Slack",
          "solution": "Escape special characters in JSON payload. Use jq to construct payload: jq -n --arg msg \"$MESSAGE\" '{text: $msg}' | curl -d @- $SLACK_WEBHOOK_URL. Avoid shell variable expansion inside JSON strings."
        },
        {
          "issue": "Hook causes timeout on every tool execution slowing workflow",
          "solution": "Run curl in background with & to avoid blocking: (curl --max-time 3 \"$SLACK_WEBHOOK_URL\" &) >/dev/null 2>&1. Add exit 0 immediately after background execution. Reduce timeout from 5s to 3s."
        },
        {
          "issue": "Slack webhook returns HTTP 410 'url_verification_failed'",
          "solution": "Webhook URL expired or was revoked. Generate new webhook at https://api.slack.com/messaging/webhooks. Update SLACK_WEBHOOK_URL environment variable. Check workspace permissions for incoming webhooks."
        },
        {
          "issue": "Git branch detection fails showing 'unknown' for detached HEAD",
          "solution": "Add fallback to commit SHA: BRANCH=$(git branch --show-current || git rev-parse --short HEAD || echo 'unknown'). Handle detached HEAD state gracefully with descriptive label like 'detached@SHA'."
        },
        {
          "issue": "Notification spam floods channel during rapid file operations",
          "solution": "Implement debouncing with timestamp check: LAST_NOTIFY=$(cat /tmp/slack_last 2>/dev/null || echo 0); NOW=$(date +%s); [ $((NOW - LAST_NOTIFY)) -lt 10 ] && exit 0. Skip notifications within 10s window."
        }
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "notification": {
              "script": "./.claude/hooks/slack-progress-notifier.sh",
              "matchers": [
                "*"
              ]
            }
          }
        },
        "scriptContent": "#!/bin/bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\n# Check if Slack webhook URL is configured\nif [ -z \"$SLACK_WEBHOOK_URL\" ]; then\n    echo \"ℹ️ Slack webhook URL not configured - skipping notification\"\n    echo \"💡 Set SLACK_WEBHOOK_URL environment variable to enable Slack notifications\"\n    exit 0\nfi\n\necho \"📢 Slack Progress Notifier - Sending team notification...\"\necho \"🔧 Tool: $TOOL_NAME\"\nif [ -n \"$FILE_PATH\" ]; then\n    echo \"📄 File: $(basename \"$FILE_PATH\")\"\nfi\n\n# Determine appropriate emoji based on tool/activity type\nEMOJI=\"📝\"  # Default emoji\n\ncase \"$TOOL_NAME\" in\n    *test*|*Test*)\n        EMOJI=\"🧪\"\n        ACTIVITY=\"Testing\"\n        ;;\n    *build*|*Build*)\n        EMOJI=\"🏗️\"\n        ACTIVITY=\"Building\"\n        ;;\n    *deploy*|*Deploy*)\n        EMOJI=\"🚀\"\n        ACTIVITY=\"Deployment\"\n        ;;\n    *commit*|*Commit*|*git*)\n        EMOJI=\"📝\"\n        ACTIVITY=\"Version Control\"\n        ;;\n    *edit*|*Edit*|*write*|*Write*)\n        EMOJI=\"✏️\"\n        ACTIVITY=\"Code Editing\"\n        ;;\n    *lint*|*Lint*|*format*|*Format*)\n        EMOJI=\"🧹\"\n        ACTIVITY=\"Code Quality\"\n        ;;\n    *install*|*Install*|*package*)\n        EMOJI=\"📦\"\n        ACTIVITY=\"Package Management\"\n        ;;\n    *security*|*Security*|*audit*)\n        EMOJI=\"🔒\"\n        ACTIVITY=\"Security\"\n        ;;\n    *debug*|*Debug*|*error*)\n        EMOJI=\"🐛\"\n        ACTIVITY=\"Debugging\"\n        ;;\n    *doc*|*Doc*|*readme*)\n        EMOJI=\"📚\"\n        ACTIVITY=\"Documentation\"\n        ;;\n    *)\n        EMOJI=\"⚡\"\n        ACTIVITY=\"Development\"\n        ;;\nesac\n\n# Prepare the message\nif [ -n \"$FILE_PATH\" ]; then\n    FILENAME=$(basename \"$FILE_PATH\")\n    MESSAGE=\"$EMOJI Claude Code: $ACTIVITY - $TOOL_NAME on $FILENAME\"\nelse\n    MESSAGE=\"$EMOJI Claude Code: $ACTIVITY - $TOOL_NAME\"\nfi\n\n# Get additional context\nTIMESTAMP=$(date '+%H:%M:%S')\nUSER=$(whoami 2>/dev/null || echo \"developer\")\nBRANCH=\"unknown\"\nif git rev-parse --git-dir >/dev/null 2>&1; then\n    BRANCH=$(git branch --show-current 2>/dev/null || echo \"unknown\")\nfi\n\n# Create rich message payload\nREPO_NAME=$(basename \"$(pwd)\" 2>/dev/null || echo \"project\")\n\n# Construct JSON payload with proper escaping\nPAYLOAD=$(cat <<EOF\n{\n  \"text\": \"$MESSAGE\",\n  \"blocks\": [\n    {\n      \"type\": \"section\",\n      \"text\": {\n        \"type\": \"mrkdwn\",\n        \"text\": \"$EMOJI *Claude Code Activity*\\n*Action:* $TOOL_NAME\\n*Time:* $TIMESTAMP\\n*User:* $USER\\n*Branch:* $BRANCH\\n*Project:* $REPO_NAME\"\n      }\n    }\n  ]\n}\nEOF\n)\n\necho \"📤 Sending notification to Slack...\"\n\n# Send to Slack with proper error handling\nif curl -X POST \\\n     -H 'Content-type: application/json' \\\n     --data \"$PAYLOAD\" \\\n     --max-time 5 \\\n     --retry 1 \\\n     \"$SLACK_WEBHOOK_URL\" \\\n     --silent \\\n     --show-error 2>/dev/null; then\n    echo \"✅ Slack notification sent successfully\"\nelse\n    CURL_EXIT_CODE=$?\n    case $CURL_EXIT_CODE in\n        6)\n            echo \"⚠️ Failed to send Slack notification - couldn't resolve host\"\n            ;;\n        7)\n            echo \"⚠️ Failed to send Slack notification - couldn't connect to server\"\n            ;;\n        22)\n            echo \"⚠️ Failed to send Slack notification - HTTP error (check webhook URL)\"\n            ;;\n        28)\n            echo \"⚠️ Failed to send Slack notification - timeout\"\n            ;;\n        *)\n            echo \"⚠️ Failed to send Slack notification - error code: $CURL_EXIT_CODE\"\n            ;;\n    esac\n    echo \"💡 Verify SLACK_WEBHOOK_URL is correct and Slack service is accessible\"\nfi\n\necho \"\"\necho \"💡 Slack Integration Tips:\"\necho \"  • Get webhook URL from: https://api.slack.com/messaging/webhooks\"\necho \"  • Set SLACK_WEBHOOK_URL environment variable\"\necho \"  • Test webhook with: curl -X POST -H 'Content-type: application/json' --data '{\\\"text\\\":\\\"Test\\\"}' \\$SLACK_WEBHOOK_URL\"\necho \"  • Configure channel-specific webhooks for different notification types\"\necho \"  • Consider rate limiting for high-activity periods\"\n\necho \"\"\necho \"🎯 Slack notification complete!\"\n\nexit 0"
      },
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/slack-progress-notifier"
    },
    {
      "slug": "svelte-component-compiler",
      "description": "Automatically compiles and validates Svelte components when they are modified",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "svelte",
        "components",
        "compilation",
        "validation",
        "frontend"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Automatic Svelte component compilation and validation",
        "Real-time syntax and type checking",
        "SvelteKit project integration",
        "Component dependency analysis",
        "Performance optimization suggestions",
        "Accessibility validation for components"
      ],
      "useCases": [
        "Validate Svelte component syntax after editing",
        "Ensure components compile without errors",
        "Check for Svelte best practices compliance",
        "Detect accessibility issues in components",
        "Analyze component dependencies and imports",
        "Optimize component performance",
        "Validate TypeScript usage in Svelte files",
        "Ensure SvelteKit compatibility"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/svelte-component-compiler.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/bin/bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Check if this is a Svelte component file\nif [[ \"$FILE_PATH\" == *.svelte ]]; then\n    echo \"🔥 Svelte Component Compiler - Validating Svelte component...\"\n    echo \"📄 Component: $FILE_PATH\"\n    \n    # Check if file exists\n    if [ ! -f \"$FILE_PATH\" ]; then\n        echo \"⚠️ Component file not found: $FILE_PATH\"\n        exit 1\n    fi\n    \n    # Check if this is a SvelteKit project\n    SVELTEKIT_PROJECT=false\n    if [ -f \"svelte.config.js\" ] || [ -f \"vite.config.js\" ] && grep -q \"@sveltejs/kit\" package.json 2>/dev/null; then\n        echo \"🎯 SvelteKit project detected\"\n        SVELTEKIT_PROJECT=true\n    elif [ -f \"package.json\" ] && grep -q \"svelte\" package.json 2>/dev/null; then\n        echo \"⚡ Svelte project detected\"\n    else\n        echo \"ℹ️ No Svelte project configuration found\"\n    fi\n    \n    # Check for required tools\n    echo \"🔍 Checking Svelte toolchain...\"\n    \n    SVELTE_CHECK_AVAILABLE=false\n    if command -v npx >/dev/null 2>&1 && npx svelte-check --version >/dev/null 2>&1; then\n        SVELTE_CHECK_AVAILABLE=true\n        SVELTE_CHECK_VERSION=$(npx svelte-check --version 2>/dev/null)\n        echo \"✅ svelte-check available: $SVELTE_CHECK_VERSION\"\n    else\n        echo \"⚠️ svelte-check not available - install with: npm install -D @sveltejs/language-server svelte-check\"\n    fi\n    \n    # Component syntax validation\n    echo \"\"\n    echo \"🔍 Validating component syntax...\"\n    \n    # Basic syntax validation\n    if grep -q '<script' \"$FILE_PATH\" && grep -q '</script>' \"$FILE_PATH\"; then\n        echo \"✅ Script block found\"\n        \n        # Check for TypeScript\n        if grep -q '<script lang=[\"']ts[\"']>' \"$FILE_PATH\"; then\n            echo \"📘 TypeScript detected in component\"\n        fi\n    fi\n    \n    if grep -q '<style' \"$FILE_PATH\" && grep -q '</style>' \"$FILE_PATH\"; then\n        echo \"✅ Style block found\"\n        \n        # Check for scoped styles\n        if grep -q '<style.*scoped' \"$FILE_PATH\"; then\n            echo \"🎯 Scoped styles detected\"\n        fi\n    fi\n    \n    # Run svelte-check if available\n    if [ \"$SVELTE_CHECK_AVAILABLE\" = true ]; then\n        echo \"\"\n        echo \"🔍 Running svelte-check validation...\"\n        \n        if npx svelte-check --output human --no-tsconfig 2>&1; then\n            echo \"✅ Svelte component validation passed\"\n        else\n            echo \"❌ Svelte component validation failed\"\n            echo \"💡 Check the errors above and fix component issues\"\n        fi\n    fi\n    \n    # Component analysis\n    echo \"\"\n    echo \"📊 Component Analysis:\"\n    \n    # Count component features\n    PROPS_COUNT=$(grep -c 'export let' \"$FILE_PATH\" 2>/dev/null || echo 0)\n    REACTIVE_COUNT=$(grep -c '\\$:' \"$FILE_PATH\" 2>/dev/null || echo 0)\n    STORES_COUNT=$(grep -c 'import.*from.*svelte/store' \"$FILE_PATH\" 2>/dev/null || echo 0)\n    \n    echo \"  • Props: $PROPS_COUNT\"\n    echo \"  • Reactive statements: $REACTIVE_COUNT\"\n    echo \"  • Store imports: $STORES_COUNT\"\n    \n    # Check for common patterns\n    if grep -q 'on:click' \"$FILE_PATH\" 2>/dev/null; then\n        echo \"  • 🖱️ Click handlers detected\"\n    fi\n    \n    if grep -q 'bind:' \"$FILE_PATH\" 2>/dev/null; then\n        echo \"  • 🔗 Data binding detected\"\n    fi\n    \n    if grep -q '{#if' \"$FILE_PATH\" 2>/dev/null; then\n        echo \"  • 🔀 Conditional rendering detected\"\n    fi\n    \n    if grep -q '{#each' \"$FILE_PATH\" 2>/dev/null; then\n        echo \"  • 🔁 List rendering detected\"\n    fi\n    \n    # Accessibility checks\n    echo \"\"\n    echo \"♿ Accessibility Analysis:\"\n    \n    if grep -q 'alt=' \"$FILE_PATH\" 2>/dev/null; then\n        echo \"  • ✅ Image alt attributes found\"\n    fi\n    \n    if grep -q 'aria-' \"$FILE_PATH\" 2>/dev/null; then\n        echo \"  • ✅ ARIA attributes detected\"\n    fi\n    \n    if grep -q 'role=' \"$FILE_PATH\" 2>/dev/null; then\n        echo \"  • ✅ Role attributes found\"\n    fi\n    \n    # Performance suggestions\n    echo \"\"\n    echo \"⚡ Performance Tips:\"\n    \n    if grep -q 'import.*from.*svelte/transition' \"$FILE_PATH\" 2>/dev/null; then\n        echo \"  • 🎬 Transitions detected - ensure they're necessary\"\n    fi\n    \n    if [ \"$REACTIVE_COUNT\" -gt 5 ]; then\n        echo \"  • ⚠️ Many reactive statements - consider component splitting\"\n    fi\n    \n    echo \"\"\n    echo \"💡 Svelte Best Practices:\"\n    echo \"  • Use 'export let' for component props\"\n    echo \"  • Prefer reactive statements over complex logic in templates\"\n    echo \"  • Use stores for shared state between components\"\n    echo \"  • Implement proper accessibility attributes\"\n    echo \"  • Use SvelteKit for full-stack applications\"\n    echo \"  • Consider component composition over large single components\"\n    \n    echo \"\"\n    echo \"🎯 Svelte component validation complete!\"\n    \nelse\n    echo \"ℹ️ File is not a Svelte component: $FILE_PATH\"\nfi\n\nexit 0"
      },
      "troubleshooting": [
        {
          "issue": "svelte-check reports 'Cannot find module' errors for valid imports",
          "solution": "Missing @types or incorrect tsconfig paths. Install: 'npm install --save-dev @sveltejs/vite-plugin-svelte @types/node'. Add to tsconfig: '\"types\": [\"svelte\", \"vite/client\"]' enabling Svelte module resolution."
        },
        {
          "issue": "Hook runs validation on every file save not just .svelte files",
          "solution": "Matchers too broad catching all writes/edits. Restrict: 'matchers': ['write:**/*.svelte', 'edit:**/*.svelte'] targeting Svelte components only. Prevents unnecessary checks on JS/TS files."
        },
        {
          "issue": "SvelteKit detection fails despite valid svelte.config.js present",
          "solution": "Config check requires both svelte.config.js AND @sveltejs/kit in package.json. Verify: 'grep @sveltejs/kit package.json'. Or simplify: 'if [ -f \"svelte.config.js\" ]; then SVELTEKIT_PROJECT=true; fi'."
        },
        {
          "issue": "Reactive statement count includes CSS variables with $ prefix",
          "solution": "grep '\\$:' matches CSS custom properties in <style>. Refine: 'grep -v '<style' file.svelte | grep -c '\\$:'' excluding style blocks. Or target: 'grep '<script' -A 100 | grep -c '\\$:''."
        },
        {
          "issue": "npx svelte-check slow taking 30+ seconds per component validation",
          "solution": "Checks entire project not single file. Remove --no-tsconfig: run full project check on session end not per-file. Or use '--workspace' limiting scope: 'svelte-check --workspace src/components'."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/svelte-component-compiler"
    },
    {
      "slug": "team-summary-email-generator",
      "description": "Generates and sends a comprehensive summary email to the team when session ends",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "email",
        "team",
        "stop-hook",
        "summary",
        "communication"
      ],
      "hookType": "Stop",
      "features": [
        "Comprehensive session summary generation",
        "HTML-formatted email reports",
        "Multiple email service integrations (SendGrid, SMTP)",
        "Git change analysis and statistics",
        "Test results and build status inclusion",
        "Automatic team communication"
      ],
      "useCases": [
        "Send detailed session summaries to development team",
        "Create automated progress reports after work sessions",
        "Document code changes and accomplishments",
        "Notify team of test results and build status",
        "Maintain project communication and transparency",
        "Generate historical record of development activities",
        "Alert team to significant changes or milestones",
        "Coordinate team awareness of automated changes"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "stop": {
              "script": "./.claude/hooks/team-summary-email-generator.sh",
              "matchers": [
                "*"
              ]
            }
          }
        },
        "scriptContent": "#!/bin/bash\n\necho \"📧 Team Summary Email Generator - Preparing session summary...\"\necho \"⏰ Session ended: $(date)\"\n\n# Check if email configuration is available\nif [ -z \"$TEAM_EMAIL\" ]; then\n    echo \"ℹ️ TEAM_EMAIL not configured - skipping email summary\"\n    echo \"💡 Set TEAM_EMAIL environment variable to enable team notifications\"\n    exit 0\nfi\n\necho \"📬 Team email configured: $TEAM_EMAIL\"\n\n# Check for email service configuration\nEMAIL_METHOD=\"none\"\nif [ -n \"$SENDGRID_API_KEY\" ]; then\n    EMAIL_METHOD=\"sendgrid\"\n    echo \"📨 Using SendGrid API for email delivery\"\nelif command -v mail >/dev/null 2>&1; then\n    EMAIL_METHOD=\"mail\"\n    echo \"📮 Using system mail command for email delivery\"\nelif command -v sendmail >/dev/null 2>&1; then\n    EMAIL_METHOD=\"sendmail\"\n    echo \"📫 Using sendmail for email delivery\"\nelse\n    echo \"⚠️ No email service available - install mail command or configure SendGrid\"\n    echo \"💡 Install: apt-get install mailutils (Ubuntu) or brew install mailutils (macOS)\"\n    exit 0\nfi\n\necho \"🔍 Analyzing session data...\"\n\n# Session metadata\nSESSION_END=$(date)\nSESSION_ID=$(date +%Y%m%d_%H%M%S)\nUSER=$(whoami 2>/dev/null || echo \"developer\")\nHOST=$(hostname 2>/dev/null || echo \"unknown\")\nWORKDIR=$(pwd)\nPROJECT_NAME=$(basename \"$WORKDIR\" 2>/dev/null || echo \"project\")\n\n# Git analysis\nif git rev-parse --git-dir >/dev/null 2>&1; then\n    echo \"📊 Analyzing git changes...\"\n    \n    BRANCH=$(git branch --show-current 2>/dev/null || echo \"unknown\")\n    FILES_CHANGED=$(git diff --name-only 2>/dev/null | wc -l | tr -d ' ')\n    FILES_LIST=$(git diff --name-only 2>/dev/null | head -10)\n    \n    # Get detailed diff stats\n    DIFF_STATS=$(git diff --stat 2>/dev/null)\n    INSERTIONS=$(echo \"$DIFF_STATS\" | tail -1 | grep -oE '[0-9]+ insertion' | grep -oE '[0-9]+' || echo \"0\")\n    DELETIONS=$(echo \"$DIFF_STATS\" | tail -1 | grep -oE '[0-9]+ deletion' | grep -oE '[0-9]+' || echo \"0\")\n    \n    # Recent commits\n    RECENT_COMMITS=$(git log --oneline -5 2>/dev/null || echo \"No recent commits\")\nelse\n    echo \"ℹ️ Not a git repository - skipping git analysis\"\n    BRANCH=\"N/A\"\n    FILES_CHANGED=\"0\"\n    FILES_LIST=\"No git repository\"\n    INSERTIONS=\"0\"\n    DELETIONS=\"0\"\n    RECENT_COMMITS=\"No git repository\"\nfi\n\n# Test results analysis\necho \"🧪 Checking test results...\"\nTEST_RESULTS=\"No test results available\"\nif [ -f \"package.json\" ] && grep -q '\"test\"' package.json 2>/dev/null; then\n    echo \"  • Running npm test...\"\n    if timeout 30 npm test -- --silent --passWithNoTests 2>/dev/null; then\n        TEST_RESULTS=\"✅ All tests passed\"\n    else\n        TEST_RESULTS=\"❌ Some tests failed - check logs\"\n    fi\nelif command -v pytest >/dev/null 2>&1; then\n    echo \"  • Running pytest...\"\n    if timeout 30 pytest --tb=no -q 2>/dev/null; then\n        TEST_RESULTS=\"✅ All Python tests passed\"\n    else\n        TEST_RESULTS=\"❌ Some Python tests failed\"\n    fi\nelif [ -f \"Cargo.toml\" ]; then\n    echo \"  • Running cargo test...\"\n    if timeout 30 cargo test --quiet 2>/dev/null; then\n        TEST_RESULTS=\"✅ All Rust tests passed\"\n    else\n        TEST_RESULTS=\"❌ Some Rust tests failed\"\n    fi\nfi\n\n# Build status analysis\necho \"🏗️ Checking build status...\"\nBUILD_STATUS=\"No build configuration found\"\nif [ -f \"package.json\" ] && grep -q '\"build\"' package.json 2>/dev/null; then\n    echo \"  • Running npm build...\"\n    if timeout 60 npm run build >/dev/null 2>&1; then\n        BUILD_STATUS=\"✅ Build successful\"\n    else\n        BUILD_STATUS=\"❌ Build failed\"\n    fi\nelif [ -f \"Cargo.toml\" ]; then\n    echo \"  • Running cargo build...\"\n    if timeout 60 cargo build --quiet 2>/dev/null; then\n        BUILD_STATUS=\"✅ Cargo build successful\"\n    else\n        BUILD_STATUS=\"❌ Cargo build failed\"\n    fi\nfi\n\n# Generate HTML email content\necho \"📝 Generating email content...\"\n\nHTML_CONTENT=$(cat <<EOF\n<!DOCTYPE html>\n<html>\n<head>\n    <style>\n        body { font-family: Arial, sans-serif; line-height: 1.6; color: #333; }\n        .header { background: #f4f4f4; padding: 20px; border-radius: 5px; }\n        .section { margin: 20px 0; padding: 15px; border-left: 4px solid #007cba; }\n        .stats { background: #f9f9f9; padding: 10px; border-radius: 3px; }\n        pre { background: #f5f5f5; padding: 10px; border-radius: 3px; overflow-x: auto; }\n        .success { color: #28a745; }\n        .error { color: #dc3545; }\n        .info { color: #17a2b8; }\n    </style>\n</head>\n<body>\n    <div class=\"header\">\n        <h1>🤖 Claude Code Session Summary</h1>\n        <p><strong>Project:</strong> $PROJECT_NAME</p>\n        <p><strong>Session ID:</strong> $SESSION_ID</p>\n        <p><strong>Completed:</strong> $SESSION_END</p>\n        <p><strong>User:</strong> $USER@$HOST</p>\n    </div>\n\n    <div class=\"section\">\n        <h2>📊 Development Statistics</h2>\n        <div class=\"stats\">\n            <ul>\n                <li><strong>Branch:</strong> $BRANCH</li>\n                <li><strong>Files Modified:</strong> $FILES_CHANGED</li>\n                <li><strong>Lines Added:</strong> $INSERTIONS</li>\n                <li><strong>Lines Removed:</strong> $DELETIONS</li>\n            </ul>\n        </div>\n    </div>\n\n    <div class=\"section\">\n        <h2>📁 Modified Files</h2>\n        <pre>$FILES_LIST</pre>\n    </div>\n\n    <div class=\"section\">\n        <h2>🧪 Test Results</h2>\n        <p>$TEST_RESULTS</p>\n    </div>\n\n    <div class=\"section\">\n        <h2>🏗️ Build Status</h2>\n        <p>$BUILD_STATUS</p>\n    </div>\n\n    <div class=\"section\">\n        <h2>📝 Recent Commits</h2>\n        <pre>$RECENT_COMMITS</pre>\n    </div>\n\n    <div class=\"section\">\n        <h2>💡 Next Steps</h2>\n        <ul>\n            <li>Review changes and test thoroughly</li>\n            <li>Update documentation if needed</li>\n            <li>Consider code review for significant changes</li>\n            <li>Merge changes when ready</li>\n        </ul>\n    </div>\n\n    <hr>\n    <p><small>Generated automatically by Claude Code Team Summary Hook</small></p>\n</body>\n</html>\nEOF\n)\n\n# Send email based on available method\nSUBJECT=\"Claude Code Session Summary - $PROJECT_NAME ($SESSION_END)\"\n\necho \"📤 Sending email via $EMAIL_METHOD...\"\n\ncase \"$EMAIL_METHOD\" in\n    \"sendgrid\")\n        SENDGRID_PAYLOAD=$(cat <<EOF\n{\n  \"personalizations\": [{\n    \"to\": [{\"email\": \"$TEAM_EMAIL\"}]\n  }],\n  \"from\": {\"email\": \"claude@yourdomain.com\", \"name\": \"Claude Code\"},\n  \"subject\": \"$SUBJECT\",\n  \"content\": [{\n    \"type\": \"text/html\",\n    \"value\": \"$(echo \"$HTML_CONTENT\" | sed 's/\"/\\\\\"'/g')\"\n  }]\n}\nEOF\n        )\n        \n        if curl -X POST \\\n             -H \"Authorization: Bearer $SENDGRID_API_KEY\" \\\n             -H \"Content-Type: application/json\" \\\n             -d \"$SENDGRID_PAYLOAD\" \\\n             \"https://api.sendgrid.com/v3/mail/send\" \\\n             --silent --show-error 2>/dev/null; then\n            echo \"✅ Email sent successfully via SendGrid\"\n        else\n            echo \"❌ Failed to send email via SendGrid\"\n        fi\n        ;;\n    \"mail\")\n        echo \"$HTML_CONTENT\" | mail -s \"$SUBJECT\" -a \"Content-Type: text/html\" \"$TEAM_EMAIL\"\n        echo \"✅ Email sent via system mail command\"\n        ;;\n    \"sendmail\")\n        {\n            echo \"To: $TEAM_EMAIL\"\n            echo \"Subject: $SUBJECT\"\n            echo \"Content-Type: text/html\"\n            echo \"\"\n            echo \"$HTML_CONTENT\"\n        } | sendmail \"$TEAM_EMAIL\"\n        echo \"✅ Email sent via sendmail\"\n        ;;\nesac\n\necho \"\"\necho \"💡 Email Configuration Tips:\"\necho \"  • Set TEAM_EMAIL environment variable\"\necho \"  • For SendGrid: Set SENDGRID_API_KEY\"\necho \"  • For system mail: Install mailutils package\"\necho \"  • Configure SMTP settings in your system\"\n\necho \"\"\necho \"🎯 Team summary email generation complete!\"\n\nexit 0"
      },
      "troubleshooting": [
        {
          "issue": "Hook skips email sending with TEAM_EMAIL not configured",
          "solution": "Set the TEAM_EMAIL environment variable before starting Claude Code: 'export TEAM_EMAIL=team@example.com'. Add to .bashrc or .zshrc for persistence across sessions."
        },
        {
          "issue": "SendGrid API returns 401 unauthorized error",
          "solution": "Verify SENDGRID_API_KEY is valid and has Mail Send permissions. Create API keys at SendGrid dashboard. Test with 'curl' command before troubleshooting hook. Check key isn't expired or revoked."
        },
        {
          "issue": "Email content shows HTML markup instead of formatted text",
          "solution": "Your email client may not support HTML rendering. The hook sends multipart emails with HTML content. Check spam folder, or configure email client to render HTML. Use plain text fallback in email settings."
        },
        {
          "issue": "Test and build checks timeout causing incomplete reports",
          "solution": "The hook uses 30-60 second timeouts to prevent hanging. For slower builds, adjust timeout values in the script or disable build checks. Results show 'No test results available' on timeout."
        },
        {
          "issue": "Git statistics show zero changes despite file modifications",
          "solution": "The hook analyzes uncommitted changes using 'git diff'. Stage or commit changes to see them in git analysis. For committed work, check recent commits section which shows last 5 commits regardless of current diff."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/team-summary-email-generator"
    },
    {
      "slug": "terraform-plan-executor",
      "description": "Automatically runs terraform plan when .tf files are modified to preview infrastructure changes",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "terraform",
        "infrastructure",
        "iac",
        "devops",
        "cloud"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Automatic Terraform plan execution on file changes",
        "Configuration syntax validation and formatting",
        "Resource change preview and analysis",
        "Multi-provider support and validation",
        "Cost estimation and impact analysis",
        "Security and compliance checking"
      ],
      "useCases": [
        "Preview infrastructure changes before applying",
        "Validate Terraform configuration syntax",
        "Check for resource dependencies and conflicts",
        "Estimate costs of proposed infrastructure changes",
        "Ensure compliance with infrastructure policies",
        "Detect potential security issues in configurations",
        "Validate provider configurations and credentials",
        "Generate infrastructure change reports"
      ],
      "troubleshooting": [
        {
          "issue": "terraform init fails with 'backend configuration changed' error",
          "solution": "Run terraform init -reconfigure to update backend configuration. Use terraform init -migrate-state to migrate existing state. Check backend {} block in .tf files matches current state location."
        },
        {
          "issue": "Plan execution triggers on .tfvars edits but fails with missing vars",
          "solution": "Pass variable file explicitly: terraform plan -var-file=\"$TF_FILE\" if .tfvars file. Add conditional: [[ \"$TF_FILE\" == *.tfvars ]] && PLAN_ARGS=\"-var-file=$TF_FILE\". Ensure terraform.tfvars is in same directory."
        },
        {
          "issue": "Hook changes to wrong directory breaking subsequent operations",
          "solution": "Save original directory: ORIG_DIR=$(pwd) before cd \"$TF_DIR\". Always return: cd \"$ORIG_DIR\" || exit 1 at script end. Use pushd/popd for safer directory stack management."
        },
        {
          "issue": "terraform validate fails when run from subdirectory with modules",
          "solution": "Always run from root module directory. Find root: while [ ! -f .terraform.lock.hcl ] && [ $(pwd) != / ]; do cd ..; done. Run terraform init before validate when .terraform/ missing."
        },
        {
          "issue": "Plan shows destroy actions when only formatting was changed",
          "solution": "This indicates state drift or provider version change. Run terraform refresh before plan. Check provider version constraints in required_providers block. Review .terraform.lock.hcl for version updates."
        }
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/terraform-plan-executor.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/bin/bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Check if this is a Terraform file\nif [[ \"$FILE_PATH\" == *.tf ]] || [[ \"$FILE_PATH\" == *.tfvars ]]; then\n    echo \"🏗️ Terraform Plan Executor - Analyzing infrastructure changes...\"\n    echo \"📄 File: $FILE_PATH\"\n    \n    # Check if file exists\n    if [ ! -f \"$FILE_PATH\" ]; then\n        echo \"⚠️ Terraform file not found: $FILE_PATH\"\n        exit 1\n    fi\n    \n    # Get the directory containing the Terraform file\n    TF_DIR=$(dirname \"$FILE_PATH\")\n    TF_FILE=$(basename \"$FILE_PATH\")\n    \n    echo \"📁 Working directory: $TF_DIR\"\n    cd \"$TF_DIR\" || exit 1\n    \n    # Check if Terraform is installed\n    if ! command -v terraform >/dev/null 2>&1; then\n        echo \"⚠️ Terraform not found - please install Terraform\"\n        echo \"💡 Install from: https://www.terraform.io/downloads\"\n        exit 1\n    fi\n    \n    # Get Terraform version\n    TF_VERSION=$(terraform version -json 2>/dev/null | jq -r '.terraform_version' 2>/dev/null || terraform version | head -1)\n    echo \"📦 Terraform version: $TF_VERSION\"\n    \n    # Step 1: Format check\n    echo \"\"\n    echo \"🎨 Checking Terraform formatting...\"\n    if terraform fmt -check \"$TF_FILE\"; then\n        echo \"✅ Terraform formatting is correct\"\n    else\n        echo \"⚠️ Terraform formatting issues detected\"\n        echo \"💡 Run 'terraform fmt' to fix formatting\"\n        \n        # Auto-fix formatting if requested\n        echo \"🔧 Auto-fixing formatting...\"\n        terraform fmt \"$TF_FILE\"\n        echo \"✅ Formatting applied to $TF_FILE\"\n    fi\n    \n    # Step 2: Validation\n    echo \"\"\n    echo \"🔍 Validating Terraform configuration...\"\n    if terraform validate; then\n        echo \"✅ Terraform configuration is valid\"\n    else\n        echo \"❌ Terraform validation failed\"\n        echo \"💡 Fix validation errors before proceeding\"\n        exit 1\n    fi\n    \n    # Step 3: Initialize if needed\n    if [ ! -d \".terraform\" ]; then\n        echo \"\"\n        echo \"🔄 Initializing Terraform...\"\n        if terraform init; then\n            echo \"✅ Terraform initialized successfully\"\n        else\n            echo \"❌ Terraform initialization failed\"\n            exit 1\n        fi\n    fi\n    \n    # Step 4: Run terraform plan\n    echo \"\"\n    echo \"📋 Running Terraform plan...\"\n    \n    PLAN_FILE=\".terraform-plan-$(date +%s)\"\n    \n    if terraform plan -out=\"$PLAN_FILE\" -compact-warnings; then\n        echo \"✅ Terraform plan completed successfully\"\n        \n        # Analyze the plan\n        echo \"\"\n        echo \"📊 Plan Analysis:\"\n        \n        # Show plan summary\n        if terraform show -json \"$PLAN_FILE\" >/dev/null 2>&1; then\n            PLAN_JSON=$(terraform show -json \"$PLAN_FILE\" 2>/dev/null)\n            \n            # Count changes\n            RESOURCES_TO_ADD=$(echo \"$PLAN_JSON\" | jq -r '.resource_changes[]? | select(.change.actions[]? == \"create\") | .address' 2>/dev/null | wc -l)\n            RESOURCES_TO_CHANGE=$(echo \"$PLAN_JSON\" | jq -r '.resource_changes[]? | select(.change.actions[]? == \"update\") | .address' 2>/dev/null | wc -l)\n            RESOURCES_TO_DESTROY=$(echo \"$PLAN_JSON\" | jq -r '.resource_changes[]? | select(.change.actions[]? == \"delete\") | .address' 2>/dev/null | wc -l)\n            \n            echo \"  • Resources to add: $RESOURCES_TO_ADD\"\n            echo \"  • Resources to change: $RESOURCES_TO_CHANGE\"\n            echo \"  • Resources to destroy: $RESOURCES_TO_DESTROY\"\n            \n            # Show resource details if any changes\n            if [ \"$RESOURCES_TO_ADD\" -gt 0 ] || [ \"$RESOURCES_TO_CHANGE\" -gt 0 ] || [ \"$RESOURCES_TO_DESTROY\" -gt 0 ]; then\n                echo \"\"\n                echo \"🔍 Detailed Changes:\"\n                \n                if [ \"$RESOURCES_TO_ADD\" -gt 0 ]; then\n                    echo \"  📦 Resources to create:\"\n                    echo \"$PLAN_JSON\" | jq -r '.resource_changes[]? | select(.change.actions[]? == \"create\") | \"    • \" + .address' 2>/dev/null\n                fi\n                \n                if [ \"$RESOURCES_TO_CHANGE\" -gt 0 ]; then\n                    echo \"  🔄 Resources to modify:\"\n                    echo \"$PLAN_JSON\" | jq -r '.resource_changes[]? | select(.change.actions[]? == \"update\") | \"    • \" + .address' 2>/dev/null\n                fi\n                \n                if [ \"$RESOURCES_TO_DESTROY\" -gt 0 ]; then\n                    echo \"  🗑️ Resources to destroy:\"\n                    echo \"$PLAN_JSON\" | jq -r '.resource_changes[]? | select(.change.actions[]? == \"delete\") | \"    • \" + .address' 2>/dev/null\n                fi\n            else\n                echo \"  ℹ️ No infrastructure changes detected\"\n            fi\n        fi\n        \n        # Clean up plan file\n        rm -f \"$PLAN_FILE\"\n        \n    else\n        echo \"❌ Terraform plan failed\"\n        rm -f \"$PLAN_FILE\"\n        exit 1\n    fi\n    \n    # Additional analysis\n    echo \"\"\n    echo \"🔍 Configuration Analysis:\"\n    \n    # Count resources in current file\n    RESOURCE_COUNT=$(grep -c '^resource ' \"$TF_FILE\" 2>/dev/null || echo 0)\n    DATA_COUNT=$(grep -c '^data ' \"$TF_FILE\" 2>/dev/null || echo 0)\n    VAR_COUNT=$(grep -c '^variable ' \"$TF_FILE\" 2>/dev/null || echo 0)\n    OUTPUT_COUNT=$(grep -c '^output ' \"$TF_FILE\" 2>/dev/null || echo 0)\n    \n    echo \"  • Resources defined: $RESOURCE_COUNT\"\n    echo \"  • Data sources: $DATA_COUNT\"\n    echo \"  • Variables: $VAR_COUNT\"\n    echo \"  • Outputs: $OUTPUT_COUNT\"\n    \n    # Check for common patterns\n    if grep -q 'provider ' \"$TF_FILE\" 2>/dev/null; then\n        echo \"  • 🔌 Provider configurations detected\"\n    fi\n    \n    if grep -q 'module ' \"$TF_FILE\" 2>/dev/null; then\n        echo \"  • 📦 Module usage detected\"\n    fi\n    \n    if grep -q 'locals ' \"$TF_FILE\" 2>/dev/null; then\n        echo \"  • 🏷️ Local values defined\"\n    fi\n    \n    # Security and best practices check\n    echo \"\"\n    echo \"🔒 Security Analysis:\"\n    \n    if grep -i 'password\\\\|secret\\\\|key' \"$TF_FILE\" 2>/dev/null | grep -v 'var\\.' | grep -v 'data\\.' >/dev/null; then\n        echo \"  • ⚠️ Potential hardcoded secrets detected - use variables instead\"\n    fi\n    \n    if grep -q '0.0.0.0/0' \"$TF_FILE\" 2>/dev/null; then\n        echo \"  • ⚠️ Open security group rules detected (0.0.0.0/0)\"\n    fi\n    \n    if ! grep -q 'tags\\\\|Tags' \"$TF_FILE\" 2>/dev/null && [ \"$RESOURCE_COUNT\" -gt 0 ]; then\n        echo \"  • 💡 Consider adding resource tags for better management\"\n    fi\n    \n    echo \"\"\n    echo \"💡 Terraform Best Practices:\"\n    echo \"  • Use terraform fmt to maintain consistent formatting\"\n    echo \"  • Store sensitive values in variables, not hardcoded\"\n    echo \"  • Use remote state backend for team collaboration\"\n    echo \"  • Implement resource tagging strategy\"\n    echo \"  • Use terraform validate in CI/CD pipelines\"\n    echo \"  • Review plans carefully before applying\"\n    \n    echo \"\"\n    echo \"🎯 Terraform plan execution complete!\"\n    \nelse\n    echo \"ℹ️ File is not a Terraform file: $FILE_PATH\"\nfi\n\nexit 0"
      },
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/terraform-plan-executor"
    },
    {
      "slug": "test-coverage-final-report",
      "description": "Generates a comprehensive test coverage report when the coding session ends",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "testing",
        "coverage",
        "stop-hook",
        "reporting",
        "quality"
      ],
      "hookType": "Stop",
      "features": [
        "Comprehensive test coverage analysis",
        "Multi-language testing framework support",
        "HTML and terminal coverage reports",
        "Coverage threshold validation",
        "Uncovered code identification",
        "Historical coverage tracking"
      ],
      "useCases": [
        "Generate final coverage report at session end",
        "Identify untested code areas requiring attention",
        "Track testing progress and coverage improvements",
        "Validate coverage meets project standards",
        "Generate coverage reports for team review",
        "Monitor test quality and completeness",
        "Document testing status for project stakeholders",
        "Ensure adequate testing before deployment"
      ],
      "troubleshooting": [
        {
          "issue": "Jest coverage reports zero percent despite passing tests",
          "solution": "collectCoverage disabled or wrong paths in jest.config.js. Verify: 'collectCoverage: true, collectCoverageFrom: [\"src/**/*.{js,ts}\"]'. Or force: 'npm test -- --coverage --collectCoverageFrom=\"src/**\"'."
        },
        {
          "issue": "Coverage summary JSON parsing fails with jq errors",
          "solution": "coverage-summary.json missing or malformed. Check exists: '[ -f coverage/coverage-summary.json ]' before jq. Generate: add 'coverageReporters: [\"json-summary\", \"html\"]' to jest.config.js."
        },
        {
          "issue": "Python pytest-cov not found despite pytest installation",
          "solution": "Separate package required. Install: 'pip install pytest-cov coverage'. Verify: 'pytest --version' shows cov plugin. Or use coverage.py: 'coverage run -m pytest; coverage report'."
        },
        {
          "issue": "Rust tarpaulin installation fails with compilation errors",
          "solution": "Requires nightly Rust and specific deps. Use Docker: 'docker run --rm -v $PWD:/volume xd009642/tarpaulin cargo tarpaulin'. Or alternative: 'cargo install cargo-llvm-cov' for stable Rust."
        },
        {
          "issue": "HTML report links show file:// protocol not opening in browser",
          "solution": "Terminal doesn't hyperlink file:// URLs. Add open command: 'echo \"Open: coverage/index.html\"; open coverage/index.html 2>/dev/null || xdg-open coverage/index.html' auto-launching browser."
        }
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "stop": {
              "script": "./.claude/hooks/test-coverage-final-report.sh",
              "matchers": [
                "*"
              ]
            }
          }
        },
        "scriptContent": "#!/bin/bash\n\necho \"🧪 Test Coverage Final Report - Analyzing test coverage...\"\necho \"⏰ Session ended: $(date)\"\necho \"═══════════════════════════════════════════════════\"\n\n# Detect project type and testing framework\nPROJECT_TYPE=\"unknown\"\nTEST_FRAMEWORK=\"unknown\"\nCOVERAGE_AVAILABLE=false\n\necho \"🔍 Detecting project type and testing framework...\"\n\n# JavaScript/Node.js project detection\nif [ -f \"package.json\" ]; then\n    PROJECT_TYPE=\"node\"\n    echo \"📦 Node.js project detected\"\n    \n    # Detect testing framework\n    if grep -q '\"jest\"' package.json 2>/dev/null; then\n        TEST_FRAMEWORK=\"jest\"\n        echo \"🃏 Jest testing framework detected\"\n    elif grep -q '\"vitest\"' package.json 2>/dev/null; then\n        TEST_FRAMEWORK=\"vitest\"\n        echo \"⚡ Vitest testing framework detected\"\n    elif grep -q '\"mocha\"' package.json 2>/dev/null; then\n        TEST_FRAMEWORK=\"mocha\"\n        echo \"☕ Mocha testing framework detected\"\n    elif grep -q '\"karma\"' package.json 2>/dev/null; then\n        TEST_FRAMEWORK=\"karma\"\n        echo \"🔄 Karma testing framework detected\"\n    fi\n    \n# Python project detection\nelif [ -f \"requirements.txt\" ] || [ -f \"setup.py\" ] || [ -f \"pyproject.toml\" ]; then\n    PROJECT_TYPE=\"python\"\n    echo \"🐍 Python project detected\"\n    \n    if command -v pytest >/dev/null 2>&1; then\n        TEST_FRAMEWORK=\"pytest\"\n        echo \"🧪 Pytest testing framework available\"\n    elif python -c \"import unittest\" 2>/dev/null; then\n        TEST_FRAMEWORK=\"unittest\"\n        echo \"🔬 Unittest framework available\"\n    fi\n    \n# Rust project detection\nelif [ -f \"Cargo.toml\" ]; then\n    PROJECT_TYPE=\"rust\"\n    TEST_FRAMEWORK=\"cargo\"\n    echo \"🦀 Rust project detected\"\n    \n# Go project detection\nelif [ -f \"go.mod\" ]; then\n    PROJECT_TYPE=\"go\"\n    TEST_FRAMEWORK=\"go_test\"\n    echo \"🐹 Go project detected\"\n    \n# Java project detection\nelif [ -f \"pom.xml\" ] || [ -f \"build.gradle\" ]; then\n    PROJECT_TYPE=\"java\"\n    echo \"☕ Java project detected\"\n    \n    if [ -f \"pom.xml\" ]; then\n        TEST_FRAMEWORK=\"maven\"\n        echo \"🏗️ Maven build system detected\"\n    else\n        TEST_FRAMEWORK=\"gradle\"\n        echo \"🐘 Gradle build system detected\"\n    fi\nfi\n\necho \"\"\necho \"📊 Running coverage analysis for $PROJECT_TYPE project...\"\n\n# Run coverage based on project type\ncase \"$PROJECT_TYPE\" in\n    \"node\")\n        case \"$TEST_FRAMEWORK\" in\n            \"jest\")\n                echo \"🃏 Running Jest with coverage...\"\n                if npm test -- --coverage --silent 2>/dev/null; then\n                    COVERAGE_AVAILABLE=true\n                    echo \"✅ Jest coverage completed successfully\"\n                elif npm run test:coverage 2>/dev/null; then\n                    COVERAGE_AVAILABLE=true\n                    echo \"✅ Coverage script completed successfully\"\n                else\n                    echo \"⚠️ Jest coverage command failed - check test configuration\"\n                fi\n                ;;\n            \"vitest\")\n                echo \"⚡ Running Vitest with coverage...\"\n                if npx vitest run --coverage 2>/dev/null; then\n                    COVERAGE_AVAILABLE=true\n                    echo \"✅ Vitest coverage completed successfully\"\n                else\n                    echo \"⚠️ Vitest coverage command failed\"\n                fi\n                ;;\n            \"mocha\")\n                echo \"☕ Running Mocha with nyc coverage...\"\n                if npx nyc mocha 2>/dev/null; then\n                    COVERAGE_AVAILABLE=true\n                    echo \"✅ Mocha coverage completed successfully\"\n                else\n                    echo \"⚠️ Mocha coverage requires nyc - install with: npm install --save-dev nyc\"\n                fi\n                ;;\n            *)\n                echo \"⚠️ No recognized testing framework - attempting generic npm test\"\n                if npm test 2>/dev/null; then\n                    echo \"✅ Tests completed (coverage unknown)\"\n                else\n                    echo \"❌ Tests failed or not configured\"\n                fi\n                ;;\n        esac\n        ;;\n    \"python\")\n        case \"$TEST_FRAMEWORK\" in\n            \"pytest\")\n                echo \"🧪 Running pytest with coverage...\"\n                if pytest --cov=. --cov-report=term-missing --cov-report=html 2>/dev/null; then\n                    COVERAGE_AVAILABLE=true\n                    echo \"✅ Pytest coverage completed successfully\"\n                else\n                    echo \"⚠️ Pytest coverage failed - install with: pip install pytest-cov\"\n                fi\n                ;;\n            \"unittest\")\n                echo \"🔬 Running unittest with coverage...\"\n                if python -m coverage run -m unittest discover 2>/dev/null; then\n                    python -m coverage report 2>/dev/null\n                    COVERAGE_AVAILABLE=true\n                    echo \"✅ Unittest coverage completed successfully\"\n                else\n                    echo \"⚠️ Coverage.py not available - install with: pip install coverage\"\n                fi\n                ;;\n            *)\n                echo \"⚠️ No Python testing framework detected\"\n                ;;\n        esac\n        ;;\n    \"rust\")\n        echo \"🦀 Running Cargo test with coverage...\"\n        if command -v cargo-tarpaulin >/dev/null 2>&1; then\n            if cargo tarpaulin --out Html 2>/dev/null; then\n                COVERAGE_AVAILABLE=true\n                echo \"✅ Cargo tarpaulin coverage completed successfully\"\n            else\n                echo \"⚠️ Cargo tarpaulin failed\"\n            fi\n        else\n            echo \"⚠️ cargo-tarpaulin not installed - install with: cargo install cargo-tarpaulin\"\n            echo \"🔄 Running basic cargo test...\"\n            cargo test 2>/dev/null && echo \"✅ Tests completed (coverage unavailable)\"\n        fi\n        ;;\n    \"go\")\n        echo \"🐹 Running Go test with coverage...\"\n        if go test -coverprofile=coverage.out ./... 2>/dev/null; then\n            go tool cover -html=coverage.out -o coverage.html 2>/dev/null\n            COVERAGE_AVAILABLE=true\n            echo \"✅ Go coverage completed successfully\"\n        else\n            echo \"⚠️ Go test coverage failed\"\n        fi\n        ;;\n    \"java\")\n        case \"$TEST_FRAMEWORK\" in\n            \"maven\")\n                echo \"🏗️ Running Maven test with JaCoCo coverage...\"\n                if mvn test jacoco:report 2>/dev/null; then\n                    COVERAGE_AVAILABLE=true\n                    echo \"✅ Maven JaCoCo coverage completed successfully\"\n                else\n                    echo \"⚠️ Maven coverage failed - ensure JaCoCo plugin is configured\"\n                fi\n                ;;\n            \"gradle\")\n                echo \"🐘 Running Gradle test with JaCoCo coverage...\"\n                if ./gradlew test jacocoTestReport 2>/dev/null; then\n                    COVERAGE_AVAILABLE=true\n                    echo \"✅ Gradle JaCoCo coverage completed successfully\"\n                else\n                    echo \"⚠️ Gradle coverage failed - ensure JaCoCo plugin is configured\"\n                fi\n                ;;\n        esac\n        ;;\n    *)\n        echo \"❓ Unknown project type - cannot generate coverage report\"\n        echo \"💡 Supported: Node.js, Python, Rust, Go, Java\"\n        ;;\nesac\n\necho \"\"\necho \"📈 Coverage Report Summary:\"\necho \"═══════════════════════════\"\n\n# Display coverage results based on available formats\nif [ \"$COVERAGE_AVAILABLE\" = true ]; then\n    case \"$PROJECT_TYPE\" in\n        \"node\")\n            if [ -d \"coverage\" ]; then\n                echo \"📊 Coverage files found in coverage/ directory\"\n                \n                # Try to parse coverage summary\n                if [ -f \"coverage/coverage-summary.json\" ]; then\n                    echo \"📋 Coverage Summary:\"\n                    cat coverage/coverage-summary.json 2>/dev/null | jq -r '.total | \"Lines: \" + (.lines.pct|tostring) + \"% (\" + (.lines.covered|tostring) + \"/\" + (.lines.total|tostring) + \")\", \"Branches: \" + (.branches.pct|tostring) + \"% (\" + (.branches.covered|tostring) + \"/\" + (.branches.total|tostring) + \")\", \"Functions: \" + (.functions.pct|tostring) + \"% (\" + (.functions.covered|tostring) + \"/\" + (.functions.total|tostring) + \")\", \"Statements: \" + (.statements.pct|tostring) + \"% (\" + (.statements.covered|tostring) + \"/\" + (.statements.total|tostring) + \")\"' 2>/dev/null || echo \"Coverage summary parsing failed\"\n                fi\n                \n                echo \"🌐 HTML Report: file://$(pwd)/coverage/index.html\"\n            fi\n            ;;\n        \"python\")\n            if [ -d \"htmlcov\" ]; then\n                echo \"🌐 HTML Report: file://$(pwd)/htmlcov/index.html\"\n            fi\n            ;;\n        \"rust\")\n            if [ -f \"tarpaulin-report.html\" ]; then\n                echo \"🌐 HTML Report: file://$(pwd)/tarpaulin-report.html\"\n            fi\n            ;;\n        \"go\")\n            if [ -f \"coverage.html\" ]; then\n                echo \"🌐 HTML Report: file://$(pwd)/coverage.html\"\n            fi\n            ;;\n        \"java\")\n            if [ -d \"target/site/jacoco\" ]; then\n                echo \"🌐 HTML Report: file://$(pwd)/target/site/jacoco/index.html\"\n            elif [ -d \"build/reports/jacoco/test/html\" ]; then\n                echo \"🌐 HTML Report: file://$(pwd)/build/reports/jacoco/test/html/index.html\"\n            fi\n            ;;\n    esac\nelse\n    echo \"❌ No coverage data available\"\n    echo \"💡 Coverage Setup Tips:\"\n    case \"$PROJECT_TYPE\" in\n        \"node\")\n            echo \"  • For Jest: Add 'collectCoverage: true' to jest.config.js\"\n            echo \"  • For Vitest: Add 'coverage' provider to vite.config.js\"\n            echo \"  • Run: npm install --save-dev @vitest/coverage-c8\"\n            ;;\n        \"python\")\n            echo \"  • Install: pip install pytest-cov coverage\"\n            echo \"  • Run: pytest --cov=your_package\"\n            ;;\n        \"rust\")\n            echo \"  • Install: cargo install cargo-tarpaulin\"\n            echo \"  • Run: cargo tarpaulin --out Html\"\n            ;;\n        \"go\")\n            echo \"  • Built-in: go test -coverprofile=coverage.out\"\n            echo \"  • View: go tool cover -html=coverage.out\"\n            ;;\n        \"java\")\n            echo \"  • Add JaCoCo plugin to Maven/Gradle configuration\"\n            echo \"  • Maven: mvn test jacoco:report\"\n            echo \"  • Gradle: ./gradlew test jacocoTestReport\"\n            ;;\n    esac\nfi\n\necho \"\"\necho \"💡 Coverage Best Practices:\"\necho \"  • Aim for 80%+ line coverage on critical code\"\necho \"  • Focus on testing business logic and edge cases\"\necho \"  • Use coverage to identify untested code, not as a quality metric\"\necho \"  • Write meaningful tests, not just coverage-driven tests\"\necho \"  • Exclude generated code and vendor dependencies\"\necho \"  • Set up coverage thresholds in CI/CD pipelines\"\n\necho \"\"\necho \"🎯 Test coverage analysis complete!\"\necho \"═══════════════════════════════════════════════════\"\n\nexit 0"
      },
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/test-coverage-final-report"
    },
    {
      "slug": "code-test-runner-hook",
      "description": "Automatically run relevant tests when code changes are detected, with intelligent test selection and parallel execution",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-16",
      "tags": [
        "testing",
        "automation",
        "ci-cd",
        "watch",
        "parallel"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Intelligent test selection based on code changes",
        "Parallel test execution for faster feedback",
        "Support for multiple testing frameworks",
        "Fail-fast mode for quick feedback",
        "Smart retry for flaky tests",
        "Impact analysis and dependency mapping",
        "Integration with CI/CD pipelines"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/code-test-runner-hook.sh",
              "matchers": [
                "write",
                "edit",
                "multiedit"
              ]
            }
          }
        },
        "scriptContent": "#!/usr/bin/env bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\necho \"🧪 Running tests for $FILE_PATH...\"\n\n# Get file extension and directory\nEXT=\"${FILE_PATH##*.}\"\nDIR=$(dirname \"$FILE_PATH\")\n\n# Find and run relevant tests based on file type\ncase \"$EXT\" in\n  js|jsx|ts|tsx)\n    # JavaScript/TypeScript files\n    if [ -f \"package.json\" ]; then\n      if command -v npm &> /dev/null && npm list jest &> /dev/null; then\n        echo \"Running Jest tests...\"\n        npm test -- --testPathPattern=\"$FILE_PATH\" --passWithNoTests 2>/dev/null\n      elif command -v npm &> /dev/null && npm list vitest &> /dev/null; then\n        echo \"Running Vitest tests...\"\n        npx vitest run \"$FILE_PATH\" 2>/dev/null\n      fi\n    fi\n    ;;\n  py)\n    # Python files\n    if command -v pytest &> /dev/null; then\n      echo \"Running pytest...\"\n      pytest \"${FILE_PATH%.*}_test.py\" \"${DIR}/test_*.py\" 2>/dev/null || echo \"No Python tests found\"\n    elif command -v python &> /dev/null; then\n      echo \"Running Python unittest...\"\n      python -m unittest discover -s \"$DIR\" -p \"*test*.py\" 2>/dev/null || echo \"No Python tests found\"\n    fi\n    ;;\n  go)\n    # Go files\n    if command -v go &> /dev/null; then\n      echo \"Running Go tests...\"\n      go test \"${DIR}/...\" 2>/dev/null || echo \"No Go tests found\"\n    fi\n    ;;\n  java)\n    # Java files\n    if command -v mvn &> /dev/null && [ -f \"pom.xml\" ]; then\n      echo \"Running Maven tests...\"\n      mvn test 2>/dev/null\n    elif command -v gradle &> /dev/null && [ -f \"build.gradle\" ]; then\n      echo \"Running Gradle tests...\"\n      gradle test 2>/dev/null\n    fi\n    ;;\nesac\n\necho \"✅ Test execution completed for $FILE_PATH\" >&2\nexit 0"
      },
      "useCases": [
        "Automated testing in CI/CD pipelines",
        "Real-time test feedback during development",
        "Intelligent test selection for large codebases",
        "Parallel test execution for faster builds",
        "Pre-commit test validation"
      ],
      "troubleshooting": [
        {
          "issue": "Tests run on every file save slowing down",
          "solution": "Add file extension filter or test file detection: `if [[ \"$FILE_PATH\" == *test* ]] || [[ \"$FILE_PATH\" == *spec* ]]; then exit 0; fi` to skip running tests when editing test files themselves."
        },
        {
          "issue": "Jest testPathPattern not finding related tests",
          "solution": "Pattern matches test file paths not source. Use `--findRelatedTests` instead: `npm test -- --findRelatedTests=\"$FILE_PATH\"` which finds tests importing the changed file through dependency graph."
        },
        {
          "issue": "Hook runs tests twice with both Jest and Vitest",
          "solution": "Detection uses `npm list jest` which may find both. Add explicit priority: `if npm list jest &> /dev/null; then run_jest; exit 0; elif npm list vitest ...` to prevent fallthrough."
        },
        {
          "issue": "Python tests fail to locate test directory",
          "solution": "Hook looks for `${FILE_PATH%.*}_test.py` and `test_*.py`. For pytest, use explicit discovery: `pytest --collect-only \"$DIR\" 2>/dev/null | grep \"test session starts\"` to verify test detection."
        },
        {
          "issue": "Go tests timeout on large module changes",
          "solution": "Add timeout flag and scope: `go test -timeout 30s \"${DIR}\" 2>/dev/null` instead of `${DIR}/...` which tests all subpackages. Or use `go test -short` for quick tests only during development."
        }
      ],
      "documentationUrl": "https://jestjs.io/docs/getting-started",
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/code-test-runner-hook"
    },
    {
      "slug": "typescript-compilation-checker",
      "seoTitle": "TypeScript Checker",
      "description": "Automatically runs TypeScript compiler checks after editing .ts or .tsx files to catch type errors early",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "typescript",
        "validation",
        "type-safety",
        "compilation"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Real-time TypeScript compilation checking",
        "Type error detection and reporting",
        "No-emit mode for fast validation",
        "TSX and TS file support",
        "Clear error messaging and feedback",
        "Integration with project tsconfig.json"
      ],
      "useCases": [
        "Catch TypeScript errors immediately after editing",
        "Validate type safety before commits",
        "Ensure code compiles without errors",
        "Prevent broken TypeScript from entering codebase",
        "Quick feedback on type-related issues",
        "Maintain code quality standards",
        "Support both .ts and .tsx files",
        "Integration with existing TypeScript projects"
      ],
      "troubleshooting": [
        {
          "issue": "tsc --noEmit checks entire project instead of single file",
          "solution": "TypeScript follows imports checking dependencies. Add --skipLibCheck: 'tsc --noEmit --skipLibCheck \"$FILE_PATH\"' or use --isolatedModules for single-file validation without imports."
        },
        {
          "issue": "Compilation fails with module resolution errors for node_modules",
          "solution": "Missing @types packages or wrong moduleResolution. Install types: 'npm install --save-dev @types/node @types/react'. Set tsconfig: '\"moduleResolution\": \"node\"' or \"bundler\"."
        },
        {
          "issue": "Hook shows success but VSCode still displays type errors",
          "solution": "Different TS versions between CLI and editor. Check: 'npx tsc --version' vs VSCode version. Sync: install workspace TS: 'npm install --save-dev typescript@latest'. Restart VSCode."
        },
        {
          "issue": "'any' type detection misses implicit any from missing type annotations",
          "solution": "grep pattern only finds explicit ': any'. Enable noImplicitAny in tsconfig.json. Or check tsc output: parse 'implicitly has an any type' from compilation errors for complete detection."
        },
        {
          "issue": "Project-wide health check freezes on large monorepos",
          "solution": "Full tsc scans thousands of files. Skip or timeout: 'timeout 10 npx tsc --noEmit >/dev/null 2>&1' with exit code check. Or remove: comment out project compilation section."
        }
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/typescript-compilation-checker.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/bin/bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Check if this is a TypeScript file\nif [[ \"$FILE_PATH\" == *.ts ]] || [[ \"$FILE_PATH\" == *.tsx ]]; then\n    echo \"🔍 TypeScript Compilation Checker - Validating TypeScript code...\"\n    echo \"📄 File: $FILE_PATH\"\n    \n    # Check if file exists\n    if [ ! -f \"$FILE_PATH\" ]; then\n        echo \"⚠️ File not found: $FILE_PATH\"\n        exit 1\n    fi\n    \n    # Check if TypeScript is available\n    if ! command -v npx >/dev/null 2>&1; then\n        echo \"⚠️ npx not found - please install Node.js\"\n        exit 1\n    fi\n    \n    if ! npx tsc --version >/dev/null 2>&1; then\n        echo \"⚠️ TypeScript not found - install with: npm install -g typescript\"\n        exit 1\n    fi\n    \n    # Get TypeScript version\n    TS_VERSION=$(npx tsc --version 2>/dev/null | grep -o '[0-9]\\+\\.[0-9]\\+\\.[0-9]\\+')\n    echo \"📦 TypeScript version: $TS_VERSION\"\n    \n    # Check for tsconfig.json\n    if [ -f \"tsconfig.json\" ]; then\n        echo \"⚙️ Using project tsconfig.json\"\n        CONFIG_FLAG=\"\"\n    else\n        echo \"⚠️ No tsconfig.json found - using default configuration\"\n        CONFIG_FLAG=\"--strict --target es2020 --module esnext --moduleResolution node\"\n    fi\n    \n    echo \"🔍 Running TypeScript compilation check...\"\n    \n    # Run TypeScript compiler in no-emit mode\n    if npx tsc --noEmit $CONFIG_FLAG \"$FILE_PATH\" 2>&1; then\n        echo \"✅ TypeScript compilation successful - no type errors found\"\n        \n        # Additional file analysis\n        echo \"\"\n        echo \"📊 File Analysis:\"\n        \n        # Count interfaces, types, classes\n        INTERFACES=$(grep -c '^interface\\\\|^export interface' \"$FILE_PATH\" 2>/dev/null || echo 0)\n        TYPES=$(grep -c '^type\\\\|^export type' \"$FILE_PATH\" 2>/dev/null || echo 0)\n        CLASSES=$(grep -c '^class\\\\|^export class' \"$FILE_PATH\" 2>/dev/null || echo 0)\n        FUNCTIONS=$(grep -c '^function\\\\|^export function' \"$FILE_PATH\" 2>/dev/null || echo 0)\n        \n        echo \"  • Interfaces: $INTERFACES\"\n        echo \"  • Type aliases: $TYPES\"\n        echo \"  • Classes: $CLASSES\"\n        echo \"  • Functions: $FUNCTIONS\"\n        \n        # Check for any usage\n        if grep -q ': any' \"$FILE_PATH\" 2>/dev/null; then\n            ANY_COUNT=$(grep -c ': any' \"$FILE_PATH\" 2>/dev/null || echo 0)\n            echo \"  • ⚠️ 'any' types found: $ANY_COUNT (consider more specific types)\"\n        fi\n        \n        # Check for strict mode compliance\n        if grep -q '\"use strict\"' \"$FILE_PATH\" 2>/dev/null; then\n            echo \"  • ✅ Strict mode enabled\"\n        fi\n        \n    else\n        echo \"❌ TypeScript compilation failed - type errors detected\"\n        echo \"\"\n        echo \"💡 Common fixes:\"\n        echo \"  • Check for missing type annotations\"\n        echo \"  • Verify import statements are correct\"\n        echo \"  • Ensure all variables are properly typed\"\n        echo \"  • Check for undefined/null value handling\"\n        echo \"  • Verify function return types match implementation\"\n        exit 1\n    fi\n    \n    # Project-wide TypeScript health check\n    echo \"\"\n    echo \"🏗️ Project TypeScript Health:\"\n    \n    # Count total TypeScript files\n    TS_FILES=$(find . -name \"*.ts\" -o -name \"*.tsx\" | grep -v node_modules | wc -l)\n    echo \"  • Total TS/TSX files: $TS_FILES\"\n    \n    # Check if project compiles\n    if [ -f \"tsconfig.json\" ]; then\n        echo \"  • 🔍 Checking project compilation...\"\n        if npx tsc --noEmit >/dev/null 2>&1; then\n            echo \"  • ✅ Project compiles successfully\"\n        else\n            echo \"  • ⚠️ Project has compilation errors - run 'npx tsc --noEmit' for details\"\n        fi\n    fi\n    \n    echo \"\"\n    echo \"💡 TypeScript Best Practices:\"\n    echo \"  • Use strict TypeScript configuration\"\n    echo \"  • Avoid 'any' types when possible\"\n    echo \"  • Use union types for multiple possibilities\"\n    echo \"  • Implement proper error handling with typed exceptions\"\n    echo \"  • Use interface segregation principle\"\n    \n    echo \"\"\n    echo \"🎯 TypeScript validation complete!\"\n    \nelse\n    echo \"ℹ️ File is not a TypeScript file: $FILE_PATH\"\nfi\n\nexit 0"
      },
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/typescript-compilation-checker"
    },
    {
      "slug": "vue-composition-api-linter",
      "description": "Lints Vue 3 components for Composition API best practices and common issues",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "vue",
        "vue3",
        "composition-api",
        "linting",
        "best-practices"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Vue 3 Composition API best practices validation",
        "Script setup syntax analysis and optimization",
        "Reactivity pattern checking (ref, reactive, computed)",
        "Lifecycle hook usage validation",
        "TypeScript support with vue-tsc integration",
        "Performance optimization suggestions"
      ],
      "useCases": [
        "Ensure proper Composition API usage in Vue 3 components",
        "Validate reactivity patterns and data flow",
        "Check for performance issues and optimization opportunities",
        "Enforce consistent component structure and practices",
        "Detect common Vue 3 migration issues",
        "Validate TypeScript usage in Vue components",
        "Ensure proper lifecycle hook implementation",
        "Maintain code quality across Vue application"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/vue-composition-api-linter.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/bin/bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\n# Check if this is a Vue component file\nif [[ \"$FILE_PATH\" == *.vue ]]; then\n    echo \"✨ Vue Composition API Linter - Analyzing Vue component...\"\n    echo \"📄 Component: $FILE_PATH\"\n    \n    # Check if file exists\n    if [ ! -f \"$FILE_PATH\" ]; then\n        echo \"⚠️ Vue component file not found: $FILE_PATH\"\n        exit 1\n    fi\n    \n    # Detect Vue version and project setup\n    VUE_VERSION=\"unknown\"\n    PROJECT_TYPE=\"vue\"\n    \n    if [ -f \"package.json\" ]; then\n        if grep -q '\"vue\".*\"^3\\.' package.json 2>/dev/null; then\n            VUE_VERSION=\"3\"\n            echo \"🎯 Vue 3 project detected\"\n        elif grep -q '\"vue\".*\"^2\\.' package.json 2>/dev/null; then\n            VUE_VERSION=\"2\"\n            echo \"⚠️ Vue 2 project detected - Composition API available with @vue/composition-api\"\n        fi\n        \n        # Check for Nuxt\n        if grep -q '\"nuxt\"' package.json 2>/dev/null; then\n            PROJECT_TYPE=\"nuxt\"\n            echo \"🚀 Nuxt project detected\"\n        fi\n        \n        # Check for Vite\n        if grep -q '\"vite\"' package.json 2>/dev/null; then\n            echo \"⚡ Vite build system detected\"\n        fi\n    fi\n    \n    # Component structure analysis\n    echo \"\"\n    echo \"🔍 Analyzing component structure...\"\n    \n    # Check for script setup\n    SCRIPT_SETUP=false\n    if grep -q '<script setup' \"$FILE_PATH\" 2>/dev/null; then\n        SCRIPT_SETUP=true\n        echo \"✅ Script setup syntax detected\"\n        \n        # Check for TypeScript\n        if grep -q '<script setup lang=\"ts\">' \"$FILE_PATH\" 2>/dev/null; then\n            echo \"📘 TypeScript script setup detected\"\n        fi\n    elif grep -q '<script>' \"$FILE_PATH\" 2>/dev/null; then\n        echo \"ℹ️ Traditional script syntax detected\"\n        echo \"💡 Consider migrating to <script setup> for better performance\"\n    fi\n    \n    # Check for template\n    if grep -q '<template>' \"$FILE_PATH\" 2>/dev/null; then\n        echo \"✅ Template block found\"\n    fi\n    \n    # Check for styles\n    if grep -q '<style' \"$FILE_PATH\" 2>/dev/null; then\n        echo \"✅ Style block found\"\n        \n        if grep -q '<style scoped' \"$FILE_PATH\" 2>/dev/null; then\n            echo \"🎯 Scoped styles detected\"\n        fi\n        \n        if grep -q 'lang=\"scss\"\\|lang=\"sass\"\\|lang=\"less\"' \"$FILE_PATH\" 2>/dev/null; then\n            echo \"🎨 CSS preprocessor detected\"\n        fi\n    fi\n    \n    # Composition API analysis\n    echo \"\"\n    echo \"🔍 Composition API Analysis:\"\n    \n    # Check for Composition API imports and usage\n    COMPOSABLES_USED=()\n    \n    if grep -q 'ref(' \"$FILE_PATH\" 2>/dev/null; then\n        REF_COUNT=$(grep -c 'ref(' \"$FILE_PATH\" 2>/dev/null || echo 0)\n        echo \"  • ref() usage: $REF_COUNT instances\"\n        COMPOSABLES_USED+=(\"ref\")\n    fi\n    \n    if grep -q 'reactive(' \"$FILE_PATH\" 2>/dev/null; then\n        REACTIVE_COUNT=$(grep -c 'reactive(' \"$FILE_PATH\" 2>/dev/null || echo 0)\n        echo \"  • reactive() usage: $REACTIVE_COUNT instances\"\n        COMPOSABLES_USED+=(\"reactive\")\n    fi\n    \n    if grep -q 'computed(' \"$FILE_PATH\" 2>/dev/null; then\n        COMPUTED_COUNT=$(grep -c 'computed(' \"$FILE_PATH\" 2>/dev/null || echo 0)\n        echo \"  • computed() usage: $COMPUTED_COUNT instances\"\n        COMPOSABLES_USED+=(\"computed\")\n    fi\n    \n    if grep -q 'watch(' \"$FILE_PATH\" 2>/dev/null; then\n        WATCH_COUNT=$(grep -c 'watch(' \"$FILE_PATH\" 2>/dev/null || echo 0)\n        echo \"  • watch() usage: $WATCH_COUNT instances\"\n        COMPOSABLES_USED+=(\"watch\")\n    fi\n    \n    if grep -q 'watchEffect(' \"$FILE_PATH\" 2>/dev/null; then\n        WATCH_EFFECT_COUNT=$(grep -c 'watchEffect(' \"$FILE_PATH\" 2>/dev/null || echo 0)\n        echo \"  • watchEffect() usage: $WATCH_EFFECT_COUNT instances\"\n        COMPOSABLES_USED+=(\"watchEffect\")\n    fi\n    \n    # Lifecycle hooks\n    LIFECYCLE_HOOKS=(\"onMounted\" \"onUpdated\" \"onUnmounted\" \"onBeforeMount\" \"onBeforeUpdate\" \"onBeforeUnmount\")\n    for hook in \"${LIFECYCLE_HOOKS[@]}\"; do\n        if grep -q \"$hook(\" \"$FILE_PATH\" 2>/dev/null; then\n            echo \"  • 🔄 $hook lifecycle hook detected\"\n        fi\n    done\n    \n    # Props and emits analysis\n    if grep -q 'defineProps' \"$FILE_PATH\" 2>/dev/null; then\n        echo \"  • 📥 defineProps() detected\"\n    fi\n    \n    if grep -q 'defineEmits' \"$FILE_PATH\" 2>/dev/null; then\n        echo \"  • 📤 defineEmits() detected\"\n    fi\n    \n    if grep -q 'defineExpose' \"$FILE_PATH\" 2>/dev/null; then\n        echo \"  • 🔗 defineExpose() detected\"\n    fi\n    \n    # ESLint analysis\n    echo \"\"\n    echo \"🔍 Running ESLint analysis...\"\n    \n    ESLINT_AVAILABLE=false\n    if command -v npx >/dev/null 2>&1 && npx eslint --version >/dev/null 2>&1; then\n        ESLINT_AVAILABLE=true\n        \n        # Try Vue-specific ESLint config first\n        if [ -f \".eslintrc.vue.js\" ] || [ -f \".eslintrc.js\" ] && grep -q 'vue' .eslintrc.js 2>/dev/null; then\n            echo \"📋 Running ESLint with Vue configuration...\"\n            if npx eslint \"$FILE_PATH\" --ext .vue 2>/dev/null; then\n                echo \"✅ ESLint analysis passed\"\n            else\n                echo \"⚠️ ESLint found issues - review output above\"\n            fi\n        else\n            echo \"⚠️ No Vue-specific ESLint configuration found\"\n            echo \"💡 Install: npm install --save-dev eslint @vue/eslint-config-typescript\"\n        fi\n    else\n        echo \"⚠️ ESLint not available - install with: npm install --save-dev eslint\"\n    fi\n    \n    # Type checking with vue-tsc\n    echo \"\"\n    echo \"📘 TypeScript Analysis:\"\n    \n    if grep -q 'lang=\"ts\"' \"$FILE_PATH\" 2>/dev/null; then\n        echo \"🔍 TypeScript component detected\"\n        \n        if command -v npx >/dev/null 2>&1 && npx vue-tsc --version >/dev/null 2>&1; then\n            echo \"🔍 Running vue-tsc type checking...\"\n            if npx vue-tsc --noEmit 2>/dev/null; then\n                echo \"✅ TypeScript type checking passed\"\n            else\n                echo \"⚠️ TypeScript type errors detected\"\n            fi\n        else\n            echo \"⚠️ vue-tsc not available - install with: npm install --save-dev vue-tsc\"\n        fi\n    else\n        echo \"ℹ️ JavaScript component - consider TypeScript for better type safety\"\n    fi\n    \n    # Best practices analysis\n    echo \"\"\n    echo \"💡 Best Practices Analysis:\"\n    \n    # Check for common issues\n    ISSUES_FOUND=0\n    \n    if grep -q 'this\\.' \"$FILE_PATH\" 2>/dev/null && [ \"$SCRIPT_SETUP\" = true ]; then\n        echo \"  • ⚠️ 'this' usage detected in script setup - use direct variable access\"\n        ISSUES_FOUND=$((ISSUES_FOUND + 1))\n    fi\n    \n    if grep -q 'reactive(' \"$FILE_PATH\" 2>/dev/null && grep -q 'ref(' \"$FILE_PATH\" 2>/dev/null; then\n        echo \"  • 💡 Both ref() and reactive() used - ensure consistent patterns\"\n    fi\n    \n    if ! grep -q 'const.*=' \"$FILE_PATH\" 2>/dev/null && [ \"${#COMPOSABLES_USED[@]}\" -gt 0 ]; then\n        echo \"  • 💡 Consider using const for reactive declarations\"\n    fi\n    \n    if grep -q 'v-for.*:key' \"$FILE_PATH\" 2>/dev/null; then\n        echo \"  • ✅ v-for with :key detected - good practice\"\n    elif grep -q 'v-for' \"$FILE_PATH\" 2>/dev/null; then\n        echo \"  • ⚠️ v-for without :key detected - add unique keys\"\n        ISSUES_FOUND=$((ISSUES_FOUND + 1))\n    fi\n    \n    if [ \"$ISSUES_FOUND\" -eq 0 ]; then\n        echo \"  • ✅ No common issues detected\"\n    fi\n    \n    echo \"\"\n    echo \"💡 Vue 3 Composition API Best Practices:\"\n    echo \"  • Use <script setup> for better performance and DX\"\n    echo \"  • Prefer ref() for primitive values, reactive() for objects\"\n    echo \"  • Use computed() for derived state\"\n    echo \"  • Implement proper TypeScript typing for better IntelliSense\"\n    echo \"  • Use defineProps/defineEmits for component interface\"\n    echo \"  • Organize composables into separate files for reusability\"\n    echo \"  • Use shallowRef/shallowReactive for performance optimization\"\n    \n    echo \"\"\n    echo \"🎯 Vue component analysis complete!\"\n    \nelse\n    echo \"ℹ️ File is not a Vue component: $FILE_PATH\"\nfi\n\nexit 0"
      },
      "troubleshooting": [
        {
          "issue": "ESLint runs on entire project not just modified .vue file causing timeout",
          "solution": "Remove --ext .vue flag scanning all components. Replace: 'npx eslint \"$FILE_PATH\"' targeting single file. Or add: '--no-eslintrc --rule \"vue/no-unused-vars\": error' for quick checks only."
        },
        {
          "issue": "vue-tsc type checking shows errors from node_modules dependencies",
          "solution": "Missing tsconfig exclude pattern. Add: 'npx vue-tsc --noEmit --skipLibCheck' ignoring external types. Or create: 'tsconfig.vue.json' with '\"exclude\": [\"node_modules\"]'."
        },
        {
          "issue": "Hook incorrectly flags 'this' usage in <template> section as error",
          "solution": "grep matches template expressions not just script. Refine: 'grep \"<script\" -A 200 \"$FILE_PATH\" | grep \"this\\.\"' limiting to script blocks. Or exclude: 'grep -v \"<template>\" before checking."
        },
        {
          "issue": "defineProps/defineEmits detection fails with TypeScript generic syntax",
          "solution": "Pattern 'defineProps(' misses generic form 'defineProps<Props>()'. Add: 'grep -E \"defineProps(<|\\\\()\" matching both. Or use: 'grep \"defineProps\" ignoring parentheses for broader match."
        },
        {
          "issue": "Reactive/ref count inflated by counting imports and comments",
          "solution": "grep matches 'import { ref }' and '// ref()' comments. Filter: 'grep -v \"^\\s*//\" | grep -v \"import\" | grep -c \"ref(\"' excluding non-usage. Or limit: 'grep \"<script setup>\" -A 100' to script body only."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/vue-composition-api-linter"
    },
    {
      "slug": "webpack-bundle-analyzer",
      "description": "Analyzes webpack bundle size when webpack config or entry files are modified",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "webpack",
        "bundle",
        "performance",
        "optimization",
        "analysis"
      ],
      "hookType": "PostToolUse",
      "features": [
        "Interactive bundle size visualization and analysis",
        "Automatic bundle analysis on configuration changes",
        "Support for multiple build tools (Webpack, Vite, Rollup)",
        "Performance optimization recommendations",
        "Dependency size tracking and optimization",
        "Tree-shaking effectiveness analysis"
      ],
      "useCases": [
        "Analyze bundle size after webpack configuration changes",
        "Identify large dependencies impacting bundle size",
        "Optimize bundle splitting and code splitting strategies",
        "Track bundle size over time for performance monitoring",
        "Identify unused code and dependencies",
        "Optimize tree-shaking and dead code elimination",
        "Compare before/after bundle sizes for optimization",
        "Generate reports for performance review"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "postToolUse": {
              "script": "./.claude/hooks/webpack-bundle-analyzer.sh",
              "matchers": [
                "write",
                "edit"
              ]
            }
          }
        },
        "scriptContent": "#!/bin/bash\n\n# Read the tool input from stdin\nINPUT=$(cat)\nTOOL_NAME=$(echo \"$INPUT\" | jq -r '.tool_name')\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // .tool_input.path // \"\"')\n\nif [ -z \"$FILE_PATH\" ]; then\n  exit 0\nfi\n\necho \"📊 Webpack Bundle Analyzer - Analyzing bundle performance...\"\necho \"📄 File: $FILE_PATH\"\n\n# Check if this is a relevant file for bundle analysis\nRELEVANT_FILE=false\n\nif [[ \"$FILE_PATH\" == *webpack.config.js ]] || \\\n   [[ \"$FILE_PATH\" == *webpack.config.ts ]] || \\\n   [[ \"$FILE_PATH\" == *vite.config.js ]] || \\\n   [[ \"$FILE_PATH\" == *vite.config.ts ]] || \\\n   [[ \"$FILE_PATH\" == *rollup.config.js ]] || \\\n   [[ \"$FILE_PATH\" == *src/index.js ]] || \\\n   [[ \"$FILE_PATH\" == *src/index.ts ]] || \\\n   [[ \"$FILE_PATH\" == *src/main.js ]] || \\\n   [[ \"$FILE_PATH\" == *src/main.ts ]] || \\\n   [[ \"$FILE_PATH\" == *package.json ]]; then\n    RELEVANT_FILE=true\nfi\n\nif [ \"$RELEVANT_FILE\" = false ]; then\n    echo \"ℹ️ File does not require bundle analysis: $FILE_PATH\"\n    exit 0\nfi\n\necho \"🔍 Detecting build system and configuration...\"\n\n# Detect build system\nBUILD_SYSTEM=\"unknown\"\nif [ -f \"webpack.config.js\" ] || [ -f \"webpack.config.ts\" ]; then\n    BUILD_SYSTEM=\"webpack\"\n    echo \"📦 Webpack configuration detected\"\nelif [ -f \"vite.config.js\" ] || [ -f \"vite.config.ts\" ]; then\n    BUILD_SYSTEM=\"vite\"\n    echo \"⚡ Vite configuration detected\"\nelif [ -f \"rollup.config.js\" ] || [ -f \"rollup.config.ts\" ]; then\n    BUILD_SYSTEM=\"rollup\"\n    echo \"🎯 Rollup configuration detected\"\nelif [ -f \"package.json\" ] && grep -q '\"react-scripts\"' package.json 2>/dev/null; then\n    BUILD_SYSTEM=\"cra\"\n    echo \"⚛️ Create React App detected\"\nelif [ -f \"next.config.js\" ] || [ -f \"next.config.ts\" ]; then\n    BUILD_SYSTEM=\"next\"\n    echo \"🔺 Next.js configuration detected\"\nelse\n    echo \"❓ No recognized build system found\"\nfi\n\n# Check for bundle analyzer availability\nANALYZER_AVAILABLE=false\nif command -v npx >/dev/null 2>&1; then\n    if npx webpack-bundle-analyzer --version >/dev/null 2>&1; then\n        ANALYZER_AVAILABLE=true\n        echo \"✅ webpack-bundle-analyzer available\"\n    else\n        echo \"⚠️ webpack-bundle-analyzer not available - install with: npm install --save-dev webpack-bundle-analyzer\"\n    fi\nelse\n    echo \"⚠️ npx not available - please install Node.js\"\nfi\n\n# Perform bundle analysis based on build system\ncase \"$BUILD_SYSTEM\" in\n    \"webpack\")\n        echo \"📊 Analyzing Webpack bundle...\"\n        \n        # Check if dist directory exists\n        if [ ! -d \"dist\" ] && [ ! -d \"build\" ]; then\n            echo \"🏗️ Building project to generate bundle...\"\n            if npm run build 2>/dev/null; then\n                echo \"✅ Build completed successfully\"\n            else\n                echo \"❌ Build failed - cannot analyze bundle\"\n                exit 1\n            fi\n        fi\n        \n        # Find stats file or generate one\n        STATS_FILE=\"\"\n        if [ -f \"dist/stats.json\" ]; then\n            STATS_FILE=\"dist/stats.json\"\n        elif [ -f \"build/stats.json\" ]; then\n            STATS_FILE=\"build/stats.json\"\n        else\n            echo \"📈 Generating webpack stats...\"\n            if npx webpack --profile --json > webpack-stats.json 2>/dev/null; then\n                STATS_FILE=\"webpack-stats.json\"\n                echo \"✅ Stats file generated: $STATS_FILE\"\n            else\n                echo \"❌ Failed to generate webpack stats\"\n                exit 1\n            fi\n        fi\n        \n        # Run bundle analyzer\n        if [ \"$ANALYZER_AVAILABLE\" = true ] && [ -n \"$STATS_FILE\" ]; then\n            echo \"🔍 Running bundle analysis...\"\n            if npx webpack-bundle-analyzer \"$STATS_FILE\" --mode static --report bundle-report.html --no-open 2>/dev/null; then\n                echo \"✅ Bundle analysis completed\"\n                echo \"📊 Report saved to: bundle-report.html\"\n                echo \"🌐 View report: file://$(pwd)/bundle-report.html\"\n            else\n                echo \"⚠️ Bundle analysis failed\"\n            fi\n        fi\n        ;;\n    \"vite\")\n        echo \"⚡ Analyzing Vite bundle...\"\n        \n        # Check if Vite has bundle analysis plugin\n        if grep -q 'vite-bundle-analyzer\\|rollup-plugin-analyzer' package.json 2>/dev/null; then\n            echo \"📊 Running Vite bundle analysis...\"\n            if npm run build -- --analyze 2>/dev/null; then\n                echo \"✅ Vite bundle analysis completed\"\n            else\n                echo \"⚠️ Vite bundle analysis failed\"\n            fi\n        else\n            echo \"💡 Install vite-bundle-analyzer for detailed analysis:\"\n            echo \"    npm install --save-dev vite-bundle-analyzer\"\n            \n            # Basic build size analysis\n            echo \"📏 Running basic build analysis...\"\n            if npm run build 2>/dev/null; then\n                if [ -d \"dist\" ]; then\n                    echo \"📊 Build output analysis:\"\n                    find dist -name \"*.js\" -exec du -h {} \\; | sort -hr | head -10\n                fi\n            fi\n        fi\n        ;;\n    \"next\")\n        echo \"🔺 Analyzing Next.js bundle...\"\n        \n        if grep -q '@next/bundle-analyzer' package.json 2>/dev/null; then\n            echo \"📊 Running Next.js bundle analysis...\"\n            if ANALYZE=true npm run build 2>/dev/null; then\n                echo \"✅ Next.js bundle analysis completed\"\n            else\n                echo \"⚠️ Next.js bundle analysis failed\"\n            fi\n        else\n            echo \"💡 Install @next/bundle-analyzer for detailed analysis:\"\n            echo \"    npm install --save-dev @next/bundle-analyzer\"\n        fi\n        ;;\n    \"cra\")\n        echo \"⚛️ Analyzing Create React App bundle...\"\n        \n        if npm list --depth=0 | grep -q 'source-map-explorer' 2>/dev/null; then\n            echo \"📊 Running source-map-explorer...\"\n            if npm run build && npx source-map-explorer 'build/static/js/*.js' 2>/dev/null; then\n                echo \"✅ CRA bundle analysis completed\"\n            else\n                echo \"⚠️ CRA bundle analysis failed\"\n            fi\n        else\n            echo \"💡 Install source-map-explorer for detailed analysis:\"\n            echo \"    npm install --save-dev source-map-explorer\"\n        fi\n        ;;\n    *)\n        echo \"❓ Unknown build system - attempting generic analysis\"\n        \n        # Try to analyze any existing build output\n        for dir in dist build public; do\n            if [ -d \"$dir\" ]; then\n                echo \"📊 Analyzing $dir directory:\"\n                find \"$dir\" -name \"*.js\" -o -name \"*.css\" | head -10 | while read -r file; do\n                    size=$(du -h \"$file\" 2>/dev/null | cut -f1)\n                    echo \"  • $file: $size\"\n                done\n            fi\n        done\n        ;;\nesac\n\n# General optimization suggestions\necho \"\"\necho \"💡 Bundle Optimization Tips:\"\necho \"  • Enable tree-shaking to remove unused code\"\necho \"  • Use dynamic imports for code splitting\"\necho \"  • Optimize images and static assets\"\necho \"  • Use compression (gzip/brotli) for production\"\necho \"  • Analyze and remove large unnecessary dependencies\"\necho \"  • Use webpack-bundle-analyzer for detailed insights\"\necho \"  • Consider lazy loading for non-critical components\"\necho \"  • Review and optimize polyfills\"\n\necho \"\"\necho \"📊 Bundle Analysis Tools:\"\necho \"  • Webpack: webpack-bundle-analyzer\"\necho \"  • Vite: vite-bundle-analyzer\"\necho \"  • Next.js: @next/bundle-analyzer\"\necho \"  • CRA: source-map-explorer\"\necho \"  • General: bundlephobia.com for dependency analysis\"\n\necho \"\"\necho \"🎯 Bundle analysis complete!\"\n\nexit 0"
      },
      "troubleshooting": [
        {
          "issue": "Build triggered on every config edit is slow",
          "solution": "Add build skip flag or cache check: `if [ -f .bundle-analyzed-$(md5sum webpack.config.js | cut -d' ' -f1) ]; then exit 0; fi` to track analyzed configs and skip rebuilds for unchanged hashes."
        },
        {
          "issue": "webpack-bundle-analyzer opens browser automatically",
          "solution": "Hook uses `--no-open` flag: `npx webpack-bundle-analyzer \"$STATS_FILE\" --mode static --report bundle-report.html --no-open`. Verify flag is present in script line 154 to prevent browser launch."
        },
        {
          "issue": "Stats file generation fails with webpack errors",
          "solution": "Check webpack config validity first: `npx webpack --config webpack.config.js --json > /dev/null 2>&1` to test. If fails, examine error with `npx webpack --profile --json 2>&1 | tee webpack-errors.log`"
        },
        {
          "issue": "Vite build doesn't support --analyze flag",
          "solution": "Install plugin: `npm i -D rollup-plugin-visualizer`, add to vite.config: `import { visualizer } from 'rollup-plugin-visualizer'; plugins: [visualizer()]`, rebuild."
        },
        {
          "issue": "Hook detects wrong build system for monorepo",
          "solution": "Detection scans root only. For workspace builds, modify check: `if [[ \"$FILE_PATH\" == packages/app/* ]]; then cd packages/app; BUILD_SYSTEM=...; fi`"
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/webpack-bundle-analyzer"
    },
    {
      "slug": "workflow-completion-report",
      "description": "Generates a comprehensive report when Claude Code workflow stops, including files modified, tests run, and git status",
      "category": "hooks",
      "author": "JSONbored",
      "dateAdded": "2025-09-19",
      "tags": [
        "reporting",
        "workflow",
        "analytics",
        "summary",
        "stop-hook"
      ],
      "hookType": "Stop",
      "features": [
        "Comprehensive workflow completion summary",
        "Detailed file modification tracking",
        "Git status and change analysis",
        "Test execution and coverage reporting",
        "Performance metrics and timing analysis",
        "Session archival and historical tracking"
      ],
      "useCases": [
        "Generate detailed session completion reports",
        "Track development productivity and progress",
        "Document code changes and modifications",
        "Analyze test coverage and quality metrics",
        "Create historical record of workflow sessions",
        "Monitor development velocity and patterns",
        "Generate reports for team review and analysis",
        "Archive session data for project documentation"
      ],
      "configuration": {
        "hookConfig": {
          "hooks": {
            "stop": {
              "script": "./.claude/hooks/workflow-completion-report.sh",
              "matchers": [
                "*"
              ]
            }
          }
        },
        "scriptContent": "#!/bin/bash\n\necho \"📊 ═══════════════════════════════════════════════════\"\necho \"🎯 WORKFLOW COMPLETION REPORT\"\necho \"📅 Session Completed: $(date)\"\necho \"═══════════════════════════════════════════════════\"\n\n# Session metadata\nSESSION_ID=\"session-$(date +%Y%m%d_%H%M%S)\"\nCOMPLETION_TIME=$(date)\nSTART_TIME=\"unknown\"\nUSER=$(whoami 2>/dev/null || echo \"developer\")\nHOST=$(hostname 2>/dev/null || echo \"unknown\")\nWORKDIR=$(pwd)\nPROJECT_NAME=$(basename \"$WORKDIR\" 2>/dev/null || echo \"project\")\n\necho \"🏷️ Session Info:\"\necho \"  • Session ID: $SESSION_ID\"\necho \"  • Project: $PROJECT_NAME\"\necho \"  • User: $USER@$HOST\"\necho \"  • Directory: $WORKDIR\"\n\n# Attempt to determine session duration\nif [ -d \".claude\" ] && [ \"$(find .claude -type f 2>/dev/null | wc -l)\" -gt 0 ]; then\n    START_TIMESTAMP=$(stat -f %B .claude/*.log 2>/dev/null | sort | head -1 || date +%s)\n    END_TIMESTAMP=$(date +%s)\n    DURATION=$((END_TIMESTAMP - START_TIMESTAMP))\n    HOURS=$((DURATION / 3600))\n    MINUTES=$(((DURATION % 3600) / 60))\n    echo \"  • Duration: ${HOURS}h ${MINUTES}m\"\nelse\n    echo \"  • Duration: Unknown (no .claude directory)\"\nfi\n\necho \"\"\necho \"📁 File System Analysis:\"\necho \"═══════════════════════════\"\n\n# Git analysis\nif git rev-parse --git-dir >/dev/null 2>&1; then\n    echo \"📊 Git Repository Status:\"\n    \n    BRANCH=$(git branch --show-current 2>/dev/null || echo \"unknown\")\n    echo \"  • Current branch: $BRANCH\"\n    \n    # Count modified files\n    MODIFIED_FILES=$(git status --porcelain 2>/dev/null | wc -l | tr -d ' ')\n    echo \"  • Modified files: $MODIFIED_FILES\"\n    \n    # Show file status breakdown\n    if [ \"$MODIFIED_FILES\" -gt 0 ]; then\n        echo \"  • File status breakdown:\"\n        git status --porcelain 2>/dev/null | cut -c1-2 | sort | uniq -c | while read -r count status; do\n            case \"$status\" in\n                \"M \"*) echo \"    - Modified: $count files\" ;;\n                \"A \"*) echo \"    - Added: $count files\" ;;\n                \"D \"*) echo \"    - Deleted: $count files\" ;;\n                \"??\"*) echo \"    - Untracked: $count files\" ;;\n                *) echo \"    - Other ($status): $count files\" ;;\n            esac\n        done\n    fi\n    \n    # Diff statistics\n    DIFF_STATS=$(git diff --stat 2>/dev/null)\n    if [ -n \"$DIFF_STATS\" ]; then\n        echo \"  • Changes summary:\"\n        echo \"$DIFF_STATS\" | tail -1 | sed 's/^/    /' 2>/dev/null || echo \"    No statistics available\"\n    fi\n    \n    # List modified files (top 10)\n    if [ \"$MODIFIED_FILES\" -gt 0 ]; then\n        echo \"  • Modified files (top 10):\"\n        git status --porcelain 2>/dev/null | head -10 | while read -r status file; do\n            echo \"    - $file ($status)\"\n        done\n    fi\n    \n    # Recent commits\n    echo \"  • Recent commits:\"\n    git log --oneline -3 2>/dev/null | sed 's/^/    /' || echo \"    No recent commits\"\n    \nelse\n    echo \"❓ Not a git repository\"\n    echo \"  • Analyzing file system changes...\"\n    \n    # Alternative: look for recently modified files\n    echo \"  • Recently modified files (last 2 hours):\"\n    find . -type f -newermt '2 hours ago' 2>/dev/null | head -10 | while read -r file; do\n        echo \"    - $file\"\n    done\nfi\n\necho \"\"\necho \"🧪 Testing & Quality Analysis:\"\necho \"═══════════════════════════════\"\n\n# Test framework detection and analysis\nTEST_FRAMEWORK=\"none\"\nTEST_COUNT=0\n\nif [ -f \"package.json\" ]; then\n    echo \"📦 Node.js Project Analysis:\"\n    \n    # Detect test framework\n    if grep -q '\"jest\"' package.json 2>/dev/null; then\n        TEST_FRAMEWORK=\"jest\"\n        echo \"  • Testing framework: Jest\"\n    elif grep -q '\"vitest\"' package.json 2>/dev/null; then\n        TEST_FRAMEWORK=\"vitest\"\n        echo \"  • Testing framework: Vitest\"\n    elif grep -q '\"mocha\"' package.json 2>/dev/null; then\n        TEST_FRAMEWORK=\"mocha\"\n        echo \"  • Testing framework: Mocha\"\n    else\n        echo \"  • Testing framework: Not detected\"\n    fi\n    \n    # Count test files\n    TEST_COUNT=$(find . -name \"*.test.*\" -o -name \"*.spec.*\" | grep -v node_modules | wc -l | tr -d ' ')\n    echo \"  • Test files found: $TEST_COUNT\"\n    \n    # Dependencies analysis\n    DEPS_COUNT=$(jq -r '.dependencies // {} | keys | length' package.json 2>/dev/null || echo \"unknown\")\n    DEV_DEPS_COUNT=$(jq -r '.devDependencies // {} | keys | length' package.json 2>/dev/null || echo \"unknown\")\n    echo \"  • Dependencies: $DEPS_COUNT production, $DEV_DEPS_COUNT development\"\n    \n    # Check for outdated packages\n    echo \"  • Checking for outdated packages...\"\n    OUTDATED_COUNT=$(npm outdated 2>/dev/null | tail -n +2 | wc -l | tr -d ' ')\n    if [ \"$OUTDATED_COUNT\" -gt 0 ]; then\n        echo \"    - $OUTDATED_COUNT packages have updates available\"\n    else\n        echo \"    - All packages are up to date\"\n    fi\n    \nelif [ -f \"requirements.txt\" ] || [ -f \"setup.py\" ] || [ -f \"pyproject.toml\" ]; then\n    echo \"🐍 Python Project Analysis:\"\n    \n    if command -v pytest >/dev/null 2>&1; then\n        TEST_FRAMEWORK=\"pytest\"\n        echo \"  • Testing framework: pytest\"\n        TEST_COUNT=$(find . -name \"test_*.py\" -o -name \"*_test.py\" | wc -l | tr -d ' ')\n    else\n        echo \"  • Testing framework: unittest (built-in)\"\n        TEST_COUNT=$(find . -name \"test*.py\" | wc -l | tr -d ' ')\n    fi\n    echo \"  • Test files found: $TEST_COUNT\"\n    \nelif [ -f \"Cargo.toml\" ]; then\n    echo \"🦀 Rust Project Analysis:\"\n    echo \"  • Testing framework: Built-in (cargo test)\"\n    TEST_COUNT=$(find . -name \"*.rs\" -exec grep -l \"#\\[test\\]\" {} \\; | wc -l | tr -d ' ')\n    echo \"  • Files with tests: $TEST_COUNT\"\n    \nelse\n    echo \"❓ Project type not recognized\"\nfi\n\n# Performance and metrics\necho \"\"\necho \"📈 Performance & Metrics:\"\necho \"═══════════════════════════\"\n\n# Code complexity analysis (basic)\nif [ \"$TEST_COUNT\" -gt 0 ]; then\n    echo \"✅ Test Coverage Status:\"\n    echo \"  • Test files available: $TEST_COUNT\"\n    echo \"  • Testing framework: $TEST_FRAMEWORK\"\nelse\n    echo \"⚠️ No test files detected\"\nfi\n\n# File type analysis\necho \"📊 Codebase Composition:\"\nfor ext in js ts jsx tsx py rs go java c cpp; do\n    count=$(find . -name \"*.$ext\" | grep -v node_modules | wc -l | tr -d ' ')\n    if [ \"$count\" -gt 0 ]; then\n        echo \"  • .$ext files: $count\"\n    fi\ndone\n\n# Lines of code estimation\nTOTAL_LOC=$(find . -type f \\( -name \"*.js\" -o -name \"*.ts\" -o -name \"*.jsx\" -o -name \"*.tsx\" -o -name \"*.py\" -o -name \"*.rs\" -o -name \"*.go\" \\) | grep -v node_modules | xargs wc -l 2>/dev/null | tail -1 | awk '{print $1}' || echo \"unknown\")\necho \"  • Estimated lines of code: $TOTAL_LOC\"\n\n# Session archival\necho \"\"\necho \"💾 Session Archival:\"\necho \"═══════════════════\"\n\n# Create session report file\nREPORT_FILE=\".claude-reports/$SESSION_ID.log\"\nmkdir -p .claude-reports\n\ncat > \"$REPORT_FILE\" << EOF\nCLAUDE CODE WORKFLOW COMPLETION REPORT\n======================================\n\nSession ID: $SESSION_ID\nCompleted: $COMPLETION_TIME\nProject: $PROJECT_NAME\nUser: $USER@$HOST\nDirectory: $WORKDIR\n\nFILE CHANGES:\n$(git status --porcelain 2>/dev/null || echo \"Not a git repository\")\n\nDIFF STATISTICS:\n$(git diff --stat 2>/dev/null || echo \"No git changes\")\n\nTEST STATUS:\n- Framework: $TEST_FRAMEWORK\n- Test files: $TEST_COUNT\n\nPROJECT METRICS:\n- Total LOC (estimated): $TOTAL_LOC\n- Modified files: $MODIFIED_FILES\n\nEOF\n\necho \"📄 Session report saved: $REPORT_FILE\"\necho \"📁 Report directory: .claude-reports/\"\n\n# Cleanup old reports (keep last 30)\nfind .claude-reports -name \"session-*.log\" | sort | head -n -30 | xargs rm -f 2>/dev/null\n\necho \"\"\necho \"💡 Workflow Summary:\"\necho \"═══════════════════\"\necho \"  • Session completed successfully\"\necho \"  • Files modified: $MODIFIED_FILES\"\necho \"  • Test files available: $TEST_COUNT\"\necho \"  • Project type: $([ -f package.json ] && echo 'Node.js' || [ -f requirements.txt ] && echo 'Python' || [ -f Cargo.toml ] && echo 'Rust' || echo 'Unknown')\"\necho \"  • Git repository: $([ -d .git ] && echo 'Yes' || echo 'No')\"\n\necho \"\"\necho \"🎯 Next Steps:\"\necho \"  • Review all changes before committing\"\necho \"  • Run tests to ensure code quality\"\necho \"  • Update documentation if needed\"\necho \"  • Consider code review for significant changes\"\n\necho \"\"\necho \"📊 ═══════════════════════════════════════════════════\"\necho \"🎉 Workflow completion report generated successfully!\"\necho \"📋 Full report available at: $REPORT_FILE\"\necho \"═══════════════════════════════════════════════════\"\n\nexit 0"
      },
      "troubleshooting": [
        {
          "issue": "Report shows 'unknown' for session duration and start time",
          "solution": "Hook reads .claude/*.log times but files may not exist. Create marker: 'echo \"$(date +%s)\" > .claude/session-start' at init, then read: 'START_TIMESTAMP=$(cat .claude/session-start)'."
        },
        {
          "issue": "Outdated package check causes long delays (npm outdated hangs)",
          "solution": "npm outdated performs network checks timing out on slow connections. Add wrapper: 'timeout 10 npm outdated 2>/dev/null || echo \"Check skipped\"'. Or comment out for speed."
        },
        {
          "issue": "Report directory cleanup removes current session's report file",
          "solution": "Sort bug: 'find | sort | head -n -30' removes newest alphabetically. Fix with time sort: 'find .claude-reports -type f -printf \"%T@ %p\\\\n\" | sort -n | head -n -30 | cut -d\" \" -f2-'."
        },
        {
          "issue": "Diff statistics show empty output despite uncommitted changes",
          "solution": "git diff excludes untracked files. Combine: 'git diff --stat; git diff --cached --stat' for staged. Or use: 'git diff HEAD --stat' showing all uncommitted modifications."
        },
        {
          "issue": "Test file count inaccurate with nested test directories",
          "solution": "find without depth limit includes node_modules. Add exclusion: 'find . -name \"*.test.*\" -not -path \"*/node_modules/*\" -not -path \"*/vendor/*\"' for accurate counts."
        }
      ],
      "source": "community",
      "type": "hook",
      "url": "https://claudepro.directory/hooks/workflow-completion-report"
    }
  ],
  "count": 65,
  "lastUpdated": "2025-10-20T19:41:24.839Z"
}