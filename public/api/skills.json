{
  "skills": [
    {
      "slug": "audio-transcription-summarization",
      "title": "Audio Transcription and Summarization",
      "seoTitle": "Audio Transcription + Summarization Skill",
      "description": "Transcribe audio with Whisper/ffmpeg and produce structured, timestamped summaries and action items.",
      "category": "skills",
      "author": "JSONbored",
      "dateAdded": "2025-10-15",
      "tags": [
        "audio",
        "transcription",
        "whisper",
        "ffmpeg"
      ],
      "content": "# Audio Transcription & Summarization Skill\n\n## What This Skill Enables\n\nClaude can transcribe audio files (MP3, WAV, M4A, etc.) and generate structured summaries with timestamps, action items, and speaker identification. This skill leverages Whisper AI and ffmpeg through Claude's Code Interpreter to process audio locally.\n\n## Prerequisites\n\n**Required:**\n- Claude Pro subscription\n- Code Interpreter feature enabled in Claude Desktop settings\n- Audio file uploaded to conversation (drag and drop)\n\n**What Claude handles automatically:**\n- Installing and running Whisper AI models\n- Audio format conversion with ffmpeg\n- Timestamp extraction and alignment\n- Summary generation and structuring\n\n## How to Use This Skill\n\n### Basic Transcription\n\n**Prompt:** \"Transcribe this audio file and give me a clean text transcript.\"\n\nClaude will:\n1. Detect the audio format\n2. Convert to optimal format for transcription\n3. Run Whisper AI transcription\n4. Return formatted text\n\n### Timestamped Summary\n\n**Prompt:** \"Transcribe this meeting recording and create a timestamped summary with key discussion points every 5 minutes.\"\n\nClaude will:\n1. Transcribe the full audio\n2. Chunk by time intervals\n3. Summarize each segment\n4. Present with timestamps\n\n### Action Items Extraction\n\n**Prompt:** \"Transcribe this audio and extract all action items, decisions, and to-dos mentioned.\"\n\nClaude will:\n1. Transcribe the audio\n2. Analyze for actionable items\n3. List action items with timestamps\n4. Identify who was assigned what (if mentioned)\n\n### Speaker Diarization\n\n**Prompt:** \"Transcribe this conversation and identify different speakers. Label them as Speaker 1, Speaker 2, etc.\"\n\nClaude will:\n1. Detect speaker changes in the audio\n2. Segment by speaker\n3. Label each segment\n4. Present as a conversation transcript\n\n## Tips for Best Results\n\n1. **Audio Quality Matters**: Clear audio with minimal background noise produces better transcriptions\n2. **File Size**: For files over 25MB, mention if you want a specific time range transcribed first\n3. **Language**: Specify the language if it's not English (e.g., \"Transcribe this Spanish audio...\")\n4. **Model Selection**: For better accuracy on difficult audio, ask Claude to use the \"medium\" or \"large\" Whisper model\n5. **Post-Processing**: Ask Claude to clean up transcription artifacts like repeated words or filler sounds\n\n## Common Workflows\n\n### Meeting Minutes Generation\n```\n\"Transcribe this meeting and create:\n1. Attendee list (if mentioned)\n2. Key discussion topics with timestamps\n3. Decisions made\n4. Action items with owners\n5. Next steps\"\n```\n\n### Podcast Summary\n```\n\"Transcribe this podcast episode and create:\n1. Episode summary (2-3 sentences)\n2. Main topics discussed with timestamps\n3. Key quotes\n4. Chapters (every 10 minutes)\"\n```\n\n### Interview Transcription\n```\n\"Transcribe this interview with speaker labels.\nFormat as Q&A with:\n- Interviewer questions highlighted\n- Interviewee responses\n- Notable quotes pulled out\"\n```\n\n## Troubleshooting\n\n**Issue:** Transcription is inaccurate\n**Solution:** Ask Claude to use a larger Whisper model or pre-process the audio for noise reduction\n\n**Issue:** Wrong language detected\n**Solution:** Explicitly specify the language in your prompt (\"Transcribe this French audio...\")\n\n**Issue:** Timestamps are off\n**Solution:** Ask Claude to re-align timestamps or specify the desired timestamp interval\n\n**Issue:** Speaker diarization missing\n**Solution:** Request it explicitly: \"Please identify different speakers and label them\"\n\n## Learn More\n\n- [Whisper AI by OpenAI](https://github.com/openai/whisper) - The underlying transcription model\n- [ffmpeg Audio Processing](https://ffmpeg.org/ffmpeg-filters.html#Audio-Filters) - Audio format conversion details\n- [Claude Code Interpreter](https://www.anthropic.com/news/code-interpreter) - How Claude executes code\n- [Simon Willison's Analysis](https://simonwillison.net/2025/Oct/10/claude-skills/) - Deep dive into Claude's skills\n",
      "features": [
        "Local processing via Whisper",
        "Format conversion with ffmpeg",
        "Timestamped notes and action items",
        "Optional speaker labels"
      ],
      "useCases": [
        "Summarize meetings and podcasts",
        "Generate action items",
        "Create searchable transcripts"
      ],
      "requirements": [
        "ffmpeg",
        "Python 3.11+ or whisper.cpp",
        "openai-whisper (pip) or whisper.cpp binary"
      ],
      "examples": [
        {
          "title": "Transcribe with Whisper CLI",
          "language": "bash",
          "code": "# Convert to mono 16kHz WAV\nffmpeg -i input.mp3 -ar 16000 -ac 1 input.wav\n\n# Python whisper (pip install -U openai-whisper)\nwhisper input.wav --model small --language en --output_format txt"
        },
        {
          "title": "Summarize timestamps (Python)",
          "language": "python",
          "code": "from pathlib import Path\n\ntext = Path('input.wav.txt').read_text(encoding='utf-8')\n# Split by timestamps like [00:12:34]\n# ... produce bullet summaries per 5-minute window ...\nprint(text[:500])"
        }
      ],
      "installation": {
        "claudeDesktop": {
          "steps": [
            "Install ffmpeg",
            "Install whisper via pip or build whisper.cpp"
          ]
        },
        "claudeCode": {
          "steps": [
            "pip install openai-whisper",
            "Verify ffmpeg is in PATH"
          ]
        }
      },
      "troubleshooting": [
        {
          "issue": "ffmpeg not found",
          "solution": "Install ffmpeg via your package manager and ensure it is on PATH."
        },
        {
          "issue": "High WER for noisy audio",
          "solution": "Downmix to mono, apply noise reduction, and use a larger model."
        },
        {
          "issue": "Whisper model download fails with SSL certificate verification error",
          "solution": "Set SSL_CERT_FILE environment variable to system certificate bundle. Alternative: use --model-dir to specify pre-downloaded model location."
        },
        {
          "issue": "Code Interpreter not enabled, skill activation fails silently",
          "solution": "Open Claude Desktop Settings, enable Code Interpreter under Features tab. Restart Claude Desktop application to activate skill execution environment."
        },
        {
          "issue": "Transcription timestamps drift out of sync with actual audio timing",
          "solution": "Use --language flag to specify correct language explicitly. Re-encode audio at constant frame rate with: ffmpeg -i input.mp3 -ar 16000 -ac 1 output.wav"
        }
      ],
      "documentationUrl": "https://github.com/openai/whisper",
      "source": "community",
      "type": "skill",
      "url": "https://claudepro.directory/skills/audio-transcription-summarization"
    },
    {
      "slug": "cli-data-viz-quickstart",
      "title": "CLI Data Viz Quickstart",
      "seoTitle": "CLI Data Visualization Quickstart Skill",
      "description": "Turn CSV/JSON into quick charts from the command line; export PNG/SVG for reports.",
      "category": "skills",
      "author": "JSONbored",
      "dateAdded": "2025-10-15",
      "tags": [
        "visualization",
        "charts",
        "python",
        "vega"
      ],
      "content": "# CLI Data Visualization Quickstart Skill\n\n## What This Skill Enables\n\nClaude can create charts and visualizations from your data (CSV, JSON, Excel) using matplotlib, seaborn, plotly, or other visualization libraries. Generate publication-ready charts, dashboards, and data visualizations with custom styling.\n\n## Prerequisites\n\n**Required:**\n- Claude Pro subscription\n- Code Interpreter feature enabled\n- Data file uploaded (CSV, JSON, Excel)\n\n**What Claude handles:**\n- Installing visualization libraries (matplotlib, seaborn, plotly)\n- Data loading and preprocessing\n- Chart generation with customization\n- Exporting to PNG, SVG, or interactive HTML\n- Multi-chart layouts and dashboards\n\n## How to Use This Skill\n\n### Quick Chart from Data\n\n**Prompt:** \"Create a bar chart from this CSV showing sales by category. Make it professional-looking with labels and save as chart.png\"\n\nClaude will:\n1. Load and analyze the CSV\n2. Generate bar chart\n3. Add labels, title, legend\n4. Apply professional styling\n5. Export high-resolution PNG\n\n### Time Series Plot\n\n**Prompt:** \"Plot this time series data: dates on x-axis, values on y-axis. Show trend line and save as SVG.\"\n\nClaude will:\n1. Parse date column\n2. Create line plot\n3. Add trend line (regression)\n4. Format dates nicely\n5. Export as scalable SVG\n\n### Multiple Subplots\n\n**Prompt:** \"Create a 2x2 grid of charts from this data:\n- Top left: revenue by month\n- Top right: customer distribution\n- Bottom left: product performance\n- Bottom right: regional breakdown\nUse consistent colors and save as dashboard.png\"\n\nClaude will:\n1. Create subplot layout\n2. Generate each chart\n3. Apply consistent styling\n4. Add overall title\n5. Export combined visualization\n\n### Interactive Chart\n\n**Prompt:** \"Create an interactive plotly chart with hover tooltips and zoom. Save as HTML.\"\n\nClaude will:\n1. Use plotly library\n2. Create interactive visualization\n3. Add hover information\n4. Enable zoom/pan\n5. Export as standalone HTML file\n\n## Common Workflows\n\n### Sales Dashboard\n```\n\"Create a sales dashboard from this data:\n1. Line chart: monthly revenue trend\n2. Bar chart: top 10 products by sales\n3. Pie chart: sales by region\n4. Table: key metrics summary\nUse a professional color scheme and save as sales_dashboard.png\"\n```\n\n### Statistical Visualization\n```\n\"Visualize this dataset statistically:\n1. Histogram with distribution curve\n2. Box plot showing quartiles\n3. Scatter plot with correlation\n4. Heatmap of correlations between variables\nAdd statistical annotations and save as analysis.png\"\n```\n\n### Comparative Analysis\n```\n\"Compare Year 2024 vs 2025 data:\n1. Side-by-side bar charts\n2. Percentage change annotations\n3. Highlight positive/negative changes with colors\n4. Add summary statistics\nMake it presentation-ready\"\n```\n\n### Custom Styled Chart\n```\n\"Create a chart matching our brand:\n- Primary color: #FF6B35\n- Font: Arial\n- Style: minimalist, no grid lines\n- Background: white\n- High DPI for print (300 dpi)\nShow monthly data as area chart\"\n```\n\n## Chart Types Available\n\n### Basic Charts\n- Line plots (single/multiple series)\n- Bar charts (vertical/horizontal)\n- Scatter plots (with trend lines)\n- Pie charts (with percentages)\n- Area charts (stacked/unstacked)\n\n### Statistical Charts\n- Histograms (with KDE)\n- Box plots (with outliers)\n- Violin plots\n- Heatmaps (correlation matrices)\n- Distribution plots\n\n### Advanced Charts\n- Multi-axis plots\n- Subplots and grids\n- 3D visualizations\n- Animated charts\n- Interactive dashboards\n\n## Tips for Best Results\n\n1. **Describe Your Data**: Tell Claude what each column represents\n2. **Specify Chart Type**: Be clear about visualization type (bar, line, scatter, etc.)\n3. **Styling Preferences**: Mention colors, fonts, size, DPI\n4. **Labels Matter**: Ask for clear titles, axis labels, legends\n5. **Export Format**: PNG for presentations, SVG for web, HTML for interactive\n6. **Size/Resolution**: Specify dimensions (\"800x600 pixels\" or \"10x6 inches at 300 dpi\")\n7. **Multiple Charts**: Describe layout (\"2x2 grid\" or \"side by side\")\n\n## Customization Options\n\n### Colors & Themes\n- Built-in themes (seaborn, ggplot, bmh)\n- Custom color palettes\n- Brand color matching\n- Color-blind friendly palettes\n\n### Annotations\n- Data labels on points/bars\n- Trend lines and statistics\n- Reference lines\n- Text annotations\n- Arrows and callouts\n\n### Export Options\n- PNG (raster, high DPI)\n- SVG (vector, scalable)\n- PDF (print-ready)\n- HTML (interactive)\n- Multiple formats at once\n\n## Troubleshooting\n\n**Issue:** Charts look cluttered\n**Solution:** \"Simplify the chart: remove grid, use fewer colors, increase spacing\"\n\n**Issue:** Text too small or overlapping\n**Solution:** \"Increase font size to 12pt and rotate x-axis labels 45 degrees\"\n\n**Issue:** Colors don't match brand\n**Solution:** Provide hex codes: \"Use #FF6B35 for primary, #4ECDC4 for secondary\"\n\n**Issue:** Export quality is poor\n**Solution:** \"Export at 300 DPI for print quality\" or \"Use vector format (SVG/PDF)\"\n\n**Issue:** Legend blocks data\n**Solution:** \"Move legend outside plot area to the right\" or \"Use smaller legend with abbreviations\"\n\n**Issue:** Date axis formatting is wrong\n**Solution:** \"Format x-axis dates as 'MMM YYYY' with one tick per month\"\n\n## Learn More\n\n- [Matplotlib Gallery](https://matplotlib.org/stable/gallery/index.html) - Chart examples and code\n- [Seaborn Tutorial](https://seaborn.pydata.org/tutorial.html) - Statistical visualization guide\n- [Plotly Documentation](https://plotly.com/python/) - Interactive charts\n- [Data Viz Best Practices](https://www.data-to-viz.com/) - Choosing the right chart\n- [Color Brewer](https://colorbrewer2.org/) - Color scheme picker\n",
      "features": [
        "CLI-first workflows",
        "Common chart templates (bar/line/scatter)",
        "Headless export",
        "Reproducible configurations"
      ],
      "useCases": [
        "Exploratory analysis",
        "Executive snapshots",
        "CI artifact generation"
      ],
      "requirements": [
        "Python 3.11+ or Node.js 18+",
        "matplotlib/seaborn or vega/vega-lite"
      ],
      "examples": [
        {
          "title": "Bar chart from CSV (Python)",
          "language": "python",
          "code": "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.read_csv('data.csv')\ndf.groupby('category')['value'].sum().plot(kind='bar')\nplt.tight_layout(); plt.savefig('chart.png', dpi=200)"
        }
      ],
      "installation": {
        "claudeDesktop": {
          "steps": [
            "Install Python 3.11+",
            "pip install pandas matplotlib seaborn"
          ]
        },
        "claudeCode": {
          "steps": [
            "For Node: npm i vega vega-lite",
            "Use headless Chrome for SVG->PNG"
          ]
        }
      },
      "troubleshooting": [
        {
          "issue": "Fonts missing in headless mode",
          "solution": "Install system fonts or specify a font path for rendering."
        },
        {
          "issue": "Skill activation fails with ModuleNotFoundError for matplotlib",
          "solution": "Run pip install matplotlib seaborn pandas in Code Interpreter environment. Verify Python 3.11+ is active. Restart Claude Desktop after installation."
        },
        {
          "issue": "Chart export produces blank PNG files or corrupted images",
          "solution": "Call plt.tight_layout() before plt.savefig(). Set explicit figure size: plt.figure(figsize=(10,6)). Use bbox_inches='tight' parameter in savefig()."
        },
        {
          "issue": "Data visualization skill not appearing in available skills list",
          "solution": "Enable Code Interpreter in Claude Desktop settings under Features. Upload data file (CSV/JSON) to conversation first to trigger skill recognition and activation."
        },
        {
          "issue": "Interactive plotly charts fail to render with JavaScript errors",
          "solution": "Save as standalone HTML with plotly.offline.plot(include_plotlyjs='cdn'). Ensure output HTML file has proper DOCTYPE and charset UTF-8 declaration."
        }
      ],
      "documentationUrl": "https://matplotlib.org/",
      "source": "community",
      "type": "skill",
      "url": "https://claudepro.directory/skills/cli-data-viz-quickstart"
    },
    {
      "slug": "cloudflare-workers-ai-edge",
      "title": "Cloudflare Workers AI Edge Functions",
      "seoTitle": "Cloudflare Workers AI Edge Functions Skill",
      "description": "Deploy AI models and serverless functions to Cloudflare's global edge network with sub-5ms cold starts and 40% edge computing market share.",
      "category": "skills",
      "author": "JSONbored",
      "dateAdded": "2025-10-16",
      "tags": [
        "cloudflare",
        "edge-computing",
        "ai",
        "serverless",
        "workers"
      ],
      "content": "# Cloudflare Workers AI Edge Functions Skill\n\n## What This Skill Enables\n\nClaude can build and deploy AI-powered serverless functions on Cloudflare's global edge network, spanning 275+ cities with sub-5ms cold start times (10-80x faster than AWS Lambda@Edge). With 40% edge computing market share and 4,000% year-over-year growth in AI inference requests, Cloudflare Workers AI brings machine learning models directly to users worldwide with minimal latency.\n\n## Prerequisites\n\n**Required:**\n- Claude Pro subscription or Claude Code CLI\n- Cloudflare account (free tier available)\n- Wrangler CLI installed (`npm install -g wrangler`)\n- Basic understanding of JavaScript/TypeScript\n\n**What Claude handles automatically:**\n- Writing Workers code with TypeScript types\n- Configuring wrangler.toml for deployments\n- Implementing AI model bindings (Llama-2, Whisper, Stable Diffusion)\n- Setting up D1 database and R2 storage integrations\n- Managing environment variables and secrets\n- Deploying to Cloudflare's edge network\n- Optimizing for V8 isolate performance\n\n## How to Use This Skill\n\n### Deploy a Basic Edge Function\n\n**Prompt:** \"Create a Cloudflare Worker that responds to HTTP requests with JSON data and deploys to the edge.\"\n\nClaude will:\n1. Generate a Worker with proper `fetch` event handler\n2. Create `wrangler.toml` configuration\n3. Set up TypeScript types for Request/Response\n4. Add error handling and CORS headers\n5. Deploy with `wrangler publish`\n6. Provide the deployed Worker URL\n\n### AI Model Integration (Llama-2 Chat)\n\n**Prompt:** \"Build a Cloudflare Worker that uses Llama-2 to generate chat responses. Accept POST requests with user messages and stream the AI responses back.\"\n\nClaude will:\n1. Configure AI binding in wrangler.toml\n2. Implement streaming response with ReadableStream\n3. Add proper prompt formatting for Llama-2\n4. Set up rate limiting to control costs\n5. Include request validation and error handling\n6. Deploy with Workers AI binding enabled\n\n### Image Generation with Stable Diffusion\n\n**Prompt:** \"Create an edge function that generates images using Stable Diffusion XL. Accept a text prompt via API and return the generated image URL stored in R2.\"\n\nClaude will:\n1. Set up Workers AI binding for Stable Diffusion\n2. Configure R2 bucket for image storage\n3. Implement image generation with proper parameters\n4. Upload generated images to R2 with public URLs\n5. Add caching headers for CDN optimization\n6. Include usage analytics with D1 database\n\n### Real-Time Translation API\n\n**Prompt:** \"Build a translation API using Cloudflare Workers AI that detects the source language and translates to the target language. Support 50+ languages with edge caching.\"\n\nClaude will:\n1. Use Workers AI translation models\n2. Implement language detection\n3. Set up KV namespace for translation caching\n4. Add rate limiting per IP address\n5. Configure CDN cache for common translations\n6. Include usage metrics and error logging\n\n## Tips for Best Results\n\n1. **Leverage V8 Isolates**: Workers use V8 isolates that start in <5ms and use 1/10th the memory of Node.js. Design stateless functions that take advantage of this architecture.\n\n2. **Use Durable Objects for State**: For stateful operations (WebSockets, real-time collaboration), request Durable Objects implementation instead of external databases.\n\n3. **Model Selection**: Choose appropriate AI models based on latency requirements. Smaller models like Llama-2-7B offer faster inference than larger variants.\n\n4. **Edge Caching**: Implement Cache API or KV storage for frequently accessed data to reduce AI inference costs.\n\n5. **Cost Optimization**: Workers AI charges per request. Use caching, rate limiting, and request batching to optimize costs.\n\n6. **Geographic Routing**: Workers automatically route to the nearest data center. For AI models, consider pinning specific regions for data residency compliance.\n\n## Common Workflows\n\n### Full-Stack AI Application\n```\n\"Create a complete AI-powered application on Cloudflare:\n1. Workers AI for text generation (Llama-2)\n2. D1 database for storing conversations\n3. R2 for file uploads and generated content\n4. KV for session management and caching\n5. Pages for frontend deployment\n6. Queue for background job processing\nInclude TypeScript types and deployment scripts.\"\n```\n\n### Content Moderation API\n```\n\"Build an edge API that:\n1. Accepts text content via POST request\n2. Uses Workers AI to detect harmful content\n3. Classifies content as safe/unsafe with confidence scores\n4. Logs results to D1 database\n5. Returns moderation decision in <100ms\n6. Handles 10,000 requests per minute\"\n```\n\n### Smart Image CDN\n```\n\"Create a Cloudflare Worker that:\n1. Intercepts image requests\n2. Analyzes image with Workers AI (OCR, object detection)\n3. Automatically optimizes images for device/bandwidth\n4. Stores optimized versions in R2\n5. Serves from edge cache on subsequent requests\n6. Includes usage analytics and cost tracking\"\n```\n\n### Real-Time Sentiment Analysis\n```\n\"Build a WebSocket-based sentiment analysis service:\n1. Accept streaming text via WebSocket\n2. Process chunks with Workers AI sentiment model\n3. Return real-time sentiment scores\n4. Store aggregate results in D1\n5. Support 1000 concurrent connections\n6. Deploy across all Cloudflare edge locations\"\n```\n\n## Troubleshooting\n\n**Issue:** Worker exceeds CPU time limits\n**Solution:** Workers have a 50ms CPU time limit on free tier (30s on paid). Optimize by using streaming responses, reducing synchronous processing, or upgrading to Unbound workers for longer execution.\n\n**Issue:** AI model inference too slow\n**Solution:** Use smaller model variants (e.g., Llama-2-7B instead of 13B), implement request queuing with Workers Queue, or cache common responses in KV storage.\n\n**Issue:** CORS errors when calling from frontend\n**Solution:** Add proper CORS headers in Worker response. Ask Claude to include OPTIONS method handler and appropriate Access-Control-* headers.\n\n**Issue:** Workers AI billing concerns\n**Solution:** Implement rate limiting with Durable Objects or KV, cache responses aggressively, use smaller models for simpler tasks, and set up billing alerts in Cloudflare dashboard.\n\n**Issue:** Cannot access environment variables\n**Solution:** Ensure secrets are set with `wrangler secret put` and bindings are properly configured in wrangler.toml. Access via `env.SECRET_NAME` in Worker code.\n\n**Issue:** Cold start latency for complex Workers\n**Solution:** Minimize dependencies (Workers bundle size should be <1MB), use dynamic imports for optional features, and consider splitting into multiple Workers for different routes.\n\n## Learn More\n\n- [Cloudflare Workers AI Documentation](https://developers.cloudflare.com/workers-ai/)\n- [Workers AI Models Catalog](https://developers.cloudflare.com/workers-ai/models/)\n- [Wrangler CLI Guide](https://developers.cloudflare.com/workers/wrangler/)\n- [Workers Platform Architecture](https://blog.cloudflare.com/cloud-computing-without-containers/)\n- [Edge Computing Best Practices](https://developers.cloudflare.com/workers/learning/how-workers-works/)\n- [Durable Objects Guide](https://developers.cloudflare.com/durable-objects/)\n",
      "features": [
        "Sub-5ms cold starts with V8 isolates",
        "20+ AI models: Llama-2, Whisper, Stable Diffusion",
        "Deploy to 275+ cities globally",
        "Integrated with D1, R2, KV, Queues"
      ],
      "useCases": [
        "Edge AI inference with minimal latency",
        "Serverless APIs with global distribution",
        "Real-time content moderation and analysis"
      ],
      "requirements": [
        "Cloudflare account",
        "Wrangler CLI 3.0+",
        "Node.js 18+",
        "@cloudflare/workers-types"
      ],
      "examples": [
        {
          "title": "AI Chat Worker with Llama-2",
          "language": "typescript",
          "code": "export interface Env {\n  AI: any;\n}\n\nexport default {\n  async fetch(request: Request, env: Env): Promise<Response> {\n    if (request.method !== 'POST') {\n      return new Response('Method not allowed', { status: 405 });\n    }\n\n    const { messages } = await request.json<{ messages: any[] }>();\n\n    const response = await env.AI.run('@cf/meta/llama-2-7b-chat-int8', {\n      messages: [\n        { role: 'system', content: 'You are a helpful assistant.' },\n        ...messages,\n      ],\n      stream: true,\n    });\n\n    return new Response(response, {\n      headers: {\n        'content-type': 'text/event-stream',\n        'cache-control': 'no-cache',\n      },\n    });\n  },\n};"
        },
        {
          "title": "Image Generation with Stable Diffusion + R2",
          "language": "typescript",
          "code": "export interface Env {\n  AI: any;\n  IMAGES: R2Bucket;\n}\n\nexport default {\n  async fetch(request: Request, env: Env): Promise<Response> {\n    const { prompt } = await request.json<{ prompt: string }>();\n\n    // Generate image with Stable Diffusion\n    const response = await env.AI.run(\n      '@cf/stabilityai/stable-diffusion-xl-base-1.0',\n      { prompt }\n    );\n\n    // Upload to R2\n    const imageKey = `${crypto.randomUUID()}.png`;\n    await env.IMAGES.put(imageKey, response, {\n      httpMetadata: { contentType: 'image/png' },\n    });\n\n    const imageUrl = `https://images.example.com/${imageKey}`;\n\n    return Response.json({\n      success: true,\n      imageUrl,\n      prompt,\n    });\n  },\n};"
        },
        {
          "title": "Translation API with KV Caching",
          "language": "typescript",
          "code": "export interface Env {\n  AI: any;\n  TRANSLATIONS: KVNamespace;\n}\n\nexport default {\n  async fetch(request: Request, env: Env): Promise<Response> {\n    const { text, targetLang = 'en' } = await request.json<{\n      text: string;\n      targetLang: string;\n    }>();\n\n    // Check cache first\n    const cacheKey = `${text}:${targetLang}`;\n    const cached = await env.TRANSLATIONS.get(cacheKey);\n    if (cached) {\n      return Response.json({ translation: cached, cached: true });\n    }\n\n    // Translate with Workers AI\n    const response = await env.AI.run('@cf/meta/m2m100-1.2b', {\n      text,\n      target_lang: targetLang,\n    });\n\n    const translation = response.translated_text;\n\n    // Cache for 24 hours\n    await env.TRANSLATIONS.put(cacheKey, translation, {\n      expirationTtl: 86400,\n    });\n\n    return Response.json({ translation, cached: false });\n  },\n};"
        },
        {
          "title": "wrangler.toml Configuration",
          "language": "toml",
          "code": "name = \"ai-worker\"\nmain = \"src/index.ts\"\ncompatibility_date = \"2025-10-16\"\n\n[ai]\nbinding = \"AI\"\n\n[[r2_buckets]]\nbinding = \"IMAGES\"\nbucket_name = \"my-images\"\n\n[[kv_namespaces]]\nbinding = \"TRANSLATIONS\"\nid = \"your-kv-namespace-id\"\n\n[[d1_databases]]\nbinding = \"DB\"\ndatabase_name = \"my-database\"\ndatabase_id = \"your-database-id\"\n\n[observability]\nenabled = true"
        }
      ],
      "installation": {
        "claudeDesktop": {
          "steps": [
            "Install Wrangler: npm install -g wrangler",
            "Login to Cloudflare: wrangler login",
            "Ask Claude: 'Create a Cloudflare Worker with AI capabilities'",
            "Claude generates code and deploys with wrangler publish"
          ]
        },
        "claudeCode": {
          "steps": [
            "npm install -g wrangler",
            "wrangler login",
            "wrangler init my-worker",
            "Add AI binding to wrangler.toml",
            "wrangler publish"
          ]
        }
      },
      "troubleshooting": [
        {
          "issue": "Worker exceeds size limit",
          "solution": "Minimize dependencies, use dynamic imports, or split into multiple Workers. Bundle size should be <1MB for optimal performance."
        },
        {
          "issue": "AI binding not available",
          "solution": "Ensure [ai] binding is configured in wrangler.toml and account has Workers AI enabled."
        },
        {
          "issue": "R2 upload fails",
          "solution": "Verify R2 bucket binding in wrangler.toml and ensure bucket exists in Cloudflare dashboard."
        }
      ],
      "documentationUrl": "https://developers.cloudflare.com/workers-ai/",
      "source": "community",
      "type": "skill",
      "url": "https://claudepro.directory/skills/cloudflare-workers-ai-edge"
    },
    {
      "slug": "csv-excel-data-wrangler",
      "title": "CSV & Excel Data Wrangler",
      "seoTitle": "CSV/Excel Data Wrangler Skill",
      "description": "Clean, filter, join, pivot, and export CSV/XLSX data reliably with reproducible steps.",
      "category": "skills",
      "author": "JSONbored",
      "dateAdded": "2025-10-15",
      "tags": [
        "csv",
        "xlsx",
        "data-cleaning",
        "pandas",
        "python"
      ],
      "content": "# CSV & Excel Data Wrangler Skill\n\n## What This Skill Enables\n\nClaude can clean, transform, analyze, and merge CSV and Excel files with pandas. Upload messy spreadsheets and get production-ready data pipelines, statistical summaries, and formatted exports.\n\n## Prerequisites\n\n**Required:**\n- Claude Pro subscription\n- Code Interpreter feature enabled\n- CSV or Excel file uploaded to conversation\n\n**What Claude handles:**\n- Installing pandas, openpyxl, and data processing libraries\n- Detecting file encodings and formats\n- Type inference and conversion\n- Memory-efficient processing of large files\n\n## How to Use This Skill\n\n### Quick Data Cleaning\n\n**Prompt:** \"Clean this CSV file: remove duplicates, fix missing values, standardize column names, and export as clean.csv\"\n\nClaude will:\n1. Load and analyze the file structure\n2. Identify data quality issues\n3. Apply cleaning transformations\n4. Export cleaned version\n\n### Data Merging & Joining\n\n**Prompt:** \"Merge customers.csv and orders.csv on customer_id. Show me the combined data and export as customer_orders.xlsx\"\n\nClaude will:\n1. Load both files\n2. Detect join keys\n3. Perform the merge (inner/left/right/outer)\n4. Validate results\n5. Export formatted Excel file\n\n### Data Analysis & Summaries\n\n**Prompt:** \"Analyze this sales data: show me summary statistics, identify top products, calculate monthly trends, and create a pivot table by region.\"\n\nClaude will:\n1. Generate descriptive statistics\n2. Perform aggregations\n3. Create pivot tables\n4. Calculate trends\n5. Present insights\n\n### Format Conversion\n\n**Prompt:** \"Convert this Excel workbook to CSV files, one per sheet, with UTF-8 encoding.\"\n\nClaude will:\n1. Read all Excel sheets\n2. Export each as separate CSV\n3. Handle encoding properly\n4. Preserve data types where possible\n\n## Common Workflows\n\n### CRM Data Cleanup\n```\n\"Clean this customer export:\n1. Remove duplicate emails (keep most recent)\n2. Standardize phone numbers to (XXX) XXX-XXXX format\n3. Fill missing company names with 'Unknown'\n4. Split full_name into first_name and last_name\n5. Export as customers_clean.xlsx\"\n```\n\n### Sales Report Generation\n```\n\"Analyze this sales data:\n1. Calculate total revenue by product category\n2. Identify top 10 customers by revenue\n3. Show month-over-month growth\n4. Create a pivot table: rows=salesperson, columns=month, values=revenue\n5. Export summary as sales_report.xlsx with formatted numbers\"\n```\n\n### Data Validation\n```\n\"Validate this CSV:\n1. Check for duplicate IDs\n2. Identify rows with missing required fields (name, email, phone)\n3. Flag invalid email formats\n4. Report data quality issues\n5. Export clean rows and error rows separately\"\n```\n\n### Multi-File Consolidation\n```\n\"Combine all CSV files I upload into one master file:\n1. Ensure columns match (add missing ones)\n2. Add a 'source_file' column\n3. Remove duplicates across all files\n4. Sort by date column\n5. Export as consolidated_data.csv\"\n```\n\n## Tips for Best Results\n\n1. **Be Specific About Columns**: Name the exact columns you want to work with\n2. **Describe Your Data**: Mention what each column represents for better context\n3. **Specify Output Format**: Tell Claude exactly how you want the result formatted\n4. **Handle Missing Data**: Be explicit about how to handle nulls (drop, fill with value, forward-fill, etc.)\n5. **Large Files**: For files >100MB, ask Claude to process in chunks or sample first\n6. **Date Formats**: Specify your expected date format (MM/DD/YYYY vs DD/MM/YYYY)\n7. **Encoding Issues**: If you see garbled text, ask Claude to try different encodings (UTF-8, latin-1, etc.)\n\n## Advanced Operations\n\n### Complex Transformations\n- Unpivoting (melt) wide data to long format\n- Creating calculated columns with business logic\n- Grouping and aggregating with custom functions\n- Handling multi-index data\n- Time series resampling and rolling windows\n\n### Data Quality Checks\n- Outlier detection and reporting\n- Referential integrity validation\n- Format consistency checks\n- Statistical anomaly detection\n\n## Troubleshooting\n\n**Issue:** File encoding errors or garbled characters\n**Solution:** Ask Claude to detect encoding or try: \"Read this with UTF-8-SIG encoding\" or \"Try latin-1 encoding\"\n\n**Issue:** Memory errors on large files\n**Solution:** \"Process this file in 10,000 row chunks\" or \"Sample 10% of rows first to test\"\n\n**Issue:** Wrong data types (dates as strings, numbers as text)\n**Solution:** Be explicit: \"Convert created_at column to datetime\" or \"Cast price to float\"\n\n**Issue:** Merge produces unexpected results\n**Solution:** Ask Claude to show sample rows before/after merge and explain the join type used\n\n**Issue:** Excel export loses formatting\n**Solution:** \"Export with formatted numbers, bold headers, and auto-column-width\"\n\n## Learn More\n\n- [Pandas Documentation](https://pandas.pydata.org/docs/) - Comprehensive data manipulation guide\n- [Excel to Pandas Mapping](https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_spreadsheets.html) - Translate Excel operations\n- [Data Cleaning Best Practices](https://github.com/Quartz/bad-data-guide) - Common data issues and solutions\n- [Claude Code Interpreter Guide](https://www.anthropic.com/news/code-interpreter) - How Claude processes data\n",
      "features": [
        "Import/export with explicit schema control",
        "Deduplicate and null-safe transformations",
        "Join/merge/pivot with predictable results",
        "Encoding-aware IO with UTF-8/UTF-8-SIG handling",
        "Parquet round-trips for performance"
      ],
      "useCases": [
        "Clean messy CRM exports",
        "Join sales and marketing datasets",
        "Generate analyst-ready summary tables"
      ],
      "requirements": [
        "Python 3.11+",
        "pandas",
        "openpyxl",
        "pyarrow (optional for Parquet)"
      ],
      "examples": [
        {
          "title": "Load, dedupe, and export",
          "language": "python",
          "code": "import pandas as pd\n\ncustomers = pd.read_csv('customers.csv', dtype=str)\norders = pd.read_excel('orders.xlsx')\n\n# Normalize and dedupe\ncustomers['email'] = customers['email'].str.strip().str.lower()\ncustomers = customers.drop_duplicates(subset=['email'])\n\n# Join and summarize\ndf = orders.merge(customers, on='customer_id', how='left')\nsales_by_region = df.groupby('region', dropna=False)['total'].sum().reset_index()\n\nsales_by_region.to_excel('sales_by_region.xlsx', index=False)"
        },
        {
          "title": "Explicit types and safe parsing",
          "language": "python",
          "code": "import pandas as pd\n\ndtypes = {\n  'id': 'Int64',\n  'price': 'float64',\n  'created_at': 'string'\n}\ndf = pd.read_csv('input.csv', dtype=dtypes, encoding='utf-8-sig')\n\n# Coerce dates after load\ndf['created_at'] = pd.to_datetime(df['created_at'], errors='coerce', utc=True)\n\ndf.to_parquet('output.parquet')"
        }
      ],
      "installation": {
        "claudeDesktop": {
          "steps": [
            "Install Python 3.11+",
            "pip install pandas openpyxl pyarrow"
          ]
        },
        "claudeCode": {
          "steps": [
            "pip install pandas openpyxl",
            "Verify versions: pandas >= 2.0"
          ]
        }
      },
      "troubleshooting": [
        {
          "issue": "Weird characters or BOM appearing in first column name",
          "solution": "Use encoding='utf-8-sig' when reading CSV to strip byte order mark, or manually rename columns after load with df.columns."
        },
        {
          "issue": "MemoryError when loading large CSV or Excel files",
          "solution": "Use chunksize parameter in read_csv to process incrementally, or convert to Parquet format first for more efficient handling."
        },
        {
          "issue": "Excel file opens but all values are NaN or None",
          "solution": "Install openpyxl engine with pip install openpyxl, then use pd.read_excel('file.xlsx', engine='openpyxl')."
        },
        {
          "issue": "Date columns imported as strings instead of datetime objects",
          "solution": "Use parse_dates parameter: pd.read_csv('file.csv', parse_dates=['date_column']) or convert post-load with pd.to_datetime()."
        },
        {
          "issue": "DtypeWarning about mixed types in columns when reading CSV",
          "solution": "Specify dtype explicitly with dtype={'column': str} or use dtype=str for all, then convert types after inspection."
        }
      ],
      "documentationUrl": "https://pandas.pydata.org/",
      "source": "community",
      "type": "skill",
      "url": "https://claudepro.directory/skills/csv-excel-data-wrangler"
    },
    {
      "slug": "docx-report-generator",
      "title": "DOCX Report Generator",
      "seoTitle": "DOCX Report Generator Skill",
      "description": "Fill templated DOCX with data to produce reports/invoices, with images and PDF export.",
      "category": "skills",
      "author": "JSONbored",
      "dateAdded": "2025-10-15",
      "tags": [
        "docx",
        "reports",
        "templating",
        "python"
      ],
      "content": "# DOCX Report Generator Skill\n\n## What This Skill Enables\n\nClaude can create, edit, and format Microsoft Word documents (.docx) programmatically. Generate professional reports, proposals, documentation, and formatted documents with tables, charts, headers, and custom styling.\n\n## Prerequisites\n\n**Required:**\n- Claude Pro subscription\n- Code Interpreter feature enabled\n- Template document uploaded (optional, for editing existing docs)\n\n**What Claude handles:**\n- Installing python-docx and document libraries\n- Document structure and formatting\n- Table generation and styling\n- Page layout and sections\n- Converting between formats (Markdown â†’ DOCX)\n\n## How to Use This Skill\n\n### Create a New Document\n\n**Prompt:** \"Create a professional business proposal document with:\n- Title page with company logo placeholder\n- Executive summary section\n- 3-column pricing table\n- Terms and conditions\nSave as proposal.docx\"\n\nClaude will:\n1. Create document structure\n2. Add formatted sections\n3. Generate styled tables\n4. Apply professional formatting\n5. Export as .docx file\n\n### Edit Existing Document\n\n**Prompt:** \"Open this contract template and:\n1. Replace all [COMPANY_NAME] with 'Acme Corp'\n2. Update the pricing table in section 3\n3. Add a new clause about termination\n4. Save as acme_contract.docx\"\n\nClaude will:\n1. Load the existing document\n2. Find and replace text\n3. Modify tables\n4. Insert new content\n5. Preserve original formatting\n\n### Generate Report from Data\n\n**Prompt:** \"Create a monthly sales report from this CSV data:\n- Executive summary with key metrics\n- Sales by region table\n- Top performers list\n- Month-over-month comparison chart\n- Save as sales_report_october.docx\"\n\nClaude will:\n1. Analyze the CSV data\n2. Calculate metrics\n3. Generate formatted sections\n4. Create tables with data\n5. Add visual elements\n\n### Format Conversion\n\n**Prompt:** \"Convert this Markdown document to a formatted Word document with:\n- Headings styled with built-in heading styles\n- Code blocks in monospace font\n- Bullet lists properly formatted\n- Save as documentation.docx\"\n\nClaude will:\n1. Parse Markdown structure\n2. Map to Word styles\n3. Apply formatting\n4. Generate DOCX\n\n## Common Workflows\n\n### Meeting Minutes Template\n```\n\"Create a meeting minutes template with:\n1. Header: Date, Time, Location, Attendees\n2. Agenda items section\n3. Discussion notes table (Topic | Discussion | Decision)\n4. Action items table (Task | Owner | Due Date | Status)\n5. Next meeting section\nUse professional formatting with the 'Office' built-in style.\"\n```\n\n### Invoice Generation\n```\n\"Generate an invoice document:\n1. Company header (name, address, logo placeholder)\n2. Invoice details (number, date, due date)\n3. Bill to / Ship to sections\n4. Line items table (Description, Qty, Rate, Amount)\n5. Subtotal, tax, total calculations\n6. Payment terms footer\nMake it look professional with borders and shading.\"\n```\n\n### Technical Documentation\n```\n\"Create technical documentation:\n1. Cover page with title and version\n2. Table of contents (auto-generated)\n3. Multiple sections with heading hierarchy\n4. Code examples in monospace with syntax highlighting\n5. Tables for API endpoints\n6. Numbered figures with captions\nUse consistent styling throughout.\"\n```\n\n### Resume/CV Formatting\n```\n\"Format this resume data into a professional document:\n1. Header with name and contact info\n2. Professional summary\n3. Work experience (company, role, dates, bullets)\n4. Education section\n5. Skills table (2 columns)\n6. Use modern, clean formatting\nSave as resume.docx\"\n```\n\n## Tips for Best Results\n\n1. **Be Specific About Formatting**: Mention fonts, sizes, colors, alignment\n2. **Reference Built-in Styles**: Use Word's built-in styles (\"Heading 1\", \"Title\", \"Intense Quote\")\n3. **Table Formatting**: Specify headers, borders, shading, column widths\n4. **Page Layout**: Mention margins, orientation, page size if non-standard\n5. **Images**: Provide image files or describe placeholder dimensions\n6. **Consistent Style**: Ask for style guides (\"use Arial 11pt throughout\")\n7. **Sections**: Use section breaks for different headers/footers\n\n## Advanced Features\n\n### Headers & Footers\n- Different first page headers\n- Page numbers with custom formatting\n- Chapter/section titles in headers\n- Watermarks and background\n\n### Table Enhancements\n- Merged cells\n- Repeating header rows\n- Conditional formatting\n- Auto-width columns\n\n### Document Automation\n- Mail merge from data files\n- Template-based generation\n- Batch document creation\n- Variable substitution\n\n## Troubleshooting\n\n**Issue:** Formatting doesn't look right\n**Solution:** Be more specific about styles. Reference Word's built-in style names or describe exact formatting (font, size, color, alignment)\n\n**Issue:** Tables break across pages poorly\n**Solution:** Ask Claude to set \"keep rows together\" or adjust table properties\n\n**Issue:** Images not appearing\n**Solution:** Upload images separately and reference them in your prompt, or describe placeholder dimensions\n\n**Issue:** Headers/footers not updating\n**Solution:** Specify which sections need different headers/footers and where section breaks should go\n\n**Issue:** Lost formatting when editing\n**Solution:** Ask Claude to preserve existing styles: \"Keep all original formatting except...\"\n\n## Learn More\n\n- [python-docx Documentation](https://python-docx.readthedocs.io/) - Comprehensive API guide\n- [Word Document Structure](https://python-docx.readthedocs.io/en/latest/user/documents.html) - Understanding .docx internals\n- [Office Open XML Spec](https://en.wikipedia.org/wiki/Office_Open_XML) - DOCX file format details\n- [Simon Willison's DOCX Analysis](https://simonwillison.net/2025/Oct/10/claude-skills/) - Claude's DOCX capabilities\n",
      "features": [
        "Template placeholders and loops",
        "Image and table insertion",
        "Page layout control",
        "Optional PDF export pipeline"
      ],
      "useCases": [
        "Invoices and statements",
        "Client reports",
        "Batch document generation"
      ],
      "requirements": [
        "Python 3.11+",
        "docxtpl",
        "docx2pdf or libreoffice for PDF"
      ],
      "examples": [
        {
          "title": "Render a template (Python)",
          "language": "python",
          "code": "from docxtpl import DocxTemplate\n\ndoc = DocxTemplate('template.docx')\ncontext = { 'client': 'Acme', 'items': [{'name': 'Widget', 'price': 9.99}] }\ndoc.render(context)\ndoc.save('invoice.docx')"
        }
      ],
      "installation": {
        "claudeDesktop": {
          "steps": [
            "Install Python 3.11+",
            "pip install docxtpl"
          ]
        },
        "claudeCode": {
          "steps": [
            "Install docxtpl",
            "Use libreoffice for reliable PDF export"
          ]
        }
      },
      "troubleshooting": [
        {
          "issue": "Fonts or rendering differ between Windows and macOS",
          "solution": "Embed fonts in the DOCX file or use containerized conversion (Docker with LibreOffice) to ensure consistent rendering."
        },
        {
          "issue": "ModuleNotFoundError when trying to import python-docx",
          "solution": "Install with pip install python-docx (note the hyphen), but import as 'import docx' without hyphen in Python code."
        },
        {
          "issue": "Tables or images appear in wrong position after editing",
          "solution": "Use explicit positioning with add_picture(width=Inches(2)) and table insertion after specific paragraphs, not floating objects."
        },
        {
          "issue": "Cannot open generated DOCX file - corruption error",
          "solution": "Ensure proper document structure: always save with doc.save(), avoid manual XML manipulation, validate sections are closed."
        },
        {
          "issue": "AttributeError: Document has no attribute 'add_heading'",
          "solution": "You're using wrong import. Use 'from docx import Document' not docxtpl. For templates use DocxTemplate, for new docs use Document."
        }
      ],
      "documentationUrl": "https://docxtpl.readthedocs.io/",
      "source": "community",
      "type": "skill",
      "url": "https://claudepro.directory/skills/docx-report-generator"
    },
    {
      "slug": "github-actions-ai-cicd",
      "title": "GitHub Actions AI-Powered CI/CD Automation",
      "seoTitle": "GitHub Actions AI-Powered CI/CD Automation Skill",
      "description": "Build intelligent CI/CD pipelines with GitHub Actions, AI-assisted workflow generation, automated testing, and deployment orchestration.",
      "category": "skills",
      "author": "JSONbored",
      "dateAdded": "2025-10-16",
      "tags": [
        "github-actions",
        "ci-cd",
        "automation",
        "devops",
        "ai"
      ],
      "content": "# GitHub Actions AI-Powered CI/CD Automation Skill\n\n## What This Skill Enables\n\nClaude can design, generate, and optimize GitHub Actions workflows for comprehensive CI/CD pipelines. This skill enables automated testing, intelligent deployment strategies, security scanning, performance monitoring, and infrastructure provisioning - all triggered by GitHub events with AI-optimized configurations.\n\n## Prerequisites\n\n**Required:**\n- GitHub repository with Actions enabled\n- Basic understanding of your deployment target (Vercel, AWS, etc.)\n- Test suite in your project\n\n**What Claude handles automatically:**\n- Generating complete workflow YAML files\n- Configuring matrix builds for multiple environments\n- Setting up caching strategies for faster builds\n- Implementing security best practices\n- Configuring deployment gates and approvals\n- Optimizing workflow performance\n\n## How to Use This Skill\n\n### Complete CI/CD Pipeline Generation\n\n**Prompt:** \"Create a GitHub Actions workflow for my Next.js 15 app that runs on every push. Include TypeScript type checking, ESLint, Vitest unit tests, Playwright E2E tests, and deploy to Vercel on main branch.\"\n\nClaude will generate:\n1. `.github/workflows/ci-cd.yml` with multiple jobs\n2. Type checking job with caching\n3. Lint job with auto-fix capability\n4. Unit test job with coverage reporting\n5. E2E test job with browser matrix\n6. Deployment job with environment protection\n7. Proper job dependencies and parallelization\n\n### Multi-Environment Deployment Strategy\n\n**Prompt:** \"Set up GitHub Actions to deploy to staging on pull requests and production on main branch merges. Include manual approval for production and rollback capabilities.\"\n\nClaude will create:\n1. Separate workflows for staging and production\n2. Environment-specific secrets configuration\n3. Manual approval gates using GitHub Environments\n4. Deployment status checks\n5. Rollback workflow with version tagging\n6. Slack/Discord notifications on deployment events\n\n### Security Scanning Pipeline\n\n**Prompt:** \"Add comprehensive security scanning to my CI pipeline: dependency vulnerabilities, CodeQL analysis, Docker image scanning, and secrets detection.\"\n\nClaude will implement:\n1. Dependabot integration for automated dependency updates\n2. CodeQL workflow for code security analysis\n3. Trivy for Docker image vulnerability scanning\n4. Gitleaks for secrets detection\n5. SARIF upload for Security tab integration\n6. Fail-fast on critical vulnerabilities\n\n### Performance Testing Integration\n\n**Prompt:** \"Create a workflow that runs Lighthouse CI on every deployment preview and fails if Core Web Vitals thresholds are not met.\"\n\nClaude will set up:\n1. Lighthouse CI workflow triggered on deployment\n2. Performance budgets configuration\n3. Core Web Vitals thresholds (LCP, FID, CLS)\n4. Comment PR with performance scores\n5. Historical performance tracking\n6. Regression detection and alerts\n\n## Tips for Best Results\n\n1. **Parallel Jobs**: Request explicit job parallelization for independent tasks (lint, test, type-check) to minimize CI runtime.\n\n2. **Smart Caching**: Ask for dependency caching strategies specific to your package manager (npm, pnpm, yarn) to speed up workflows.\n\n3. **Matrix Builds**: For libraries, request matrix builds across Node versions (18, 20, 22) and OS (ubuntu, macos, windows).\n\n4. **Conditional Execution**: Use path filters to only run workflows when relevant files change (e.g., only run E2E tests when app/ changes).\n\n5. **Reusable Workflows**: For common patterns, ask Claude to create reusable workflows that can be called from multiple repositories.\n\n6. **Security First**: Always request OIDC authentication instead of long-lived credentials for cloud deployments (AWS, GCP, Azure).\n\n## Common Workflows\n\n### Complete Next.js Production Pipeline\n```\n\"Create a production-grade GitHub Actions pipeline for Next.js 15:\n1. Install dependencies with pnpm caching\n2. Run TypeScript type checking in parallel with linting\n3. Run Vitest unit tests with coverage (fail if < 80%)\n4. Run Playwright E2E tests on Chrome and Firefox\n5. Build Next.js app and verify no build errors\n6. Deploy to Vercel preview on PR, production on main\n7. Run Lighthouse CI and comment scores on PR\n8. Send Slack notification on success/failure\"\n```\n\n### Monorepo CI/CD with Turborepo\n```\n\"Set up GitHub Actions for Turborepo monorepo:\n1. Use Turborepo remote caching with Vercel\n2. Run affected tasks only (lint, test, build)\n3. Matrix build for each package\n4. Publish packages to npm on release tags\n5. Deploy apps to respective environments\n6. Coordinate deployments across dependent services\"\n```\n\n### Docker Multi-Stage Build & Deploy\n```\n\"Create workflow for Docker application:\n1. Build Docker image with multi-stage caching\n2. Run security scan with Trivy\n3. Run integration tests in Docker Compose\n4. Push to GitHub Container Registry with semantic versioning\n5. Deploy to AWS ECS using OIDC authentication\n6. Run smoke tests post-deployment\n7. Rollback on failure\"\n```\n\n### Infrastructure as Code Pipeline\n```\n\"Generate Terraform deployment workflow:\n1. Validate Terraform syntax and formatting\n2. Run terraform plan and comment on PR\n3. Run security scan with tfsec and Checkov\n4. Require manual approval for apply\n5. Apply Terraform on main branch merge\n6. Store state in S3 with DynamoDB locking\n7. Post-apply validation tests\"\n```\n\n## Troubleshooting\n\n**Issue:** Workflows are too slow (>15 minutes)\n**Solution:** Ask Claude to implement aggressive caching (dependencies, build artifacts), parallelize independent jobs, and use path filters to skip unnecessary runs.\n\n**Issue:** Flaky E2E tests causing false failures\n**Solution:** Request implementation of test retry logic with `@playwright/test` retry configuration, and ask for separate \"required\" vs \"optional\" status checks.\n\n**Issue:** Deployment fails intermittently\n**Solution:** Ask for timeout increases, exponential backoff retry logic, and health check validation before marking deployment as successful.\n\n**Issue:** Secrets management is complex\n**Solution:** Request migration to GitHub Environments for environment-specific secrets, and OIDC for cloud provider authentication instead of long-lived tokens.\n\n**Issue:** Too many concurrent workflow runs\n**Solution:** Ask for concurrency groups configuration to cancel in-progress runs when new commits are pushed to same branch.\n\n## Learn More\n\n- [GitHub Actions Documentation](https://docs.github.com/en/actions)\n- [GitHub Actions Best Practices](https://docs.github.com/en/actions/learn-github-actions/best-practices)\n- [Workflow Syntax Reference](https://docs.github.com/en/actions/reference/workflow-syntax-for-github-actions)\n- [Security Hardening Guide](https://docs.github.com/en/actions/security-guides/security-hardening-for-github-actions)\n- [Reusable Workflows](https://docs.github.com/en/actions/learn-github-actions/reusing-workflows)\n",
      "features": [
        "Complete CI/CD pipeline generation",
        "Multi-environment deployment strategies",
        "Security scanning integration (CodeQL, Trivy, Dependabot)",
        "Performance testing with Lighthouse CI",
        "Matrix builds across platforms",
        "Smart caching and parallelization"
      ],
      "useCases": [
        "Automated testing and deployment pipelines",
        "Security vulnerability scanning",
        "Performance regression detection",
        "Multi-environment infrastructure deployment"
      ],
      "requirements": [
        "GitHub repository with Actions enabled",
        "Test suite (Vitest, Jest, Playwright)",
        "Deployment target (Vercel, AWS, GCP, etc.)"
      ],
      "examples": [
        {
          "title": "Complete Next.js CI/CD Pipeline",
          "language": "yaml",
          "code": "name: CI/CD Pipeline\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main, develop]\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\njobs:\n  install:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      \n      - uses: pnpm/action-setup@v2\n        with:\n          version: 8\n      \n      - uses: actions/setup-node@v4\n        with:\n          node-version: 20\n          cache: 'pnpm'\n      \n      - name: Install dependencies\n        run: pnpm install --frozen-lockfile\n      \n      - name: Cache node_modules\n        uses: actions/cache@v4\n        with:\n          path: node_modules\n          key: ${{ runner.os }}-node-${{ hashFiles('**/pnpm-lock.yaml') }}\n\n  lint:\n    needs: install\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: pnpm/action-setup@v2\n      - uses: actions/setup-node@v4\n        with:\n          node-version: 20\n          cache: 'pnpm'\n      \n      - name: Restore dependencies\n        uses: actions/cache@v4\n        with:\n          path: node_modules\n          key: ${{ runner.os }}-node-${{ hashFiles('**/pnpm-lock.yaml') }}\n      \n      - name: Run ESLint\n        run: pnpm lint\n\n  typecheck:\n    needs: install\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: pnpm/action-setup@v2\n      - uses: actions/setup-node@v4\n        with:\n          node-version: 20\n          cache: 'pnpm'\n      \n      - name: Restore dependencies\n        uses: actions/cache@v4\n        with:\n          path: node_modules\n          key: ${{ runner.os }}-node-${{ hashFiles('**/pnpm-lock.yaml') }}\n      \n      - name: Run TypeScript\n        run: pnpm type-check\n\n  test:\n    needs: install\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: pnpm/action-setup@v2\n      - uses: actions/setup-node@v4\n        with:\n          node-version: 20\n          cache: 'pnpm'\n      \n      - name: Restore dependencies\n        uses: actions/cache@v4\n        with:\n          path: node_modules\n          key: ${{ runner.os }}-node-${{ hashFiles('**/pnpm-lock.yaml') }}\n      \n      - name: Run unit tests\n        run: pnpm test:unit --coverage\n      \n      - name: Upload coverage\n        uses: codecov/codecov-action@v4\n        with:\n          token: ${{ secrets.CODECOV_TOKEN }}\n\n  e2e:\n    needs: install\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        browser: [chromium, firefox]\n    steps:\n      - uses: actions/checkout@v4\n      - uses: pnpm/action-setup@v2\n      - uses: actions/setup-node@v4\n        with:\n          node-version: 20\n          cache: 'pnpm'\n      \n      - name: Restore dependencies\n        uses: actions/cache@v4\n        with:\n          path: node_modules\n          key: ${{ runner.os }}-node-${{ hashFiles('**/pnpm-lock.yaml') }}\n      \n      - name: Install Playwright Browsers\n        run: pnpm exec playwright install --with-deps ${{ matrix.browser }}\n      \n      - name: Run E2E tests\n        run: pnpm test:e2e --project=${{ matrix.browser }}\n      \n      - name: Upload test results\n        if: failure()\n        uses: actions/upload-artifact@v4\n        with:\n          name: playwright-report-${{ matrix.browser }}\n          path: playwright-report/\n\n  deploy:\n    needs: [lint, typecheck, test, e2e]\n    if: github.ref == 'refs/heads/main'\n    runs-on: ubuntu-latest\n    environment:\n      name: production\n      url: https://yourapp.com\n    steps:\n      - uses: actions/checkout@v4\n      \n      - name: Deploy to Vercel\n        uses: amondnet/vercel-action@v25\n        with:\n          vercel-token: ${{ secrets.VERCEL_TOKEN }}\n          vercel-org-id: ${{ secrets.VERCEL_ORG_ID }}\n          vercel-project-id: ${{ secrets.VERCEL_PROJECT_ID }}\n          vercel-args: '--prod'\n      \n      - name: Notify Slack\n        uses: slackapi/slack-github-action@v1\n        with:\n          payload: |\n            {\n              \"text\": \"Deployment to production successful!\",\n              \"blocks\": [\n                {\n                  \"type\": \"section\",\n                  \"text\": {\n                    \"type\": \"mrkdwn\",\n                    \"text\": \"âœ… *Deployment Successful*\\nCommit: ${{ github.sha }}\\nAuthor: ${{ github.actor }}\"\n                  }\n                }\n              ]\n            }\n        env:\n          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK }}"
        },
        {
          "title": "Security Scanning Workflow",
          "language": "yaml",
          "code": "name: Security Scan\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n  schedule:\n    - cron: '0 0 * * 1' # Weekly on Monday\n\njobs:\n  codeql:\n    name: CodeQL Analysis\n    runs-on: ubuntu-latest\n    permissions:\n      security-events: write\n      actions: read\n      contents: read\n    \n    strategy:\n      matrix:\n        language: [javascript, typescript]\n    \n    steps:\n      - uses: actions/checkout@v4\n      \n      - name: Initialize CodeQL\n        uses: github/codeql-action/init@v3\n        with:\n          languages: ${{ matrix.language }}\n      \n      - name: Autobuild\n        uses: github/codeql-action/autobuild@v3\n      \n      - name: Perform CodeQL Analysis\n        uses: github/codeql-action/analyze@v3\n\n  dependency-scan:\n    name: Dependency Vulnerability Scan\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      \n      - name: Run npm audit\n        run: npm audit --audit-level=moderate\n      \n      - name: Run Snyk\n        uses: snyk/actions/node@master\n        env:\n          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}\n        with:\n          args: --severity-threshold=high\n\n  secrets-scan:\n    name: Secrets Detection\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n      \n      - name: Run Gitleaks\n        uses: gitleaks/gitleaks-action@v2\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}"
        }
      ],
      "installation": {
        "claudeDesktop": {
          "steps": [
            "Create .github/workflows directory in your repository",
            "Ask Claude to generate workflow for your specific needs",
            "Copy generated YAML to .github/workflows/ci-cd.yml",
            "Configure required secrets in GitHub repository settings",
            "Push workflow file and verify Actions tab"
          ]
        },
        "claudeCode": {
          "steps": [
            "mkdir -p .github/workflows",
            "Ask Claude for workflow generation",
            "Save workflow YAML files",
            "Configure GitHub secrets via Settings > Secrets and variables > Actions",
            "Test workflow with git push"
          ]
        }
      },
      "troubleshooting": [
        {
          "issue": "Workflow runs are too slow",
          "solution": "Implement dependency caching, parallelize independent jobs, and use path filters to skip unnecessary runs."
        },
        {
          "issue": "Authentication failures in deployment",
          "solution": "Use OIDC instead of long-lived tokens. Configure GitHub Environments with proper permissions."
        },
        {
          "issue": "Flaky test failures",
          "solution": "Add retry logic to Playwright tests, separate required vs optional checks, increase timeouts."
        }
      ],
      "documentationUrl": "https://docs.github.com/en/actions",
      "source": "community",
      "type": "skill",
      "url": "https://claudepro.directory/skills/github-actions-ai-cicd"
    },
    {
      "slug": "image-ocr-table-extraction",
      "title": "Image OCR and Table Extraction",
      "seoTitle": "Image OCR + Table Extraction Skill",
      "description": "Extract text and tabular data from images/scans using Tesseract and OpenCV with preprocessing.",
      "category": "skills",
      "author": "JSONbored",
      "dateAdded": "2025-10-15",
      "tags": [
        "ocr",
        "image",
        "pytesseract",
        "opencv",
        "tables"
      ],
      "content": "# Image OCR & Table Extraction Skill\n\n## What This Skill Enables\n\nClaude can extract text and tables from images, screenshots, scanned documents, and PDFs using OCR (Optical Character Recognition). Convert images of receipts, invoices, forms, and tables into editable text and structured data.\n\n## Prerequisites\n\n**Required:**\n- Claude Pro subscription\n- Code Interpreter feature enabled\n- Image file uploaded (PNG, JPG, PDF with images)\n\n**What Claude handles:**\n- Installing Tesseract OCR and vision libraries\n- Image preprocessing and enhancement\n- Text recognition and layout analysis\n- Table structure detection\n- Data extraction and formatting\n\n## How to Use This Skill\n\n### Basic Text Extraction\n\n**Prompt:** \"Extract all text from this screenshot and give me the content as plain text.\"\n\nClaude will:\n1. Preprocess the image\n2. Run OCR\n3. Extract text with layout preservation\n4. Return formatted text\n\n### Table Extraction\n\n**Prompt:** \"Extract the table from this image and export it as CSV.\"\n\nClaude will:\n1. Detect table boundaries\n2. Identify rows and columns\n3. Extract cell contents\n4. Structure as tabular data\n5. Export as CSV\n\n### Form Data Extraction\n\n**Prompt:** \"Extract data from this invoice image:\n- Invoice number\n- Date\n- Vendor name\n- Line items (description, quantity, price)\n- Total amount\nFormat as JSON.\"\n\nClaude will:\n1. OCR the entire image\n2. Identify fields by labels\n3. Extract values\n4. Structure as JSON\n5. Validate data format\n\n### Receipt Processing\n\n**Prompt:** \"Process this receipt image and extract:\n- Merchant name\n- Date and time\n- All item names and prices\n- Subtotal, tax, total\nCreate a structured expense record.\"\n\nClaude will:\n1. OCR the receipt\n2. Parse line items\n3. Extract financial data\n4. Calculate totals\n5. Format as structured data\n\n## Common Workflows\n\n### Batch Invoice Processing\n```\n\"Process all invoice images I upload and:\n1. Extract: invoice #, date, vendor, total\n2. Create a master spreadsheet with all invoices\n3. Flag any invoices where OCR confidence is low\n4. Export as invoices_data.csv\"\n```\n\n### Screenshot Text Recovery\n```\n\"Extract all code from this screenshot of a terminal:\n1. Recognize monospace text accurately\n2. Preserve indentation\n3. Clean up any OCR artifacts\n4. Save as code.py\"\n```\n\n### Business Card Digitization\n```\n\"Extract contact information from this business card:\n1. Name\n2. Title/Position\n3. Company\n4. Email\n5. Phone\n6. Address\nFormat as vCard or CSV for import to contacts.\"\n```\n\n### Table from PDF Extraction\n```\n\"This PDF contains a table that I can't copy/paste properly:\n1. Extract the table using OCR\n2. Recognize the column headers\n3. Parse all rows\n4. Handle multi-line cells\n5. Export as clean CSV\"\n```\n\n## Tips for Best Results\n\n1. **Image Quality Matters**: Higher resolution, clear contrast, straight orientation = better OCR\n2. **Preprocessing**: Ask Claude to enhance/preprocess low-quality images first\n3. **Language**: Specify if text isn't in English (\"OCR this German document...\")\n4. **Table Complexity**: For complex tables, describe the structure (\"5 columns, headers in first row\")\n5. **Multiple Pages**: Upload one page at a time for best results, or ask Claude to process sequentially\n6. **Handwriting**: Note that OCR works best on printed text; handwriting recognition is limited\n7. **Confidence Thresholds**: Ask Claude to report OCR confidence scores for verification\n\n## Image Quality Enhancements\n\n### Preprocessing Options\n- Rotate/deskew images\n- Increase contrast\n- Remove noise and artifacts\n- Binarization (convert to black/white)\n- Upscale low-resolution images\n- Crop to region of interest\n\n### Common Issues Claude Can Fix\n- Skewed/rotated images\n- Low contrast\n- Background noise\n- Poor lighting\n- Watermarks (some removal possible)\n\n## Advanced Extraction\n\n### Multi-Column Layouts\n- Newspaper-style columns\n- Magazine layouts\n- Academic papers\n- Forms with complex layouts\n\n### Special Document Types\n- Passports and IDs\n- Medical forms\n- Financial statements\n- Legal documents\n- Shipping labels\n\n## Troubleshooting\n\n**Issue:** OCR results are garbled or inaccurate\n**Solution:** Ask Claude to preprocess the image first: \"Enhance this image (increase contrast, deskew) and then run OCR\"\n\n**Issue:** Table structure not recognized properly\n**Solution:** Describe the table: \"This is a 4-column table with headers in row 1. Extract it as CSV.\"\n\n**Issue:** Numbers recognized as letters (0 as O, 1 as I)\n**Solution:** Tell Claude what type of data to expect: \"Extract invoice number (numeric only) and date\"\n\n**Issue:** Multi-page document results are mixed up\n**Solution:** Process pages individually: \"Extract text from page 1 only\" then \"Now page 2\"\n\n**Issue:** Handwriting not recognized\n**Solution:** OCR works best on printed text. For handwriting, describe it: \"This is handwritten notes, do your best to extract text\"\n\n**Issue:** Foreign language not recognized\n**Solution:** Specify language explicitly: \"OCR this Japanese document using Japanese language model\"\n\n## Learn More\n\n- [Tesseract OCR](https://github.com/tesseract-ocr/tesseract) - Open-source OCR engine\n- [pytesseract Documentation](https://pypi.org/project/pytesseract/) - Python wrapper for Tesseract\n- [OpenCV for Image Processing](https://opencv.org/) - Image preprocessing techniques\n- [Table Detection Methods](https://nanonets.com/blog/table-extraction-deep-learning/) - How table extraction works\n- [Claude Vision Capabilities](https://www.anthropic.com/news/claude-3-family) - Claude's image understanding\n",
      "features": [
        "OpenCV preprocessing recipes",
        "Pytesseract OCR with language packs",
        "Export tables to CSV/JSON",
        "Confidence-aware extraction"
      ],
      "useCases": [
        "Digitize receipts and invoices",
        "Extract tables from scans",
        "Searchable archives"
      ],
      "requirements": [
        "Python 3.11+",
        "opencv-python",
        "pytesseract",
        "tesseract-ocr binary with language data"
      ],
      "examples": [
        {
          "title": "OCR with preprocessing (Python)",
          "language": "python",
          "code": "import cv2, pytesseract\nimg = cv2.imread('scan.png', cv2.IMREAD_GRAYSCALE)\nimg = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\ntext = pytesseract.image_to_string(img, lang='eng')\nprint(text[:300])"
        }
      ],
      "installation": {
        "claudeDesktop": {
          "steps": [
            "Install tesseract-ocr",
            "pip install opencv-python pytesseract"
          ]
        },
        "claudeCode": {
          "steps": [
            "Verify TESSDATA_PREFIX",
            "Install language packs as needed"
          ]
        }
      },
      "troubleshooting": [
        {
          "issue": "Garbled or incorrect text from low-contrast scans",
          "solution": "Apply OpenCV adaptive thresholding with cv2.THRESH_BINARY + cv2.THRESH_OTSU, or increase DPI via resampling before OCR."
        },
        {
          "issue": "TesseractNotFoundError when running pytesseract",
          "solution": "Install Tesseract OCR binary separately: apt-get install tesseract-ocr or brew install tesseract, then set path if needed."
        },
        {
          "issue": "OCR returns empty string for valid image with text",
          "solution": "Check image preprocessing: convert to grayscale, apply binarization, ensure correct page segmentation mode (--psm) parameter."
        },
        {
          "issue": "Numbers confused with letters (0 vs O, 1 vs l)",
          "solution": "Use config='--psm 6 --oem 3 -c tessedit_char_whitelist=0123456789' to restrict character set for numeric-only fields."
        },
        {
          "issue": "Non-English text recognition fails or returns gibberish",
          "solution": "Install language data with apt-get install tesseract-ocr-[lang] or brew install tesseract-lang, then use lang='fra' parameter."
        }
      ],
      "documentationUrl": "https://tesseract-ocr.github.io/",
      "source": "community",
      "type": "skill",
      "url": "https://claudepro.directory/skills/image-ocr-table-extraction"
    },
    {
      "slug": "json-schema-validation-transformation",
      "title": "JSON Schema Validation and Transformation",
      "seoTitle": "JSON Schema Validate + Transform Skill",
      "description": "Validate JSON with Ajv/Zod and perform safe, lossless schema migrations and transformations.",
      "category": "skills",
      "author": "JSONbored",
      "dateAdded": "2025-10-15",
      "tags": [
        "json",
        "schema",
        "validation",
        "ajv",
        "zod"
      ],
      "content": "# JSON Schema Validation & Transformation Skill\n\n## What This Skill Enables\n\nClaude can validate JSON data against schemas, transform data between formats, migrate between schema versions, and generate TypeScript types from JSON schemas using tools like Ajv, Zod, and json-schema-to-typescript.\n\n## Prerequisites\n\n**Required:**\n- Claude Pro subscription\n- Code Interpreter feature enabled\n- JSON data or schema file uploaded\n\n**What Claude handles:**\n- Installing validation libraries (Ajv, Zod)\n- Schema compilation and validation\n- Error reporting and debugging\n- Data transformation and migration\n- Type generation from schemas\n\n## How to Use This Skill\n\n### Validate JSON Against Schema\n\n**Prompt:** \"Validate this JSON data against the provided JSON Schema. Show me all validation errors.\"\n\nClaude will:\n1. Load schema and data\n2. Compile schema\n3. Run validation\n4. Report all errors with paths\n5. Suggest fixes\n\n### Generate TypeScript Types\n\n**Prompt:** \"Generate TypeScript interfaces from this JSON Schema.\"\n\nClaude will:\n1. Parse the JSON Schema\n2. Generate TypeScript types\n3. Include JSDoc comments\n4. Export as .d.ts file\n\n### Transform Data Format\n\n**Prompt:** \"Transform this API response from format A to format B according to this mapping schema.\"\n\nClaude will:\n1. Analyze source and target schemas\n2. Create transformation logic\n3. Map fields\n4. Validate output\n5. Return transformed data\n\n### Schema Migration\n\n**Prompt:** \"Migrate these 100 JSON documents from schema v1 to schema v2. Show me the migration script and any issues.\"\n\nClaude will:\n1. Compare schema versions\n2. Identify changes\n3. Generate migration script\n4. Process all documents\n5. Report any migration failures\n\n## Common Workflows\n\n### API Payload Validation\n```\n\"Create a validation script that:\n1. Loads this OpenAPI spec\n2. Extracts the POST /users request schema\n3. Validates this payload against it\n4. Returns detailed error messages for invalid fields\n5. Suggests corrections\"\n```\n\n### Config File Validation\n```\n\"Validate all JSON config files in the uploaded directory:\n1. Check against config.schema.json\n2. Report which files are invalid\n3. For each error, show: file, path, expected type, actual value\n4. Suggest fixes for common errors\n5. Generate a validation report\"\n```\n\n### Data Normalization\n```\n\"Normalize this messy JSON data:\n1. Validate against the schema\n2. Fix common issues (trim strings, coerce types)\n3. Remove extra properties not in schema\n4. Fill in default values for missing optional fields\n5. Export clean, validated JSON\"\n```\n\n### Batch Transformation\n```\n\"Transform all JSON files from old format to new:\n1. Load transformation rules\n2. For each file:\n   - Parse and validate source\n   - Apply transformations\n   - Validate against target schema\n   - Save to output/\n3. Report success/failure stats\"\n```\n\n## Tips for Best Results\n\n1. **Provide Complete Schemas**: Include all $ref dependencies or use inline definitions\n2. **Specify Validation Rules**: Be clear about strictness (additional properties, coercion, etc.)\n3. **Error Reporting**: Ask for detailed error paths: \"Show me the JSON path for each error\"\n4. **Examples**: Provide sample valid and invalid data\n5. **Version Info**: Specify JSON Schema draft version (draft-07, 2019-09, 2020-12)\n6. **Custom Formats**: If using custom formats, define validation logic\n7. **Large Datasets**: For many files, ask Claude to process in batches\n\n## Advanced Features\n\n### Schema Generation\n- Generate schema from sample JSON\n- Infer types and patterns\n- Add validation rules\n- Export as JSON Schema or TypeScript\n\n### Complex Validations\n- Custom validation functions\n- Conditional schemas (if/then/else)\n- Dependencies between properties\n- Pattern properties\n- Recursive schemas\n\n### Data Transformation Patterns\n- Field renaming and mapping\n- Nested object flattening/nesting\n- Array transformations\n- Type coercion with validation\n- Conditional transformations\n\n## Troubleshooting\n\n**Issue:** Schema validation too strict\n**Solution:** Ask Claude to adjust: \"Allow additional properties\" or \"Coerce types when possible\"\n\n**Issue:** $ref resolution errors\n**Solution:** Either inline all schemas or ensure all referenced files are uploaded\n\n**Issue:** Type coercion not working as expected\n**Solution:** Be explicit: \"Convert string numbers to integers\" or \"Parse ISO date strings to Date objects\"\n\n**Issue:** Large JSON files cause memory issues\n**Solution:** \"Process this file in streaming mode\" or \"Validate in chunks of 1000 records\"\n\n**Issue:** Validation errors are cryptic\n**Solution:** Ask for better errors: \"Explain each validation error in plain English with examples\"\n\n**Issue:** Migration breaks data\n**Solution:** \"Validate each step of the migration\" and \"Keep backup of original values for rollback\"\n\n## Learn More\n\n- [JSON Schema Specification](https://json-schema.org/) - Official JSON Schema docs\n- [Ajv Documentation](https://ajv.js.org/) - The fastest JSON Schema validator\n- [Zod](https://zod.dev/) - TypeScript-first schema validation\n- [Understanding JSON Schema](https://json-schema.org/understanding-json-schema/) - Comprehensive guide\n- [JSON Schema Tools](https://json-schema.org/implementations.html) - Validators and generators\n",
      "features": [
        "Strict validation with helpful errors",
        "Schema-aware migration",
        "Format and ref handling",
        "CLI-friendly usage"
      ],
      "useCases": [
        "API payload validation",
        "Config migration",
        "Data pipeline guards"
      ],
      "requirements": [
        "Node.js 18+",
        "ajv or zod"
      ],
      "examples": [
        {
          "title": "Validate with Ajv",
          "language": "javascript",
          "code": "import Ajv from 'ajv';\nconst ajv = new Ajv({ allErrors: true, strict: true });\nconst validate = ajv.compile({ type: 'object', properties: { id: { type: 'string' } }, required: ['id'], additionalProperties: false });\nconsole.log(validate({ id: 'abc' })); // true\nconsole.log(validate({})); // false, see validate.errors"
        }
      ],
      "installation": {
        "claudeDesktop": {
          "steps": [
            "Install Node.js 18+",
            "npm i ajv zod"
          ]
        },
        "claudeCode": {
          "steps": [
            "npm i ajv",
            "Enable strict mode for better guarantees"
          ]
        }
      },
      "troubleshooting": [
        {
          "issue": "Schema $ref resolution fails with 'can't resolve reference'",
          "solution": "Use absolute URIs for external refs or configure Ajv with custom schema loader using addSchema() for multi-file schemas."
        },
        {
          "issue": "Validation passes but TypeScript complains about types",
          "solution": "Use json-schema-to-typescript to generate types from schema, ensuring runtime validation matches compile-time types."
        },
        {
          "issue": "additionalProperties: false causes valid data to fail",
          "solution": "Check for extra fields in input data or relax schema with additionalProperties: true; use removeAdditional option in Ajv."
        },
        {
          "issue": "Format validation fails for valid dates or URIs",
          "solution": "Install ajv-formats package and enable: import addFormats from 'ajv-formats'; addFormats(ajv) for standard format validators."
        },
        {
          "issue": "Ajv throws 'strict mode: unknown keyword' error",
          "solution": "Disable strict mode with new Ajv({strict: false}) or add custom keywords using ajv.addKeyword() for non-standard properties."
        }
      ],
      "documentationUrl": "https://ajv.js.org/",
      "source": "community",
      "type": "skill",
      "url": "https://claudepro.directory/skills/json-schema-validation-transformation"
    },
    {
      "slug": "log-parsing-incident-timeline",
      "title": "Log Parsing and Incident Timeline",
      "seoTitle": "Log Parsing + Incident Timeline Skill",
      "description": "Parse web/app/system logs into structured incidents and timelines with anomaly hints.",
      "category": "skills",
      "author": "JSONbored",
      "dateAdded": "2025-10-15",
      "tags": [
        "logs",
        "observability",
        "ripgrep",
        "bash"
      ],
      "content": "# Log Parsing & Incident Timeline Skill\n\n## What This Skill Enables\n\nClaude can parse application logs, server logs, and system logs to extract errors, create incident timelines, identify patterns, and correlate events across distributed systems. Transform raw log data into actionable insights.\n\n## Prerequisites\n\n**Required:**\n- Claude Pro subscription\n- Code Interpreter feature enabled\n- Log files uploaded (text, JSON, or compressed)\n\n**What Claude handles:**\n- Installing log parsing tools (grep, awk, jq, logparser)\n- Pattern matching and extraction\n- Timestamp parsing and correlation\n- Error aggregation and analysis\n- Timeline generation\n\n## How to Use This Skill\n\n### Extract Errors from Logs\n\n**Prompt:** \"Find all errors in this application log from the past hour. Group by error type and show frequency.\"\n\nClaude will:\n1. Parse log timestamps\n2. Filter to last hour\n3. Extract error messages\n4. Group and count\n5. Present sorted by frequency\n\n### Create Incident Timeline\n\n**Prompt:** \"Create a timeline of what happened during the outage (2pm-3pm):\n- Filter to that time range\n- Show key events (errors, warnings, restarts)\n- Correlate across multiple log files\n- Present chronologically\"\n\nClaude will:\n1. Parse multiple log sources\n2. Filter by time range\n3. Extract significant events\n4. Merge and sort chronologically\n5. Create incident timeline\n\n### Analyze Request Flow\n\n**Prompt:** \"Trace request ID 'abc123' through all log files. Show the complete journey with timestamps and any errors encountered.\"\n\nClaude will:\n1. Search for request ID across files\n2. Extract all matching lines\n3. Sort by timestamp\n4. Identify errors or anomalies\n5. Show complete flow\n\n### Performance Analysis\n\n**Prompt:** \"Analyze response times in this access log:\n- Calculate p50, p95, p99 percentiles\n- Identify slowest requests\n- Show distribution histogram\n- Flag requests over 1 second\"\n\nClaude will:\n1. Extract response time data\n2. Calculate statistics\n3. Identify outliers\n4. Create visualization\n5. Report findings\n\n## Common Workflows\n\n### Post-Incident Analysis\n```\n\"Analyze logs from the incident:\n1. Extract all errors between 14:00-15:00\n2. Identify first error that occurred\n3. Show cascade of subsequent errors\n4. Correlate with deployment timestamp\n5. Create incident report with timeline\"\n```\n\n### Security Audit\n```\n\"Audit access logs for security issues:\n1. Find failed login attempts (3+ in 5 min)\n2. Identify IP addresses with suspicious patterns\n3. Detect potential SQL injection attempts\n4. Flag unusual user agent strings\n5. Generate security report\"\n```\n\n### Error Aggregation\n```\n\"Aggregate errors from past 7 days:\n1. Group by error type/stack trace\n2. Count occurrences over time\n3. Identify trends (increasing/decreasing)\n4. Show top 10 most common errors\n5. Export as CSV for tracking\"\n```\n\n### Multi-Service Correlation\n```\n\"Correlate logs from:\n- API gateway (nginx)\n- Application server (node.js)\n- Database (postgres)\n- Cache (redis)\nFor request ID xyz789, show complete flow across all services.\"\n```\n\n## Log Formats Supported\n\n### Common Formats\n- Apache/Nginx access logs\n- JSON structured logs\n- Syslog format\n- Application logs (various formats)\n- AWS CloudWatch logs\n- Docker container logs\n\n### Custom Formats\n- Claude can parse custom log formats\n- Provide sample line and field descriptions\n- Define regex patterns or delimiters\n\n## Tips for Best Results\n\n1. **Provide Context**: Describe log format and what you're looking for\n2. **Time Ranges**: Be specific about time periods (\"last hour\", \"between 2-3pm EST\")\n3. **Sample Lines**: Show Claude a few example log lines\n4. **Identifiers**: Mention correlation IDs (request ID, user ID, session ID)\n5. **Large Files**: For huge logs, ask Claude to sample or filter first\n6. **Compressed Logs**: Claude can handle .gz files directly\n7. **Multiple Files**: Upload related files together for correlation\n\n## Advanced Analysis\n\n### Pattern Detection\n- Anomaly detection in log volume\n- Unusual pattern recognition\n- Cyclic pattern identification\n- Outlier detection\n\n### Correlation Techniques\n- Cross-service request tracing\n- Time-based event correlation\n- User session reconstruction\n- Dependency mapping\n\n### Filtering & Extraction\n- Regex-based pattern matching\n- JSON path extraction\n- Field parsing and normalization\n- PII redaction\n\n## Troubleshooting\n\n**Issue:** Timestamps in different formats across logs\n**Solution:** Tell Claude the format: \"Timestamps are in ISO 8601 in app.log but Unix epoch in system.log\"\n\n**Issue:** Log files too large to process\n**Solution:** \"Sample every 10th line\" or \"Filter to errors only first\" or \"Process in 1-hour chunks\"\n\n**Issue:** Can't find specific error messages\n**Solution:** Provide example error text or pattern: \"Look for lines containing '500' or 'exception' or 'fatal'\"\n\n**Issue:** Multiple services use different request ID fields\n**Solution:** Map them: \"request_id in API logs, correlation_id in app logs, trace_id in database logs\"\n\n**Issue:** Logs contain sensitive data\n**Solution:** \"Redact IP addresses, emails, and API keys before analysis\" or \"Mask PII fields\"\n\n**Issue:** Time zone confusion\n**Solution:** Specify: \"All timestamps are in UTC\" or \"Convert to Eastern Time for analysis\"\n\n## Learn More\n\n- [Log Analysis Best Practices](https://www.loggly.com/ultimate-guide/analyzing-log-data/) - Comprehensive guide\n- [jq Manual](https://stedolan.github.io/jq/manual/) - JSON log parsing\n- [ripgrep Guide](https://github.com/BurntSushi/ripgrep) - Fast log searching\n- [Log Parsing Patterns](https://logz.io/blog/logstash-grok/) - Common log patterns\n- [Distributed Tracing](https://opentelemetry.io/docs/concepts/observability-primer/#distributed-traces) - Request correlation\n",
      "features": [
        "ripgrep-based fast filtering",
        "Session/request correlation",
        "Timeline generation",
        "PII/secret redaction"
      ],
      "useCases": [
        "Post-incident analysis",
        "Live debugging",
        "Compliance reporting"
      ],
      "requirements": [
        "ripgrep (rg)",
        "jq (optional)",
        "bash or Python 3.11+"
      ],
      "examples": [
        {
          "title": "Extract errors and build a simple timeline",
          "language": "bash",
          "code": "# Filter 5xx from nginx and sort by time\nrg -n ' 5\\d\\d ' access.log | awk '{print $4, $5, $9, $7}' | sort > timeline.txt\nhead -n 5 timeline.txt"
        }
      ],
      "installation": {
        "claudeDesktop": {
          "steps": [
            "Install ripgrep and jq"
          ]
        },
        "claudeCode": {
          "steps": [
            "Ensure logs are locally accessible",
            "Use rg for fast searches"
          ]
        }
      },
      "troubleshooting": [
        {
          "issue": "ripgrep finds no matches in logs with known content",
          "solution": "Check for encoding issues, try case-insensitive search with -i flag, test regex pattern with small sample first using rg -A 2."
        },
        {
          "issue": "Timestamps in multiple formats causing incorrect sorting",
          "solution": "Parse all timestamps to Unix epoch or ISO 8601 format first, then sort numerically before building timeline."
        },
        {
          "issue": "ripgrep regex pattern not matching expected lines",
          "solution": "Use rg --pcre2 for Perl-compatible regex, or simplify patterns and test with rg -o to show only matched parts."
        },
        {
          "issue": "jq command fails with parse error on log JSON",
          "solution": "Use jq -R for raw input if logs are line-delimited JSON, not pure JSON array; try jq -s for slurp mode on multiple objects."
        },
        {
          "issue": "Log correlation fails across microservices with different IDs",
          "solution": "Map correlation IDs in preprocessing step: create lookup table linking request_id, trace_id, correlation_id before timeline merge."
        }
      ],
      "documentationUrl": "https://github.com/BurntSushi/ripgrep",
      "source": "community",
      "type": "skill",
      "url": "https://claudepro.directory/skills/log-parsing-incident-timeline"
    },
    {
      "slug": "markdown-knowledge-base-composer",
      "title": "Markdown Knowledge Base Composer",
      "seoTitle": "Markdown Knowledge Base Composer Skill",
      "description": "Aggregate Markdown folders into a cohesive knowledge base with TOC, cross-links, and export.",
      "category": "skills",
      "author": "JSONbored",
      "dateAdded": "2025-10-15",
      "tags": [
        "markdown",
        "docs",
        "remark",
        "node"
      ],
      "content": "# Markdown Knowledge Base Composer Skill\n\n## What This Skill Enables\n\nClaude can organize, process, and transform Markdown documentation into cohesive knowledge bases. Generate table of contents, fix broken links, convert formats, create static sites, and export to PDF or HTML.\n\n## Prerequisites\n\n**Required:**\n- Claude Pro subscription\n- Code Interpreter feature enabled\n- Markdown files uploaded (can be multiple files/folders)\n\n**What Claude handles:**\n- Installing Markdown processing tools (remark, unified, pandoc)\n- Parsing and transforming Markdown\n- Link validation and fixing\n- TOC generation\n- Format conversion (MD â†’ HTML, PDF, DOCX)\n- Static site generation\n\n## How to Use This Skill\n\n### Generate Table of Contents\n\n**Prompt:** \"Generate a table of contents from all these Markdown files. Include links to each section.\"\n\nClaude will:\n1. Parse all Markdown files\n2. Extract headings\n3. Create hierarchical TOC\n4. Add anchor links\n5. Save as README.md or TOC.md\n\n### Fix Broken Links\n\n**Prompt:** \"Check all internal links in these Markdown files and fix any broken ones. Report what was fixed.\"\n\nClaude will:\n1. Parse all Markdown files\n2. Extract all links\n3. Validate targets exist\n4. Fix broken links\n5. Report changes made\n\n### Convert Format\n\n**Prompt:** \"Convert all these Markdown docs to a single PDF with:\n- Table of contents\n- Page numbers\n- Consistent heading styles\n- Code syntax highlighting\"\n\nClaude will:\n1. Merge Markdown files\n2. Generate TOC\n3. Apply styling\n4. Convert to PDF\n5. Export final document\n\n### Create Static Site\n\n**Prompt:** \"Generate a static HTML site from these docs:\n- Homepage with navigation\n- Responsive design\n- Search functionality\n- Dark mode toggle\"\n\nClaude will:\n1. Process Markdown to HTML\n2. Generate navigation\n3. Apply responsive CSS\n4. Add JavaScript features\n5. Create static site files\n\n## Common Workflows\n\n### Documentation Site Generation\n```\n\"Create documentation site:\n1. Parse all .md files in docs/\n2. Generate sidebar navigation\n3. Create search index\n4. Add syntax highlighting for code blocks\n5. Export as static HTML site\nUse clean, professional styling.\"\n```\n\n### Knowledge Base Consolidation\n```\n\"Consolidate scattered notes:\n1. Combine all Markdown files into sections\n2. Generate master TOC\n3. Normalize heading levels (start all at H1)\n4. Fix relative links between files\n5. Create single comprehensive document\nExport as both Markdown and PDF.\"\n```\n\n### README Generation\n```\n\"Generate professional README.md:\n1. Extract project info from package.json\n2. Add badges (build status, version, license)\n3. Create sections: About, Installation, Usage, Contributing\n4. Add table of contents with anchor links\n5. Include code examples from docs/\"\n```\n\n### Multi-Format Export\n```\n\"Export documentation in multiple formats:\n1. HTML (with navigation and search)\n2. PDF (with TOC and page numbers)\n3. EPUB (for e-readers)\n4. DOCX (for Word)\nMaintain consistent styling across all formats.\"\n```\n\n## Features & Capabilities\n\n### Markdown Processing\n- Parse frontmatter (YAML, TOML)\n- Extract and process links\n- Handle images and media\n- Process code blocks\n- Parse tables\n- Support GFM (GitHub Flavored Markdown)\n\n### Link Management\n- Validate internal links\n- Fix broken references\n- Convert relative to absolute\n- Update moved files\n- Generate anchor links\n\n### Content Organization\n- Auto-generate TOC at any level\n- Sort files by frontmatter or name\n- Create hierarchical structure\n- Merge multiple files\n- Split large files\n\n### Format Conversion\n- Markdown â†’ HTML\n- Markdown â†’ PDF\n- Markdown â†’ DOCX\n- Markdown â†’ EPUB\n- HTML â†’ Markdown\n\n## Tips for Best Results\n\n1. **File Organization**: Upload files with clear directory structure\n2. **Frontmatter**: Use YAML frontmatter for metadata (title, date, tags)\n3. **Link Style**: Be consistent with link styles (relative vs absolute)\n4. **Heading Hierarchy**: Start with H1, don't skip levels\n5. **File Naming**: Use kebab-case or snake_case consistently\n6. **Image Paths**: Keep images in dedicated folder (./images/ or ./assets/)\n7. **Code Blocks**: Always specify language for syntax highlighting\n\n## Advanced Operations\n\n### Custom Transformations\n- Replace text patterns across all files\n- Add custom frontmatter\n- Insert headers/footers\n- Inject custom CSS/JS\n- Apply templates\n\n### Multi-Language Support\n- Organize by language (en/, es/, etc.)\n- Generate language switcher\n- Maintain translation links\n\n### Version Control\n- Track changes between versions\n- Generate changelogs\n- Compare documentation versions\n\n## Troubleshooting\n\n**Issue:** Broken links after reorganizing files\n**Solution:** \"Scan all links and update paths based on new file structure\"\n\n**Issue:** TOC not rendering correctly\n**Solution:** Ensure consistent heading hierarchy (H1 â†’ H2 â†’ H3, no skipping)\n\n**Issue:** Images not showing in PDF export\n**Solution:** \"Use absolute paths for images\" or \"Embed images inline as base64\"\n\n**Issue:** Code blocks losing formatting\n**Solution:** \"Preserve code block syntax highlighting in export\" and specify language\n\n**Issue:** Special characters breaking exports\n**Solution:** \"Escape special characters\" or \"Use UTF-8 encoding throughout\"\n\n**Issue:** Large files causing memory issues\n**Solution:** \"Process files in batches\" or \"Split into smaller sections first\"\n\n## Learn More\n\n- [Markdown Guide](https://www.markdownguide.org/) - Comprehensive Markdown reference\n- [Remark](https://github.com/remarkjs/remark) - Markdown processor\n- [Pandoc](https://pandoc.org/) - Universal document converter\n- [MkDocs](https://www.mkdocs.org/) - Documentation site generator\n- [VitePress](https://vitepress.dev/) - Modern documentation framework\n",
      "features": [
        "Heading normalization and slug consistency",
        "TOC generation across directories",
        "Cross-link rewriting and validation",
        "Export to static HTML/PDF"
      ],
      "useCases": [
        "Assemble a product handbook",
        "Publish internal notes",
        "Create a client-facing knowledge pack"
      ],
      "requirements": [
        "Node.js 18+",
        "remark / unified",
        "Playwright (optional for PDF export)"
      ],
      "examples": [
        {
          "title": "Build TOC and rewrite links (Node)",
          "language": "javascript",
          "code": "import { readFileSync, readdirSync } from 'node:fs';\nimport { join } from 'node:path';\nimport { unified } from 'unified';\nimport remarkParse from 'remark-parse';\nimport remarkStringify from 'remark-stringify';\n\nconst dir = './notes';\nconst files = readdirSync(dir).filter(f => f.endsWith('.md'));\n\nfor (const file of files) {\n  const input = readFileSync(join(dir, file), 'utf8');\n  const tree = unified().use(remarkParse).parse(input);\n  // ... transform headings and links ...\n  const out = unified().use(remarkStringify).stringify(tree);\n  // writeFileSync(join('dist', file), out)\n}"
        }
      ],
      "installation": {
        "claudeDesktop": {
          "steps": [
            "Install Node.js 18+",
            "npm i remark remark-parse remark-stringify"
          ]
        },
        "claudeCode": {
          "steps": [
            "npm i remark unified",
            "Optionally install Playwright for PDF export"
          ]
        }
      },
      "troubleshooting": [
        {
          "issue": "Broken links after re-organization",
          "solution": "Regenerate slugs and run a link validator; ensure relative paths are correct."
        },
        {
          "issue": "Remark/unified plugins throwing 'Cannot read property' errors",
          "solution": "Ensure plugin order is correct: parse â†’ transform plugins â†’ stringify. Check unified() pipeline sequence and plugin compatibility."
        },
        {
          "issue": "Frontmatter YAML parsing fails with special characters in values",
          "solution": "Quote YAML values containing colons, brackets, or special chars. Use remark-frontmatter with yaml-safe mode enabled."
        },
        {
          "issue": "PDF export cuts off code blocks or loses syntax highlighting",
          "solution": "Use Playwright with explicit page breaks. Install prism.js or highlight.js for code styling, set print CSS media queries."
        },
        {
          "issue": "TOC anchor links not working after Markdown-to-HTML conversion",
          "solution": "Use remark-slug to generate consistent heading IDs, then remark-toc with 'tight' option. Ensure heading hierarchy is valid."
        }
      ],
      "documentationUrl": "https://github.com/remarkjs/remark",
      "source": "community",
      "type": "skill",
      "url": "https://claudepro.directory/skills/markdown-knowledge-base-composer"
    },
    {
      "slug": "mintlify-documentation-automation",
      "title": "Mintlify AI Documentation Automation",
      "seoTitle": "Mintlify AI Documentation Automation Skill",
      "description": "Automate beautiful, searchable documentation creation with Mintlify, AI-powered content generation from code, and interactive MDX components.",
      "category": "skills",
      "author": "JSONbored",
      "dateAdded": "2025-10-16",
      "tags": [
        "mintlify",
        "documentation",
        "mdx",
        "api-docs",
        "automation"
      ],
      "content": "# Mintlify AI Documentation Automation Skill\n\n## What This Skill Enables\n\nClaude can generate comprehensive, production-ready documentation using Mintlify - the modern documentation platform that has become the standard for developer-facing docs in 2025. This skill enables automatic API reference generation from code, interactive MDX components, multi-version documentation, and AI-powered content creation from JSDoc/TypeScript types.\n\n## Prerequisites\n\n**Required:**\n- Node.js 18+\n- Existing codebase with functions/APIs to document\n- Basic understanding of Markdown\n\n**What Claude handles automatically:**\n- Generating MDX documentation from TypeScript/JSDoc\n- Creating mint.json configuration with navigation\n- Building API reference pages from OpenAPI specs\n- Setting up interactive code examples\n- Configuring search, analytics, and versioning\n- Creating custom MDX components\n\n## How to Use This Skill\n\n### API Documentation from TypeScript\n\n**Prompt:** \"Generate Mintlify documentation from my TypeScript API client at src/api/users.ts. Include all JSDoc comments, parameter types, return types, and code examples.\"\n\nClaude will:\n1. Parse TypeScript file and extract exported functions\n2. Read JSDoc comments for descriptions\n3. Generate MDX files for each API endpoint\n4. Create proper Mintlify components (ParamField, ResponseField)\n5. Add code examples in multiple languages\n6. Generate response examples with proper formatting\n7. Update mint.json navigation\n\n### OpenAPI to Interactive Documentation\n\n**Prompt:** \"Convert my OpenAPI 3.0 spec (openapi.yaml) into Mintlify documentation with interactive API playground and authentication examples.\"\n\nClaude will create:\n1. API reference section in mint.json\n2. MDX file for each endpoint with proper structure\n3. Request/response examples using CodeGroup\n4. Authentication documentation with examples\n5. Error code reference table\n6. API playground integration\n7. SDK code examples (TypeScript, Python, cURL)\n\n### Complete Documentation Site Setup\n\n**Prompt:** \"Set up a complete Mintlify documentation site for my SaaS product with: Introduction, Quickstart, API Reference, Guides, Changelog. Include dark mode, search, and analytics.\"\n\nClaude will generate:\n1. Directory structure with organized MDX files\n2. mint.json with proper navigation tabs\n3. Introduction page with hero and feature cards\n4. Quickstart with step-by-step instructions\n5. API reference structure\n6. Guide templates\n7. Changelog format\n8. Dark mode configuration\n9. Search and analytics integration\n\n### Interactive Component Library Documentation\n\n**Prompt:** \"Document my React component library with interactive examples, prop tables, and usage guidelines. Components are in src/components/ui.\"\n\nClaude will create:\n1. Component documentation pages with descriptions\n2. PropTable components with TypeScript types\n3. Interactive code playgrounds\n4. Usage examples with best practices\n5. Accessibility guidelines per component\n6. Storybook integration links\n7. Installation and import instructions\n\n## Tips for Best Results\n\n1. **Rich JSDoc Comments**: Ensure your code has comprehensive JSDoc comments with @param, @returns, @throws, and @example tags for best auto-generation results.\n\n2. **OpenAPI First**: If you have an OpenAPI spec, use that as the source of truth. Mintlify's OpenAPI integration is more reliable than manual documentation.\n\n3. **Code Examples**: Request examples in multiple languages (TypeScript, JavaScript, Python, cURL) to maximize usefulness for different audiences.\n\n4. **Interactive Elements**: Ask for Mintlify-specific components (Accordion, Card, Tabs, CodeGroup) to make docs more engaging than plain Markdown.\n\n5. **Version Management**: For libraries, request versioned documentation setup from the start to avoid migration pain later.\n\n6. **Search Optimization**: Include descriptive meta titles and descriptions in frontmatter for better search discoverability.\n\n## Common Workflows\n\n### Complete API Documentation\n```\n\"Generate full Mintlify API documentation:\n1. Parse src/api/*.ts files for all exported functions\n2. Create API reference pages with proper Mintlify components\n3. Include TypeScript type definitions\n4. Add code examples in TypeScript, JavaScript, Python, and cURL\n5. Document all error codes and responses\n6. Set up authentication guide with OAuth 2.0 flow\n7. Configure API playground with authentication\n8. Add rate limiting documentation\"\n```\n\n### Component Library Docs\n```\n\"Build Mintlify docs for React component library:\n1. Document all components in src/components/ui\n2. Extract prop types from TypeScript interfaces\n3. Create PropTable for each component\n4. Add usage examples with CodeGroup\n5. Include accessibility guidelines (ARIA, keyboard)\n6. Link to Storybook for interactive demos\n7. Add installation guide with package manager options\n8. Create theming and customization guide\"\n```\n\n### SDK Documentation with Examples\n```\n\"Generate SDK documentation from TypeScript client:\n1. Document all SDK methods with parameters and returns\n2. Create quickstart with installation and auth setup\n3. Add comprehensive code examples for each method\n4. Include error handling patterns\n5. Document webhook integration\n6. Add retry and timeout configuration\n7. Create migration guide from v1 to v2\n8. Set up changelog with semantic versioning\"\n```\n\n### Multi-Version Documentation\n```\n\"Set up versioned Mintlify docs for API v1 and v2:\n1. Create separate documentation for each version\n2. Configure version switcher in mint.json\n3. Highlight breaking changes between versions\n4. Provide migration guide from v1 to v2\n5. Maintain v1 docs in archive with deprecation notice\n6. Set up URL structure: /v1/... and /v2/...\n7. Add version-specific examples\"\n```\n\n## Troubleshooting\n\n**Issue:** Mintlify build fails with \"Invalid frontmatter\"\n**Solution:** Ensure all MDX files have valid YAML frontmatter with required fields (title, description). Ask Claude to validate frontmatter syntax.\n\n**Issue:** Navigation doesn't match folder structure\n**Solution:** mint.json navigation must explicitly list all pages. Ask Claude to regenerate navigation section matching your actual MDX file structure.\n\n**Issue:** Code examples aren't syntax highlighted correctly\n**Solution:** Specify language in code fence (```typescript, not ```ts). Ask Claude to use full language names for better highlighting.\n\n**Issue:** API Reference pages look inconsistent\n**Solution:** Use Mintlify's built-in components (ParamField, ResponseField) instead of manual tables. Request Claude to refactor using proper components.\n\n**Issue:** Search doesn't find relevant pages\n**Solution:** Add descriptive `seoTitle` and `description` in frontmatter. Ask Claude to optimize metadata for search.\n\n## Learn More\n\n- [Mintlify Documentation](https://mintlify.com/docs)\n- [Mintlify Components](https://mintlify.com/docs/components)\n- [OpenAPI Integration](https://mintlify.com/docs/api-playground/openapi)\n- [Custom Components](https://mintlify.com/docs/components/custom)\n- [Versioning Guide](https://mintlify.com/docs/settings/versioning)\n",
      "features": [
        "Auto-generate docs from TypeScript/JSDoc",
        "OpenAPI to interactive API reference",
        "Interactive MDX components (Tabs, Accordion, CodeGroup)",
        "Multi-version documentation support",
        "Built-in search and analytics",
        "API playground with authentication"
      ],
      "useCases": [
        "API reference documentation from code",
        "SDK and library documentation",
        "Product documentation with guides and tutorials",
        "Component library documentation"
      ],
      "requirements": [
        "Node.js 18+",
        "Mintlify CLI: npm install -g mintlify",
        "Codebase with JSDoc or TypeScript types"
      ],
      "examples": [
        {
          "title": "API Reference Page from TypeScript",
          "language": "mdx",
          "code": "---\ntitle: 'Get User'\ndescription: 'Retrieve a user by their unique identifier'\napi: 'GET /api/users/{userId}'\n---\n\n# Get User\n\nRetrieves a user by their unique identifier.\n\n## Path Parameters\n\n<ParamField path=\"userId\" type=\"string\" required>\n  The user's unique identifier\n</ParamField>\n\n## Response\n\n<ResponseField name=\"id\" type=\"string\" required>\n  Unique user identifier\n</ResponseField>\n\n<ResponseField name=\"email\" type=\"string\" required>\n  User's email address\n</ResponseField>\n\n<ResponseField name=\"name\" type=\"string\" required>\n  Display name\n</ResponseField>\n\n<ResponseField name=\"role\" type=\"'admin' | 'user' | 'guest'\" required>\n  User role determining access permissions\n</ResponseField>\n\n## Code Examples\n\n<CodeGroup>\n\n```typescript TypeScript SDK\nimport { getUser } from '@yourapp/sdk';\n\nconst user = await getUser('user_123');\nconsole.log(user.name);\n```\n\n```javascript JavaScript\nconst response = await fetch('/api/users/user_123');\nconst user = await response.json();\n```\n\n```python Python\nimport requests\n\nresponse = requests.get('https://api.yourapp.com/users/user_123')\nuser = response.json()\n```\n\n```bash cURL\ncurl https://api.yourapp.com/users/user_123 \\\\\n  -H \"Authorization: Bearer YOUR_TOKEN\"\n```\n\n</CodeGroup>\n\n## Response Example\n\n<ResponseExample>\n\n```json 200 Success\n{\n  \"id\": \"user_123\",\n  \"email\": \"user@example.com\",\n  \"name\": \"John Doe\",\n  \"role\": \"user\",\n  \"createdAt\": \"2025-10-16T12:00:00Z\"\n}\n```\n\n```json 404 Not Found\n{\n  \"error\": \"User not found\",\n  \"code\": \"USER_NOT_FOUND\"\n}\n```\n\n</ResponseExample>\n\n## Error Codes\n\n<ResponseField name=\"404\" type=\"NotFoundError\">\n  User with the specified ID doesn't exist\n</ResponseField>\n\n<ResponseField name=\"403\" type=\"AuthorizationError\">\n  Caller lacks permission to access this user\n</ResponseField>"
        },
        {
          "title": "Quickstart Guide with Steps",
          "language": "mdx",
          "code": "---\ntitle: 'Quickstart'\ndescription: 'Get started in 5 minutes'\nicon: 'rocket'\n---\n\n# Getting Started\n\nThis guide will help you integrate our SDK in under 5 minutes.\n\n<Steps>\n\n<Step title=\"Install the SDK\">\n  Install using your preferred package manager:\n\n  <CodeGroup>\n\n  ```bash npm\n  npm install @yourapp/sdk\n  ```\n\n  ```bash pnpm\n  pnpm add @yourapp/sdk\n  ```\n\n  ```bash yarn\n  yarn add @yourapp/sdk\n  ```\n\n  </CodeGroup>\n</Step>\n\n<Step title=\"Configure Environment\">\n  Add your API credentials to `.env`:\n\n  ```bash .env\n  API_KEY=your-api-key\n  API_URL=https://api.yourapp.com\n  ```\n\n  <Warning>\n    Never commit your `.env` file to version control.\n  </Warning>\n</Step>\n\n<Step title=\"Initialize the Client\">\n  Create a client instance:\n\n  ```typescript lib/client.ts\n  import { createClient } from '@yourapp/sdk';\n\n  export const client = createClient({\n    apiKey: process.env.API_KEY!,\n    baseUrl: process.env.API_URL!,\n  });\n  ```\n</Step>\n\n<Step title=\"Make Your First Request\">\n  Use the client in your application:\n\n  ```typescript app/page.tsx\n  import { client } from '@/lib/client';\n\n  export default async function Page() {\n    const users = await client.users.list();\n    \n    return (\n      <div>\n        {users.map(user => (\n          <div key={user.id}>{user.name}</div>\n        ))}\n      </div>\n    );\n  }\n  ```\n\n  <Check>\n    You're all set! Check out the API reference for more.\n  </Check>\n</Step>\n\n</Steps>\n\n## Next Steps\n\n<CardGroup cols={2}>\n\n<Card title=\"API Reference\" icon=\"code\" href=\"/api-reference\">\n  Explore the complete API documentation\n</Card>\n\n<Card title=\"Authentication\" icon=\"shield\" href=\"/guides/authentication\">\n  Learn about authentication and security\n</Card>\n\n</CardGroup>"
        },
        {
          "title": "mint.json Configuration",
          "language": "json",
          "code": "{\n  \"$schema\": \"https://mintlify.com/schema.json\",\n  \"name\": \"Your API Documentation\",\n  \"logo\": {\n    \"dark\": \"/logo/dark.svg\",\n    \"light\": \"/logo/light.svg\"\n  },\n  \"favicon\": \"/favicon.svg\",\n  \"colors\": {\n    \"primary\": \"#0D9373\",\n    \"light\": \"#07C983\",\n    \"dark\": \"#0D9373\"\n  },\n  \"topbarLinks\": [\n    {\n      \"name\": \"Support\",\n      \"url\": \"mailto:support@example.com\"\n    }\n  ],\n  \"topbarCtaButton\": {\n    \"name\": \"Dashboard\",\n    \"url\": \"https://dashboard.example.com\"\n  },\n  \"tabs\": [\n    {\n      \"name\": \"API Reference\",\n      \"url\": \"api-reference\"\n    },\n    {\n      \"name\": \"Guides\",\n      \"url\": \"guides\"\n    }\n  ],\n  \"navigation\": [\n    {\n      \"group\": \"Get Started\",\n      \"pages\": [\n        \"introduction\",\n        \"quickstart\",\n        \"authentication\"\n      ]\n    },\n    {\n      \"group\": \"API Reference\",\n      \"pages\": [\n        \"api-reference/users\",\n        \"api-reference/organizations\",\n        \"api-reference/webhooks\"\n      ]\n    },\n    {\n      \"group\": \"Guides\",\n      \"pages\": [\n        \"guides/error-handling\",\n        \"guides/rate-limiting\",\n        \"guides/pagination\"\n      ]\n    }\n  ],\n  \"footerSocials\": {\n    \"twitter\": \"https://twitter.com/example\",\n    \"github\": \"https://github.com/example\"\n  },\n  \"analytics\": {\n    \"posthog\": {\n      \"apiKey\": \"phc_xxx\"\n    }\n  },\n  \"api\": {\n    \"baseUrl\": \"https://api.example.com\",\n    \"auth\": {\n      \"method\": \"bearer\"\n    }\n  }\n}"
        }
      ],
      "installation": {
        "claudeDesktop": {
          "steps": [
            "Install Mintlify CLI: npm install -g mintlify",
            "Initialize Mintlify: mintlify init",
            "Ask Claude to generate documentation from your code",
            "Review generated MDX files and mint.json",
            "Run mintlify dev to preview locally"
          ]
        },
        "claudeCode": {
          "steps": [
            "npm install -g mintlify",
            "mintlify init",
            "Ask Claude for documentation generation",
            "mintlify dev",
            "Deploy with mintlify deploy or integrate with Vercel"
          ]
        }
      },
      "troubleshooting": [
        {
          "issue": "Mintlify build fails with frontmatter errors",
          "solution": "Ensure all MDX files have valid YAML frontmatter with 'title' and 'description' fields. No tabs in YAML."
        },
        {
          "issue": "Navigation doesn't show all pages",
          "solution": "Update mint.json navigation array to explicitly list all MDX file paths without .mdx extension."
        },
        {
          "issue": "Code syntax highlighting not working",
          "solution": "Use full language names in code fences: typescript, javascript, python, bash (not ts, js, py, sh)."
        }
      ],
      "documentationUrl": "https://mintlify.com/docs",
      "source": "community",
      "type": "skill",
      "url": "https://claudepro.directory/skills/mintlify-documentation-automation"
    },
    {
      "slug": "playwright-e2e-testing",
      "title": "Playwright E2E Testing Automation",
      "seoTitle": "Playwright E2E Testing Automation Skill",
      "description": "Automate end-to-end testing with Playwright, AI-powered test generation, and comprehensive browser coverage for modern web applications.",
      "category": "skills",
      "author": "JSONbored",
      "dateAdded": "2025-10-16",
      "tags": [
        "testing",
        "playwright",
        "e2e",
        "automation",
        "ai"
      ],
      "content": "# Playwright E2E Testing Automation Skill\n\n## What This Skill Enables\n\nClaude can write, execute, and maintain end-to-end tests using Playwright, the modern browser automation framework that has overtaken Cypress in npm downloads as of 2025. This skill enables cross-browser testing (Chrome, Firefox, Safari/WebKit), AI-powered test generation with GitHub Copilot integration, and official MCP (Model Context Protocol) support for structured DOM interactions.\n\n## Prerequisites\n\n**Required:**\n- Claude Pro subscription or Claude Code CLI\n- Node.js 18+ installed\n- Basic understanding of your application's user flows\n\n**What Claude handles automatically:**\n- Installing Playwright and browser binaries\n- Generating test files with proper TypeScript types\n- Setting up test configurations and reporters\n- Writing selectors using accessibility snapshots\n- Debugging test failures with traces and screenshots\n- Optimizing tests for parallel execution\n\n## How to Use This Skill\n\n### Basic Test Generation\n\n**Prompt:** \"Create a Playwright test that logs into my application at localhost:3000, navigates to /dashboard, and verifies the welcome message appears.\"\n\nClaude will:\n1. Install Playwright if not present (`npm init playwright@latest`)\n2. Generate a test file with proper page object patterns\n3. Use accessibility-first selectors (role, label, text)\n4. Include assertions with auto-retry logic\n5. Add screenshot capture on failure\n\n### AI-Powered Test Creation from User Stories\n\n**Prompt:** \"I have a checkout flow: user adds product to cart, enters shipping info, selects payment method, and completes order. Write comprehensive Playwright tests covering happy path and error cases.\"\n\nClaude will:\n1. Break down the user story into discrete test scenarios\n2. Generate test files organized by feature\n3. Include data-driven tests with fixtures\n4. Add network mocking for payment gateway\n5. Implement custom assertions for order confirmation\n6. Set up test retry logic for flaky network calls\n\n### Cross-Browser Testing Suite\n\n**Prompt:** \"Set up Playwright to test my application across Chrome, Firefox, and Safari with parallel execution. Include mobile viewport testing for iOS and Android.\"\n\nClaude will:\n1. Configure `playwright.config.ts` with multiple projects\n2. Define desktop and mobile browser contexts\n3. Set up parallel worker configuration\n4. Configure test sharding for CI/CD\n5. Add HTML reporter with trace viewer\n6. Include screenshot comparison for visual regression\n\n### API Testing Integration\n\n**Prompt:** \"Write Playwright tests that verify my REST API endpoints before running UI tests. Mock the API responses for offline testing.\"\n\nClaude will:\n1. Use Playwright's `request` context for API calls\n2. Create API test fixtures for reusable setup\n3. Implement request/response interception\n4. Generate mock data with realistic values\n5. Set up contract testing with schema validation\n6. Add performance timing assertions\n\n## Tips for Best Results\n\n1. **Use Accessibility Selectors**: Playwright's MCP support leverages accessibility snapshots. Ask Claude to use `getByRole()`, `getByLabel()`, and `getByText()` instead of CSS selectors for more resilient tests.\n\n2. **Parallel Execution**: Playwright's native parallelism is a key advantage. Request test organization that maximizes parallel worker usage with proper test isolation.\n\n3. **Auto-Wait Smart Defaults**: Playwright automatically waits for elements to be actionable. Avoid explicit waits unless dealing with specific timing requirements.\n\n4. **Trace on Failure**: Enable trace recording for CI environments to debug failures without reproducing locally: `--trace on-first-retry`.\n\n5. **Codegen for Complex Flows**: For intricate user interactions, ask Claude to generate tests using `npx playwright codegen` output as a starting point.\n\n6. **Test Sharding**: For large test suites in CI, request sharding configuration: `--shard=1/4` to split tests across multiple jobs.\n\n## Common Workflows\n\n### Complete E2E Test Suite Setup\n```\n\"Set up a production-ready Playwright test suite for my Next.js app with:\n1. Authentication flow tests with session storage\n2. Visual regression testing with screenshot comparison\n3. API mocking for external services\n4. CI/CD integration with GitHub Actions\n5. HTML report with trace viewer\n6. Parallel execution across 4 workers\"\n```\n\n### AI-Assisted Test Maintenance\n```\n\"My application's login form changed from using email to username.\nUpdate all Playwright tests that interact with the login form,\nusing accessibility selectors instead of data-testid attributes.\"\n```\n\n### Performance Testing\n```\n\"Write Playwright tests that measure:\n1. First Contentful Paint (FCP)\n2. Largest Contentful Paint (LCP)\n3. Time to Interactive (TTI)\n4. Total Blocking Time (TBT)\nFail tests if any metric exceeds Web Vitals thresholds.\"\n```\n\n### Mobile-First Testing\n```\n\"Create Playwright tests for mobile web experience:\n1. Test on iPhone 13 and Pixel 5 viewports\n2. Verify touch interactions (swipe, pinch-to-zoom)\n3. Test offline mode with service worker\n4. Validate responsive image loading\n5. Check mobile-specific navigation menu\"\n```\n\n## Troubleshooting\n\n**Issue:** Tests are flaky and fail intermittently\n**Solution:** Ask Claude to add explicit `waitForLoadState('networkidle')` calls, increase timeout for specific actions with `{ timeout: 10000 }`, or implement custom wait conditions with `page.waitForFunction()`.\n\n**Issue:** Selectors break when UI changes\n**Solution:** Request migration to accessibility selectors (`getByRole`, `getByLabel`) which are more resilient to DOM structure changes. Playwright's MCP integration makes this the preferred approach.\n\n**Issue:** Tests run too slowly in CI\n**Solution:** Ask Claude to implement test sharding across multiple GitHub Actions jobs, optimize test setup with global authentication fixtures, and enable trace recording only on failure.\n\n**Issue:** Cannot test third-party authentication (OAuth, SSO)\n**Solution:** Request implementation of authentication state storage with `storageState` option, bypassing the login flow for most tests while keeping one dedicated authentication test.\n\n**Issue:** Screenshot comparison fails due to font rendering differences\n**Solution:** Ask Claude to configure Playwright's `maxDiffPixels` or `threshold` options, or use textual assertions instead of visual regression for text-heavy areas.\n\n## Learn More\n\n- [Playwright Official Documentation](https://playwright.dev/)\n- [Playwright MCP Integration Guide](https://github.com/microsoft/playwright/blob/main/docs/src/mcp.md)\n- [Playwright vs Cypress 2025 Comparison](https://playwright.dev/docs/why-playwright)\n- [AI-Powered Testing with Playwright](https://playwright.dev/docs/codegen)\n- [Playwright Test Best Practices](https://playwright.dev/docs/best-practices)\n",
      "features": [
        "Cross-browser testing: Chrome, Firefox, Safari (WebKit)",
        "AI-powered test generation with GitHub Copilot",
        "MCP support for accessibility-driven interactions",
        "Native parallel execution and test sharding"
      ],
      "useCases": [
        "End-to-end testing for web applications",
        "Visual regression testing with screenshots",
        "API testing and contract validation"
      ],
      "requirements": [
        "Node.js 18+",
        "Playwright 1.40+",
        "@playwright/test"
      ],
      "examples": [
        {
          "title": "Basic E2E Test with Authentication",
          "language": "typescript",
          "code": "import { test, expect } from '@playwright/test';\n\ntest.describe('Dashboard Tests', () => {\n  test.beforeEach(async ({ page }) => {\n    // Login before each test\n    await page.goto('http://localhost:3000/login');\n    await page.getByLabel('Email').fill('user@example.com');\n    await page.getByLabel('Password').fill('password123');\n    await page.getByRole('button', { name: 'Sign In' }).click();\n    await page.waitForURL('**/dashboard');\n  });\n\n  test('displays welcome message', async ({ page }) => {\n    const heading = page.getByRole('heading', { name: /welcome/i });\n    await expect(heading).toBeVisible();\n  });\n\n  test('loads user profile data', async ({ page }) => {\n    await page.getByRole('link', { name: 'Profile' }).click();\n    await expect(page.getByText('user@example.com')).toBeVisible();\n  });\n});"
        },
        {
          "title": "API Testing with Request Context",
          "language": "typescript",
          "code": "import { test, expect } from '@playwright/test';\n\ntest.describe('API Tests', () => {\n  test('GET /api/users returns valid data', async ({ request }) => {\n    const response = await request.get('http://localhost:3000/api/users');\n    expect(response.ok()).toBeTruthy();\n    \n    const users = await response.json();\n    expect(users).toHaveLength(10);\n    expect(users[0]).toHaveProperty('email');\n  });\n\n  test('POST /api/users creates new user', async ({ request }) => {\n    const response = await request.post('http://localhost:3000/api/users', {\n      data: {\n        name: 'Test User',\n        email: 'test@example.com'\n      }\n    });\n    expect(response.status()).toBe(201);\n    \n    const user = await response.json();\n    expect(user.id).toBeDefined();\n  });\n});"
        },
        {
          "title": "Parallel Test Configuration",
          "language": "typescript",
          "code": "// playwright.config.ts\nimport { defineConfig, devices } from '@playwright/test';\n\nexport default defineConfig({\n  testDir: './tests',\n  fullyParallel: true,\n  forbidOnly: !!process.env.CI,\n  retries: process.env.CI ? 2 : 0,\n  workers: process.env.CI ? 4 : undefined,\n  reporter: [['html'], ['json', { outputFile: 'test-results.json' }]],\n  use: {\n    baseURL: 'http://localhost:3000',\n    trace: 'on-first-retry',\n    screenshot: 'only-on-failure',\n  },\n  projects: [\n    {\n      name: 'chromium',\n      use: { ...devices['Desktop Chrome'] },\n    },\n    {\n      name: 'firefox',\n      use: { ...devices['Desktop Firefox'] },\n    },\n    {\n      name: 'webkit',\n      use: { ...devices['Desktop Safari'] },\n    },\n    {\n      name: 'Mobile Chrome',\n      use: { ...devices['Pixel 5'] },\n    },\n    {\n      name: 'Mobile Safari',\n      use: { ...devices['iPhone 13'] },\n    },\n  ],\n  webServer: {\n    command: 'npm run dev',\n    url: 'http://localhost:3000',\n    reuseExistingServer: !process.env.CI,\n  },\n});"
        }
      ],
      "installation": {
        "claudeDesktop": {
          "steps": [
            "Ask Claude: 'Set up Playwright for my project'",
            "Claude will run: npm init playwright@latest",
            "Select TypeScript, test directory, and GitHub Actions options",
            "Claude installs browsers automatically"
          ]
        },
        "claudeCode": {
          "steps": [
            "npx playwright install --with-deps",
            "Verify installation: npx playwright --version",
            "Generate example test: npx playwright codegen localhost:3000"
          ]
        }
      },
      "troubleshooting": [
        {
          "issue": "Browser binaries not found",
          "solution": "Run 'npx playwright install' to download Chromium, Firefox, and WebKit binaries."
        },
        {
          "issue": "Tests timeout in CI",
          "solution": "Increase timeout in config: use: { actionTimeout: 10000, navigationTimeout: 30000 }"
        },
        {
          "issue": "Selectors not found",
          "solution": "Use accessibility selectors (getByRole, getByLabel) instead of CSS selectors. Enable MCP integration for better selector generation."
        }
      ],
      "documentationUrl": "https://playwright.dev/",
      "source": "community",
      "type": "skill",
      "url": "https://claudepro.directory/skills/playwright-e2e-testing"
    },
    {
      "slug": "postgresql-query-optimization",
      "title": "PostgreSQL Query Optimization",
      "seoTitle": "PostgreSQL Query Optimization Skill",
      "description": "Analyze and optimize PostgreSQL queries for OLTP and OLAP workloads with AI-assisted performance tuning, indexing strategies, and execution plan analysis.",
      "category": "skills",
      "author": "JSONbored",
      "dateAdded": "2025-10-16",
      "tags": [
        "postgresql",
        "database",
        "optimization",
        "performance",
        "sql"
      ],
      "content": "# PostgreSQL Query Optimization Skill\n\n## What This Skill Enables\n\nClaude can analyze PostgreSQL query performance, interpret EXPLAIN plans, design optimal indexes, and tune database configurations for specific workloads (OLTP, OLAP, or hybrid). With expertise in PostgreSQL 16+ features including parallel query execution, JIT compilation, and advanced partitioning strategies, Claude helps achieve sub-millisecond query times for high-traffic applications.\n\n## Prerequisites\n\n**Required:**\n- Claude Pro subscription or Claude Code CLI\n- PostgreSQL 14+ installed (16+ recommended)\n- Access to database with slow queries or performance issues\n- Basic SQL knowledge\n\n**What Claude handles automatically:**\n- Analyzing EXPLAIN ANALYZE output\n- Identifying missing or inefficient indexes\n- Suggesting query rewrites for better performance\n- Recommending configuration parameter tuning\n- Detecting N+1 query problems\n- Proposing table partitioning strategies\n- Analyzing vacuum and autovacuum settings\n- Identifying connection pooling needs\n\n## How to Use This Skill\n\n### Analyze Slow Query\n\n**Prompt:** \"My PostgreSQL query is taking 5 seconds. Here's the query: [paste query]. Analyze the execution plan and suggest optimizations.\"\n\nClaude will:\n1. Run EXPLAIN (ANALYZE, BUFFERS, VERBOSE)\n2. Identify bottlenecks (seq scans, nested loops)\n3. Suggest missing indexes with CREATE INDEX statements\n4. Rewrite query if needed (JOIN order, subquery optimization)\n5. Estimate performance improvement\n6. Provide before/after comparison\n\n### Index Strategy Design\n\n**Prompt:** \"Design an optimal indexing strategy for a high-traffic e-commerce database with 10M products. Include queries: product search by name, filter by category and price range, sort by popularity.\"\n\nClaude will:\n1. Analyze query patterns and access patterns\n2. Create B-tree indexes for equality/range queries\n3. Add GIN indexes for full-text search\n4. Design composite indexes for multi-column filters\n5. Include partial indexes for filtered queries\n6. Add BRIN indexes for time-series data\n7. Calculate index maintenance overhead\n\n### Database Configuration Tuning\n\n**Prompt:** \"Tune PostgreSQL configuration for a 32GB RAM server running high-write OLTP workload with 200 concurrent connections.\"\n\nClaude will:\n1. Set shared_buffers (25% of RAM = 8GB)\n2. Configure work_mem per connection\n3. Adjust max_connections and connection pooling\n4. Tune WAL settings for write performance\n5. Configure autovacuum for high-write scenarios\n6. Set effective_cache_size\n7. Enable parallel query workers\n\n### Query Rewriting for Performance\n\n**Prompt:** \"Rewrite this slow query to eliminate the N+1 problem: [paste ORM-generated query with multiple subqueries].\"\n\nClaude will:\n1. Identify N+1 or N+M pattern\n2. Convert subqueries to JOINs\n3. Use CTEs for readability\n4. Apply window functions for ranking\n5. Implement LATERAL joins where appropriate\n6. Add proper indexes for new query\n7. Validate result correctness\n\n## Tips for Best Results\n\n1. **Always Use EXPLAIN ANALYZE**: Share full EXPLAIN (ANALYZE, BUFFERS) output with Claude. The BUFFERS option reveals I/O patterns crucial for optimization.\n\n2. **Provide Table Schemas**: Include CREATE TABLE statements and existing indexes. Claude needs column types and constraints for accurate recommendations.\n\n3. **Share Query Frequency**: Mention if a query runs once per day or 10,000 times per second. Optimization strategies differ dramatically.\n\n4. **Workload Type Matters**: OLTP (many small transactions) and OLAP (complex analytics) require opposite tuning. Specify your workload.\n\n5. **Include Real Data Volume**: \"1000 rows\" vs \"100M rows\" changes everything. Share actual table sizes with pg_size_pretty.\n\n6. **Monitor After Changes**: Ask Claude to generate monitoring queries to verify improvements don't cause regressions elsewhere.\n\n## Common Workflows\n\n### Complete Performance Audit\n```\n\"Perform a comprehensive PostgreSQL performance audit:\n1. Identify top 10 slowest queries from pg_stat_statements\n2. Analyze EXPLAIN plans for each\n3. Detect missing indexes with pg_stat_user_tables\n4. Find bloated tables needing VACUUM FULL\n5. Review configuration parameters\n6. Check for long-running transactions blocking others\n7. Provide prioritized optimization action plan\"\n```\n\n### Time-Series Optimization\n```\n\"Optimize PostgreSQL for time-series data:\n1. 100M rows of sensor data per month\n2. Queries filter by device_id and time range\n3. Need 90-day retention with automated archival\n4. Implement declarative partitioning by month\n5. Add BRIN indexes on timestamp columns\n6. Configure autovacuum for partition management\n7. Create aggregate materialized views\"\n```\n\n### Full-Text Search Tuning\n```\n\"Build high-performance full-text search:\n1. Search across title, description, tags fields\n2. Support phrase queries and ranking\n3. Handle 50M documents\n4. Sub-100ms query response time\n5. Use GIN indexes with tsvector\n6. Implement trigram similarity for typo tolerance\n7. Add weighted search across columns\"\n```\n\n### Replication Lag Analysis\n```\n\"Debug PostgreSQL replication lag:\n1. Replica is 30 seconds behind primary\n2. Analyze pg_stat_replication metrics\n3. Check for long-running queries on replica\n4. Identify write-heavy tables causing lag\n5. Tune max_wal_senders and wal_keep_size\n6. Recommend synchronous vs asynchronous replication\n7. Implement connection pooling strategy\"\n```\n\n## Troubleshooting\n\n**Issue:** Query still slow after adding index\n**Solution:** Index may not be used. Check EXPLAIN plan shows Index Scan (not Seq Scan). Run ANALYZE to update statistics. Consider index-only scans with INCLUDE columns or covering indexes.\n\n**Issue:** Database running out of connections\n**Solution:** Implement connection pooling with PgBouncer or pgpool-II. Reduce max_connections and increase per-connection work_mem. Fix application connection leaks.\n\n**Issue:** Autovacuum not keeping up\n**Solution:** Lower autovacuum_vacuum_scale_factor and autovacuum_vacuum_threshold for high-write tables. Increase autovacuum_max_workers. Consider manual VACUUM during maintenance windows.\n\n**Issue:** Query fast in development, slow in production\n**Solution:** Production has different data distribution. Run ANALYZE on production. Check if production has proper indexes. Compare EXPLAIN plans between environments.\n\n**Issue:** Disk I/O bottleneck\n**Solution:** Increase shared_buffers for caching. Use NVMe SSDs. Consider table partitioning to reduce I/O per query. Implement read replicas for read-heavy workloads.\n\n**Issue:** Connection pool exhausted\n**Solution:** Tune pool size based on `connections = ((core_count * 2) + effective_spindle_count)`. Implement queue_timeout. Add monitoring for pool saturation.\n\n## Learn More\n\n- [PostgreSQL Performance Tuning Guide](https://www.postgresql.org/docs/current/performance-tips.html)\n- [Use The Index, Luke! - SQL Indexing Guide](https://use-the-index-luke.com/)\n- [Depesz EXPLAIN Visualizer](https://explain.depesz.com/)\n- [PGTune Configuration Calculator](https://pgtune.leopard.in.ua/)\n- [pgAdmin Query Tool](https://www.pgadmin.org/)\n- [pg_stat_statements Extension](https://www.postgresql.org/docs/current/pgstatstatements.html)\n",
      "features": [
        "EXPLAIN plan analysis and visualization",
        "Automatic index recommendation",
        "Workload-specific tuning (OLTP/OLAP)",
        "Query rewriting for performance"
      ],
      "useCases": [
        "Optimize slow database queries",
        "Design indexing strategies",
        "Tune PostgreSQL configuration"
      ],
      "requirements": [
        "PostgreSQL 14+ (16+ recommended)",
        "pg_stat_statements extension",
        "EXPLAIN access permissions",
        "psql or database client"
      ],
      "examples": [
        {
          "title": "Analyze Query Performance",
          "language": "sql",
          "code": "-- Run with EXPLAIN ANALYZE to get actual execution times\nEXPLAIN (ANALYZE, BUFFERS, VERBOSE)\nSELECT p.name, c.name as category, p.price\nFROM products p\nJOIN categories c ON p.category_id = c.id\nWHERE p.price BETWEEN 100 AND 500\n  AND c.name = 'Electronics'\nORDER BY p.created_at DESC\nLIMIT 20;\n\n-- Check if indexes are being used\nSELECT schemaname, tablename, indexname, idx_scan, idx_tup_read, idx_tup_fetch\nFROM pg_stat_user_indexes\nWHERE schemaname = 'public'\nORDER BY idx_scan ASC;"
        },
        {
          "title": "Create Optimal Indexes",
          "language": "sql",
          "code": "-- Composite index for filtered queries\nCREATE INDEX idx_products_category_price \nON products(category_id, price) \nWHERE price IS NOT NULL;\n\n-- Partial index for active records only\nCREATE INDEX idx_products_active \nON products(created_at) \nWHERE status = 'active';\n\n-- GIN index for full-text search\nCREATE INDEX idx_products_search \nON products USING GIN(to_tsvector('english', name || ' ' || description));\n\n-- BRIN index for time-series data\nCREATE INDEX idx_events_timestamp \nON events USING BRIN(created_at);\n\n-- Covering index (index-only scan)\nCREATE INDEX idx_products_category_include \nON products(category_id) \nINCLUDE (name, price);"
        },
        {
          "title": "Find Slow Queries",
          "language": "sql",
          "code": "-- Enable pg_stat_statements first\nCREATE EXTENSION IF NOT EXISTS pg_stat_statements;\n\n-- Find slowest queries by total time\nSELECT \n  query,\n  calls,\n  total_exec_time,\n  mean_exec_time,\n  max_exec_time,\n  stddev_exec_time\nFROM pg_stat_statements\nORDER BY total_exec_time DESC\nLIMIT 10;\n\n-- Find queries with high I/O\nSELECT \n  query,\n  calls,\n  shared_blks_hit,\n  shared_blks_read,\n  (shared_blks_hit::float / NULLIF(shared_blks_hit + shared_blks_read, 0)) * 100 AS cache_hit_ratio\nFROM pg_stat_statements\nWHERE shared_blks_read > 0\nORDER BY shared_blks_read DESC\nLIMIT 10;"
        },
        {
          "title": "Configuration Tuning",
          "language": "sql",
          "code": "-- OLTP Workload Configuration (postgresql.conf)\n-- For 32GB RAM, 8 cores, NVMe SSD\n\n-- Memory Settings\nshared_buffers = 8GB                    -- 25% of RAM\neffective_cache_size = 24GB             -- 75% of RAM\nwork_mem = 64MB                         -- Per operation\nmaintenance_work_mem = 2GB              -- For VACUUM, CREATE INDEX\n\n-- Write Performance\nwal_buffers = 16MB\ncheckpoint_completion_target = 0.9\nmax_wal_size = 4GB\nmin_wal_size = 1GB\n\n-- Query Planner\nrandom_page_cost = 1.1                  -- For SSD\neffective_io_concurrency = 200          -- For SSD\n\n-- Connections\nmax_connections = 200\n\n-- Parallelism\nmax_worker_processes = 8\nmax_parallel_workers_per_gather = 4\nmax_parallel_workers = 8\n\n-- Autovacuum (high-write workload)\nautovacuum_max_workers = 4\nautovacuum_naptime = 10s\nautovacuum_vacuum_scale_factor = 0.05\nautovacuum_analyze_scale_factor = 0.02"
        }
      ],
      "installation": {
        "claudeDesktop": {
          "steps": [
            "Install PostgreSQL: brew install postgresql@16",
            "Start server: brew services start postgresql@16",
            "Enable extensions: CREATE EXTENSION pg_stat_statements;",
            "Ask Claude: 'Analyze this slow query and optimize it'"
          ]
        },
        "claudeCode": {
          "steps": [
            "sudo apt install postgresql-16",
            "sudo systemctl start postgresql",
            "psql -U postgres",
            "CREATE EXTENSION pg_stat_statements;",
            "ALTER SYSTEM SET shared_preload_libraries = 'pg_stat_statements';"
          ]
        }
      },
      "troubleshooting": [
        {
          "issue": "Index not being used by query planner",
          "solution": "Run ANALYZE to update statistics, check WHERE clause matches index columns exactly, lower random_page_cost for SSDs, or use pg_hint_plan extension to force index usage."
        },
        {
          "issue": "Out of memory errors",
          "solution": "Reduce work_mem or max_connections. Implement connection pooling with PgBouncer. Check for memory-intensive queries using hash joins or sorts."
        },
        {
          "issue": "Slow VACUUM operations",
          "solution": "Increase maintenance_work_mem, run VACUUM during off-peak hours, consider VACUUM FREEZE for old tables, or use pg_repack for online table reorganization."
        }
      ],
      "documentationUrl": "https://www.postgresql.org/docs/current/performance-tips.html",
      "source": "community",
      "type": "skill",
      "url": "https://claudepro.directory/skills/postgresql-query-optimization"
    },
    {
      "slug": "rest-api-client-harness",
      "title": "REST API Client Harness",
      "seoTitle": "REST API Client Harness Skill",
      "description": "Explore and script against REST APIs with auth, pagination, retries, and error handling.",
      "category": "skills",
      "author": "JSONbored",
      "dateAdded": "2025-10-15",
      "tags": [
        "rest",
        "http",
        "api",
        "curl",
        "node"
      ],
      "content": "# REST API Client Harness Skill\n\n## What This Skill Enables\n\nClaude can interact with REST APIs: make requests, handle authentication (API keys, OAuth, JWT), paginate through results, handle rate limits with retries, and process responses. Build API integration scripts, test endpoints, and extract data from web services.\n\n## Prerequisites\n\n**Required:**\n- Claude Pro subscription\n- Code Interpreter feature enabled\n- API credentials (if required by the API)\n\n**What Claude handles:**\n- Installing HTTP libraries (requests, axios, fetch)\n- Making authenticated requests\n- Handling pagination\n- Retry logic with exponential backoff\n- Response parsing and data extraction\n- Error handling\n\n## How to Use This Skill\n\n### Simple API Request\n\n**Prompt:** \"Fetch data from this REST API endpoint: https://api.example.com/users\nUse API key: [your-key]\nShow me the first 10 results.\"\n\nClaude will:\n1. Make GET request with auth header\n2. Parse JSON response\n3. Extract and display data\n4. Handle errors gracefully\n\n### Paginated Data Extraction\n\n**Prompt:** \"Fetch all pages from this paginated API:\nURL: https://api.example.com/items\nPagination: cursor-based (next_cursor field)\nAPI Key: [your-key]\nSave all results to items.json\"\n\nClaude will:\n1. Make first request\n2. Loop through pages using cursor\n3. Collect all results\n4. Save to JSON file\n5. Report total count\n\n### POST Request with Data\n\n**Prompt:** \"Create a new user via POST request:\nURL: https://api.example.com/users\nPayload: {name: 'John Doe', email: 'john@example.com'}\nAuth: Bearer token [your-token]\nShow me the response.\"\n\nClaude will:\n1. Prepare POST request\n2. Set headers (auth, content-type)\n3. Send JSON payload\n4. Parse response\n5. Display result or error\n\n### Batch Operations\n\n**Prompt:** \"Upload all these records to the API:\n- Read from users.csv\n- For each row, POST to /users endpoint\n- Handle rate limits (max 10 requests/second)\n- Log successes and failures\n- Retry failures once\"\n\nClaude will:\n1. Read CSV data\n2. Iterate through rows\n3. Make POST requests with rate limiting\n4. Retry on failures\n5. Generate success/failure report\n\n## Common Workflows\n\n### API Testing & Exploration\n```\n\"Test this API endpoint:\n1. Make GET request to /api/products\n2. Check status code and headers\n3. Validate JSON response schema\n4. Show sample of first 3 records\n5. Report if any fields are null/missing\"\n```\n\n### Data Migration\n```\n\"Migrate data from API A to API B:\n1. Fetch all records from source API (paginated)\n2. Transform to target API format\n3. POST to destination API\n4. Handle rate limits (5 req/sec)\n5. Log migration progress and errors\nSave unmigrated records to errors.json\"\n```\n\n### Webhook Testing\n```\n\"Test this webhook:\n1. POST sample payload to webhook URL\n2. Check response status\n3. Validate response format\n4. Test with invalid payload\n5. Report all results\"\n```\n\n### API Monitoring\n```\n\"Monitor API health:\n1. Hit /health endpoint every minute for 10 minutes\n2. Record response time and status\n3. Alert if response time > 1 second\n4. Create uptime report\n5. Plot response times\"\n```\n\n## Authentication Methods\n\n### API Key Authentication\n- Header: `X-API-Key: your-key`\n- Query parameter: `?api_key=your-key`\n- Custom header format\n\n### Bearer Token (JWT)\n- Header: `Authorization: Bearer your-token`\n- Token refresh handling\n- Expiration detection\n\n### Basic Authentication\n- Header: `Authorization: Basic base64(user:pass)`\n- Credentials encoding\n\n### OAuth 2.0\n- Client credentials flow\n- Authorization code flow\n- Token refresh logic\n\n## Advanced Features\n\n### Rate Limiting & Retries\n- Respect rate limit headers\n- Exponential backoff\n- Jitter for retry timing\n- Max retry attempts\n\n### Response Handling\n- JSON parsing\n- XML/HTML parsing\n- Binary data (images, files)\n- Streaming responses\n\n### Error Handling\n- HTTP status code detection\n- Custom error messages\n- Validation errors\n- Network timeouts\n\n### Data Transformation\n- JSON to CSV conversion\n- Field mapping and renaming\n- Data type coercion\n- Filtering and aggregation\n\n## Tips for Best Results\n\n1. **Provide API Docs**: Share API documentation link or describe endpoints\n2. **Authentication**: Be clear about auth method and provide credentials securely\n3. **Rate Limits**: Mention any known rate limits (\"max 100 requests/minute\")\n4. **Pagination**: Describe pagination style (cursor, offset, page-based)\n5. **Error Handling**: Specify how to handle failures (\"retry 3 times then skip\")\n6. **Data Volume**: Estimate how many requests (\"expect 1000 records across 10 pages\")\n7. **Response Format**: Mention expected format (JSON, XML, etc.)\n\n## Common Patterns\n\n### Cursor-Based Pagination\n```python\nurl = \"https://api.example.com/items\"\nall_items = []\ncursor = None\nwhile True:\n    params = {\"cursor\": cursor} if cursor else {}\n    response = requests.get(url, params=params)\n    data = response.json()\n    all_items.extend(data[\"items\"])\n    cursor = data.get(\"next_cursor\")\n    if not cursor:\n        break\n```\n\n### Retry with Exponential Backoff\n```python\nimport time\nmax_retries = 3\nfor attempt in range(max_retries):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        break\n    except requests.exceptions.RequestException:\n        if attempt < max_retries - 1:\n            wait = 2 ** attempt  # 1s, 2s, 4s\n            time.sleep(wait)\n        else:\n            raise\n```\n\n## Troubleshooting\n\n**Issue:** Authentication failing\n**Solution:** Double-check auth method and credentials. Show Claude the API docs for auth section.\n\n**Issue:** Rate limit errors (429)\n**Solution:** \"Add retry logic with exponential backoff\" or \"Reduce concurrent requests to 5/second\"\n\n**Issue:** Response parsing errors\n**Solution:** \"Show me raw response first\" then describe expected structure\n\n**Issue:** Pagination not working\n**Solution:** Clarify pagination method: \"Use offset pagination starting at 0, increment by 100\"\n\n**Issue:** Timeouts on large requests\n**Solution:** \"Increase timeout to 60 seconds\" or \"Fetch in smaller batches\"\n\n**Issue:** CORS errors (in browser context)\n**Solution:** Note: Code Interpreter runs server-side, no CORS issues\n\n## Learn More\n\n- [HTTP Methods](https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods) - GET, POST, PUT, DELETE, etc.\n- [HTTP Status Codes](https://httpstatuses.com/) - Understanding response codes\n- [REST API Best Practices](https://restfulapi.net/) - API design principles\n- [Postman Learning](https://learning.postman.com/) - API testing tutorials\n- [Python Requests](https://requests.readthedocs.io/) - Popular HTTP library\n",
      "features": [
        "Token management patterns",
        "Pagination utilities",
        "Retry with exponential backoff",
        "Typed responses (TS)"
      ],
      "useCases": [
        "ETL from third-party APIs",
        "Backfills and migrations",
        "Monitoring scripts"
      ],
      "requirements": [
        "Node.js 18+",
        "undici or axios"
      ],
      "examples": [
        {
          "title": "Fetch all pages with backoff (TS)",
          "language": "typescript",
          "code": "import { setTimeout as delay } from 'node:timers/promises';\nimport { fetch } from 'undici';\n\nasync function fetchAll(url, token) {\n  let next = url;\n  const items = [];\n  while (next) {\n    const res = await fetch(next, { headers: { Authorization: `Bearer ${token}` } });\n    if (!res.ok) {\n      if (res.status >= 500) { await delay(1000); continue; }\n      throw new Error(`HTTP ${res.status}`);\n    }\n    const data = await res.json();\n    items.push(...data.items);\n    next = data.next;\n  }\n  return items;\n}"
        }
      ],
      "installation": {
        "claudeDesktop": {
          "steps": [
            "Install Node.js 18+",
            "npm i undici"
          ]
        },
        "claudeCode": {
          "steps": [
            "Set env vars for tokens",
            "Use .netrc or keychain where possible"
          ]
        }
      },
      "troubleshooting": [
        {
          "issue": "Rate limits",
          "solution": "Respect Retry-After headers and implement exponential backoff with jitter."
        },
        {
          "issue": "OAuth token refresh failing with 'invalid_grant' error",
          "solution": "Check token expiry before requests. Store refresh token securely. Ensure clock sync between client/server (use NTP)."
        },
        {
          "issue": "Request body not being sent or arriving as empty object",
          "solution": "Set Content-Type header to 'application/json'. Use JSON.stringify() for body. Check if API expects form-urlencoded instead."
        },
        {
          "issue": "SSL certificate verification errors (CERT_HAS_EXPIRED, UNABLE_TO_VERIFY)",
          "solution": "Update Node.js and CA certificates. For dev/testing only: disable with NODE_TLS_REJECT_UNAUTHORIZED=0 (never in production)."
        },
        {
          "issue": "Pagination cursor getting stuck in infinite loop or returning duplicates",
          "solution": "Check if cursor equals previous value before continuing. Implement max iteration limit. Verify API cursor is URL-encoded properly."
        }
      ],
      "documentationUrl": "https://developer.mozilla.org/en-US/docs/Web/HTTP/Overview",
      "source": "community",
      "type": "skill",
      "url": "https://claudepro.directory/skills/rest-api-client-harness"
    },
    {
      "slug": "supabase-realtime-database",
      "title": "Supabase Realtime Database Builder",
      "seoTitle": "Supabase Realtime Database Builder Skill",
      "description": "Build full-stack applications with Supabase Postgres, real-time subscriptions, Edge Functions, and pgvector AI integration for 4M+ developers.",
      "category": "skills",
      "author": "JSONbored",
      "dateAdded": "2025-10-16",
      "tags": [
        "supabase",
        "postgres",
        "realtime",
        "backend",
        "database"
      ],
      "content": "# Supabase Realtime Database Builder Skill\n\n## What This Skill Enables\n\nClaude can build complete backend systems using Supabase, the open-source Firebase alternative that raised $100M at $5B valuation in October 2025. With 4M+ developers and enterprise-scale Multigres features launching, Supabase provides PostgreSQL database, real-time subscriptions, authentication, storage, and Edge Functions - all with automatic APIs and pgvector for AI embeddings.\n\n## Prerequisites\n\n**Required:**\n- Claude Pro subscription or Claude Code CLI\n- Supabase account (free tier available)\n- Node.js 18+ for client libraries\n- Basic SQL and JavaScript knowledge\n\n**What Claude handles automatically:**\n- Setting up Supabase project and database schema\n- Creating Row Level Security (RLS) policies\n- Generating TypeScript types from database\n- Implementing real-time subscriptions\n- Configuring authentication with multiple providers\n- Building Edge Functions with Deno\n- Setting up Storage buckets with access control\n- Integrating pgvector for AI embeddings\n\n## How to Use This Skill\n\n### Initialize Supabase Project\n\n**Prompt:** \"Set up a Supabase project for a task management app with users, projects, tasks tables. Include RLS policies and TypeScript types.\"\n\nClaude will:\n1. Create database schema with foreign keys\n2. Set up RLS policies for multi-tenant data\n3. Generate migration files\n4. Create TypeScript types with supabase gen types\n5. Initialize Supabase client in application\n6. Add authentication flow\n7. Configure authorization rules\n\n### Real-Time Collaboration\n\n**Prompt:** \"Build real-time chat functionality where users see messages instantly when posted. Include typing indicators and online presence.\"\n\nClaude will:\n1. Create messages table with indexes\n2. Set up real-time subscription channel\n3. Implement message broadcasting\n4. Add presence tracking\n5. Show typing indicator\n6. Handle connection state\n7. Optimize with message batching\n\n### AI Integration with pgvector\n\n**Prompt:** \"Create a semantic search system using pgvector. Store document embeddings from OpenAI and enable similarity search with cosine distance.\"\n\nClaude will:\n1. Enable pgvector extension\n2. Create table with vector column\n3. Generate embeddings with OpenAI\n4. Store vectors in Supabase\n5. Implement similarity search RPC\n6. Add HNSW index for performance\n7. Create semantic search API\n\n### Edge Functions for Business Logic\n\n**Prompt:** \"Build Edge Functions that: send welcome emails on signup, process webhook from Stripe, and run nightly data aggregation job.\"\n\nClaude will:\n1. Create Deno Edge Functions\n2. Set up function triggers (database, HTTP, cron)\n3. Implement email sending with Resend\n4. Add Stripe webhook validation\n5. Create scheduled job\n6. Include error handling and logging\n7. Deploy with supabase functions deploy\n\n## Tips for Best Results\n\n1. **RLS is Critical**: Always implement Row Level Security policies. Request policies that match your access patterns (user owns data, team members can access, public read).\n\n2. **Type Generation**: Use `supabase gen types typescript` to generate TypeScript types. This ensures client code matches database schema.\n\n3. **Real-Time Channels**: Supabase real-time has different channel types (postgres_changes, broadcast, presence). Specify which you need based on use case.\n\n4. **Edge Functions with Deno**: Supabase uses Deno for Edge Functions. Request Deno-compatible code (no Node.js-specific APIs).\n\n5. **Storage Access Control**: Storage buckets can be public or private. Request appropriate RLS policies for file access.\n\n6. **Connection Pooling**: For serverless deployments, use Supabase connection pooling to avoid exceeding connection limits.\n\n## Common Workflows\n\n### Complete SaaS Backend\n```\n\"Build a SaaS backend with Supabase:\n1. Authentication with email, Google, GitHub OAuth\n2. Organizations and team member management\n3. Role-based access control (owner, admin, member)\n4. Real-time activity feed\n5. File uploads to Storage with access control\n6. Billing integration with Stripe webhooks\n7. Edge Functions for business logic\n8. pgvector for AI-powered search\"\n```\n\n### Social Media Platform\n```\n\"Create social media backend:\n1. User profiles with avatars in Storage\n2. Posts with likes, comments, shares\n3. Real-time notifications\n4. Follow/unfollow relationships\n5. Feed algorithm with RLS\n6. Direct messaging with presence\n7. Content moderation Edge Function\n8. Full-text search with PostgreSQL\"\n```\n\n### IoT Data Collection\n```\n\"Build IoT data collection system:\n1. Device registration and authentication\n2. Time-series data table with partitioning\n3. Real-time sensor data streaming\n4. Edge Functions for data aggregation\n5. Alert system for threshold violations\n6. Historical data analytics queries\n7. Dashboard real-time updates\n8. Export to CSV with Storage\"\n```\n\n### AI-Powered Knowledge Base\n```\n\"Create knowledge base with AI:\n1. Document storage with chunking\n2. Generate embeddings with OpenAI\n3. Store vectors in pgvector\n4. Semantic search with similarity\n5. Full-text search fallback\n6. Real-time collaborative editing\n7. Version history with temporal tables\n8. Edge Function for embedding generation\"\n```\n\n## Troubleshooting\n\n**Issue:** RLS policies blocking valid queries\n**Solution:** Check policies with `EXPLAIN` to see applied policies. Use service role key for admin operations. Test policies in SQL editor with `set role authenticated` and `set request.jwt.claim.sub = 'user-id'`.\n\n**Issue:** Real-time subscriptions not receiving updates\n**Solution:** Verify table has REPLICA IDENTITY configured. Check RLS policies allow SELECT on rows. Confirm real-time is enabled in Supabase dashboard. Use broadcast channels if PostgreSQL changes insufficient.\n\n**Issue:** Edge Functions timing out\n**Solution:** Edge Functions have 60s limit. Optimize database queries. Use connection pooling. Move long-running tasks to background jobs. Check function logs in dashboard.\n\n**Issue:** Type generation failing\n**Solution:** Ensure PostgreSQL schema is valid. Check for circular foreign keys. Update Supabase CLI to latest. Use `--local` flag if working with local instance.\n\n**Issue:** Storage upload fails\n**Solution:** Check bucket is created and RLS policies allow INSERT. Verify file size within limits. Check MIME type restrictions. Use service role for admin uploads.\n\n**Issue:** Connection pool exhausted\n**Solution:** Use Supabase pooler (port 6543 instead of 5432). Implement connection caching. Close connections properly. Consider upgrading plan for more connections.\n\n## Learn More\n\n- [Supabase Official Documentation](https://supabase.com/docs)\n- [Supabase JavaScript Client](https://supabase.com/docs/reference/javascript/introduction)\n- [Row Level Security Guide](https://supabase.com/docs/guides/auth/row-level-security)\n- [Real-Time Subscriptions](https://supabase.com/docs/guides/realtime)\n- [Edge Functions Guide](https://supabase.com/docs/guides/functions)\n- [pgvector Extension](https://supabase.com/docs/guides/ai/vector-columns)\n- [Database Migrations](https://supabase.com/docs/guides/cli/local-development)\n",
      "features": [
        "PostgreSQL with automatic REST and GraphQL APIs",
        "Real-time subscriptions with websockets",
        "Built-in authentication and authorization",
        "pgvector for AI embeddings and similarity search"
      ],
      "useCases": [
        "Full-stack web applications",
        "Real-time collaborative tools",
        "AI-powered semantic search"
      ],
      "requirements": [
        "Supabase account",
        "@supabase/supabase-js ^2.38.0",
        "Node.js 18+",
        "Supabase CLI for local development"
      ],
      "examples": [
        {
          "title": "Initialize Supabase Client",
          "language": "typescript",
          "code": "import { createClient } from '@supabase/supabase-js';\nimport { Database } from './types/supabase';\n\nconst supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL!;\nconst supabaseAnonKey = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!;\n\nexport const supabase = createClient<Database>(supabaseUrl, supabaseAnonKey);\n\n// With authentication\nexport const createAuthenticatedClient = (accessToken: string) => {\n  return createClient<Database>(supabaseUrl, supabaseAnonKey, {\n    global: {\n      headers: {\n        Authorization: `Bearer ${accessToken}`,\n      },\n    },\n  });\n};"
        },
        {
          "title": "Database Schema with RLS",
          "language": "sql",
          "code": "-- Create tables\nCREATE TABLE profiles (\n  id UUID PRIMARY KEY REFERENCES auth.users(id),\n  username TEXT UNIQUE NOT NULL,\n  avatar_url TEXT,\n  created_at TIMESTAMPTZ DEFAULT NOW()\n);\n\nCREATE TABLE projects (\n  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n  name TEXT NOT NULL,\n  owner_id UUID REFERENCES profiles(id) NOT NULL,\n  created_at TIMESTAMPTZ DEFAULT NOW()\n);\n\nCREATE TABLE tasks (\n  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n  project_id UUID REFERENCES projects(id) ON DELETE CASCADE,\n  title TEXT NOT NULL,\n  completed BOOLEAN DEFAULT FALSE,\n  assigned_to UUID REFERENCES profiles(id),\n  created_at TIMESTAMPTZ DEFAULT NOW()\n);\n\n-- Enable Row Level Security\nALTER TABLE profiles ENABLE ROW LEVEL SECURITY;\nALTER TABLE projects ENABLE ROW LEVEL SECURITY;\nALTER TABLE tasks ENABLE ROW LEVEL SECURITY;\n\n-- RLS Policies\nCREATE POLICY \"Users can view own profile\"\n  ON profiles FOR SELECT\n  USING (auth.uid() = id);\n\nCREATE POLICY \"Users can update own profile\"\n  ON profiles FOR UPDATE\n  USING (auth.uid() = id);\n\nCREATE POLICY \"Users can view own projects\"\n  ON projects FOR SELECT\n  USING (auth.uid() = owner_id);\n\nCREATE POLICY \"Users can create projects\"\n  ON projects FOR INSERT\n  WITH CHECK (auth.uid() = owner_id);\n\nCREATE POLICY \"Users can view tasks in own projects\"\n  ON tasks FOR SELECT\n  USING (\n    EXISTS (\n      SELECT 1 FROM projects\n      WHERE projects.id = tasks.project_id\n      AND projects.owner_id = auth.uid()\n    )\n  );"
        },
        {
          "title": "Real-Time Subscription",
          "language": "typescript",
          "code": "import { useEffect, useState } from 'react';\nimport { supabase } from './supabase';\nimport { Database } from './types/supabase';\n\ntype Task = Database['public']['Tables']['tasks']['Row'];\n\nexport function useTasks(projectId: string) {\n  const [tasks, setTasks] = useState<Task[]>([]);\n\n  useEffect(() => {\n    // Fetch initial data\n    const fetchTasks = async () => {\n      const { data } = await supabase\n        .from('tasks')\n        .select('*')\n        .eq('project_id', projectId)\n        .order('created_at', { ascending: false });\n      \n      if (data) setTasks(data);\n    };\n\n    fetchTasks();\n\n    // Subscribe to real-time changes\n    const channel = supabase\n      .channel(`tasks:${projectId}`)\n      .on(\n        'postgres_changes',\n        {\n          event: '*',\n          schema: 'public',\n          table: 'tasks',\n          filter: `project_id=eq.${projectId}`,\n        },\n        (payload) => {\n          if (payload.eventType === 'INSERT') {\n            setTasks((current) => [payload.new as Task, ...current]);\n          } else if (payload.eventType === 'UPDATE') {\n            setTasks((current) =>\n              current.map((task) =>\n                task.id === payload.new.id ? (payload.new as Task) : task\n              )\n            );\n          } else if (payload.eventType === 'DELETE') {\n            setTasks((current) =>\n              current.filter((task) => task.id !== payload.old.id)\n            );\n          }\n        }\n      )\n      .subscribe();\n\n    return () => {\n      channel.unsubscribe();\n    };\n  }, [projectId]);\n\n  return tasks;\n}"
        },
        {
          "title": "Edge Function Example",
          "language": "typescript",
          "code": "// supabase/functions/send-welcome-email/index.ts\nimport { serve } from 'https://deno.land/std@0.177.0/http/server.ts';\nimport { createClient } from 'https://esm.sh/@supabase/supabase-js@2';\n\nconst supabase = createClient(\n  Deno.env.get('SUPABASE_URL')!,\n  Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!\n);\n\nserve(async (req) => {\n  try {\n    const { record } = await req.json();\n    const userId = record.id;\n\n    // Get user email\n    const { data: profile } = await supabase\n      .from('profiles')\n      .select('email')\n      .eq('id', userId)\n      .single();\n\n    if (!profile) {\n      throw new Error('Profile not found');\n    }\n\n    // Send email (integrate with Resend, SendGrid, etc.)\n    const response = await fetch('https://api.resend.com/emails', {\n      method: 'POST',\n      headers: {\n        'Authorization': `Bearer ${Deno.env.get('RESEND_API_KEY')}`,\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        from: 'welcome@yourapp.com',\n        to: profile.email,\n        subject: 'Welcome to YourApp!',\n        html: '<h1>Welcome!</h1><p>Thanks for signing up.</p>',\n      }),\n    });\n\n    return new Response(JSON.stringify({ success: true }), {\n      headers: { 'Content-Type': 'application/json' },\n    });\n  } catch (error) {\n    return new Response(JSON.stringify({ error: error.message }), {\n      status: 500,\n      headers: { 'Content-Type': 'application/json' },\n    });\n  }\n});"
        }
      ],
      "installation": {
        "claudeDesktop": {
          "steps": [
            "Create account at supabase.com",
            "Install CLI: npm install -g supabase",
            "Initialize project: supabase init",
            "Ask Claude: 'Set up Supabase for [your app]'",
            "Claude generates schema, RLS policies, and client code"
          ]
        },
        "claudeCode": {
          "steps": [
            "npm install @supabase/supabase-js",
            "supabase login",
            "supabase init",
            "supabase start (for local development)",
            "supabase gen types typescript > types/supabase.ts"
          ]
        }
      },
      "troubleshooting": [
        {
          "issue": "RLS policies blocking queries",
          "solution": "Test policies with service role key first. Check policy using EXPLAIN in SQL editor. Verify auth.uid() returns expected user ID."
        },
        {
          "issue": "Real-time not working",
          "solution": "Enable real-time in table settings. Check RLS allows SELECT. Verify REPLICA IDENTITY is FULL. Use broadcast channel if needed."
        },
        {
          "issue": "Edge Function deployment fails",
          "solution": "Check Deno compatibility of imports. Verify environment variables set. Check function logs in dashboard for errors."
        }
      ],
      "documentationUrl": "https://supabase.com/docs",
      "source": "community",
      "type": "skill",
      "url": "https://claudepro.directory/skills/supabase-realtime-database"
    },
    {
      "slug": "trpc-type-safe-api",
      "title": "tRPC Type-Safe API Builder",
      "seoTitle": "tRPC Type-Safe API Builder Skill",
      "description": "Build end-to-end type-safe APIs with tRPC and TypeScript, eliminating code generation and runtime bloat for full-stack applications.",
      "category": "skills",
      "author": "JSONbored",
      "dateAdded": "2025-10-16",
      "tags": [
        "trpc",
        "typescript",
        "api",
        "type-safety",
        "t3-stack"
      ],
      "content": "# tRPC Type-Safe API Builder Skill\n\n## What This Skill Enables\n\nClaude can build fully type-safe APIs using tRPC (TypeScript Remote Procedure Call), part of the T3 Stack explosion in 2025. tRPC provides end-to-end type safety without code generation, schema stitching, or serialization layers - delivering a lighter, more intuitive developer experience than REST or GraphQL. With zero dependencies, tiny client-side footprint, and automatic type inference, tRPC makes full-stack TypeScript development actually enjoyable.\n\n## Prerequisites\n\n**Required:**\n- Claude Pro subscription or Claude Code CLI  \n- Node.js 18+ with TypeScript 5.0+\n- Understanding of React or Next.js\n- Basic API development knowledge\n\n**What Claude handles automatically:**\n- Setting up tRPC server with Express, Next.js, or standalone\n- Creating type-safe routers and procedures\n- Implementing middleware for authentication\n- Generating React Query hooks automatically\n- Adding input validation with Zod\n- Configuring error handling and transformers\n- Setting up WebSocket subscriptions\n- Integrating with Prisma or other ORMs\n\n## How to Use This Skill\n\n### Create Basic tRPC API\n\n**Prompt:** \"Set up a tRPC API with Next.js 15 that has procedures for creating, reading, updating, and deleting todos. Include Zod validation and automatic React Query hooks.\"\n\nClaude will:\n1. Initialize tRPC router with type-safe procedures\n2. Add Zod schemas for input validation\n3. Create CRUD operations with proper types\n4. Set up Next.js API route handlers\n5. Generate React hooks for client usage\n6. Include error handling and transformers\n7. Add TypeScript types exported automatically\n\n### Authentication Middleware\n\n**Prompt:** \"Add JWT authentication middleware to my tRPC API. Protected procedures should verify the token and attach user data to context.\"\n\nClaude will:\n1. Create authentication middleware\n2. Verify JWT tokens with jose library\n3. Extend tRPC context with user data\n4. Create protected procedure wrapper\n5. Add type-safe context typing\n6. Include refresh token logic\n7. Implement role-based authorization\n\n### Real-Time Subscriptions\n\n**Prompt:** \"Build a tRPC subscription that sends real-time notifications when new messages are posted. Use WebSocket transport.\"\n\nClaude will:\n1. Configure WebSocket link on client\n2. Create subscription procedure\n3. Implement event emitter pattern\n4. Add connection status handling\n5. Include automatic reconnection\n6. Type subscription payloads properly\n7. Add subscription filters\n\n### Full-Stack T3 App\n\n**Prompt:** \"Create a complete T3 Stack application with tRPC, Prisma, NextAuth, and Tailwind. Include user authentication, database models, and type-safe API routes.\"\n\nClaude will:\n1. Initialize T3 app with create-t3-app\n2. Set up Prisma schema and migrations\n3. Configure NextAuth providers\n4. Create tRPC routers for all features\n5. Build authenticated UI components\n6. Add optimistic updates with React Query\n7. Include comprehensive error handling\n\n## Tips for Best Results\n\n1. **Use Zod for Validation**: tRPC integrates perfectly with Zod. Always request Zod schemas for input validation to get runtime safety matching TypeScript types.\n\n2. **Leverage Context**: Put database clients, auth sessions, and shared utilities in tRPC context for type-safe access across all procedures.\n\n3. **React Query Integration**: tRPC's React hooks are powered by React Query. Request configurations for caching, refetching, and optimistic updates.\n\n4. **Organize with Sub-Routers**: For large APIs, ask Claude to split procedures into feature-based sub-routers (users, posts, comments) merged into a root router.\n\n5. **Type Inference Magic**: tRPC's `inferProcedureInput` and `inferProcedureOutput` utilities maintain types across client/server. Request these for shared type definitions.\n\n6. **Error Handling**: Use tRPC's `TRPCError` with specific codes (BAD_REQUEST, UNAUTHORIZED, etc.) for consistent error responses.\n\n## Common Workflows\n\n### E-Commerce API\n```\n\"Build a type-safe e-commerce API with tRPC:\n1. Product catalog with filtering and search\n2. Shopping cart management\n3. Order processing with Stripe\n4. User authentication with NextAuth\n5. Admin dashboard procedures\n6. Real-time inventory updates\n7. Include Zod validation and Prisma integration\"\n```\n\n### Social Media Backend\n```\n\"Create a social media backend using tRPC:\n1. User profiles with follow/unfollow\n2. Posts with likes and comments\n3. Real-time notifications via subscriptions\n4. Image uploads to S3\n5. Feed algorithm with pagination\n6. Direct messaging between users\n7. Content moderation procedures\"\n```\n\n### SaaS Multi-Tenant API\n```\n\"Build a multi-tenant SaaS API with tRPC:\n1. Organization and team management\n2. Role-based access control middleware\n3. Usage tracking and billing\n4. Webhook integrations\n5. Audit logging for all actions\n6. Rate limiting per tenant\n7. Data isolation at database level\"\n```\n\n### AI Chat Application\n```\n\"Create a chat app with tRPC and streaming:\n1. OpenAI integration with streaming responses\n2. Chat history with Prisma\n3. Real-time message updates\n4. Typing indicators via subscriptions\n5. File uploads for context\n6. Conversation summarization\n7. Cost tracking per user\"\n```\n\n## Troubleshooting\n\n**Issue:** Type errors between client and server\n**Solution:** Ensure both use the same TypeScript version and tRPC version. Export `AppRouter` type from server and import on client. Run `tsc --noEmit` to catch type issues.\n\n**Issue:** Queries not refetching properly\n**Solution:** Configure React Query's `staleTime` and `cacheTime`. Use `utils.invalidate()` after mutations or enable optimistic updates with `onMutate`.\n\n**Issue:** Authentication context undefined\n**Solution:** Verify middleware runs before protected procedures. Check that `createContext` properly extracts auth token from headers. Ensure client passes credentials.\n\n**Issue:** Slow API responses\n**Solution:** Add database query optimization, implement batching with DataLoader pattern, use tRPC's batching link on client, and consider Redis caching for expensive operations.\n\n**Issue:** WebSocket subscriptions disconnecting\n**Solution:** Implement heartbeat/ping-pong pattern, add automatic reconnection with exponential backoff, check firewall/proxy timeouts, and use connection pooling.\n\n**Issue:** Zod validation too strict\n**Solution:** Use `.optional()`, `.nullable()`, or `.default()` on schema fields. For flexible objects, use `z.record()` or `.passthrough()` to allow extra keys.\n\n## Learn More\n\n- [tRPC Official Documentation](https://trpc.io/docs/)\n- [T3 Stack Tutorial](https://create.t3.gg/)\n- [tRPC with Next.js 15 Guide](https://trpc.io/docs/nextjs)\n- [React Query Integration](https://trpc.io/docs/react-query)\n- [tRPC Awesome List](https://github.com/trpc/trpc/blob/main/www/docs/awesome-trpc.md)\n",
      "features": [
        "End-to-end type safety without code generation",
        "Zero runtime dependencies and tiny bundle size",
        "Automatic React Query hooks generation",
        "WebSocket subscriptions support"
      ],
      "useCases": [
        "Full-stack TypeScript applications",
        "Real-time collaborative apps",
        "Type-safe microservices communication"
      ],
      "requirements": [
        "Node.js 18+",
        "TypeScript 5.0+",
        "@trpc/server ^10.0.0",
        "@trpc/client ^10.0.0",
        "@trpc/react-query ^10.0.0"
      ],
      "examples": [
        {
          "title": "tRPC Server Setup",
          "language": "typescript",
          "code": "import { initTRPC, TRPCError } from '@trpc/server';\nimport { z } from 'zod';\nimport { db } from './db';\n\n// Context creation\nexport const createContext = async ({ req }: { req: Request }) => {\n  const token = req.headers.get('authorization')?.replace('Bearer ', '');\n  const user = token ? await verifyToken(token) : null;\n  \n  return {\n    db,\n    user,\n  };\n};\n\ntype Context = Awaited<ReturnType<typeof createContext>>;\n\nconst t = initTRPC.context<Context>().create();\n\n// Middleware\nconst isAuthed = t.middleware(({ ctx, next }) => {\n  if (!ctx.user) {\n    throw new TRPCError({ code: 'UNAUTHORIZED' });\n  }\n  return next({\n    ctx: {\n      user: ctx.user,\n    },\n  });\n});\n\n// Procedures\nexport const publicProcedure = t.procedure;\nexport const protectedProcedure = t.procedure.use(isAuthed);\n\n// Router\nexport const appRouter = t.router({\n  users: t.router({\n    list: publicProcedure\n      .query(async ({ ctx }) => {\n        return ctx.db.user.findMany();\n      }),\n    \n    create: protectedProcedure\n      .input(\n        z.object({\n          name: z.string().min(3),\n          email: z.string().email(),\n        })\n      )\n      .mutation(async ({ ctx, input }) => {\n        return ctx.db.user.create({\n          data: input,\n        });\n      }),\n  }),\n});\n\nexport type AppRouter = typeof appRouter;"
        },
        {
          "title": "Next.js API Route",
          "language": "typescript",
          "code": "// app/api/trpc/[trpc]/route.ts\nimport { fetchRequestHandler } from '@trpc/server/adapters/fetch';\nimport { appRouter, createContext } from '~/server/trpc';\n\nconst handler = (req: Request) =>\n  fetchRequestHandler({\n    endpoint: '/api/trpc',\n    req,\n    router: appRouter,\n    createContext,\n  });\n\nexport { handler as GET, handler as POST };"
        },
        {
          "title": "React Client Usage",
          "language": "typescript",
          "code": "// app/providers.tsx\nimport { QueryClient, QueryClientProvider } from '@tanstack/react-query';\nimport { httpBatchLink } from '@trpc/client';\nimport { trpc } from '~/utils/trpc';\nimport { useState } from 'react';\n\nexport function Providers({ children }: { children: React.ReactNode }) {\n  const [queryClient] = useState(() => new QueryClient());\n  const [trpcClient] = useState(() =>\n    trpc.createClient({\n      links: [\n        httpBatchLink({\n          url: 'http://localhost:3000/api/trpc',\n          headers() {\n            return {\n              authorization: `Bearer ${getToken()}`,\n            };\n          },\n        }),\n      ],\n    })\n  );\n\n  return (\n    <trpc.Provider client={trpcClient} queryClient={queryClient}>\n      <QueryClientProvider client={queryClient}>\n        {children}\n      </QueryClientProvider>\n    </trpc.Provider>\n  );\n}\n\n// Component usage\nexport function UsersList() {\n  const { data: users, isLoading } = trpc.users.list.useQuery();\n  const createUser = trpc.users.create.useMutation();\n\n  if (isLoading) return <div>Loading...</div>;\n\n  return (\n    <div>\n      {users?.map((user) => (\n        <div key={user.id}>{user.name}</div>\n      ))}\n      <button\n        onClick={() =>\n          createUser.mutate({\n            name: 'New User',\n            email: 'user@example.com',\n          })\n        }\n      >\n        Add User\n      </button>\n    </div>\n  );\n}"
        },
        {
          "title": "Real-Time Subscription",
          "language": "typescript",
          "code": "import { EventEmitter } from 'events';\nimport { observable } from '@trpc/server/observable';\n\nconst ee = new EventEmitter();\n\nexport const appRouter = t.router({\n  messages: t.router({\n    onNew: publicProcedure.subscription(() => {\n      return observable<Message>((emit) => {\n        const onMessage = (data: Message) => {\n          emit.next(data);\n        };\n        \n        ee.on('newMessage', onMessage);\n        \n        return () => {\n          ee.off('newMessage', onMessage);\n        };\n      });\n    }),\n    \n    send: protectedProcedure\n      .input(z.object({ text: z.string() }))\n      .mutation(async ({ ctx, input }) => {\n        const message = await ctx.db.message.create({\n          data: {\n            text: input.text,\n            userId: ctx.user.id,\n          },\n        });\n        \n        ee.emit('newMessage', message);\n        return message;\n      }),\n  }),\n});"
        }
      ],
      "installation": {
        "claudeDesktop": {
          "steps": [
            "Initialize T3 app: npm create t3-app@latest",
            "Or add to existing: npm install @trpc/server @trpc/client @trpc/react-query",
            "Ask Claude: 'Set up tRPC with Next.js and create user CRUD routes'",
            "Claude generates server and client configuration"
          ]
        },
        "claudeCode": {
          "steps": [
            "npm install @trpc/server @trpc/client @trpc/react-query zod",
            "npm install @tanstack/react-query",
            "Create server/trpc.ts with router",
            "Create utils/trpc.ts for client",
            "Set up API route handler"
          ]
        }
      },
      "troubleshooting": [
        {
          "issue": "Type inference not working",
          "solution": "Export AppRouter type from server, import on client. Ensure same TypeScript and tRPC versions. Check tsconfig.json has strict: true."
        },
        {
          "issue": "React Query hooks missing",
          "solution": "Verify trpc.Provider wraps app with QueryClientProvider. Check createTRPCReact import and proper initialization."
        },
        {
          "issue": "CORS errors",
          "solution": "Add CORS middleware to tRPC handler or set proper headers in Next.js API route. For development, use proxy in next.config.js."
        }
      ],
      "documentationUrl": "https://trpc.io/docs/",
      "source": "community",
      "type": "skill",
      "url": "https://claudepro.directory/skills/trpc-type-safe-api"
    },
    {
      "slug": "v0-rapid-prototyping",
      "title": "V0 Rapid UI Prototyping Workflow",
      "seoTitle": "V0 Rapid UI Prototyping Workflow Skill",
      "description": "Build production-ready React components and full pages in minutes using V0.dev AI with shadcn/ui, TailwindCSS v4, and Next.js 15 integration.",
      "category": "skills",
      "author": "JSONbored",
      "dateAdded": "2025-10-16",
      "tags": [
        "v0",
        "prototyping",
        "ui",
        "shadcn",
        "react"
      ],
      "content": "# V0 Rapid UI Prototyping Workflow Skill\n\n## What This Skill Enables\n\nClaude can generate production-ready React components and complete page layouts using V0.dev patterns - Vercel's breakthrough AI UI generator that has transformed frontend development in 2025. This skill enables instant component creation with shadcn/ui integration, TailwindCSS v4 styling, full TypeScript support, and seamless Next.js 15 App Router compatibility.\n\n## Prerequisites\n\n**Required:**\n- Next.js 15+ project (App Router)\n- TailwindCSS v4.1+ configured\n- shadcn/ui components installed\n- Node.js 18+\n\n**What Claude handles automatically:**\n- Generating React 19 components with proper TypeScript types\n- Applying TailwindCSS v4 styling with CSS variables\n- Integrating shadcn/ui components\n- Creating responsive, mobile-first layouts\n- Adding framer-motion animations\n- Implementing accessibility (WCAG 2.2 Level AA)\n- Server/Client component distinction\n\n## How to Use This Skill\n\n### Component Generation from Description\n\n**Prompt:** \"Create a pricing table component with 3 tiers (Basic, Pro, Enterprise). Include monthly/annual toggle, feature lists with checkmarks, and prominent CTA buttons. Use shadcn/ui Card and Button components.\"\n\nClaude will:\n1. Generate TypeScript component with proper types\n2. Use shadcn/ui primitives (Card, Button, Switch)\n3. Apply TailwindCSS v4 utility classes\n4. Implement state management with useState\n5. Add responsive grid layout\n6. Include accessibility attributes (ARIA labels)\n7. Add smooth transitions with CSS\n\n### Dashboard Layout Creation\n\n**Prompt:** \"Build an analytics dashboard layout with sidebar navigation, header with search and notifications, stat cards showing KPIs, revenue chart using Recharts, and recent activity table. Make it fully responsive.\"\n\nClaude will:\n1. Create Server Component for static shell\n2. Add Client Components for interactive elements\n3. Implement responsive sidebar (mobile drawer)\n4. Generate stat cards with icons from lucide-react\n5. Integrate Recharts with proper TypeScript types\n6. Add loading states with Suspense boundaries\n7. Include dark mode support via next-themes\n\n### Form Generation with Validation\n\n**Prompt:** \"Create a user registration form with email, password, confirm password, and terms acceptance. Use react-hook-form with Zod validation. Show validation errors inline and disable submit until valid.\"\n\nClaude will:\n1. Generate form with shadcn/ui Form components\n2. Define Zod schema with comprehensive validation\n3. Integrate react-hook-form with zodResolver\n4. Add password strength indicator\n5. Implement real-time validation feedback\n6. Create accessible error messages\n7. Add loading state during submission\n\n### Landing Page Section\n\n**Prompt:** \"Design a hero section with gradient background, animated headline text, two CTA buttons, and three feature highlights below. Include subtle animations on scroll using framer-motion.\"\n\nClaude will:\n1. Create responsive hero layout\n2. Add gradient backgrounds with TailwindCSS\n3. Implement text animations with framer-motion\n4. Add button hover effects\n5. Create feature cards with icons\n6. Implement scroll-triggered animations\n7. Optimize for Core Web Vitals\n\n## Tips for Best Results\n\n1. **Be Specific About Components**: Mention exact shadcn/ui components you want (Card, Button, Dialog, etc.) for consistent design system usage.\n\n2. **Request Mobile-First**: Always specify \"mobile-first responsive design\" to ensure proper breakpoints and touch-friendly interactions.\n\n3. **Accessibility First**: Ask for WCAG 2.2 Level AA compliance to get proper semantic HTML, ARIA labels, and keyboard navigation.\n\n4. **Server vs Client**: Clarify if components need interactivity (Client Component with 'use client') or can be static (Server Component).\n\n5. **Animation Budgets**: Request \"performant animations\" to get GPU-accelerated framer-motion transitions instead of heavy JavaScript.\n\n6. **Dark Mode**: Specify \"with dark mode support\" to get proper color variable usage compatible with next-themes.\n\n## Common Workflows\n\n### Complete Page Generation\n```\n\"Create a complete product details page with:\n1. Image gallery with thumbnails (Client Component)\n2. Product info section (title, price, description)\n3. Add to cart button with quantity selector\n4. Reviews section with star ratings\n5. Related products carousel\n6. Mobile-responsive layout with good UX\n7. Loading states and error handling\"\n```\n\n### Component Library Starter\n```\n\"Generate a set of reusable UI components:\n1. CustomButton with variants (primary, secondary, outline, ghost)\n2. CustomCard with header, content, footer slots\n3. CustomInput with label, error message, help text\n4. CustomSelect with search and multi-select\n5. All components with TypeScript props, accessibility, and Storybook-ready\"\n```\n\n### Data Visualization Dashboard\n```\n\"Build a data visualization dashboard component:\n1. KPI summary cards at top (Revenue, Users, Conversion)\n2. Line chart for 30-day trends using Recharts\n3. Bar chart for category breakdown\n4. Pie chart for traffic sources\n5. Data table with sorting and filtering\n6. Export to CSV functionality\n7. Responsive grid that stacks on mobile\"\n```\n\n### Authentication UI Flow\n```\n\"Create a complete authentication flow:\n1. Login page with email/password and OAuth buttons\n2. Registration page with form validation\n3. Forgot password page with email input\n4. Email verification pending page\n5. Password reset page\n6. All pages with consistent styling using shadcn/ui\n7. Loading states and error handling\"\n```\n\n## Troubleshooting\n\n**Issue:** Generated components don't match my design system colors\n**Solution:** Ask Claude to use CSS variables from globals.css (--primary, --secondary, etc.) instead of hardcoded color values. Specify \"use our existing design tokens.\"\n\n**Issue:** Components are not responsive on mobile\n**Solution:** Request \"mobile-first responsive design with specific breakpoints: sm (640px), md (768px), lg (1024px)\" and ask for preview at each breakpoint.\n\n**Issue:** Too many client components affecting performance\n**Solution:** Ask Claude to \"identify which components can be Server Components and only use 'use client' for interactive elements like forms, buttons with onClick.\"\n\n**Issue:** Animations cause layout shift (CLS)\n**Solution:** Request \"animations that don't affect layout, using transform and opacity only\" to maintain good Core Web Vitals scores.\n\n**Issue:** TypeScript errors with component props\n**Solution:** Ask Claude to \"define explicit TypeScript interfaces for all component props with JSDoc comments\" for better type safety.\n\n## Learn More\n\n- [V0.dev Documentation](https://v0.dev/docs)\n- [shadcn/ui Components](https://ui.shadcn.com/)\n- [TailwindCSS v4 Guide](https://tailwindcss.com/docs)\n- [Next.js 15 App Router](https://nextjs.org/docs/app)\n- [React 19 Documentation](https://react.dev/)\n",
      "features": [
        "Instant React component generation with V0 patterns",
        "shadcn/ui integration with full type safety",
        "TailwindCSS v4 styling with CSS variables",
        "Responsive mobile-first layouts",
        "framer-motion animations",
        "WCAG 2.2 Level AA accessibility"
      ],
      "useCases": [
        "Rapid prototyping of UI designs",
        "Building production-ready components",
        "Creating landing pages and marketing sites",
        "Dashboard and admin panel development"
      ],
      "requirements": [
        "Next.js 15+",
        "React 19+",
        "TailwindCSS v4.1+",
        "shadcn/ui components"
      ],
      "examples": [
        {
          "title": "Pricing Table Component",
          "language": "typescript",
          "code": "'use client';\n\nimport { useState } from 'react';\nimport { Check } from 'lucide-react';\nimport { Button } from '@/components/ui/button';\nimport { Card, CardContent, CardDescription, CardFooter, CardHeader, CardTitle } from '@/components/ui/card';\nimport { Switch } from '@/components/ui/switch';\n\ninterface PricingTier {\n  name: string;\n  price: { monthly: number; annual: number };\n  features: string[];\n  cta: string;\n  popular?: boolean;\n}\n\nconst tiers: PricingTier[] = [\n  {\n    name: 'Basic',\n    price: { monthly: 9, annual: 90 },\n    features: ['5 projects', '1GB storage', 'Email support'],\n    cta: 'Get Started',\n  },\n  {\n    name: 'Pro',\n    price: { monthly: 29, annual: 290 },\n    features: ['Unlimited projects', '10GB storage', 'Priority support', 'Advanced analytics'],\n    cta: 'Start Free Trial',\n    popular: true,\n  },\n  {\n    name: 'Enterprise',\n    price: { monthly: 99, annual: 990 },\n    features: ['Unlimited everything', '100GB storage', '24/7 phone support', 'Custom integrations', 'SLA'],\n    cta: 'Contact Sales',\n  },\n];\n\nexport function PricingTable() {\n  const [isAnnual, setIsAnnual] = useState(false);\n\n  return (\n    <div className=\"py-12\">\n      <div className=\"mx-auto max-w-7xl px-4 sm:px-6 lg:px-8\">\n        <div className=\"text-center\">\n          <h2 className=\"text-3xl font-bold tracking-tight sm:text-4xl\">Simple, transparent pricing</h2>\n          <div className=\"mt-6 flex items-center justify-center gap-3\">\n            <span className={!isAnnual ? 'font-semibold' : 'text-muted-foreground'}>Monthly</span>\n            <Switch checked={isAnnual} onCheckedChange={setIsAnnual} />\n            <span className={isAnnual ? 'font-semibold' : 'text-muted-foreground'}>\n              Annual <span className=\"text-sm text-primary\">(Save 20%)</span>\n            </span>\n          </div>\n        </div>\n\n        <div className=\"mt-12 grid gap-8 lg:grid-cols-3\">\n          {tiers.map((tier) => (\n            <Card key={tier.name} className={tier.popular ? 'border-primary shadow-lg' : ''}>\n              <CardHeader>\n                <CardTitle className=\"flex items-center justify-between\">\n                  {tier.name}\n                  {tier.popular && (\n                    <span className=\"rounded-full bg-primary px-3 py-1 text-xs text-primary-foreground\">\n                      Popular\n                    </span>\n                  )}\n                </CardTitle>\n                <CardDescription>\n                  <div className=\"mt-4 flex items-baseline\">\n                    <span className=\"text-4xl font-bold\">\n                      ${isAnnual ? tier.price.annual / 12 : tier.price.monthly}\n                    </span>\n                    <span className=\"ml-1 text-muted-foreground\">/month</span>\n                  </div>\n                  {isAnnual && (\n                    <p className=\"mt-1 text-sm\">Billed annually (${tier.price.annual}/year)</p>\n                  )}\n                </CardDescription>\n              </CardHeader>\n              <CardContent>\n                <ul className=\"space-y-3\">\n                  {tier.features.map((feature) => (\n                    <li key={feature} className=\"flex items-center gap-2\">\n                      <Check className=\"h-5 w-5 text-primary\" />\n                      <span>{feature}</span>\n                    </li>\n                  ))}\n                </ul>\n              </CardContent>\n              <CardFooter>\n                <Button className=\"w-full\" variant={tier.popular ? 'default' : 'outline'}>\n                  {tier.cta}\n                </Button>\n              </CardFooter>\n            </Card>\n          ))}\n        </div>\n      </div>\n    </div>\n  );\n}"
        },
        {
          "title": "Registration Form with Validation",
          "language": "typescript",
          "code": "'use client';\n\nimport { useState } from 'react';\nimport { useForm } from 'react-hook-form';\nimport { zodResolver } from '@hookform/resolvers/zod';\nimport * as z from 'zod';\nimport { Button } from '@/components/ui/button';\nimport { Form, FormControl, FormField, FormItem, FormLabel, FormMessage } from '@/components/ui/form';\nimport { Input } from '@/components/ui/input';\nimport { Checkbox } from '@/components/ui/checkbox';\nimport { Loader2 } from 'lucide-react';\n\nconst formSchema = z.object({\n  email: z.string().email({ message: 'Please enter a valid email address' }),\n  password: z\n    .string()\n    .min(8, { message: 'Password must be at least 8 characters' })\n    .regex(/[A-Z]/, { message: 'Password must contain at least one uppercase letter' })\n    .regex(/[0-9]/, { message: 'Password must contain at least one number' }),\n  confirmPassword: z.string(),\n  acceptTerms: z.boolean().refine((val) => val === true, {\n    message: 'You must accept the terms and conditions',\n  }),\n}).refine((data) => data.password === data.confirmPassword, {\n  message: \"Passwords don't match\",\n  path: ['confirmPassword'],\n});\n\ntype FormValues = z.infer<typeof formSchema>;\n\nexport function RegistrationForm() {\n  const [isSubmitting, setIsSubmitting] = useState(false);\n\n  const form = useForm<FormValues>({\n    resolver: zodResolver(formSchema),\n    defaultValues: {\n      email: '',\n      password: '',\n      confirmPassword: '',\n      acceptTerms: false,\n    },\n  });\n\n  const onSubmit = async (data: FormValues) => {\n    setIsSubmitting(true);\n    try {\n      // Submit form\n      await new Promise((resolve) => setTimeout(resolve, 2000));\n      console.log(data);\n    } finally {\n      setIsSubmitting(false);\n    }\n  };\n\n  return (\n    <Form {...form}>\n      <form onSubmit={form.handleSubmit(onSubmit)} className=\"space-y-6\">\n        <FormField\n          control={form.control}\n          name=\"email\"\n          render={({ field }) => (\n            <FormItem>\n              <FormLabel>Email</FormLabel>\n              <FormControl>\n                <Input type=\"email\" placeholder=\"you@example.com\" {...field} />\n              </FormControl>\n              <FormMessage />\n            </FormItem>\n          )}\n        />\n\n        <FormField\n          control={form.control}\n          name=\"password\"\n          render={({ field }) => (\n            <FormItem>\n              <FormLabel>Password</FormLabel>\n              <FormControl>\n                <Input type=\"password\" placeholder=\"â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢\" {...field} />\n              </FormControl>\n              <FormMessage />\n            </FormItem>\n          )}\n        />\n\n        <FormField\n          control={form.control}\n          name=\"confirmPassword\"\n          render={({ field }) => (\n            <FormItem>\n              <FormLabel>Confirm Password</FormLabel>\n              <FormControl>\n                <Input type=\"password\" placeholder=\"â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢\" {...field} />\n              </FormControl>\n              <FormMessage />\n            </FormItem>\n          )}\n        />\n\n        <FormField\n          control={form.control}\n          name=\"acceptTerms\"\n          render={({ field }) => (\n            <FormItem className=\"flex flex-row items-start space-x-3 space-y-0\">\n              <FormControl>\n                <Checkbox checked={field.value} onCheckedChange={field.onChange} />\n              </FormControl>\n              <div className=\"space-y-1 leading-none\">\n                <FormLabel>I accept the terms and conditions</FormLabel>\n                <FormMessage />\n              </div>\n            </FormItem>\n          )}\n        />\n\n        <Button type=\"submit\" className=\"w-full\" disabled={isSubmitting}>\n          {isSubmitting && <Loader2 className=\"mr-2 h-4 w-4 animate-spin\" />}\n          Create Account\n        </Button>\n      </form>\n    </Form>\n  );\n}"
        }
      ],
      "installation": {
        "claudeDesktop": {
          "steps": [
            "Ensure shadcn/ui is installed: npx shadcn-ui@latest init",
            "Ask Claude: 'Generate a [component description] using V0 patterns'",
            "Claude will create component with proper imports and types",
            "Install missing shadcn/ui components if needed"
          ]
        },
        "claudeCode": {
          "steps": [
            "npx shadcn-ui@latest init",
            "npx shadcn-ui@latest add button card input form",
            "Use prompts to generate components",
            "Copy generated code to your components directory"
          ]
        }
      },
      "troubleshooting": [
        {
          "issue": "Missing shadcn/ui components",
          "solution": "Run 'npx shadcn-ui@latest add [component-name]' to install required components."
        },
        {
          "issue": "TypeScript errors with component props",
          "solution": "Ensure all shadcn/ui components are properly typed. Update to latest versions."
        },
        {
          "issue": "Styling conflicts with TailwindCSS",
          "solution": "Verify TailwindCSS v4 is configured correctly with CSS variables in globals.css."
        }
      ],
      "documentationUrl": "https://v0.dev/docs",
      "source": "community",
      "type": "skill",
      "url": "https://claudepro.directory/skills/v0-rapid-prototyping"
    },
    {
      "slug": "webassembly-module-development",
      "title": "WebAssembly Module Development",
      "seoTitle": "WebAssembly WASM Module Development Skill",
      "description": "Build high-performance WebAssembly modules with WASI 0.3, multi-language support, and production-ready deployments for web, serverless, and AI workloads.",
      "category": "skills",
      "author": "JSONbored",
      "dateAdded": "2025-10-16",
      "tags": [
        "webassembly",
        "wasm",
        "rust",
        "performance",
        "wasi"
      ],
      "content": "# WebAssembly Module Development Skill\n\n## What This Skill Enables\n\nClaude can build production-ready WebAssembly modules that run at near-native speeds across web browsers, serverless platforms, and edge computing environments. With WASI 0.3 bringing native async support and WebAssembly 2.0 complete as of March 2025, WASM has transitioned from experimental to production-ready for AI workloads, cloud-native applications, and high-performance web apps.\n\n## Prerequisites\n\n**Required:**\n- Claude Pro subscription or Claude Code CLI\n- Rust (recommended) or C++/Go compiler\n- Node.js 18+ for JavaScript integration\n- Basic understanding of systems programming\n\n**What Claude handles automatically:**\n- Writing Rust/C++ code optimized for WASM\n- Compiling to WebAssembly with proper optimizations\n- Generating JavaScript bindings with wasm-bindgen\n- Setting up WASI for system calls\n- Implementing Component Model for interoperability\n- Optimizing binary size and performance\n- Testing WASM modules in multiple runtimes\n\n## How to Use This Skill\n\n### Create a Basic WASM Module\n\n**Prompt:** \"Build a WebAssembly module in Rust that calculates Fibonacci numbers. Include JavaScript bindings and deploy to npm.\"\n\nClaude will:\n1. Set up Rust project with wasm-pack\n2. Write optimized Fibonacci implementation\n3. Add wasm-bindgen annotations\n4. Compile to WASM with size optimizations\n5. Generate TypeScript definitions\n6. Create npm package configuration\n7. Include usage examples for web and Node.js\n\n### Image Processing with WASM\n\n**Prompt:** \"Create a WebAssembly module that applies image filters (grayscale, blur, sharpen) to ImageData from canvas. Optimize for processing 4K images in real-time.\"\n\nClaude will:\n1. Write Rust image processing algorithms\n2. Use rayon for parallel processing\n3. Interface with JavaScript canvas API\n4. Implement zero-copy memory sharing\n5. Add SIMD optimizations where available\n6. Create worker thread wrapper\n7. Benchmark against pure JavaScript\n\n### AI Model Inference with WASM\n\n**Prompt:** \"Build a WebAssembly module that runs ONNX neural network models in the browser. Support image classification with MobileNetV3.\"\n\nClaude will:\n1. Integrate wasm-bindgen with onnxruntime-web\n2. Load and cache ONNX models\n3. Implement preprocessing pipeline\n4. Run inference with WebAssembly backend\n5. Add batching for multiple inputs\n6. Optimize memory allocation\n7. Include model quantization for smaller binaries\n\n### Serverless Function with WASI\n\n**Prompt:** \"Create a WebAssembly module with WASI 0.3 that processes CSV files, performs data transformations, and writes results to stdout. Deploy to Fermyon Spin.\"\n\nClaude will:\n1. Write Rust code using WASI SDK\n2. Implement async file I/O with WASI 0.3\n3. Add CSV parsing and transformation logic\n4. Configure for Spin serverless platform\n5. Set up component model interfaces\n6. Add error handling and logging\n7. Deploy with spin.toml configuration\n\n## Tips for Best Results\n\n1. **Choose Rust for Production**: While multiple languages compile to WASM, Rust offers the best tooling (wasm-pack, wasm-bindgen) and smallest binary sizes. Ask Claude to use Rust unless you have specific requirements.\n\n2. **Optimize Binary Size**: WASM modules should be <500KB for web deployments. Request `wasm-opt -Oz` optimization and enable LTO (Link-Time Optimization) in Cargo.toml.\n\n3. **Use Component Model**: For WASI 0.3, request Component Model implementation for better interoperability and async support.\n\n4. **Memory Management**: WebAssembly uses linear memory. Ask Claude to implement proper memory allocation strategies and avoid memory leaks with proper drop implementations.\n\n5. **JavaScript Interop**: Use wasm-bindgen for seamless JavaScript integration. Request TypeScript definitions generation for better DX.\n\n6. **SIMD When Available**: For compute-intensive tasks, ask Claude to use WebAssembly SIMD instructions for 4-8x performance improvements.\n\n## Common Workflows\n\n### High-Performance Web App Component\n```\n\"Create a WebAssembly module for my React app that:\n1. Parses and validates 10MB JSON files instantly\n2. Performs complex data aggregations\n3. Exports results to CSV format\n4. Includes TypeScript types\n5. Loads asynchronously without blocking UI\n6. Caches compiled module in IndexedDB\n7. Falls back to JavaScript if WASM not supported\"\n```\n\n### Cryptocurrency Mining (Educational)\n```\n\"Build a WebAssembly SHA-256 hasher in Rust:\n1. Implements Bitcoin mining algorithm\n2. Uses multi-threading with Web Workers\n3. Achieves >1000 hashes per second\n4. Includes difficulty adjustment\n5. Reports progress to JavaScript\n6. Optimized with SIMD instructions\"\n```\n\n### Video Codec in Browser\n```\n\"Create a WebAssembly H.264 decoder:\n1. Decode video streams in real-time (30fps)\n2. Output to canvas via ImageData\n3. Support seeking and playback controls\n4. Use multi-threading for parallel decode\n5. Implement memory-efficient frame buffer\n6. Package as Web Component\"\n```\n\n### Database Query Engine\n```\n\"Build a WebAssembly SQLite query engine:\n1. Compile SQLite to WASM with WASI\n2. Implement virtual file system in browser\n3. Support full SQL query syntax\n4. Persist database to IndexedDB\n5. Include transaction support\n6. Expose async API to JavaScript\n7. Add query performance analytics\"\n```\n\n## Troubleshooting\n\n**Issue:** WASM module binary is too large (>2MB)\n**Solution:** Enable LTO and opt-level in Cargo.toml, run wasm-opt with -Oz flag, remove unused dependencies, and consider dynamic linking for shared code.\n\n**Issue:** JavaScript can't call WASM functions\n**Solution:** Ensure wasm-bindgen attributes are present (#[wasm_bindgen]), rebuild with wasm-pack, and check that JavaScript imports the generated bindings correctly.\n\n**Issue:** Performance slower than expected\n**Solution:** Enable WASM SIMD, use multi-threading with Web Workers, avoid frequent boundary crossings between JS and WASM, and profile with Chrome DevTools Performance tab.\n\n**Issue:** Memory errors or crashes\n**Solution:** Check for buffer overflows, ensure proper memory allocation, implement Drop trait for cleanup, and use wasm-bindgen's #[wasm_bindgen(inspectable)] for debugging.\n\n**Issue:** WASI functions not available\n**Solution:** Update to WASI SDK 0.3+, configure WASI runtime (wasmtime, wasmer), and use preview2 modules. Not all WASI functions are available in browser environments.\n\n**Issue:** Cannot debug WASM code\n**Solution:** Enable source maps with wasm-pack build --dev, use Chrome DevTools WASM debugging, add console.log bindings via web_sys crate, or use wasmtime with --invoke for CLI debugging.\n\n## Learn More\n\n- [WebAssembly Official Site](https://webassembly.org/)\n- [Rust and WebAssembly Book](https://rustwasm.github.io/book/)\n- [wasm-pack Documentation](https://rustwasm.github.io/wasm-pack/)\n- [WASI 0.3 Specification](https://github.com/WebAssembly/WASI/blob/main/preview2/README.md)\n- [WebAssembly Component Model](https://github.com/WebAssembly/component-model)\n- [AssemblyScript Language](https://www.assemblyscript.org/)\n",
      "features": [
        "Near-native performance in browser and serverless",
        "Multi-language support: Rust, C++, Go, AssemblyScript",
        "WASI 0.3 with native async support",
        "Component Model for interoperability"
      ],
      "useCases": [
        "High-performance web applications",
        "AI model inference in browser",
        "Serverless functions with portable code"
      ],
      "requirements": [
        "Rust 1.70+ and wasm-pack",
        "wasm-bindgen 0.2.87+",
        "WASI SDK 20+ (for WASI modules)",
        "Node.js 18+ for JavaScript integration"
      ],
      "examples": [
        {
          "title": "Fibonacci Calculator (Rust)",
          "language": "rust",
          "code": "use wasm_bindgen::prelude::*;\n\n#[wasm_bindgen]\npub fn fibonacci(n: u32) -> u64 {\n    match n {\n        0 => 0,\n        1 => 1,\n        _ => {\n            let mut a = 0u64;\n            let mut b = 1u64;\n            for _ in 2..=n {\n                let temp = a + b;\n                a = b;\n                b = temp;\n            }\n            b\n        }\n    }\n}\n\n#[wasm_bindgen]\npub struct Calculator {\n    cache: Vec<u64>,\n}\n\n#[wasm_bindgen]\nimpl Calculator {\n    #[wasm_bindgen(constructor)]\n    pub fn new() -> Calculator {\n        Calculator { cache: vec![0, 1] }\n    }\n\n    pub fn nth(&mut self, n: usize) -> u64 {\n        while self.cache.len() <= n {\n            let len = self.cache.len();\n            let next = self.cache[len - 1] + self.cache[len - 2];\n            self.cache.push(next);\n        }\n        self.cache[n]\n    }\n}"
        },
        {
          "title": "Image Grayscale Filter",
          "language": "rust",
          "code": "use wasm_bindgen::prelude::*;\nuse wasm_bindgen::Clamped;\nuse web_sys::ImageData;\n\n#[wasm_bindgen]\npub fn grayscale(data: &mut [u8]) {\n    for pixel in data.chunks_exact_mut(4) {\n        let gray = (0.299 * pixel[0] as f32\n            + 0.587 * pixel[1] as f32\n            + 0.114 * pixel[2] as f32) as u8;\n        pixel[0] = gray;\n        pixel[1] = gray;\n        pixel[2] = gray;\n    }\n}\n\n#[wasm_bindgen]\npub fn process_image(image_data: ImageData) -> Result<ImageData, JsValue> {\n    let mut data = image_data.data().to_vec();\n    grayscale(&mut data);\n    \n    ImageData::new_with_u8_clamped_array_and_sh(\n        Clamped(&data),\n        image_data.width(),\n        image_data.height(),\n    )\n}"
        },
        {
          "title": "JavaScript Integration",
          "language": "javascript",
          "code": "import init, { fibonacci, Calculator } from './pkg/wasm_module.js';\n\nasync function runWasm() {\n  // Initialize the WASM module\n  await init();\n\n  // Call simple function\n  console.log('Fibonacci(10):', fibonacci(10));\n\n  // Use class instance\n  const calc = new Calculator();\n  console.log('nth(20):', calc.nth(20));\n  console.log('nth(30):', calc.nth(30));\n\n  // Process image\n  const canvas = document.getElementById('canvas');\n  const ctx = canvas.getContext('2d');\n  const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);\n  \n  const processedImage = process_image(imageData);\n  ctx.putImageData(processedImage, 0, 0);\n}\n\nrunWasm();"
        },
        {
          "title": "Cargo.toml Configuration",
          "language": "toml",
          "code": "[package]\nname = \"wasm-module\"\nversion = \"0.1.0\"\nedition = \"2021\"\n\n[lib]\ncrate-type = [\"cdylib\", \"rlib\"]\n\n[dependencies]\nwasm-bindgen = \"0.2\"\nweb-sys = { version = \"0.3\", features = [\"ImageData\"] }\njs-sys = \"0.3\"\n\n[profile.release]\nopt-level = \"z\"\nlto = true\ncodegen-units = 1\npanic = \"abort\"\n\n[package.metadata.wasm-pack.profile.release]\nwasm-opt = ['-Oz']"
        }
      ],
      "installation": {
        "claudeDesktop": {
          "steps": [
            "Install Rust: curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh",
            "Add WASM target: rustup target add wasm32-unknown-unknown",
            "Install wasm-pack: cargo install wasm-pack",
            "Ask Claude: 'Create a WebAssembly module for [task]'"
          ]
        },
        "claudeCode": {
          "steps": [
            "cargo new --lib my-wasm-module",
            "Edit Cargo.toml with wasm dependencies",
            "wasm-pack build --target web",
            "Import in JavaScript: import init from './pkg/module.js'"
          ]
        }
      },
      "troubleshooting": [
        {
          "issue": "wasm-pack build fails",
          "solution": "Ensure Rust toolchain is up-to-date (rustup update), wasm32-unknown-unknown target is installed, and Cargo.toml has correct crate-type."
        },
        {
          "issue": "Binary size too large",
          "solution": "Enable LTO, set opt-level = 'z', run wasm-opt -Oz, and remove debug symbols with wasm-strip."
        },
        {
          "issue": "JavaScript imports fail",
          "solution": "Use correct import path to pkg/ directory, ensure init() is called before using WASM functions, and check browser console for loading errors."
        }
      ],
      "documentationUrl": "https://webassembly.org/",
      "source": "community",
      "type": "skill",
      "url": "https://claudepro.directory/skills/webassembly-module-development"
    },
    {
      "slug": "website-crawler-summarizer",
      "title": "Website Content Crawler and Summarizer",
      "seoTitle": "Website Crawler + Summarizer Skill",
      "description": "Crawl domains respectfully, extract readable content, dedupe, and generate structured summaries.",
      "category": "skills",
      "author": "JSONbored",
      "dateAdded": "2025-10-15",
      "tags": [
        "crawler",
        "scraping",
        "summarization",
        "readability"
      ],
      "content": "# Website Crawler & Summarizer Skill\n\n## What This Skill Enables\n\nClaude can crawl websites, extract content from web pages, clean HTML to readable text, respect robots.txt, and generate structured summaries or documentation from web content. Perfect for research, competitive analysis, and content aggregation.\n\n## Prerequisites\n\n**Required:**\n- Claude Pro subscription\n- Code Interpreter feature enabled\n- URLs to crawl (or sitemap)\n\n**What Claude handles:**\n- Installing scraping libraries (BeautifulSoup, Playwright, Scrapy)\n- Fetching web pages\n- Parsing HTML\n- Extracting readable content\n- Respecting robots.txt\n- Rate limiting requests\n- Content deduplication\n\n## How to Use This Skill\n\n### Single Page Extraction\n\n**Prompt:** \"Extract the main content from this webpage: https://example.com/article\nConvert to clean Markdown and save as article.md\"\n\nClaude will:\n1. Fetch the webpage\n2. Parse HTML\n3. Extract main content (remove ads, nav, footer)\n4. Convert to Markdown\n5. Save clean output\n\n### Multi-Page Crawl\n\n**Prompt:** \"Crawl all pages linked from this site:\nStart URL: https://docs.example.com\nOnly crawl pages under /docs/\nExtract content from each page\nSave as individual Markdown files\nMax 50 pages\"\n\nClaude will:\n1. Fetch start URL\n2. Find all links\n3. Filter to matching paths\n4. Crawl each page (with rate limiting)\n5. Extract and save content\n6. Generate index of pages\n\n### Content Summarization\n\n**Prompt:** \"Crawl these 10 blog posts and:\n1. Extract main content from each\n2. Generate 2-sentence summary per post\n3. Identify key topics\n4. Create master summary document\nFormat as JSON with metadata.\"\n\nClaude will:\n1. Fetch all URLs\n2. Extract content\n3. Generate summaries\n4. Extract topics/tags\n5. Structure as JSON\n\n### Sitemap-Based Crawl\n\n**Prompt:** \"Download sitemap from https://example.com/sitemap.xml and:\n1. Extract all article URLs\n2. Crawl each article\n3. Extract: title, date, author, content\n4. Save as CSV with metadata\"\n\nClaude will:\n1. Fetch sitemap XML\n2. Parse URL list\n3. Crawl each URL (respecting rate limits)\n4. Extract structured data\n5. Export as CSV\n\n## Common Workflows\n\n### Competitor Analysis\n```\n\"Analyze competitor website:\n1. Crawl main site (max 20 pages)\n2. Extract: services, pricing mentions, features\n3. Identify key messaging themes\n4. Create structured comparison report\nFocus on product/service pages.\"\n```\n\n### Documentation Mirror\n```\n\"Create local mirror of documentation:\n1. Start at https://docs.example.com\n2. Crawl all /docs/* pages\n3. Download images referenced\n4. Convert to Markdown\n5. Preserve link structure\n6. Generate offline-browseable site\"\n```\n\n### Research Aggregation\n```\n\"Gather research from these 20 URLs:\n1. Extract main content from each\n2. Identify key findings and quotes\n3. Extract citations and references\n4. Group by topic/theme\n5. Create annotated bibliography\nOutput as structured Markdown.\"\n```\n\n### Change Detection\n```\n\"Monitor this webpage for changes:\n1. Fetch current version\n2. Extract main content\n3. Compare with version from last week\n4. Highlight what changed\n5. Generate change report\"\n```\n\n## Web Scraping Best Practices\n\n### Respect & Ethics\n- **Always check robots.txt**: Claude will respect crawl rules\n- **Rate limiting**: Default to 1-2 requests/second\n- **User agent**: Identify bot politely\n- **Terms of service**: Respect website ToS\n- **Copyright**: Content remains property of original creator\n\n### Technical Considerations\n- **Dynamic content**: Use Playwright for JavaScript-heavy sites\n- **Authentication**: Provide cookies/tokens if needed\n- **Pagination**: Handle \"Load More\" and infinite scroll\n- **Anti-bot measures**: Respect CAPTCHAs (don't try to bypass)\n\n## Content Extraction Methods\n\n### HTML Parsing\n- BeautifulSoup for static HTML\n- CSS selectors for targeting elements\n- XPath for complex queries\n\n### Readability Algorithms\n- Remove boilerplate (nav, ads, footers)\n- Extract main article content\n- Preserve formatting (headings, lists, links)\n\n### Structured Data\n- JSON-LD extraction\n- Schema.org metadata\n- Open Graph tags\n- Twitter Cards\n\n## Tips for Best Results\n\n1. **Start Small**: Test with 1-2 pages before bulk crawling\n2. **Specify Scope**: Define which pages to crawl (\"only /blog/* paths\")\n3. **Rate Limits**: Mention if you need slower crawling (\"1 page per 5 seconds\")\n4. **Content Type**: Describe what to extract (\"article text only, no comments\")\n5. **Error Handling**: \"Skip pages that error and continue\" vs \"stop on first error\"\n6. **Deduplication**: \"Skip duplicate content\" if crawling related pages\n7. **Storage**: Specify output format (Markdown, JSON, CSV, HTML)\n\n## Advanced Features\n\n### JavaScript Rendering\n- Use Playwright for SPAs\n- Wait for dynamic content to load\n- Handle infinite scroll\n- Click \"Load More\" buttons\n\n### Link Discovery\n- Find all links on page\n- Filter by pattern (regex)\n- Depth-limited crawling\n- Breadth-first vs depth-first\n\n### Data Extraction\n- Tables to CSV\n- Lists to arrays\n- Forms and inputs\n- Metadata extraction\n\n### Content Processing\n- HTML to Markdown conversion\n- Text cleaning and normalization\n- Language detection\n- Content summarization\n\n## Troubleshooting\n\n**Issue:** Getting blocked or rate limited\n**Solution:** \"Slow down to 1 request per 10 seconds\" and \"Add random delays between requests\"\n\n**Issue:** Content not extracting correctly\n**Solution:** \"Show me the raw HTML first\" then identify CSS selectors for main content\n\n**Issue:** JavaScript content not loading\n**Solution:** \"Use Playwright to render JavaScript\" or \"Wait 5 seconds for content to load\"\n\n**Issue:** Too many pages being crawled\n**Solution:** Set limits: \"Max 50 pages\" or \"Only crawl 2 levels deep\" or \"Stick to /docs/* path\"\n\n**Issue:** Images/assets not downloading\n**Solution:** \"Download all images referenced in articles\" or provide specific asset types needed\n\n**Issue:** Different page structures\n**Solution:** Provide multiple CSS selectors: \"Try article.content, then div.post-body, then main\"\n\n## Legal & Ethical Considerations\n\n**Important**: Always respect:\n- Copyright and intellectual property\n- Website terms of service\n- robots.txt directives\n- Rate limits and server resources\n- Privacy and personal data\n- Commercial use restrictions\n\n**Use cases**: Research, archival, accessibility, personal use\n**Prohibited**: Spam, unauthorized scraping, data theft, ToS violations\n\n## Learn More\n\n- [robots.txt Guide](https://developers.google.com/search/docs/crawling-indexing/robots/intro) - Crawling etiquette\n- [BeautifulSoup Docs](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) - HTML parsing\n- [Scrapy Tutorial](https://docs.scrapy.org/en/latest/intro/tutorial.html) - Advanced crawling\n- [Playwright](https://playwright.dev/) - Browser automation\n- [Mozilla Readability](https://github.com/mozilla/readability) - Content extraction\n",
      "features": [
        "Robots-aware crawling",
        "Boilerplate removal",
        "Language detection",
        "JSON/MD export"
      ],
      "useCases": [
        "Competitive intel packs",
        "Documentation mirrors",
        "Research briefs"
      ],
      "requirements": [
        "Node.js 18+ or Python 3.11+",
        "Playwright (optional)",
        "readability or newspaper3k"
      ],
      "examples": [
        {
          "title": "Basic fetch + Readability (Node)",
          "language": "javascript",
          "code": "import { JSDOM } from 'jsdom';\nimport { Readability } from '@mozilla/readability';\nimport fetch from 'node-fetch';\n\nconst html = await (await fetch('https://example.com')).text();\nconst doc = new JSDOM(html, { url: 'https://example.com' });\nconst article = new Readability(doc.window.document).parse();\nconsole.log(article.title);"
        }
      ],
      "installation": {
        "claudeDesktop": {
          "steps": [
            "Install Node.js 18+",
            "npm i jsdom @mozilla/readability node-fetch"
          ]
        },
        "claudeCode": {
          "steps": [
            "Configure rate-limit and user-agent",
            "Respect robots.txt"
          ]
        }
      },
      "troubleshooting": [
        {
          "issue": "Blocked by anti-bot",
          "solution": "Reduce concurrency, add polite delays, and avoid sensitive endpoints."
        },
        {
          "issue": "BeautifulSoup returning None for elements that visibly exist on page",
          "solution": "Content may be JavaScript-rendered. Use Playwright or Puppeteer to render DOM. Check if element is in iframe or shadow DOM."
        },
        {
          "issue": "UnicodeDecodeError or mojibake characters in extracted content",
          "solution": "Detect charset from HTTP headers or meta tags. Use response.encoding='utf-8' or chardet library. Specify parser='lxml' explicitly."
        },
        {
          "issue": "Playwright crawl timing out or consuming excessive memory with multiple pages",
          "solution": "Close browser contexts after each page. Use browser.newContext() per session. Set timeout limits and enable headless mode."
        },
        {
          "issue": "Readability extraction missing article content or extracting wrong sections",
          "solution": "Try different parsers (lxml, html.parser, html5lib). Manually specify article CSS selector as fallback if auto-detect fails."
        }
      ],
      "documentationUrl": "https://github.com/mozilla/readability",
      "source": "community",
      "type": "skill",
      "url": "https://claudepro.directory/skills/website-crawler-summarizer"
    },
    {
      "slug": "windsurf-collaborative-development",
      "title": "Windsurf AI-Native Collaborative Development",
      "seoTitle": "Windsurf AI-Native Collaborative Development Skill",
      "description": "Master collaborative AI-assisted development with Windsurf IDE's Cascade AI, multi-file context awareness, and Flow patterns for team workflows.",
      "category": "skills",
      "author": "JSONbored",
      "dateAdded": "2025-10-16",
      "tags": [
        "windsurf",
        "collaboration",
        "cascade",
        "ai-ide",
        "workflow"
      ],
      "content": "# Windsurf AI-Native Collaborative Development Skill\n\n## What This Skill Enables\n\nClaude can guide you through Windsurf's AI-native development environment, featuring Cascade AI for context-aware multi-file operations, Flow collaboration patterns for team coordination, and intelligent code navigation. Windsurf is emerging as a powerful alternative to GitHub Copilot in 2025, with superior multi-file refactoring and real-time collaboration features.\n\n## Prerequisites\n\n**Required:**\n- Windsurf IDE installed (download from codeium.com/windsurf)\n- Active project/codebase\n- Basic understanding of your tech stack\n\n**What Claude helps you master:**\n- Cascade AI prompts for multi-file operations\n- Flow sessions for team collaboration\n- Context-aware code navigation\n- Intelligent refactoring workflows\n- AI-assisted debugging patterns\n- Code review with Cascade\n\n## How to Use This Skill\n\n### Multi-File Refactoring with Cascade\n\n**Prompt:** \"I need to refactor our authentication system from NextAuth to better-auth v1.3.9. Walk me through using Cascade AI to update all files while maintaining existing functionality.\"\n\nClaude will guide you to:\n1. Select all auth-related files in Windsurf sidebar (Cmd/Ctrl+Click)\n2. Open Cascade panel (Cmd/Ctrl+K)\n3. Use specific Cascade prompt:\n   ```\n   Refactor authentication across these files to use better-auth v1.3.9:\n   - Update lib/auth.ts to use betterAuth() instead of NextAuth()\n   - Migrate session handling to better-auth patterns\n   - Update all import statements\n   - Maintain existing OAuth providers\n   - Keep current session management logic\n   ```\n4. Review Cascade's proposed changes before applying\n5. Test authentication flow after refactoring\n\n### Flow Collaboration for Feature Development\n\n**Prompt:** \"Show me how to use Windsurf Flow to coordinate with my team on building a real-time notification system.\"\n\nClaude will explain:\n1. Create Flow session (Cmd/Ctrl+Shift+F)\n2. Define feature scope with Cascade:\n   ```\n   Implement real-time notifications using Supabase Realtime:\n   - Database schema: notifications table with RLS\n   - Server-side: Supabase client setup\n   - Hooks: useNotifications with real-time subscription\n   - UI: NotificationBell component\n   - Follow patterns in /lib/supabase and /components/ui\n   ```\n3. Cascade generates coordinated changes across multiple files\n4. Team members can review and collaborate in Flow session\n5. Apply changes with atomic commits\n\n### Context-Aware Code Navigation\n\n**Prompt:** \"Help me use Cascade to understand how error handling works across our codebase.\"\n\nClaude will demonstrate:\n1. Select a complex error handling function\n2. Right-click â†’ Ask Cascade\n3. Use prompt:\n   ```\n   Explain this error handling pattern and show me:\n   1. Where else this pattern is used\n   2. All files that import this error handler\n   3. How errors propagate to the UI layer\n   4. Any inconsistencies in error handling\n   ```\n4. Cascade provides context-aware analysis with file references\n5. Navigate to related code using Cascade's suggestions\n\n### Component Extraction with Cascade\n\n**Prompt:** \"Use Cascade to extract a reusable UserProfile component from my dashboard page.\"\n\nClaude will guide:\n1. Select the user profile section in dashboard/page.tsx\n2. Open Cascade (Cmd/Ctrl+K)\n3. Use extraction prompt:\n   ```\n   Extract user profile section into reusable component:\n   - Create components/user/profile.tsx\n   - Add TypeScript props interface\n   - Support 'compact' and 'full' variants\n   - Move styles to component\n   - Update dashboard to import and use new component\n   ```\n4. Review Cascade's component design\n5. Apply changes atomically\n\n## Tips for Best Results\n\n1. **Specific File Context**: When using Cascade, select all related files first (Cmd/Ctrl+Click in sidebar) to provide complete context for multi-file operations.\n\n2. **Structured Prompts**: Format Cascade prompts with numbered steps or bullet points for complex refactorings to get organized, sequential changes.\n\n3. **Reference Existing Patterns**: In prompts, reference specific files or patterns (\"Follow patterns in /lib/api\") to ensure consistency.\n\n4. **Atomic Operations**: Use Flow sessions for coordinated multi-file changes to maintain codebase integrity.\n\n5. **Verify Before Apply**: Always review Cascade's proposed changes before applying, especially for critical security or authentication code.\n\n6. **Leverage Type Awareness**: Windsurf's deep TypeScript integration helps Cascade understand type dependencies across files - mention \"maintain type safety\" in prompts.\n\n## Common Workflows\n\n### Complete Feature Implementation\n```\n\"Use Cascade Flow to implement user profile editing:\n1. Database: Add Prisma schema for user profiles\n2. API: Create tRPC mutations for profile updates\n3. Validation: Define Zod schemas\n4. UI: Build profile edit form with react-hook-form\n5. State: Add optimistic updates\n6. Follow our existing patterns in /lib and /components\"\n```\n\n### Security Audit with Cascade\n```\n\"Run Cascade security audit on authentication flow:\n1. Analyze all files in /lib/auth and /app/api/auth\n2. Check for OWASP Top 10 vulnerabilities\n3. Verify input validation with Zod\n4. Review session management security\n5. Identify any exposed secrets or tokens\n6. Suggest security improvements\"\n```\n\n### Codebase Modernization\n```\n\"Use Cascade to migrate from React 18 to React 19:\n1. Update package.json dependencies\n2. Migrate class components to functional components with hooks\n3. Replace deprecated lifecycle methods\n4. Update ReactDOM.render to createRoot\n5. Adopt new React 19 features (useOptimistic, useFormStatus)\n6. Update tests for new React Testing Library patterns\"\n```\n\n### Performance Optimization\n```\n\"Cascade analysis for performance optimization:\n1. Identify components causing unnecessary re-renders\n2. Suggest React.memo, useCallback, useMemo placements\n3. Find expensive operations that could use useTransition\n4. Optimize database queries in Server Components\n5. Suggest code splitting opportunities\n6. Analyze bundle size impact\"\n```\n\n## Troubleshooting\n\n**Issue:** Cascade makes changes that break type safety\n**Solution:** In your prompt, explicitly state \"maintain strict TypeScript type safety\" and \"verify all type definitions are updated.\" Review changes before applying.\n\n**Issue:** Cascade doesn't understand project-specific patterns\n**Solution:** Reference specific files in your prompt: \"Follow the API pattern in /lib/api/base.ts\" to teach Cascade your conventions.\n\n**Issue:** Flow sessions become too large and slow\n**Solution:** Break large features into smaller Flow sessions focused on specific layers (database, API, UI) rather than entire features at once.\n\n**Issue:** Cascade refactorings miss edge cases\n**Solution:** After Cascade applies changes, ask: \"Review the refactoring for edge cases, error handling, and boundary conditions. Suggest tests to verify correctness.\"\n\n**Issue:** Team members can't see Flow changes\n**Solution:** Ensure Flow session is properly shared (check session permissions) and all team members have latest Windsurf version installed.\n\n## Learn More\n\n- [Windsurf Documentation](https://docs.codeium.com/windsurf)\n- [Cascade AI Guide](https://docs.codeium.com/windsurf/cascade)\n- [Flow Collaboration Patterns](https://docs.codeium.com/windsurf/flow)\n- [Windsurf vs Cursor Comparison](https://codeium.com/compare/windsurf-cursor)\n- [AI-Native Development Best Practices](https://docs.codeium.com/windsurf/best-practices)\n",
      "features": [
        "Cascade AI for multi-file context-aware operations",
        "Flow sessions for team collaboration",
        "Intelligent code navigation with AI assistance",
        "Automated refactoring workflows",
        "Real-time collaborative coding",
        "Deep TypeScript and project context understanding"
      ],
      "useCases": [
        "Multi-file refactoring and migrations",
        "Team-based feature development",
        "Codebase understanding and navigation",
        "Automated code reviews and quality checks"
      ],
      "requirements": [
        "Windsurf IDE installed",
        "Active project/codebase",
        "Git repository (recommended)"
      ],
      "examples": [
        {
          "title": "Multi-File Authentication Refactoring",
          "language": "typescript",
          "code": "// Cascade Prompt Example:\n// \"Refactor authentication to use better-auth v1.3.9 across these files:\n//  - lib/auth.ts\n//  - app/api/auth/[...auth]/route.ts\n//  - components/login-form.tsx\n//  Maintain all existing OAuth providers and session logic.\"\n\n// Before: lib/auth.ts (NextAuth)\nimport NextAuth from 'next-auth';\nimport { authOptions } from './options';\n\nexport const { handlers, signIn, signOut, auth } = NextAuth(authOptions);\n\n// After: lib/auth.ts (better-auth) - Generated by Cascade\nimport { betterAuth } from 'better-auth';\nimport { prismaAdapter } from 'better-auth/adapters/prisma';\nimport { prisma } from '@/lib/db';\n\nexport const auth = betterAuth({\n  database: prismaAdapter(prisma, { provider: 'postgresql' }),\n  emailAndPassword: { enabled: true },\n  socialProviders: {\n    github: {\n      clientId: process.env.GITHUB_CLIENT_ID!,\n      clientSecret: process.env.GITHUB_CLIENT_SECRET!,\n    },\n    google: {\n      clientId: process.env.GOOGLE_CLIENT_ID!,\n      clientSecret: process.env.GOOGLE_CLIENT_SECRET!,\n    },\n  },\n});\n\nexport const { signIn, signOut } = auth;"
        },
        {
          "title": "Component Extraction with Cascade",
          "language": "typescript",
          "code": "// Cascade Prompt:\n// \"Extract user profile section into components/user/profile.tsx\n//  with variants support and proper TypeScript types.\"\n\n// After: components/user/profile.tsx - Generated by Cascade\nimport type { User } from '@/types/user';\nimport { Avatar, AvatarFallback, AvatarImage } from '@/components/ui/avatar';\n\ninterface UserProfileProps {\n  user: User;\n  variant?: 'compact' | 'full';\n}\n\nexport function UserProfile({ user, variant = 'full' }: UserProfileProps) {\n  return (\n    <div className=\"flex items-center gap-4\">\n      <Avatar className={variant === 'compact' ? 'h-8 w-8' : 'h-16 w-16'}>\n        <AvatarImage src={user.avatar} alt={user.name} />\n        <AvatarFallback>{user.name.charAt(0)}</AvatarFallback>\n      </Avatar>\n      <div>\n        <h3 className={variant === 'compact' ? 'text-sm font-medium' : 'text-lg font-semibold'}>\n          {user.name}\n        </h3>\n        {variant === 'full' && (\n          <>\n            <p className=\"text-sm text-muted-foreground\">{user.email}</p>\n            {user.bio && <p className=\"mt-2 text-sm\">{user.bio}</p>}\n          </>\n        )}\n      </div>\n    </div>\n  );\n}\n\n// Updated dashboard usage:\nimport { UserProfile } from '@/components/user/profile';\n\nexport default function DashboardPage() {\n  const { user } = useAuth();\n  return (\n    <div>\n      <UserProfile user={user} variant=\"full\" />\n    </div>\n  );\n}"
        }
      ],
      "installation": {
        "claudeDesktop": {
          "steps": [
            "Download Windsurf IDE from codeium.com/windsurf",
            "Install and open your project",
            "Learn Cascade shortcuts: Cmd/Ctrl+K for prompts",
            "Ask Claude for Cascade prompt examples for your tasks"
          ]
        },
        "claudeCode": {
          "steps": [
            "Install Windsurf IDE",
            "Open project in Windsurf",
            "Practice with Cascade on small refactorings first",
            "Use Flow for team collaboration features"
          ]
        }
      },
      "troubleshooting": [
        {
          "issue": "Cascade doesn't understand project patterns",
          "solution": "Reference specific files in prompts: 'Follow patterns in /lib/api/base.ts' to teach Cascade your conventions."
        },
        {
          "issue": "Type errors after Cascade refactoring",
          "solution": "Always include 'maintain strict TypeScript type safety' in prompts and review changes before applying."
        },
        {
          "issue": "Flow session changes not visible to team",
          "solution": "Verify session permissions and ensure all team members have latest Windsurf version."
        }
      ],
      "documentationUrl": "https://docs.codeium.com/windsurf",
      "source": "community",
      "type": "skill",
      "url": "https://claudepro.directory/skills/windsurf-collaborative-development"
    },
    {
      "slug": "zod-schema-validator",
      "title": "Zod Schema Validator",
      "seoTitle": "Zod Schema Validation Skill",
      "description": "Build type-safe runtime validation with Zod for APIs, forms, and data pipelines with TypeScript 5.5+ integration and automatic type inference.",
      "category": "skills",
      "author": "JSONbored",
      "dateAdded": "2025-10-16",
      "tags": [
        "zod",
        "validation",
        "typescript",
        "type-safety",
        "schema"
      ],
      "content": "# Zod Schema Validator Skill\n\n## What This Skill Enables\n\nClaude can build comprehensive validation schemas using Zod, the TypeScript-first validation library tested against TypeScript v5.5+. Zod provides runtime validation that matches compile-time types, enabling you to validate untrusted data (API inputs, user forms, external integrations) while maintaining end-to-end type safety. With zero dependencies and automatic type inference, Zod eliminates the gap between static types and runtime reality.\n\n## Prerequisites\n\n**Required:**\n- Claude Pro subscription or Claude Code CLI\n- TypeScript 5.0+ (5.5+ recommended)\n- Node.js 18+ or modern browser\n- Basic TypeScript knowledge\n\n**What Claude handles automatically:**\n- Writing Zod schemas with proper validators\n- Inferring TypeScript types from schemas\n- Adding custom validation logic with refinements\n- Generating error messages in multiple formats\n- Creating reusable schema compositions\n- Implementing async validation\n- Adding transforms for data coercion\n- Integrating with React Hook Form or tRPC\n\n## How to Use This Skill\n\n### Basic Schema Creation\n\n**Prompt:** \"Create Zod schemas for a user registration API that validates email, password (min 8 chars, requires number and special char), age (18-100), and optional phone number.\"\n\nClaude will:\n1. Write Zod schema with proper validators\n2. Add regex patterns for email and password\n3. Include range validation for age\n4. Make phone number optional\n5. Generate custom error messages\n6. Infer TypeScript type from schema\n7. Show validation usage examples\n\n### Form Validation with React Hook Form\n\n**Prompt:** \"Build a React form with Zod validation for: name, email, address (street, city, state, zip), and checkbox for terms acceptance. Integrate with React Hook Form and show field-level errors.\"\n\nClaude will:\n1. Create nested Zod schema for address\n2. Set up React Hook Form with zodResolver\n3. Add real-time validation on blur\n4. Display error messages per field\n5. Prevent submission until valid\n6. Include TypeScript types\n7. Add accessible error announcements\n\n### API Request/Response Validation\n\n**Prompt:** \"Create Zod schemas for a REST API with request validation and response parsing. Include pagination parameters, filters, and error handling.\"\n\nClaude will:\n1. Define request body schemas\n2. Create query parameter validators\n3. Add response schema with safeParse\n4. Handle validation errors gracefully\n5. Include pagination metadata\n6. Add discriminated unions for responses\n7. Generate OpenAPI types from schemas\n\n### Complex Business Logic Validation\n\n**Prompt:** \"Build a Zod schema for order validation where: if payment method is 'credit_card', require card details; if 'paypal', require email; shipping date must be after today; total must match items sum.\"\n\nClaude will:\n1. Use discriminated unions for payment methods\n2. Add conditional validation with refine()\n3. Implement cross-field validation\n4. Calculate and validate totals\n5. Add date comparison logic\n6. Provide clear error paths\n7. Include async validation for external checks\n\n## Tips for Best Results\n\n1. **Infer Types, Don't Duplicate**: Always use `z.infer<typeof schema>` instead of defining types manually. This ensures runtime validation matches compile-time types.\n\n2. **Use `.safeParse()` for Untrusted Data**: In API routes or external inputs, use `safeParse()` instead of `parse()` to avoid throwing exceptions. Handle validation errors gracefully.\n\n3. **Custom Error Messages**: Request custom error messages with `.min(8, { message: 'Password must be at least 8 characters' })` for better UX.\n\n4. **Refinements for Complex Logic**: Use `.refine()` or `.superRefine()` for validation that involves multiple fields or external calls.\n\n5. **Reusable Schemas**: Create base schemas and extend them with `.extend()` or compose with `.merge()` to avoid duplication.\n\n6. **Transforms for Coercion**: Use `.transform()` to normalize data (trim strings, parse numbers) before validation.\n\n## Common Workflows\n\n### E-Commerce Checkout Validation\n```\n\"Create complete Zod validation for checkout flow:\n1. Customer info: email, phone, billing address\n2. Shipping: address with validation (can't be PO box), preferred delivery date\n3. Payment: discriminated union for credit card, PayPal, crypto\n4. Items: array of products with quantity (min 1, max 10), size, color\n5. Promo code: optional, alphanumeric, validate against API\n6. Total must match cart calculation\n7. Accept terms and conditions (required)\"\n```\n\n### API Gateway Validation Layer\n```\n\"Build API validation middleware with Zod:\n1. Validate request headers (auth token, content-type)\n2. Parse and validate query parameters with coercion\n3. Validate request body based on endpoint\n4. Add rate limiting metadata validation\n5. Validate response format before sending to client\n6. Log validation errors with request context\n7. Return standardized error responses\"\n```\n\n### Database Input Sanitization\n```\n\"Create Zod schemas for database operations:\n1. User input sanitization before INSERT\n2. Strip dangerous characters from strings\n3. Validate foreign key relationships exist\n4. Ensure email uniqueness with async validator\n5. Transform dates to ISO format\n6. Validate JSON columns match expected structure\n7. Add database constraint validation\"\n```\n\n### File Upload Validation\n```\n\"Build file upload validator with Zod:\n1. Validate MIME types (images: PNG, JPG, WebP)\n2. Check file size (max 5MB)\n3. Validate image dimensions (min 800x600, max 4000x4000)\n4. Sanitize filename (alphanumeric, hyphens, underscores)\n5. Validate metadata (EXIF data)\n6. Check for malware signatures\n7. Transform to standard format\"\n```\n\n## Troubleshooting\n\n**Issue:** Type inference not working\n**Solution:** Ensure TypeScript version is 5.0+. Use `z.infer<typeof schema>` correctly. Check tsconfig.json has `strict: true`. Update Zod to latest version.\n\n**Issue:** Validation errors not showing custom messages\n**Solution:** Add message parameter to validators: `.min(8, { message: '...' })`. Use `error.format()` to get structured errors. Check error path matches form field names.\n\n**Issue:** Async validation not working\n**Solution:** Use `.refine()` with async function, not `.transform()`. Ensure you `await` the parse result. Consider using `.parseAsync()` or `.safeParseAsync()`.\n\n**Issue:** Performance slow with large arrays\n**Solution:** Use `.nonempty()` instead of `.min(1)` for faster validation. Implement pagination. Consider lazy validation with `.lazy()` for recursive structures.\n\n**Issue:** Optional fields not working correctly\n**Solution:** Use `.optional()` for truly optional fields, `.nullable()` for null values, `.default()` for default values. Don't mix `.optional()` with `.nullable()` unless you mean to accept both.\n\n**Issue:** Union types confusing in errors\n**Solution:** Use discriminated unions with `.discriminatedUnion()` for better error messages. Add explicit type checking before validation. Provide user-friendly labels.\n\n## Learn More\n\n- [Zod Official Documentation](https://zod.dev/)\n- [Zod GitHub Repository](https://github.com/colinhacks/zod)\n- [React Hook Form + Zod Integration](https://react-hook-form.com/get-started#SchemaValidation)\n- [tRPC + Zod Guide](https://trpc.io/docs/server/validators)\n- [Zod to JSON Schema](https://github.com/StefanTerdell/zod-to-json-schema)\n- [Zod Error Formatting](https://zod.dev/ERROR_HANDLING)\n",
      "features": [
        "TypeScript-first with automatic type inference",
        "Zero dependencies, 8kb minified",
        "Composable schemas with .extend() and .merge()",
        "Custom validation with .refine() and async support"
      ],
      "useCases": [
        "API request/response validation",
        "Form validation with error messages",
        "Database input sanitization"
      ],
      "requirements": [
        "TypeScript 5.0+",
        "zod ^3.22.0",
        "Node.js 18+ or modern browser"
      ],
      "examples": [
        {
          "title": "User Registration Schema",
          "language": "typescript",
          "code": "import { z } from 'zod';\n\nconst passwordSchema = z\n  .string()\n  .min(8, 'Password must be at least 8 characters')\n  .regex(/[0-9]/, 'Password must contain a number')\n  .regex(/[^a-zA-Z0-9]/, 'Password must contain a special character');\n\nconst userRegistrationSchema = z.object({\n  email: z.string().email('Invalid email address'),\n  password: passwordSchema,\n  confirmPassword: z.string(),\n  age: z.number().int().min(18, 'Must be 18 or older').max(100),\n  phone: z.string().regex(/^\\+?[1-9]\\d{1,14}$/).optional(),\n  acceptTerms: z.literal(true, {\n    errorMap: () => ({ message: 'You must accept the terms' }),\n  }),\n}).refine((data) => data.password === data.confirmPassword, {\n  message: 'Passwords do not match',\n  path: ['confirmPassword'],\n});\n\ntype UserRegistration = z.infer<typeof userRegistrationSchema>;\n\n// Usage\nconst result = userRegistrationSchema.safeParse({\n  email: 'user@example.com',\n  password: 'SecureP@ss1',\n  confirmPassword: 'SecureP@ss1',\n  age: 25,\n  acceptTerms: true,\n});\n\nif (!result.success) {\n  console.error(result.error.format());\n} else {\n  console.log('Valid user:', result.data);\n}"
        },
        {
          "title": "React Hook Form Integration",
          "language": "typescript",
          "code": "import { useForm } from 'react-hook-form';\nimport { zodResolver } from '@hookform/resolvers/zod';\nimport { z } from 'zod';\n\nconst formSchema = z.object({\n  name: z.string().min(2, 'Name must be at least 2 characters'),\n  email: z.string().email(),\n  address: z.object({\n    street: z.string().min(5),\n    city: z.string().min(2),\n    state: z.string().length(2, 'Use 2-letter state code'),\n    zip: z.string().regex(/^\\d{5}(-\\d{4})?$/, 'Invalid ZIP code'),\n  }),\n});\n\ntype FormData = z.infer<typeof formSchema>;\n\nexport function RegistrationForm() {\n  const {\n    register,\n    handleSubmit,\n    formState: { errors },\n  } = useForm<FormData>({\n    resolver: zodResolver(formSchema),\n  });\n\n  const onSubmit = (data: FormData) => {\n    console.log('Valid form data:', data);\n  };\n\n  return (\n    <form onSubmit={handleSubmit(onSubmit)}>\n      <input {...register('name')} />\n      {errors.name && <span>{errors.name.message}</span>}\n\n      <input {...register('email')} />\n      {errors.email && <span>{errors.email.message}</span>}\n\n      <input {...register('address.street')} placeholder=\"Street\" />\n      {errors.address?.street && <span>{errors.address.street.message}</span>}\n\n      {/* ... other fields ... */}\n\n      <button type=\"submit\">Submit</button>\n    </form>\n  );\n}"
        },
        {
          "title": "API Validation Middleware",
          "language": "typescript",
          "code": "import { z } from 'zod';\nimport { Request, Response, NextFunction } from 'express';\n\nconst createUserSchema = z.object({\n  body: z.object({\n    name: z.string().min(2),\n    email: z.string().email(),\n    role: z.enum(['user', 'admin']).default('user'),\n  }),\n  query: z.object({\n    sendWelcomeEmail: z\n      .string()\n      .transform((val) => val === 'true')\n      .default('false'),\n  }),\n});\n\ntype CreateUserRequest = z.infer<typeof createUserSchema>;\n\nexport const validateRequest =\n  (schema: z.ZodSchema) =>\n  async (req: Request, res: Response, next: NextFunction) => {\n    try {\n      const result = await schema.parseAsync({\n        body: req.body,\n        query: req.query,\n        params: req.params,\n      });\n\n      req.body = result.body;\n      req.query = result.query as any;\n      next();\n    } catch (error) {\n      if (error instanceof z.ZodError) {\n        res.status(400).json({\n          error: 'Validation failed',\n          details: error.format(),\n        });\n      } else {\n        next(error);\n      }\n    }\n  };\n\n// Usage\napp.post('/users', validateRequest(createUserSchema), async (req, res) => {\n  const { name, email, role } = req.body;\n  // Data is validated and typed\n  const user = await createUser({ name, email, role });\n  res.json(user);\n});"
        },
        {
          "title": "Discriminated Union for Payments",
          "language": "typescript",
          "code": "import { z } from 'zod';\n\nconst creditCardPayment = z.object({\n  method: z.literal('credit_card'),\n  cardNumber: z.string().regex(/^\\d{16}$/),\n  expiryMonth: z.number().min(1).max(12),\n  expiryYear: z.number().min(2025),\n  cvv: z.string().regex(/^\\d{3,4}$/),\n});\n\nconst paypalPayment = z.object({\n  method: z.literal('paypal'),\n  email: z.string().email(),\n});\n\nconst cryptoPayment = z.object({\n  method: z.literal('crypto'),\n  walletAddress: z.string().regex(/^0x[a-fA-F0-9]{40}$/),\n  cryptocurrency: z.enum(['BTC', 'ETH', 'USDC']),\n});\n\nconst paymentSchema = z.discriminatedUnion('method', [\n  creditCardPayment,\n  paypalPayment,\n  cryptoPayment,\n]);\n\ntype Payment = z.infer<typeof paymentSchema>;\n\n// TypeScript knows the shape based on method\nfunction processPayment(payment: Payment) {\n  switch (payment.method) {\n    case 'credit_card':\n      return chargeCreditCard(payment.cardNumber, payment.cvv);\n    case 'paypal':\n      return chargePayPal(payment.email);\n    case 'crypto':\n      return chargeCrypto(payment.walletAddress);\n  }\n}"
        }
      ],
      "installation": {
        "claudeDesktop": {
          "steps": [
            "Install Zod: npm install zod",
            "Ask Claude: 'Create Zod validation schemas for [your use case]'",
            "Claude generates schemas with TypeScript types",
            "Integrate with forms or API routes"
          ]
        },
        "claudeCode": {
          "steps": [
            "npm install zod",
            "npm install @hookform/resolvers (for React Hook Form)",
            "Create schemas in src/schemas/",
            "Import and use with safeParse() or parse()"
          ]
        }
      },
      "troubleshooting": [
        {
          "issue": "Type inference returns 'any'",
          "solution": "Check TypeScript version is 5.0+. Ensure you're using 'z.infer<typeof schema>' correctly. Update tsconfig.json with strict: true."
        },
        {
          "issue": "Optional fields not working",
          "solution": "Use .optional() for optional, .nullable() for null, .default() for defaults. Don't chain .optional().nullable() unless you need both undefined and null."
        },
        {
          "issue": "Async validation failing",
          "solution": "Use .refine() with async callback, call .parseAsync() or .safeParseAsync(), ensure you await the result."
        }
      ],
      "documentationUrl": "https://zod.dev/",
      "source": "community",
      "type": "skill",
      "url": "https://claudepro.directory/skills/zod-schema-validator"
    }
  ],
  "count": 21,
  "lastUpdated": "2025-10-20T19:41:24.854Z"
}