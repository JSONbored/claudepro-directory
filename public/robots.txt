# Robots.txt for Claude Pro Directory
# https://claudepro.directory/robots.txt

User-agent: *
Allow: /

# Important pages
Allow: /agents*
Allow: /mcp*
Allow: /rules*
Allow: /commands*
Allow: /hooks*
Allow: /statuslines*
Allow: /guides*

# API endpoints (allow for better indexing of JSON-LD structured data)
Allow: /api/*

# Block admin areas if they exist
Disallow: /admin*
Disallow: /.well-known*

# Sitemap location
Sitemap: https://claudepro.directory/sitemap.xml

# Crawl delay (be respectful)
Crawl-delay: 1